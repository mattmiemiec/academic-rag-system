{
  "filename": "2509.10257v1.pdf",
  "total_chunks": 8,
  "text_length": 26013,
  "chunks": [
    "Robustness and Diagnostic Performance of Super-Resolution Fetal Brain MRI Ema Masterl1,†[0009−0007−4115−4304], Tina Vesnaver Vipotnik2, and Žiga Špiclin3 1Faculty of Medicine, University of Ljubljana, Ljubljana, Slovenia 2University Medical Centre Ljubljana, Ljubljana, Slovenia 3Faculty of Electrical Engineering, University of Ljubljana, Ljubljana, Slovenia †Corresponding author:ema.masterl@mf.uni-lj.si Abstract.Fetal brain MRI relies on rapid multi-view 2D slice acqui- sitions to reduce motion artifacts caused by fetal movement. However, these stacks are typically low resolution, may suffer from motion cor- ruption, and do not adequately capture 3D anatomy. Super-resolution reconstruction (SRR) methods aim to address these limitations by com- bining slice-to-volume registration and super-resolution techniques to generate high-resolution (HR) 3D volumes. While several SRR meth- ods have been proposed, their comparative performance—particularly in pathological cases—and their influence on downstream volumetric analysis and diagnostic tasks remain underexplored. In this study, we applied three state-of-the-art SRR methods—NiftyMIC, SVRTK, and NeSVoR—to 140 fetal brain MRI scans, including both healthy controls (HC) and pathological cases (PC) with ventriculomegaly (VM). Each HR reconstruction was segmented using the BoUNTi algorithm to ex- tract volumes of nine principal brain structures. We evaluated visual quality, SRR success rates, volumetric measurement agreement, and di- agnostic classification performance. NeSVoR demonstrated the highest and most consistent reconstruction success rate (>90%) across both HC and PC groups. Although significant differences in volumetric estimates were observed between SRR methods, classification performance for VM was not affected by the choice of SRR method. These findings highlight NeSVoR’srobustnessandtheresilienceofdiagnosticperformancedespite SRR-induced volumetric variability. Keywords:Fetal brain MRI·Super-Resolution Reconstruction·Image Quality Assessment·Brain Volumetry·Ventriculomegaly Diagnosis. 1 Introduction Fetal MRI acquisitions employ rapid multi-view 2D slice stacks to mitigate the effects of continuous fetal movement. While the acquisitions provide high tissue contrast ideal for studying brain development and anomaly detection, the multi- view slice stacks are low resolution, may contain motion-corrupted slices and generally do not visualize the 3D anatomy. To address these challenges, a rangearXiv:2509.10257v1 [cs.CV] 12 Sep 2025 2 E. Masterl et al. of super-resolution reconstruction (SRR) methods has been introduced [2,5,12, 13,8] that combine iterative slice-to-volume registration with super-resolution to generate a single 3D high-resolution (HR) image. In context of fetal brain imaging, the SRR methods also involve a spatial co-registration of the 3D HR image to gestational age (GA) matched brain atlas image. However, the perfor- mance and impact of particular SRR method on the performance of obtained 3D HR image in downstream tasks, like brain structure segmentation, biometry and diagnostics, especially in pathological cases, requires further study. Most previous studies comparatively assessed in context of fetal brain imag- ing two or more of the four widely used SRR methods: NiftyMIC [2], SVRTK [5, 10,12],NeSVoR[13]andMIALSRTK[8].Forinstance,Sanchezetal.[6]assessed the first three on 84 fetuses ranging from 20-36 weeks of GA and established that NeSVoR demonstrated the most consistent performance, with minimal bias field and overall image reliability. When assessing volumetric measurement biases be- tween these methods, these were found small and systematic at 2.8% [7]. While evaluating the three aforementioned SRR pipelines – NiftyMIC, SVRTK and MIALSRTK – on 17 healthy fetuses with GA of 20–21 weeks, Ciceri et al. [1] reported a rather low success rate of SVRTK of",
    "measurement biases be- tween these methods, these were found small and systematic at 2.8% [7]. While evaluating the three aforementioned SRR pipelines – NiftyMIC, SVRTK and MIALSRTK – on 17 healthy fetuses with GA of 20–21 weeks, Ciceri et al. [1] reported a rather low success rate of SVRTK of 44%. Xu et al. [14], while com- paringNeSVoRwithSVRTKreconstructionsbasedonautomatedqualityassess- ment metrics and signal-to-noise ratio across 20 fetuses in the 21–32 week GA range, the NeSVoR achieved superior image quality. In qualitative comparative assessment of NiftyMIC, SVRTK and MIALSRTK, Uus et al. [9] concluded that image quality was comparable. However, studies included rather small sample sizes, rendering estimates of success rate unreliable and did not include patho- logical cases that could have adverse impact. The impact on volumetry and its diagnostic performance also remains unclear. In this study, we applied NiftyMIC [2], SVRTK [5,10,12] and NeSVoR [13] to 140 fetal brain MRI acquisitions, comprising both healthy and pathological cases (HCandPCs,resp.)withventriculomegaly(VM).Followingreconstruction,each 3D HR image was segmented using the BoUNTi method [11] to extract 9 brain structures and corresponding volumes. Besides visual quality and SRR success rate assessment, we evaluated the agreement between volumetric measurements with respect to SRR method and their diagnostic performance for HC versus PC classification, using rigorous statistical analyses. Study design is visualised in Figure 1. 2 Materials and Methods 2.1 Dataset A total of 140 fetal MRI acquisitions with GA from 21 to 37 weeks were ret- rospectively collected for this study. Inclusion criteria were: (1) only singletone pregnancies, (2) absence of excess fetal motion or artifacts, and (3) image stacks captured whole fetal brain. The cohort comprised fetuses with normally devel- oping brain and those diagnosed with VM. Diagnosis of VM was re-confirmed by a neuroradiologist (>15 years of experience in reading fetal MRI) based Robustness and Diagnostic Performance of SRR Methods 3 Fig. 1.EvaluationpipelinecomparingtheSRRmethods,encompassingreconstruction- quality assessment, volumetric analysis and diagnostic-performance testing. on measuring the diameter, using linear measurement tool in OsiriX 12.0, the lateral ventricles in axial transventricular plane, and following the recommenda- tions of the Society for Maternal-Fetal Medicine[4], using a cut-off threshold of≥ 10 mm for VM diagnosis. Stratification into mild/moderate/severe VM showed high imbalance towards mild cases, hence it was not used for the purposes of this study. All imaging was performed at the University Medical Center Ljubljana on a 1.5 T clinical MRI scanner (Siemens Aera, Siemens Healthineers, Erlangen, Germany) using a T2-weighted Half-Fourier Acquisition Single-shot Turbo spin- Echo (HASTE) sequence. Each case included at least three orthogonal image stacks encompassing the entire fetal brain. In cases where either maternal or fetal motion was observed on a given stack, the acquisition of that stack was repeated to ensure adequate image quality. Acquisition parameters were set to achieve high in-plane resolution (0.625×0.625 mm) with a slice thickness of 3 mm, resulting in image matrices of 512×320 pixels and with 31–35 slices per stack. All data were anonymized prior to analysis. The study protocol received approval from the Institutional Review Board (IRB; approval no.: 0120-56/2022/3). The IRB waived collection of informed consents for this retrospective, secondary data",
    "thickness of 3 mm, resulting in image matrices of 512×320 pixels and with 31–35 slices per stack. All data were anonymized prior to analysis. The study protocol received approval from the Institutional Review Board (IRB; approval no.: 0120-56/2022/3). The IRB waived collection of informed consents for this retrospective, secondary data analysis study. 2.2 Super-Resolution Reconstruction Super-resolution reconstruction was carried out using three established meth- ods: NiftyMIC [2], SVRTK [5,10,12] and NeSVoR [13]. Each SRR image was reconstructed at 0.5 mm isotropic resolution. For the NiftyMIC pipeline, each 4 E. Masterl et al. input stack was first skull-stripped to generate a brain mask; any masks deemed suboptimal were manually refined prior to reconstruction. During NiftyMIC processing, we also modified the default outlier slice re- jection thresholds (threshold=0.1;threshold_first=0.5). The SVRTK and NeSVoR methods were executed using default parameter settings. All SRR images underwent visual quality control (VQC) in 3D Slicer4by a rater with over two years of fetal MRI reading experience. A successful VQC required complete whole-brain coverage and absence of intraparenchymal signal dropouts(gaps)orothermajorartifactswithinthebrainparenchyma(blurry/distorted anatomy). Cases for which all three SRR methods resulted in a successful VQC were retained for subsequent analyses. Success rates were recorded. Statisticalanalysis.WithinthegroupofHCandPCcases,weusedFisher’s exact test to evaluate whether the proportion of correctly classified cases differed significantly between SRR methods. The Benjamini–Hochberg procedure was applied to control the false discovery rate. 2.3 Brain Segmentation and Volumetry Volumetric segmentation of the principal brain structures was carried out using the pre-trained BoUNTi algorithm [11]. Nine volumetric measurements were ex- tracted for each case and each of three SRR images, corresponding to the major anatomical regions of interest: (1) extra-cerebral spinal fluid (ECSF), (2) grey matter/cerebral cortex (GM), (3) white cerebral matter (WM), (4) lateral ven- tricles (LV), (5) right LV (R_LV), (6) left LV (L_LV), (7) deep grey matter (DGM), (8) cerebellum (CRB), and (9) brainstem (BS). Volumetric measure- ments were recorded in cubic millimeters (mm3). Statistical analysis.To assess the agreement of volumetric measurements of principal brain structures across the three SRR methods, a non-parametric statisticalanalysiswasconductedduetothenon-normaldistributionofthedata. The Friedman test was employed for univariate repeated measures analysis to detect overall differences in volumetric estimates among the SRR methods for each brain structure. Analyses were performed separately for HCs and PCs to account for potential group-specific variability. Holm’s method was applied to adjust p-values for multiple comparisons, ensuring control of the family-wise error rate across the set of statistical tests. In instances where the Friedman test indicated statistically significant dif- ferences (p < 0.05), post-hoc pairwise comparisons between SRR methods were performed using the Wilcoxon signed-rank test, with Holm correction for multi- ple comparisons. 2.4 Diagnosis Classification To evaluate the diagnostic performance of SRR fetal brain images, we performed a classification of HCs versus PCs using the volumetric measurements. For each 43D Slicer: https://www.slicer.org/ Robustness and Diagnostic Performance of SRR Methods 5 SRR method (NiftyMIC, SVRTK, NeSVoR), a separate classification model was trained and evaluated using a 50:50% case-wise stratified train:test split. The classification models were developed using theauto-sklearn[3] automated ma- chine learning toolbox, which selected and optimized the best-performing model based on the training",
    "and Diagnostic Performance of SRR Methods 5 SRR method (NiftyMIC, SVRTK, NeSVoR), a separate classification model was trained and evaluated using a 50:50% case-wise stratified train:test split. The classification models were developed using theauto-sklearn[3] automated ma- chine learning toolbox, which selected and optimized the best-performing model based on the training set volumetry corresponding to each SRR method. The following key parameters were configured:time_left_for_this_task was set to 3600 seconds (1 hour), whileper_run_time_limitwas set to 300 seconds to restrict the time allocated to individual model evaluations. The ensemble_sizeandensemble_nbestparameters were at default values of 50, enablingauto-sklearnto construct an ensemble from the top 50 models based on validation performance. Theresampling_strategywas set toholdoutto match the fixed 50:50 traintest split used in our study design. All other param- eters were kept at their default settings. When best overall classification model was identified, it was fixed and the training repeated. This setup ensured automated model training and unbiased results across experiments runs. Statistical analysis.The trained models were evaluated on all test sets (across volumetry obtained with different SRR methods), and performance was assessed using area under the receiver operating characteristic curve (AUC), sensitivity, and specificity metrics. The optimal operating point on each ROC curve was identified using Youden’s index (maximizing sum of sensitivity and specificity minus one). To compare diagnostic performance across SRR methods, we conducted pair- wise statistical testing: the DeLong test was applied to compare AUCs, while McNemar’s test was used to assess differences in sensitivity and specificity. This framework enabled a systematic evaluation of the impact of SRR method choice on classification performance in distinguishing HC from PC based on quantita- tive brain volumetry. 3 Experiments and Results 3.1 SRR Success Rates ExamplesofreconstructionsnotpassingandpassingVQCareshowninFigure2. Table 1 shows the amount of successful reconstructions per each method. At the end, 95 of 140 cases were used for analysis, i.e. 44/50 HC (88.00%) and 51/90 PC (56.67%). The NeSVoR method had highest overall success rate, while in general the performance of all methods was lower for PC, with the most noticable drop when using the SVRTK method. Fisher’s exact tests revealed no significant differences in sucess rate between methods for HCs (p = 0.345). In contrast, the differences were statistically sig- nificant for the PCs (p = 0.00028). Post-hoc comparisons showed significant dif- ferences between SVRTK and NeSVoR (p = 0.00069) as well as between SVRTK and NiftyMIC (p = 0.013), while no significant difference was observed between NiftyMIC and NeSVoR (p = 0.372). 6 E. Masterl et al. Fig. 2.Discarded (top) and successful (bottom) cases incolumnswith corresponding reconstructions for NiftyMIC, SVRTK, NeSVoR (1st, 2nd, 3rdrow, resp.). Some cases on topwith NeSVoR method were successful, those withred outlineare failed ones. Table 1.Success rates of SRR methods, overall and stratified by HCs and PCs. Group NiftyMIC SVRTK NeSVoR HC46 (92.0%) 45 (90.0%) 49 (98.0%) PC76 (84.4%) 60 (66.7%) 81 (90.0%) Overall122 (87.1%) 105 (75.0%) 130 (92.8%) 3.2 Consistency of Volumetric Measurements Volumetric measurements were analysed for 44 HCs and 51 PCs, in which all SRRmethodsweresuccessfulaccordingtotheVQC.Figure3showsthedistribu- tion of volumetric measurements for all SRR methods. The differences between HC and PC groups are",
    "(90.0%) 49 (98.0%) PC76 (84.4%) 60 (66.7%) 81 (90.0%) Overall122 (87.1%) 105 (75.0%) 130 (92.8%) 3.2 Consistency of Volumetric Measurements Volumetric measurements were analysed for 44 HCs and 51 PCs, in which all SRRmethodsweresuccessfulaccordingtotheVQC.Figure3showsthedistribu- tion of volumetric measurements for all SRR methods. The differences between HC and PC groups are most evident in LV, R_LV and L_LV volumes. Sta- tistically significant differences were observed for each volumetric measurement when comparing the three SRR methods. The weakest significance was found in WM, where differences were the least pronounced. Lower p-values were generally observed in the HC group, with the strongest significance in DGM, ECSF, and CRB. In the PC group, the most prominent differences were found in ECSF, DGM, and LV. Post hoc analysis revealed that volume differences were statistically signifi- cantforagreaternumberofstructuresintheHCgroup,withsixvolumes(ECSF, LV, R_LV, L_LV, CRB, and BS) showing significant differences across all three pairwise comparisons. In PC only the LV, R_LV, and L_LV showed consistent differences across all SRR methods, while the remaining structures exhibited Robustness and Diagnostic Performance of SRR Methods 7 differences in only a subset of pairwise comparisons. Notably, for ventricular volumes, NeSVoR consistently yielded most significant differences. Fig. 3.Box-whisker plots of 9 volumetric measurements for HC (left) and PC (right) groups. The p-valueson top of each plotare for Friedman test, while for post-hoc pairwise test they are indicated withbarsas *p<0.05, **p<0.01 and ***p<0.001. 3.3 Ventriculomegaly Classification Linear discriminant analysis was identified as the optimal classifier based on auto-sklearn. The 3D HR images as obtained by the three SRR methods, and upon based brain volumetry, deliver virtually identical diagnostic performance as shown in Table 2; namely, the AUC values clustered tightly in range 0.94– 0.95 across every model×test-set pairing; sensitivity was constant at 0.96 on NiftyMIC- and SVRTK-derived test sets and only marginally lower on NeSVoR 8 E. Masterl et al. data (0.88 for NiftyMIC/SVRTK models, 0.92 for the NeSVoR model); speci- ficity was lowest for the in-domain NiftyMIC and SVRTK evaluations (0.86) but rised to range 0.90–0.95 in cross-domain settings, keeping overall discrim- ination unchanged. DeLong’s and McNemar’s tests both yielded p > 0.5, con- firming that none of the reconstruction-specific models was statistically superior for HC-versus-VM classification. Table 2.Classification performance between HC and PC cases usingauto-sklearn. SRR model / Test data NiftyMIC SVRTK NeSVoR AUCSens Spec AUCSens Spec AUCSens Spec NiftyMIC 0.940.96 0.86 0.950.96 0.90 0.950.88 0.95 SVRTK 0.940.96 0.86 0.950.96 0.90 0.950.88 0.95 NeSVoR 0.940.96 0.86 0.950.96 0.90 0.940.92 0.90 Sens–Sensitivity; Spec–Specificity 4 Discussion This study evaluated the influence of three SRR methods — NiftyMIC, SVRTK and NeSVoR — on reconstruction quality, volumetric quantification of nine fetal brain volumes, and downstream classification of VM. All three SRR pipelines demonstrated high reconstruction success rates in HC. Fisher’s exact test confirmed that the success rates did not differ signifi- cantly. Reconstruction quality, however, declined for the PC. The lower success rate observed for SVRTK is consistent with Ciceri et al. [1], who reported unsuc- cessful reconstructions in 44 % of the cases when using the SVRTK method. The highest success rate for both HC and PC was achieved",
    "signifi- cantly. Reconstruction quality, however, declined for the PC. The lower success rate observed for SVRTK is consistent with Ciceri et al. [1], who reported unsuc- cessful reconstructions in 44 % of the cases when using the SVRTK method. The highest success rate for both HC and PC was achieved by the NeSVoR method. Thenon-parametricFriedmantestdemonstratedstatisticallysignificantinter- method differences in the volumetric estimates of all nine brain structures for both HCs and PCs. Post-hoc tests showed broader inter-method divergence in HC — significant for six structures—whereas in PC consistent differences were limited to ventricular volumes. This underscores the need to evaluate classifica- tion performance for additional fetal brain anomalies beyond ventriculomegaly. Comparative evaluation of volumetric measurements across SRR methods, in the absence of a reliable ground truth, may be insufficient to assess their diagnosticperformance.Whilesystematicdifferencesinvolumetricestimatescan be quantified, their practical relevance remains unclear without linking them to downstream tasks. For example, Sanchez et al. [7] reported small but consistent volumetric biases ( 2.8%) among the NiftyMIC, SVRTK and NeSVoR methods, as also evident from our analysis. However, such evaluations, based solely on inter-methoddiscrepancies,donotnecessarilyinformthediagnosticperformance of the measurements. Robustness and Diagnostic Performance of SRR Methods 9 In our study, despite observing statistically significant and systematic volu- metric differences across SRR methods, the HC/VM classification performance remained unaffected. This finding underscores the need for evaluation protocols that extend beyond volumetric agreement and incorporate task-specific per- formance metrics. Statistical comparison of the classifiers trained on volumes reconstructed with NiftyMIC, SVRTK and NeSVoR methods revealed no sig- nificant differences in performance. Accordingly, for the binary task of distin- guishing HCs from VM cases, all three SRR methods provided equivalent di- agnostic performance. Whether this concordance persists when VM is stratified by severity (mild, moderate, severe) or when a different intracranial pathology is analysed remains undetermined. Ultimately, thoroughly assessing diagnostic performance requires validating whether method-dependent variability impacts decision-makingoutcomes,ratherthanfocusingexclusivelyonmeasurementcon- sistency. An important consideration for strengthening the evaluation lies in the in- clusion of additional quality control (QC) metrics, particularly segmentation accuracy. While intuitively appealing, evaluating segmentation accuracy is non- trivial in this context. Establishing a reference segmentation requires manual an- notations, which are inherently subjective and labor-intensive, especially in fetal MRI where anatomical boundaries can be ambiguous. More critically, manual segmentations are typically performed on reconstructed images, making them inherently biased toward the SRR method used to generate the images and upon based reference segmentations. Any comparison of segmentation accuracy across SRR methods would thus conflate true segmentation performance with differences in image quality and reconstruction artifacts, undermining the valid- ity of such evaluation. Moreover, reconstruction errors—such as misalignment or motion artifacts—can propagate into the segmentations, further distorting the assessment. Given these challenges, while segmentation accuracy remains a desirable QC metric, its implementation in this setting would require careful protocol design to minimize method-specific biases, and may ultimately offer limited additional insight compared to task-based evaluations such as diagnostic classification. The default parameter settings in NiftyMIC method generally results in a high rejection rate of input slices, which substantially increases the number of unsuccessful reconstructions. Similar observations were reported by Sanchez et al.",
    "method-specific biases, and may ultimately offer limited additional insight compared to task-based evaluations such as diagnostic classification. The default parameter settings in NiftyMIC method generally results in a high rejection rate of input slices, which substantially increases the number of unsuccessful reconstructions. Similar observations were reported by Sanchez et al. [6]. To address this issue, parameter adjustment was performed in order to re- duce the number of rejected slices and improve the overall reconstruction success rate.Conversely,theautomatedSVRTKmethoddoesnotpermitmanualadjust- ment of key reconstruction parameters, which prevents empirical tuning based on systematic evaluation. Consequently, it is not possible to identify and apply a globally optimal parameter configuration that could improve reconstruction suc- cess rates across the dataset. This introduces a potential bias in the comparison between methods. In conclusion, although the SRR methods yield virtually identical diagnostic performance for VM classification, NeSVoR attains the highest reconstruction 10 E. Masterl et al. successrate,comparedtotheNiftyMICandSVRTK.Inroutineclinicalexamina- tions – where fetal motion often compromises acquisition quality – this superior robustness maximizes the likelihood of generating usable high-resolution volume reconstructions without compromising diagnostic performance. 5 Acknowledgements This study was supported by the Slovenian Research Agency (Core Research Grant No. P2-0232 and Research Grants No. and J2-3059). References 1. Ciceri, T., Squarcina, L., Pigoni, A., Ferro, A., Montano, F., Bertoldo, A., Per- sico, N., Boito, S., Triulzi, F.M., Conte, G., et al.: Geometric reliability of super- resolution reconstructed images from clinical fetal mri in the second trimester. Neuroinformatics21(3), 549–563 (2023) 2. Ebner, M., Wang, G., Li, W., Aertsen, M., Patel, P.A., Aughwane, R., Melbourne, A., Doel, T., Dymarkowski, S., De Coppi, P., et al.: An automated framework for localization, segmentation and super-resolution reconstruction of fetal brain mri. NeuroImage206, 116324 (2020) 3. Feurer, M., Klein, A., Eggensperger, K., Springenberg, J., Blum, M., Hutter, F.: Efficient and robust automated machine learning. In: Advances in Neural Informa- tion Processing Systems 28 (2015). pp. 2962–2970 (2015) 4. Fox, N.S., Monteagudo, A., Kuller, J.A., Craigo, S., Norton, M.E.: Mild fetal ventriculomegaly: diagnosis, evaluation, and management. Ameri- can Journal of Obstetrics and Gynecology219(1), B2–B9 (Jul 2018). https://doi.org/10.1016/j.ajog.2018.04.039 5. Kuklisova-Murgasova, M., Quaghebeur, G., Rutherford, M.A., Hajnal, J.V., Schn- abel, J.A.: Reconstruction of fetal brain mri with intensity matching and complete outlier removal. Medical image analysis16(8), 1550–1564 (2012) 6. Sanchez, T., Mihailov, A., Gomez, Y., Juan, G.M., Eixarch, E., Jakab, A., Dunet, V., Koob, M., Auzias, G., Cuadra, M.B.: Assessing data quality on fetal brain mri reconstruction: a multi-site and multi-rater study. In: International Workshop on Preterm, Perinatal and Paediatric Image Analysis. pp. 46–56. Springer (2024) 7. Sanchez, T., Mihailov, A., Koob, M., Girard, N., Manchon, A., Valenzuela, I., Gómez-Chiari, M., Martí Juan, G., Pron, A., Eixarch, E., et al.: Biometry and volumetry in multi-centric fetal brain mri: assessing the bias of super-resolution reconstruction. medRxiv pp. 2024–09 (2024) 8. Tourbier, S., Velasco-Annis, C., Taimouri, V., Hagmann, P., Meuli, R., Warfield, S.K., Bach Cuadra, M., Gholipour, A.: Automated template-based brain localiza- tion and extraction for fetal brain MRI reconstruction. NeuroImage155, 460–472 (2017). https://doi.org/10.1016/j.neuroimage.2017.04.004 9. Uus, A.U., Egloff Collado, A., Roberts, T.A., Hajnal, J.V., Rutherford, M.A., De- prez, M.: Retrospective motion correction in",
    "Velasco-Annis, C., Taimouri, V., Hagmann, P., Meuli, R., Warfield, S.K., Bach Cuadra, M., Gholipour, A.: Automated template-based brain localiza- tion and extraction for fetal brain MRI reconstruction. NeuroImage155, 460–472 (2017). https://doi.org/10.1016/j.neuroimage.2017.04.004 9. Uus, A.U., Egloff Collado, A., Roberts, T.A., Hajnal, J.V., Rutherford, M.A., De- prez, M.: Retrospective motion correction in foetal mri for clinical applications: existing methods, applications and integration into clinical practice. The British journal of radiology96(1147), 20220071 (2023) Robustness and Diagnostic Performance of SRR Methods 11 10. Uus, A.U., Hall, M., Payette, K., Hajnal, J.V., Deprez, M., Rutherford, M.A., Hutter, J., Story, L.: Combined quantitative t2* map and structural t2-weighted tissue-specific analysis for fetal brain mri: pilot automated pipeline. In: Interna- tional Workshop on Preterm, Perinatal and Paediatric Image Analysis. pp. 28–38. Springer (2023) 11. Uus, A.U., Kyriakopoulou, V., Makropoulos, A., Fukami-Gartner, A., Cromb, D., Davidson,A.,Cordero-Grande,L.,Price,A.N.,Grigorescu,I.,Williams,L.Z.,etal.: Bounti: Brain volumetry and automated parcellation for 3d fetal mri. bioRxiv (2023) 12. Uus, A.U., Neves Silva, S., Aviles Verdera, J., Payette, K., Hall, M., Colford, K., Luis, A., Sousa, H.S., Ning, Z., Roberts, T., et al.: Scanner-based real-time 3d brain+ body slice-to-volume reconstruction for t2-weighted 0.55 t low field fetal mri. medRxiv pp. 2024–04 (2024) 13. Xu, J., Moyer, D., Gagoski, B., Iglesias, J.E., Ellen Grant, P., Golland, P., Adalsteinsson, E.: Nesvor: Implicit neural representation for slice-to-volume re- construction in mri. IEEE Transactions on Medical Imaging pp. 1–1 (2023). https://doi.org/10.1109/TMI.2023.3236216 14. Xu, J., Moyer, D., Gagoski, B., Iglesias, J.E., Grant, P.E., Golland, P., Adalsteins- son, E.: Nesvor: implicit neural representation for slice-to-volume reconstruction in mri. IEEE transactions on medical imaging42(6), 1707–1719 (2023)"
  ]
}