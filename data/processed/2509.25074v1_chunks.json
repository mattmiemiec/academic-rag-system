{
  "filename": "2509.25074v1.pdf",
  "total_chunks": 121,
  "text_length": 346930,
  "chunks": [
    "Unsourced Random Access Kirill Andreevk.andreev@skoltech.ru Pavel Rybin, p.rybin@skoltech.ru Alexey Frolov, al.frolov@skoltech.ru Skolkovo Institute of Science and TechnologyarXiv:2509.25074v1 [cs.IT] 29 Sep 2025 2 Contents 1 Massive machine-type communications 17 1.1 Internet of Things standardization . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18 1.1.1 Short-range IoT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19 1.1.2 Wide-area IoT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19 1.1.3 Cellular IoT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21 1.2 Challenges for the next-generation cellular systems . . . . . . . . . . . . . . . . . . . 25 1.3 Monograph organization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25 2 Classical multiple-access problem statements 27 2.1 Zero-error decoding . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28 2.2 MAC with all-active users . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28 2.2.1 Capacity region . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29 2.2.2 Finite blocklength . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29 2.2.3 Practical schemes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31 2.3 MAC with partial user activity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36 2.3.1 Slotted ALOHA model assumptions . . . . . . . . . . . . . . . . . . . . . . . 37 2.3.2",
    ". . . . . . . . . . . . . . . . . . . 36 2.3.1 Slotted ALOHA model assumptions . . . . . . . . . . . . . . . . . . . . . . . 37 2.3.2 Throughput and stability of slotted ALOHA . . . . . . . . . . . . . . . . . . 38 2.3.3 Lower and upper bounds on throughput in slotted ALOHA . . . . . . . . . . 39 2.3.4 Coded slotted ALOHA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40 2.3.5 Carrier sensing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41 3 2.4 Many-access channels . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41 2.4.1 Noiseless and noisy many-access binary adder channel (BAC) . . . . . . . . . 42 2.4.2 Many-access Gaussian MAC (GMAC) . . . . . . . . . . . . . . . . . . . . . . 43 2.4.3 Finite energy and joint probability of error . . . . . . . . . . . . . . . . . . . 45 2.5 Outcomes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47 3 URA problem statement and compressed sensing interpretation 49 3.1 System model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49 3.2 URA as an approximate support recovery problem . . . . . . . . . . . . . . . . . . . 51 3.3 Converse bounds . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53 3.4 Parameters of interest . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55 4 URA over Gaussian MAC: achievability bounds 57 4.1 Maximum likelihood decoding rule . . . . .",
    ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55 4 URA over Gaussian MAC: achievability bounds 57 4.1 Maximum likelihood decoding rule . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58 4.1.1 Probabilistic method,t-error events andP eestimate . . . . . . . . . . . . . . 58 4.2 Useful tricks to tighten the union bound . . . . . . . . . . . . . . . . . . . . . . . . . 60 4.2.1 Gallager’s trick . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60 4.2.2 Fano’s trick . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60 4.3 Achievability bounds . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61 4.3.1 The bound based on Gallager’sρ-trick . . . . . . . . . . . . . . . . . . . . . . 61 4.3.2 The bound based on Fano’s trick . . . . . . . . . . . . . . . . . . . . . . . . . 64 4.3.3 Combination of the tricks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67 4.4 The case of binary codebooks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 70 4.5 Further comments and discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72 4.5.1 Random number of active users . . . . . . . . . . . . . . . . . . . . . . . . . . 72 4.5.2 Gordon’s lemma and achievability improvements . . . . . . . . . . . . . . . . 73 4.6 Numerical evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .",
    ". . . . . . . . . . . . 73 4.6 Numerical evaluation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76 4 5 URA over Gaussian MAC: low-complexity schemes 79 5.1T-fold coded slotted ALOHA . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 80 5.1.1 BasicT-fold irregular repetition slotted ALOHA (IRSA) scheme . . . . . . . 81 5.1.2 Achievability bound forT-fold IRSA scheme . . . . . . . . . . . . . . . . . . 85 5.1.3T-fold IRSA modifications for the G-URA . . . . . . . . . . . . . . . . . . . . 90 5.1.4 Collision resolution methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . 93 5.2 Sparse interleave division multiple-access . . . . . . . . . . . . . . . . . . . . . . . . . 103 5.3 Coded compressed sensing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 105 5.3.1 Channel for the outer code . . . . . . . . . . . . . . . . . . . . . . . . . . . . 107 5.3.2 Random coding bound . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 108 5.3.3t-tree code-based practical scheme . . . . . . . . . . . . . . . . . . . . . . . . 109 5.3.4 Reed-Solomon code-based practical scheme . . . . . . . . . . . . . . . . . . . 111 5.3.5 Further modifications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114 5.4 Random spreading . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114 5.4.1 Encoder . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 115 5.4.2",
    ". . . . . . 114 5.4.1 Encoder . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 115 5.4.2 Decoder . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 117 5.4.3 Discussion and further improvements . . . . . . . . . . . . . . . . . . . . . . . 119 5.5 Comments on same linear codes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 120 5.6 Numerical comparisons . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 125 5.6.1T-fold irregular repetition slotted ALOHA-based schemes . . . . . . . . . . . 125 5.6.2 Sparse interleave division multiple-access-based schemes . . . . . . . . . . . . 128 5.6.3 Coded compressed sensing-based schemes . . . . . . . . . . . . . . . . . . . . 129 5.6.4 Random spreading-based solutions . . . . . . . . . . . . . . . . . . . . . . . . 130 6 Fading channels 133 6.1 Channel model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 134 6.1.1 Rayleigh fading model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 134 5 6.1.2 Decoding rules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 135 6.2 Single-antenna quasi-static Rayleigh fading MAC . . . . . . . . . . . . . . . . . . . . 136 6.2.1 Capacity region, all-active users . . . . . . . . . . . . . . . . . . . . . . . . . . 136 6.2.2 Shamai-Bettesh capacity bound . . . . . . . . . . . . . . . . . . . . . . . . . . 137 6.2.3 FBL regime, partial activity . . . . . .",
    ". . . . . . . 136 6.2.2 Shamai-Bettesh capacity bound . . . . . . . . . . . . . . . . . . . . . . . . . . 137 6.2.3 FBL regime, partial activity . . . . . . . . . . . . . . . . . . . . . . . . . . . . 137 6.3 Multi-antenna quasi-static Rayleigh fading MAC . . . . . . . . . . . . . . . . . . . . 140 6.3.1 Scaling laws . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141 6.3.2 Achievability bounds for multiple input, multiple output (MIMO) receiver . . 141 6.3.3 Converse bound for MIMO receiver . . . . . . . . . . . . . . . . . . . . . . . . 144 6.3.4 Numerical comparison of the proposed bounds . . . . . . . . . . . . . . . . . 144 6.4 Low-complexity receiver architectures . . . . . . . . . . . . . . . . . . . . . . . . . . 146 6.4.1 Single-antenna case . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 146 6.4.2 Multiple-antenna case . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 150 7 Open problems 155 A Minimum mean squared error estimation 157 B Standard CS codebooks and decoders 159 B.1 Decoding algorithms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 160 B.1.1 Non-negative least squares . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 160 B.1.2 LASSO: Sparse linear regression . . . . . . . . . . . . . . . . . . . . . . . . . 160 B.1.3 Approximate message passing . . . . . . . . . . . . . . . . . . . . . . . . . . . 160 B.1.4 Orthogonal matching pursuit . . . . . . . . . . . . . . . . . . . . . . . . . . . 161 B.2 Codebook design . . . . . . . . .",
    ". . . . . 160 B.1.4 Orthogonal matching pursuit . . . . . . . . . . . . . . . . . . . . . . . . . . . 161 B.2 Codebook design . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 162 B.2.1 Gaussian codebook . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 162 B.2.2 Spherical codebook . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 163 B.2.3 BCH subcodes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 163 6 B.2.4 Codebook from the parity-check matrix of at-error-correcting code . . . . . . 164 B.2.5 Binary chirps . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 164 C CS sensing matrices 167 D IRSA: replica count distribution 171 E Coded CS: further results 175 E.1 Capacity of the channel for the outer code . . . . . . . . . . . . . . . . . . . . . . . . 175 E.2t-tree code: the average number of paths . . . . . . . . . . . . . . . . . . . . . . . . . 177 F Asymptotics 181 F.1 Converse bound . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 181 F.2 Achievability bounds . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 182 F.3 Numerical results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 184 G Some useful lemmas 187 Bibliography 188 7 Acronyms 3GPPThird-Generation Partnership Project 5G NRFifth-generation New Radio ACKacknowledgment AMPapproximate message passing AoAangle-of-arrival ARQAutomatic Repeat reQuest ASRapproximate support recovery BACbinary adder channel BCHBose-Chaudhuri-Hocquenghem BPbelief propagation BPSKbinary phase-shift keying BSbase station CCScoded compressed sensing CDMAcode division multiple-access CNOPcheck-node operation CRCcyclic redundancy check CRDSAcontention",
    "G Some useful lemmas 187 Bibliography 188 7 Acronyms 3GPPThird-Generation Partnership Project 5G NRFifth-generation New Radio ACKacknowledgment AMPapproximate message passing AoAangle-of-arrival ARQAutomatic Repeat reQuest ASRapproximate support recovery BACbinary adder channel BCHBose-Chaudhuri-Hocquenghem BPbelief propagation BPSKbinary phase-shift keying BSbase station CCScoded compressed sensing CDMAcode division multiple-access CNOPcheck-node operation CRCcyclic redundancy check CRDSAcontention resolution diversity slotted ALOHA CScompressed sensing CSIchannel state information CSMAcarrier-sense multiple-access CSMA/CAcarrier-sense multiple-access with collision avoidance CSSchirp spread spectrum DBPSKdifferential binary phase-shift keying DEdensity evolution DFTdiscrete Fourier transform DSSSdirect-sequence spread spectrum FARfalse alarm rate 8 FBLfinite blocklength FCFSfirst-come, first-serve FDMAfrequency division multiple-access FFTfast Fourier transform FTFourier transform GMACGaussian MAC G-URAURA over Gaussian MAC IDMAinterleave division multiple-access IoTInternet of Things IRSAirregular repetition slotted ALOHA IRSA-Bbasic IRSA protocol IRSA-FIRSA with per-frame preambles IRSA-SIRSA with per-slot preambles JSCjoint successive cancellation LDPClow-density parity check LDSlow-density signature LLRlog-likelihood ratio LMMSElinear MMSE LPWANlow-power wide area network MACmultiple-access channel MFmatched filter MIMOmultiple input, multiple output MLmaximum likelihood MMSEminimum mean squared error MMVmultiple measurement vector MPAmessage passing algorithm MSEmean squared error MTCmachine-type communications 9 MUDmulti-user detector NNLSnon-negative least squares ODMAon-off division multiple access OFDMorthogonal frequency-division multiplexing OMPorthogonal matching pursuit PANpersonal-area network PEXITprotograph extrinsic information transfer POphysical uplink shared channel occasion PUPEper-user probability of error PUSCHphysical uplink shared channel QoSquality of service QPSKquadrature phase-shift keying RArandom access RACHrandom access channel RCBrandom coding bound RFIDradio-frequency identification RIPrestricted isometry property RMReed-Muller RSReed-Solomon RSMArate-splitting multiple-access SAslotted ALOHA SCsuccessive cancellation SCLsuccessive cancellation list SCMAsparse-coded multiple-access SFspreading factor SICsuccessive interference cancellation SINRsignal-to-interference-plus-noise ratio SoICsoft SIC 10 SPARCssparse regression codes SPCsingle-parity-check TDMAtime-division multiple-access TINtreat interference as noise TIN-SICTIN followed by SIC UEuser equipment URAunsourced random access VNOPvariable-node operation 11 12 Abstract Current wireless networks are designed to optimize spectral efficiency for human users, who typically require sustained connections for high-data-rate applications like file transfers and video streaming. However, these networks are increasingly inadequate for the emerging era of MTC. With a vast number of devices exhibiting sporadic traffic patterns consisting of short packets, the grant-based multiple access procedures utilized by existing networks lead to significant delays and inefficiencies. To address this issue the URA paradigm has been proposed. This paradigm assumes the devices to share a common encoder thus simplifying the reception process by eliminating the identification procedure. The URA paradigm not only addresses the computational challenges but it also con- siders the random access (RA) as a coding problem, i.e., takes into account both medium access protocols and physical layer effects. In this monograph we provide a comprehensive overview of the URA problem in noisy channels, with the main task being to explain the major ideas rather than to list all existing solutions. 13 14 Notation Throughout the monograph we use the following notations and abbreviations: x,Xdeterministic scalar value xdeterministic column-vector Xdeterministic matrix In n×nidentity matrix diag diagonal matrix ∥x∥2 Euclidean norm of vectorx supp (x) support of vectorx wt (x) the number of nonzero components in vectorx Nset of natural numbers Cset of complex numbers Fq finite field withqelements Xset Xsequence of setsFdisjoint union [n] [n] ={1, . . . , n}, wheren∈N aI aI= (a i1, . . . , a is), wherea= (a",
    "support of vectorx wt (x) the number of nonzero components in vectorx Nset of natural numbers Cset of complex numbers Fq finite field withqelements Xset Xsequence of setsFdisjoint union [n] [n] ={1, . . . , n}, wheren∈N aI aI= (a i1, . . . , a is), wherea= (a 1, . . . , a n) andI={i 1, . . . , i s} ⊆[n] with i1< . . . < i s AI AI= (a i1, . . . ,a is), whereA= (a 1, . . . ,a n) andI={i 1, . . . , i s} ⊆[n] withi 1< . . . < i s CN(0,I n) circularly symmetric complex standard normal distribution Bern(p) Bernoulli distribution with parameterp Unif([Q]) uniform distribution on [Q] x,Xrandom scalar value xrandom column-vector Xrandom matrix Eevent Eccomplementary event toE 1E indicator of the eventE Pr [E] probability of the eventE Eexpectation operator H(x) entropy of discrete random variablex I(x,y) mutual information of random variablesxandy 15 h(p)h(p) =−plog2(p)−(1−p) log2(1−p), 0≤p≤1, whereh(1) =h(0) = 0 τ(x) binary phase-shift keying (BPSK) modulationτ(x) = (1−2x)√ P w.l.o.g. “without loss of generality” r.v. “random variable” i.i.d. “independent identically distributed” p.m.f. “probability mass function” 16 Chapter 1 Massive machine-type communications Machine-type communications (MTC) dramatically change traffic patterns. Instead of focusing on peak data rates and low latencies, massive connectivity becomes a key requirement. The MTC concept involves a massive number of autonomous devices and sensors being connected to a gateway: a node (or a set of nodes) responsible for data collection. MTC is a crucial component of the IoT paradigm, which defines the infrastructure and scenarios for interconnecting devices rather than humans. IoT encompasses various tasks, including monitoring, remote and automated control, data collection, and data-related services. MTC is a communication technology specifically designed to support this paradigm, enabling connectivity for a vast number of devices. In this monograph, we focus on the communication aspects and use the terms IoT and MTC interchangeably. IoT applications encompass a wide range of use cases, including: •Environmental and health monitoring. •Smart homes, cities, and industries. •Road traffic monitoring and tracking to improve efficiency and safety. Typical MTC transmissions involve short measurement reports generated either regularly or spo- radically, resulting in additional requirements. 1. Improvedbattery lifeis essential. Wiring a large number of devices to the electricity grid would require expensive cabling, making it preferable for these devices to be autonomous. Moreover, monitoring the battery status of thousands (or even millions) of devices may also be prohibitively costly. Therefore, the battery lifetime must match the device lifetime (approx- imately 10 years). As a result, energy-efficient solutions must utilize simple radio-frequency devices with low-complexity signal processing algorithms. 17 2017 2018 2019 2020 2021 2022 2023 2024 2025 2026 2027 2028 202901234567Broadband IoT and Critical IoT (4G/5G) Massive IoT (NB-IoT/Cat-M) Legacy (2G/3G)Figure 1.1: Predicted number of worldwide IoT cellular subscriptions (billions) in accordance with Ericsson mobility report [1] (Nov. 2023). 2. There is a need forimproved coverage. Many sensors may be located in so-called deep in- door environments (e.g., building basements), leading to significant signal loss between",
    "Massive IoT (NB-IoT/Cat-M) Legacy (2G/3G)Figure 1.1: Predicted number of worldwide IoT cellular subscriptions (billions) in accordance with Ericsson mobility report [1] (Nov. 2023). 2. There is a need forimproved coverage. Many sensors may be located in so-called deep in- door environments (e.g., building basements), leading to significant signal loss between the transmitter and receiver. 3.Low costis a critical factor. The challenge of low cost is twofold: •since IoT devices generate only small amounts of data, subscription fees should be much lower compared to those for ordinary smartphones, minimizing operational expenses; •the massive deployment of IoT devices necessitates a low cost per device, reducing capital expenses. According to Ericsson’s forecast [1], the number of cellular IoT devices (see Fig. 1.1) is expected to reach 6.1 billion by 2029, while the total number of connected devices across all IoT technologies is projected to reach approximately 39 billion. Currently, the IoT industry exhibits a compound annual growth rate of approximately 16%. Given this rapid growth, standardization plays a crucial role in ensuring sustainable IoT development. 1.1 Internet of Things standardization There are various standards for IoT, each fulfilling different requirements specified above. We distinguish three main branches of IoT technologies: short-range, wide-area, and cellular. Short-range IoT encompasses a variety of technologies, including radio-frequency identification (RFID) and personal-area networks (PANs) such as Bluetooth and Zigbee. These technologies typically operate in unlicensed spectrum and within a very short range. Massive connectivity in this case is limited by the small coverage area (on the order of several meters) of the corresponding radio devices [2]. In contrast, wide-area technologies have the potential to connect millions of autonomous devices to a single base station (BS). In this short overview, we focus on Sigfox and LoRa technologies, which 18 are described in Section 1.1.2. 1.1.1 Short-range IoT Short-range, or PAN, provides a communication environment for various IoT applications, such as communication between wearable devices, short-range location tags, home controllers, and more. A typical network consists of at most a few dozen devices, making communication between them relatively simple in terms of channel access. The low communication range is beneficial for energy efficiency and security. An extreme example of energy efficiency (particularly regarding remote device battery life) is RFID technology, where the energy required to transmit data is induced by an interrogation pulse from a nearby reader device. The short communication range also prevents signals from being detected over large distances between the transmitter and receiver, which significantly simplifies security protocols. Due to the absence of massive connectivity issues and the wide variety of PAN technologies, we will not consider them in the remainder of this monograph. 1.1.2 Wide-area IoT To fulfill the requirements described above, several solutions are commonly employed in wide-area IoT systems – low-power wide area networks (LPWANs). To improve system range, narrowband signals are typically utilized. Since thermal noise power is proportional to the processed bandwidth, narrowband signals can tolerate a greater link loss for the same transmitter power and hence enable coverage of a wider area. Additionally, due to the extended communication distances, narrowband signals benefit from",
    "improve system range, narrowband signals are typically utilized. Since thermal noise power is proportional to the processed bandwidth, narrowband signals can tolerate a greater link loss for the same transmitter power and hence enable coverage of a wider area. Additionally, due to the extended communication distances, narrowband signals benefit from the reduced frequency selectivity of the wireless channel. Consequently, there is no need for complex multi-carrier modulations or high-complexity signal processing algorithms at the transmitter. To simplify remote devices, wide-area IoT communication systems often have limited or even com- pletely absent downlink functionality. This limitation reduces the ability to coordinate transmitting devices and typically eliminates the possibility of employing Automatic Repeat reQuest (ARQ) mechanisms. Additionally, the use of ARQ in scenarios involving sporadic data transmission by a massive number of devices can overwhelm the control channel. To address this issue, transmissions can be repeated multiple times, potentially at different fre- quencies, to exploit both frequency and time diversity, assuming the retransmission delay exceeds the channel coherence time. Further transmitter simplifications often include the use of constant- envelope modulation formats, which do not require expensive or power-inefficient signal amplifiers. At the receiver, additional solutions are applied to enhance performance. The simplest way to increase diversity is throughmultiple receptions. When multiple nodes collect the transmitted data, many can detect, demodulate, and decode the message, thereby enhancingspatial diversity. 19 These typical solutions are implemented in Sigfox and LoRa, the most popular wide-area IoT technologies, which are described below. Both approaches rely on distributed resource coordi- nation mechanisms1based on ALOHA and carrier-sense multiple-access with collision avoidance (CSMA/CA), rather than the centralized coordination employed in cellular systems. Sigfox – an ultra-narrowband IoT technology The main feature of Sigfox is its extremely narrow transmission bandwidth of just 100 Hz. This narrow bandwidth significantly reduces in-band thermal noise to very low levels (approximately −154 dBm), which is a key enabler of its long-range communication. Downlink functionality is extremely limited, with a complete absence of synchronization, coordination, and ARQ mechanisms. To send a packet, a device selects a transmission frequency within a 192 kHz band and transmits the packet, followed by two replicas at different randomly selected frequencies to enhance diversity. Multiple reception is achieved by deploying multiple BSs, which continuously scan the entire 192 kHz bandwidth to detect uplink messages. The transmitted packets are exceptionally short. Each packet consists of: •a 4-byte preamble, •a 2-byte frame-synchronization sequence, •a 4-byte device identifier, •a payload of up to 12 bytes, •a variable-length hash code for packet authentication within the Sigfox network, and •a 2-byte cyclic redundancy check (CRC). Uplink packets are typically modulated using differential binary phase-shift keying (DBPSK). Dif- ferential modulation is chosen to allow for non-coherent detection. The combination of simple modulation and coding, along with a very low sampling rate, results in a highly cost-effective so- lution. Additionally, the high link budget enables a reduction in transmit power, thereby fulfilling battery efficiency requirements with ease. Downlink messages (if configured) are triggered by a transmitting device in the form of a callback. The BS’s response has a fixed delay",
    "sampling rate, results in a highly cost-effective so- lution. Additionally, the high link budget enables a reduction in transmit power, thereby fulfilling battery efficiency requirements with ease. Downlink messages (if configured) are triggered by a transmitting device in the form of a callback. The BS’s response has a fixed delay and is transmitted at the reception frequency of the request plus a predefined frequency shift. The payload size for a downlink message is fixed at 8 bytes. 1These mechanisms are often referred to as medium access control (MAC). In this monograph, however, we interpret the abbreviation MAC as multiple-access channel. 20 LoRa The LoRa (Long Range) protocol is another IoT alternative. Similar to the previously described ultra-narrowband solutions, this communication standard assumes a BS and end devices connected to it, managed by a simple medium access protocol. LoRa supports wider communication band- widths (125 or 500 kHz) based on the chirp spread spectrum (CSS) technique, which utilizes linear frequency modulation. LetBdenote the total transmission bandwidth at a carrier frequencyf c, and letTrepresent the symbol duration. The instantaneous frequencyf(t), t∈[0, T], of the CSS signal changes linearly with a rate of B/T, wrapping around when it reaches the edges of the transmitted bandwidth: f(t) =f c−B 2+\u001aB Tt+B Mi\u001b modB, wherei∈[M] is the transmitted message index, and the transmission rate is log2Mbits per symbol. Different values ofMcorrespond to different spreading factor (SF) values [3]. Different SFs are supported by LoRa, and signals corresponding to different SFs are almost or- thogonal [3]. This property reduces interference between transmissions with different SFs, thereby improving the communication range. The medium access mechanism also allows for downlink transmissions. The LoRa standard supports three different classes of devices. Devices of the first class (A) behave similarly to Sigfox: they send data as it becomes available, and downlink messages can be sent duringreceive windows, whose timings are configurable. After an uplink transmission, the device waits for the start of a downlink message within two receive windows. If no downlink message is detected, the device enters sleep mode. For this type of device, the sender spends most of its time in sleep mode, enabling long battery life. Class-A functionality is basic and must be supported by all devices. Devices of the second class (B) extend the downlink functionality by opening periodic receive windows (or ping slots). To manage this functionality, periodic beacons are sent by the network to maintain synchronization. Finally, devices of the third class (C) enhance the capabilities of Class-A devices by keeping the receive windows open unless transmitting an uplink message. As a result, Class-C devices can receive downlink messages almost any time, offering very low latency for downlink transmissions. Typical use cases for Class-A devices include sensors that periodically report measurements or send data triggered by an alarm event. Class-B devices are useful for applications requiring measurements on request, while Class-C devices are ideal for remote control mechanisms powered by a continuous power source. 1.1.3 Cellular IoT Cellular systems are highly attractive for massive deployments due to their wide coverage, straight- forward subscription procedures, operation over",
    "an alarm event. Class-B devices are useful for applications requiring measurements on request, while Class-C devices are ideal for remote control mechanisms powered by a continuous power source. 1.1.3 Cellular IoT Cellular systems are highly attractive for massive deployments due to their wide coverage, straight- forward subscription procedures, operation over licensed spectrum with effective interference man- 21 agement, and robust security protocols. However, cellular systems employ centralized coordination algorithms (as opposed to distributed CSMA/CA), which are better suited for high data rates among a fixed and relatively small number of active users within the coverage area of a single BS. Cellular networks did not support machine-type devices prior to Third-Generation Partnership Project (3GPP) Release 12. Earlier releases assumed that any device connecting to the BS would support the full bandwidth of 20 MHz. This large bandwidth requirement was not suitable for achieving the long battery life needed by IoT devices. Different device types The 3GPP standards define various categories of devices based on their capabilities. These cate- gories are represented by numbers, where higher numbers indicate devices that support higher peak uplink and downlink rates, a greater number of supported antennas, and so on. However, these categories primarily pertain to devices operated by humans, while the requirements for IoT devices can differ significantly. 3GPP Release 13 introduced the Cat-M category (with “M” denoting MTC). This user equipment category was the first narrowband device type, supporting a bandwidth of 6 resource blocks (1.08 MHz). This new device type required novel approach to control channel design. Further optimization for MTC devices was achieved in Release 13 with the introduction of the NB (narrowband) device category. Devices in this category reduced the total supported bandwidth to 200 kHz. Additionally, optimizations enabled narrowband transmissions with bandwidths reduced to a single subcarrier, referred to as single-tone transmission. The subcarrier bandwidth for these transmissions is either 15 kHz or 3.75 kHz. The Fifth-generation New Radio (5G NR) standard introduced broadband IoT, allowing sensing devices to transmit larger amounts of data. In Release 17, the RedCap (Reduced Capabilities) network type was introduced. The RedCap standard aims to support all industrial applications by enabling broadband communication services for machine-type devices. This standard assumes the utilization of up to 20 MHz bandwidth in the frequency range below 6 GHz. Random access procedures in cellular systems To initiate a connection with a cellular network, each device must proceed with random access (RA) procedure. The introduction of IoT devices and their massive deployments could overload the control channel. To address this issue, a new RA procedure should be developed, aiming to reduce the overall communication overhead. As specified in 3GPP TS 138.321, the original RA procedure follows a four-way handshake, as illustrated in Fig. 1.2. This handshake consists of the following phases: 22 UEtimeBS UEtimeBS Preamble Resource allocation Data ACKPreamble + Data ACKFigure 1.2: Four-step RA (left) and two-step RA procedures specified in 3GPP TS 138.321. A time diagram corresponds to message exchange between user equipment (UE) and base station (BS). Table 1.1: Simulation parameters for numerical comparison presented in Fig. 1.4 Parameter",
    "UEtimeBS UEtimeBS Preamble Resource allocation Data ACKPreamble + Data ACKFigure 1.2: Four-step RA (left) and two-step RA procedures specified in 3GPP TS 138.321. A time diagram corresponds to message exchange between user equipment (UE) and base station (BS). Table 1.1: Simulation parameters for numerical comparison presented in Fig. 1.4 Parameter Value Preamble length 2×139 (A1 configuration) Error-correcting code (500,100) LDPC (5G NR base graph 2) Modulation Quadrature phase-shift keying (QPSK) Decoding algorithm TIN / TIN-SIC Pilot configuration Pilot-free Number of POs 64 Overall frame length 16278 channel uses 1. RA through preamble transmission to identify users. 2. Resource allocation provided by the BS. 3. Data transmission using orthogonal resources assigned to the identified users. 4. Final acknowledgment (ACK). The described above procedure separates the RA phase from data transmission. Starting with 3GPP Release 16, this procedure was simplified, requiring only a two-way handshake. In this updated procedure, the preamble transmission also announces the resources to be used for data transmission, which follows immediately. Users select preambles from a predefined orthogonal set. Data is then transmitted during specified positions of the physical uplink shared channel occasion (PO)s. If the BS successfully receives the data, it sends an acknowledgment. Otherwise, the traditional four-way handshake is performed. This transmission scheme is depicted in Fig. 1.3 (see the detailed description in [4]). 23 preamble data user 1 user 2 user 3 user 4··· ··· ··· ··· ··· PO 1 PO 2 PO 3 PO 4 PO 5 PON↓ ↓ ↓ ↓ ↓ ↓ ↓ RACH slot NPUSCH occasions (POs)Figure 1.3: Two-step RA procedure with data transmission. −1 0 1 2 3 4 5 6 7 8 9 10020406080100120140 Achievability 5G NR 2-step RA (msg. A)TIN-SIC TIN Energy per bit (dB)Number of active users in the frame Figure 1.4: Energy efficiency of the proposed 2-step RA procedure in 5G NR versus achievability bound on energy efficiency [5]. AWGN channel model, reference signals are not considered [4]. 24 1.2 Challenges for the next-generation cellular systems The key challenge for the next generation of radio-access networks is managing the massive number of infrequently communicating sensors. Current solutions are inadequate due to their reliance on centralized resource allocation, which orthogonalizes access for different users. For MTC, this approach is unacceptable as it results in significant control-layer overhead and latency. Therefore, a new communication solution is required. As evidence, we will first demonstrate the performance of the two-step RA procedure presented above. Following the exposition in [4], we reproduce several numerical results from the referenced manuscript. The objective of the numerical setup is to highlight the significant gap between the energy efficiency of the two-step RA procedure and the achievable energy efficiency in a massive RA scenario (see Theorem 4.1). Energy efficiency is defined as the minimum energy required to transmit a single information bit (or energy per bit) under certain quality of service (QoS) constraints. The exact definition of energy efficiency will be provided in Chapter 3. The technical details of this numerical experiment are as follows. The preamble dictionary consists of 64 Zadoff-Chu sequences with varying lengths. For short",
    "a single information bit (or energy per bit) under certain quality of service (QoS) constraints. The exact definition of energy efficiency will be provided in Chapter 3. The technical details of this numerical experiment are as follows. The preamble dictionary consists of 64 Zadoff-Chu sequences with varying lengths. For short preambles, the length is 139, while for long preambles, it is 839. Each preamble corresponds to a PO. Within a PO, data is transmitted using low-density parity check (LDPC) codes as specified in 5G NR standards. The additive white Gaussian noise (AWGN) channel model is considered, and reference signals are not required in this setup. The system parameters outlined in Table 1.1, and the energy efficiency as a function of the number of simultaneously active users is presented in Fig. 1.4. Current schemes that are part of existing standards exhibit significantly lower energy efficiency compared to theoretical bounds. Moreover, the two-step RA procedure proposed by 3GPP remains optional. The lack of energy-efficient schemes has motivated many researchers to extensively study this new massive MTC scenario. In this monograph, we outline the core ideas behind these theoretical bounds and provide a brief overview of the challenges in designing low-complexity schemes. We demonstrate that some of these schemes closely approach the achievability bounds. In our introductory example in Fig. 1.4, we considered the simple case of a Gaussian channel. However, real wireless channels are affected by multipath propagation, which introduces additional random effects during signal transmission. In the subsequent chapters, we address various challenges posed by real propagation environments. 1.3 Monograph organization The monograph is organized as follows: •Chapter 2 explores MAC problems and their formulations, emphasizing the differences be- tween classical MAC scenarios and the unsourced random access (URA) setup. 25 •Chapter 3 defines the URA problem and introduces per-user probability of error (PUPE), the primary measure of the system’s operational quality. It also revisits the definition of energy efficiency (see (3.3)) previously discussed in Fig. 1.4. Additionally, this chapter establishes a connection between the URA problem and the well-known CS problem. •Chapter 4 investigates the fundamental limits of energy efficiency under PUPE constraints in the Gaussian channel. •Chapter 5 focuses on low-complexity schemes for the Gaussian channel. •Chapter 6 examines more realistic channels with fading effects, specifically the quasi-static Rayleigh fading channel. It covers scenarios where the BS is equipped with either a single antenna or multiple antennas. •Chapter 7 concludes the monograph by highlighting the remaining challenges and open prob- lems. 26 Chapter 2 Classical multiple-access problem statements The study of MACs originated in Shannon’s paper [6]. Today, various variants of the MAC problem exist. These variants differ in terms of noise models (noiseless, noisy, or worst-case/adversarial), probability of error (zero-error, vanishing, per-user, or joint) the presence of feedback, user activity, and other factors. Following [7, 5], in this chapter, we classify MAC problems based on user activity. We focus on the vanishing probability of error case and briefly describe the zero-error results in Section 2.1. We consider two main setups from the literature: all-active users (information-theoretic approach) and partial user",
    "and other factors. Following [7, 5], in this chapter, we classify MAC problems based on user activity. We focus on the vanishing probability of error case and briefly describe the zero-error results in Section 2.1. We consider two main setups from the literature: all-active users (information-theoretic approach) and partial user activity. It is important to distinguish between cases where users utilize different encoders or codebooks (e.g.,[8, 9, 10]) and cases where users share the same encoder. The scenario with all-active users utilizing different encoders is typical forcoordinated multiple access, i.e., a form of transmission where channel access is managed by a centralized scheduler that assigns resources to the users. The scenario of partial user activity and same encoders is typical for uncoordinated multiple accessorrandom access[11, 12, 13, 14, 15, 16]. In the latter case, the total number of users is irrelevant, and it is common to assume it to be infinite, which aligns well with the massive access scenario. Note that for the case of partial user activity, we distinguish between the total number of users and the number of active users. The classification and, consequently, the organization of this chapter is depicted in Fig. 2.1. We start with zero-error decoding, as presented in Section 2.1. Then, we consider two different cases depending on the user activity. We present the case of all-active users in Section 2.2. Another important branch is partial user activity, as described in Section 2.3. Next, we consider the so-called many-access channel, as presented in Section 2.4. This is an extreme asymptotic case, where the number of active users grows simultaneously with the block length. This setup is the closest to the URA model. Finally, we discuss the main differences and justify the need for a new information- theoretic framework. 27 MAC Zero-error decoding 2.1 Vanishing-error decoding All-active users 2.2 Partially active 2.3 Capacity region 2.2.1 Finite blocklength 2.2.2 Practical schemes 2.2.3ALOHA 2.3.1 Carrier sensing 2.3.5 Coded ALOHA 2.3.4Many-access channel 2.4Figure 2.1: Classification of MAC problems based on user activity. References to corresponding section of this chapter are added. 2.1 Zero-error decoding A significant amount of effort has been devoted to evaluating the zero-error capacity for various natural and relatively simple MAC models. One of the most popular models is the noiseless adder MAC, where users send 0 and 1, and the channel output equals their ordinary sum. This problem was first studied in the context of group testing [17, 18, 19], and was rediscovered nearly twenty years later within MAC theory [20]. Notably, one of the most intriguing topics in MAC theory is determining the zero-error capacity for the simplest case of the two-user BAC, with the current best upper bound being 0.5753, as reported in [21]. The majority of zero-error coding schemes focus on the case of partially active users (T-of-Nschemes for activity detection). These solutions can be viewed as Sidon sets [22], specifically for scenarios where the input alphabet consists of binary orq-ary vectors ({0,1}nor{0,1, . . . , q−1}n). Relevant work includesB 2-sequences [23, 24] and subsequent studies [25, 26, 27, 28]. The construction",
    "of partially active users (T-of-Nschemes for activity detection). These solutions can be viewed as Sidon sets [22], specifically for scenarios where the input alphabet consists of binary orq-ary vectors ({0,1}nor{0,1, . . . , q−1}n). Relevant work includesB 2-sequences [23, 24] and subsequent studies [25, 26, 27, 28]. The construction proposed in [25] has been utilized as a component of several low-complexity URA schemes (see Chapter 5). For an overview of the latest results, we refer the reader to [29]. 2.2 MAC with all-active users Classical information theory provides an exact solution for the case of a constant number of users, an infinite blocklengthn→ ∞, and a vanishing probability of error, as described in [9, 8]. Consider a fixed number of transmitters,K, sending their messages over a shared channel. The receiver observes a noisy linear combination of the transmitted signals. Assuming a discrete-time 28 memoryless channel: y=KX k=1xk+z,z∼ N(0,I n),∥x k∥2≤nP k (2.1) whereP kis the transmit power of thek-th user, and the termsx kandz1represent the transmitted signal of thek-th user and the noise, respectively. This setup is known as the GMAC. 2.2.1 Capacity region The most straightforward way to manageKsimultaneously active users in a shared channel is to allocate them orthogonal resources. Orthogonality can be achieved in the time, frequency, code, or spatial domains. The corresponding strategies are known as time-division multiple-access (TDMA), frequency division multiple-access (FDMA), code division multiple-access (CDMA), and spatial multiplexing, respectively. As we see in Section 2.2.3, some of these strategies may, in certain cases, achieve optimal perfor- mance. Nevertheless, in many scenarios, an orthogonalization strategy is suboptimal. In 1973, Ahlswede [8] and Liao [9] derived a coding theorem for the MAC. These theorems state that given aK-user MAC channel with transmit powersP 1, . . . , P K, any tuple of ratesR 1, . . . , R K is achievable if X k∈KRk≤C X k∈KPk! ∀K ⊆[K],(2.2) whereC(P) is Shannon’s capacity, given by C(P) =1 2log2(1 +P).(2.3) An illustration for the caseK= 2 is provided in Fig. 2.2. It is worth noting that user 1 can increase their data rate by increasingP 1without affecting user 2’s data rate until point B is reached. The line A–B of the resulting capacity region corresponds to the condition R1+R 2=C(P 1+P2),(2.4) which represents a point-to-point communication channel with a total transmit power ofP 1+P2 and is referred to as thedominant facet. 2.2.2 Finite blocklength In this section, we examine a normal approximation introduced in [30, 31] and applied to the capacity region of theK-user MAC, as given in (2.2). The core concept of the normal approximation ischannel dispersion. For an AWGN channel with transmit powerP, the dispersion is given by [30, Theorem 54]: 1For simplicity, we consider real degrees of freedom. 29 R1R2 1/2log2/parenleftig 1 +P1 P2+1/parenrightigB 1/2log2/parenleftig 1 +P2 P1+1/parenrightig A1/2log2(1 +P 2) 1/2log2(1 +P 1)TINFDMA TDMA1/2log2(1 +P 1+P 2)Figure 2.2: A 2-user MAC for an AWGN channel with real degrees of freedom. The information- theoretic capacity region is represented by a black polygon passing through points A and B. The capacity region of the TDMA",
    "1/2log2/parenleftig 1 +P2 P1+1/parenrightig A1/2log2(1 +P 2) 1/2log2(1 +P 1)TINFDMA TDMA1/2log2(1 +P 1+P 2)Figure 2.2: A 2-user MAC for an AWGN channel with real degrees of freedom. The information- theoretic capacity region is represented by a black polygon passing through points A and B. The capacity region of the TDMA scheme without power control is shown by an orange line, while the FDMA capacity region is depicted by a green line. The capacity region of TIN is a single point, denoted by a blue dot. V(P) =log2e 2·P(P+ 2) (1 +P)2.(2.5) The following theorem [32, Theorem 3] considers the joint probability of errorεfor aK-user MAC in the finite blocklength (FBL) regime. The authors consider the codebook generated from the uniform distribution on then-dimensional sphere, which is typically referred to as apower shell (see Appendix B.2.2). Theorem 2.1.A second-order achievable rate region with power shell inputs for theK-user GMAC with a power constraintP ufor each useru∈[K]is the set of all rate tuples(R 1, . . . , R K)satisfying RK< C(P K)−r V(PK) +V c(PK) nQ−1(λKε) +O\u00121 n\u0013 ,(2.6) for all subsetsK ⊆[K]and any choice of non-negative coefficientsλ Kthat sum to one: X K⊆[K]λK= 1. Here,P Kis the total transmit power of users in subsetK: PK=X u∈KPu, V(·)is the channel dispersion defined in(2.5), andV c(·)is the channel cross-dispersion given by: Vc(PK) =log2e 2·(PK)2−P u∈KP2 u (1 +P K)2. 30 To gain some intuition about this theorem, let us consider the sum-rate case, which corresponds to the dominant facet,K= [K], with equal power allocationP u=Pfor allu. In this case, the sum-rate is given by: R⋆=C(KP)−r V(KP) +V c(K, P) nQ−1(ε) +O\u00121 n\u0013 , where Vc(K, P) =log2e 2·K(K−1)P2 (1 +KP)2. One can observe an increased dispersion value over the dominant facet. 2.2.3 Practical schemes In this section, we consider practical coding schemes that achieve points on (or the entirety of) the dominant facet of the capacity region and may be implemented with low computational complexity through appropriate single-user code selection. Orthogonal schemes Let us begin with orthogonal schemes by considering TDMA, FDMA, and the orthogonal case of CDMA. To proceed with our discussion, recall the capacity region presented in Fig. 2.2. TDMA.GivenP ias the transmission power of thei-th user (i= 1,2), the corresponding capaci- ties of the point-to-point channels areC(P 1) andC(P 2). In TDMA, orthogonalization is performed in the time domain. Letαbe the fraction of resources allocated to user 1, meaning that 1−αis the fraction allocated to user 2. For a MAC with TDMA, the set of achievable sum rates is given by: αC(P 1) + (1−α)C(P 2),(2.7) whereαC(P 1) and (1−α)C(P 2) form a pair of achievable individual transmission rates. Equa- tion (2.7) represents a straight line, as illustrated in Fig. 2.2. In terms of the capacity region, this scheme is strictly suboptimal for allα∈(0,1). Suboptimality means that the achievable rate pairs lie strictly inside the capacity region. FDMA.In the TDMA strategy, each transmission occupies the entire bandwidth allocated for the shared channel. In contrast, FDMA allows for better utilization of transmit power spectral density by occupying only a fraction of the",
    "suboptimal for allα∈(0,1). Suboptimality means that the achievable rate pairs lie strictly inside the capacity region. FDMA.In the TDMA strategy, each transmission occupies the entire bandwidth allocated for the shared channel. In contrast, FDMA allows for better utilization of transmit power spectral density by occupying only a fraction of the allocated bandwidth. Given a bandwidth fractionα, the channel capacity for a fractionαof the total frequency resources is: Cf(P, α) =α 2log2\u0012 1 +P α\u0013 . 31 For the previously discussed two-user MAC with the FDMA strategy, the achievable individual transmission rate pairs are: R1=C f(P1, α), R 2=C f(P2,1−α), which corresponds to the green curve shown in Fig. 2.2. This transmission scheme becomes optimal (touching the dominant facet of the capacity region) when: α⋆=P1 P1+P2,(2.8) due to the increased transmit power spectral density, compared to TDMA without power control as considered previously. Remark 2.1(TDMA with power control).In the previous discussion, we considered TDMA with- out power control. According to(2.1), the energy transmitted by the first user is limited toαnP 1, and by the second user to(1−α)nP 2. Hence, to fulfill the energy constraint from(2.1), and given a fraction of allocated resources equal toα, the first user can transmit with an instantaneous power ofP1/α, and the second user with P2/1−α. As a result, the TDMA scheme with power control (the term described in [33]) has the same capacity region as FDMA. CDMA.To achieve orthogonality in thecodedomain, the transmitted signal can bespreadusing a spreading sequencea(i). We refer the reader to (5.23) and Section 5.4.1 for details. To detect a user’s signal from the received sequence, the receiver employs a matched filter (MF) matched to the spreading sequencea(i)assigned to thei-th user. Given orthogonal spreading sequences, i.e.,\u0000 a(i)\u0001T·a(j)= 0, applying a MF converts the two-user MAC channel into a TDMA channel, as described above, withα= 1/22. Thus, the capacity region of CDMA with orthogonal spreading sequences reduces to a single point on the TDMA capacity region. In the case ofP 1=P 2, and following (2.8), this point lies on the dominant facet of the capacity region. Note that the maximum number of orthogonal sequences is limited by their length, meaning that the maximum number of users that can be orthogonalized equals the length of the spreading sequence. Additionally, the spreading technique also helps to perform time-domain channel equalization in the presence of multipath propagation with delay spread, using a RAKE receiver [34]. Treat interference as noise To recover allKtransmitted codewords from the received signal (2.1) in a non-orthogonal regime, a joint decoder is required. However, the complexity of joint decoding can be prohibitively high for practical applications. In practice, particularly in a non-symmetrical MAC – where the received powersP iare unequal – the user with the strongest received power is more likely to be successfully 2This can be easily verified by expressing the spread signal in the form (5.25) and (5.24), keeping in mind that theKspreading sequences form aK×Korthogonal matrix. Then, a simple basis change transforms (5.25) into a TDMA channel (identity spreading matrix) without altering the noise properties. 32 decoded by asingle-userdecoder, even when treating",
    "can be easily verified by expressing the spread signal in the form (5.25) and (5.24), keeping in mind that theKspreading sequences form aK×Korthogonal matrix. Then, a simple basis change transforms (5.25) into a TDMA channel (identity spreading matrix) without altering the noise properties. 32 decoded by asingle-userdecoder, even when treating other users’ signals as noise. This approach is known as treat interference as noise (TIN). Applying an information-theoretic analysis to TIN in the two-user MAC, the noise and interference3 power experienced by the first user’s TIN decoder is 1 +P 2, resulting in a maximum achievable communication rate ofR 1: R1=1 2log2\u0012 1 +P1 1 +P 2\u0013 , R 2=1 2log2\u0012 1 +P2 1 +P 1\u0013 , whereR 2is obtained similarly. Note that in this case, the relative received power of each user does not affect the result. This rate pair is represented by the blue dot in Fig. 2.2. This scenario was previously discussed in the context of CDMA with pseudo-orthogonal spreading sequences. Notably, depending on the values ofP 1andP 2, the TIN point can lie either inside or outside the capacity region of the TDMA scheme. The reference case in Fig. 2.2 corresponds to equal power allocation. Now, let us analyze aK-user symmetric MAC and consider the achievable sum rate asK→ ∞in the case where a TIN strategy is applied to the codewords of each user: lim K→∞K 2log2\u0012 1 +P (K−1)P+ 1\u0013 ≈log2e 2. This sum rate is limited and falls far below the dominant facet of the capacity region, where the maximum sum rate is equal toC(KP), which is unbounded. Successive interference cancellation Can the previously discussed TIN strategy be improved without significantly increasing computa- tional complexity? After performing the TIN step and applying capacity-achieving codes, the receiver successfully decodes a codeword. This codeword can then be subtracted from the received sequence. For instance, if user 1 is decoded using the TIN approach, the residual signal – after subtracting the first user’s codeword – will consist only of user 2’s signal and noise. This effectively reduces the problem to a single-user decoding scenario in the AWGN channel, where user 2 can achieve the rateC(P 2). The corresponding rate pair is given by: R1=1 2log2\u0012 1 +P1 1 +P 2\u0013 , R 2=C(P 2). This rate pair corresponds to pointBin the capacity region shown in Fig. 2.2. Similarly, pointA can be achieved by reversing the order in which the TIN step and subtraction are applied. 3Under the assumption of random coding with i.i.d. Gaussian codebooks, the sum of noise and interference will also follow a Gaussian distribution. 33 For theK-user MAC, the TIN step followed by subtraction can be repeated multiple times. This method is known as successive interference cancellation (SIC). After each SIC step, the dimension- ality of the problem is reduced. In the two-user MAC example, applying SIC allows us to achieve pointsAandBon the dominant facet of the capacity region. To reach any point along the line segment A–B, a TDMA strategy can be employed, alternating between different decoding orders of the TIN step followed by SIC.",
    "the problem is reduced. In the two-user MAC example, applying SIC allows us to achieve pointsAandBon the dominant facet of the capacity region. To reach any point along the line segment A–B, a TDMA strategy can be employed, alternating between different decoding orders of the TIN step followed by SIC. As a result, we obtain a low-complexity scheme capable of achieving any point on the dominant facet of the capacity region. Non-orthogonal CDMA Orthogonal sequences allow us to use a single-user decoder to solve a multiple-access problem. However, the spreading sequences may not always be orthogonal. In this case, the system load may be higher compared to orthogonal spreading, at the cost of additional interference. In the presence of interference, a multi-user detector (MUD) may outperform a single-user one. The problem of MUD in CDMA has been studied in [35, 36]. In [37], the idea of blind detection was proposed – a scenario in which the receiver knows the target spreading sequence but does not know the interfering spreading sequences. Regarding the relationship between CDMA and the capacity region, the authors of [38] proposed the design of spreading sequences for synchronous overloaded CDMA (where the number of active users exceeds the length of the spreading sequence) in an equal-power setting and estimated the achievable sum rate. The unequal-power case was considered in [39]. Finally, MUD combined with SIC, as proposed in [40], achieved full capacity region. For randomly generated sequences, the authors of [41, 42] analyzed capacity for random binary and spherical sequences under joint decoding and linear MUDs. Additionally, an iterative decoding scheme for turbo codes with spreading was proposed in [43]. Lastly, let us highlight the work of Montanari and Tse in [44], where they proposed message-passing algorithms to design near-optimal MUDs. This approach later evolved into low-density signature (LDS) CDMA [45] and sparse-coded multiple-access (SCMA), as proposed in [10]. Rate-splitting multiple-access In the previous discussion, we found that the dominant facet of the capacity region can be achieved using the TIN-SIC strategy with time-sharing. However, is there a simpler strategy that can be achieved using only single-user codes? As proposed in [46], this can be accomplished through RSMA. To explain the main idea, let us redefine Shannon’s capacity (2.3) by explicitly considering the noise powerσ2: Cσ\u0000 P, σ2\u0001 =1 2log2\u0012 1 +P σ2\u0013 34 As we observed previously, the maximum sum-rateR Σof the two-user MAC is achieved on the dominant facet, resulting in RΣ=C σ\u0000 P1+P2, σ2\u0001 =C σ\u0000 P2, σ2\u0001 +C σ\u0000 P1, P2+σ2\u0001 ,(2.9) where the last equation is referred to as thechain rule. The physical meaning of this chain rule is as follows: In the first step, we apply a TIN step, resulting inR 1=C σ\u0000 P1, P2+σ2\u0001 , followed by a SIC step, yieldingR 2=C σ\u0000 P2, σ2\u0001 . This strategy allows us to achieve one corner point of the capacity region pentagon. An interesting observation is that the chain rule (2.9) allows us to split a high-rate code into two codes with lower rates. Then, the TIN-SIC strategy can be used to decode two",
    "σ\u0000 P2, σ2\u0001 . This strategy allows us to achieve one corner point of the capacity region pentagon. An interesting observation is that the chain rule (2.9) allows us to split a high-rate code into two codes with lower rates. Then, the TIN-SIC strategy can be used to decode two superimposed codes. As proposed in [46], any point in the two-user MAC capacity region can be achieved by splitting the higher-rate code of the user with the larger received power into two superimposed codes. Then, a TIN-SIC strategy can be applied to decode all three codes. To illustrate this, let us consider the case whereP 1> P 2, and let us choose some 0< δ < P 1. Next, we define p1=δ, p2=P2, p3=P1−δ. Then, letr i=C σ\u0000 pi, σ2\u0001 be the rate achievable by thei-th code. The sum rate of the three codes equals r1+r2+r3=C σ\u0000 p1+p2+p3, σ2\u0001 =C σ\u0000 P1+P2, σ2\u0001 =R Σ. Note also that for anyδ, there is a uniquer 1value. Hence, any point on the dominant facet can be achieved. Furthermore, the result above was generalized to the case of aK-user MAC in [46]. It was shown that a total of 2K−1 superimposed codes are required to achieve an arbitrary point on the dominant facet. Schemes based on polar codes Several works present theoretical results on the achievability of the capacity region using polar coding. In [47], it was shown that two users with a uniform data source, using Arıkan’s construction, may achieve a point on the dominant facet of the capacity region. The resulting MAC polarizes into five extreme channels, with the corresponding capacity regions illustrated in Fig. 2.3. Next, it was shown that a polar coding technique allows the achievement of any point in the capacity region of a two-user MAC [48].4Finally, a method for improving the performance of two-user MAC polar coding through list decoding was described in [49]. 4A Slepian-Wolf source coding problem was considered, which is a problem dual to the two-user MAC. The solution is based on monotone chain rule expansions. 35 (1)R1R2 (2)R1R2 (3)R1R2 (4)R1R2 (5)R1R2Figure 2.3: Five extreme channels for two-user MAC polarization [47]. The figure illustrates: (1) a completely useless channel, where the capacity region is a single point at (0,0); (2, 3) two channels that are useless for one of the two users; (4) a MAC with a TDMA-like capacity region; and (5) a channel where both users can transmit in parallel. Theoretical results for two-user MAC polarization were further extended to theK-user MAC case in [50]. Moreover, the achievability of the entire uniform rate region5for theK-user MAC was proposed in [51]. At the same time, there are no efficient decoding or optimization methods for the FBL case. Schemes based on LDPC codes Finally, let us consider the capacity-approaching scheme based on LDPC codes presented in [52]. The authors employed a message passing algorithm (MPA) to iteratively decode both codes, and each LDPC code was optimized for degree distributions using density evolution (DE). Their results showed that the resulting decoding threshold is only 0.18 dB away from",
    "the capacity-approaching scheme based on LDPC codes presented in [52]. The authors employed a message passing algorithm (MPA) to iteratively decode both codes, and each LDPC code was optimized for degree distributions using density evolution (DE). Their results showed that the resulting decoding threshold is only 0.18 dB away from Shannon’s limit. Moreover, another capacity-approaching scheme is based on spatially coupled LDPC codes [53], whose authors validated their claim using DE. 2.3 MAC with partial user activity Now, let us consider RA protocols. In this scenario, users generate messages at random time instances and attempt to transmit them over a shared channel. In 1970, Abramson proposed the first random access protocol, which is also the simplest, known as ALOHA [54]. The core idea is straightforward: whenever a new packet arrives, the transmitter immediately sends it. If two or more transmissions occur simultaneously, the signals interfere, making them undecodable and resulting in a collision. This original protocol is known as pure ALOHA. In this non-synchronized system, a collision occurs even when transmitted messages partially over- lap. To mitigate this, time synchronization was later introduced [11], giving rise to what is now 5For a MAC, the uniform rate region is the achievable region when the input distributions are uniform. 36 Pure ALOHA: TimeUser A B C D ECollision Collision Slotted ALOHA: TimeUser A B C D ECollisionFigure 2.4: Pure (top) and slotted (bottom) ALOHA. Packets are generated at the same time instances, resulting in five packet collisions during transmission in the case of pure ALOHA. In SA, transmission is allowed only in the nearest slot after a packet appears. As a result, the number of collided packets is reduced to two. Slot boundaries are marked by dashed lines. known as SA. An example illustrating how synchronization reduces the number of collisions is shown in Fig. 2.4. Thus, in the subsequent analysis, we consider only the SA system. Below are some key assumptions of the SA model. Based on these assumptions, various throughput optimization techniques have been developed. 2.3.1 Slotted ALOHA model assumptions As we demonstrate later, the use of collision resolution algorithms can significantly enhance the performance of SA. We now outline the assumptions for SA used in the study of collision resolution algorithms. 1. Slotted transmission system: Each message has a fixed duration and is transmitted within a unit slot length. 2. Collision: Occurs when two or more simultaneous transmissions happen within a slot, and successful reception is impossible. 3. Immediate feedback: The system provides feedback indicating whether the slot was empty (no transmission), a success (a single packet was transmitted), or a collision (two or more packets were transmitted). To work with a mathematical model of ALOHA, we make the following additional assumptions: 1. An infinite number of transmitters. 37 2. The arrival rate of incoming messages follows a Poisson point process with intensityλ. This approximation is reasonable given a large number of independent sources. Remark 2.2(Worst-case performance estimation in terms of collisions).The assumption of an infinite number of transmitters combined with a finite message rate allows for estimating worst-case performance in",
    "arrival rate of incoming messages follows a Poisson point process with intensityλ. This approximation is reasonable given a large number of independent sources. Remark 2.2(Worst-case performance estimation in terms of collisions).The assumption of an infinite number of transmitters combined with a finite message rate allows for estimating worst-case performance in terms of collisions. Indeed, if the number of transmitters were finite, a message arriving at a transmitting station would be queued rather than causing a collision. Remark 2.3(Correlated transmissions).We should also note that correlated transmissions (which are typical in sensor networks [55]) may lead to significantly worse performance than a Poisson model assuming independent transmissions. Remark 2.4(Collision model considerations).The ALOHA model does not account for physical- layer coding techniques. The previously mentioned SIC, which is a physical-layer coding technique, could significantly alter system performance. Nevertheless, the above assumptions provide a simpli- fied setup for studying collision resolution algorithms. Remark 2.5(Collisions and capture effect).In the case of real signal propagation models and additive white Gaussian noise (AWGN), a phenomenon known as thecapture effectoccurs [56]. When two messages collide and arrive with different received power levels, the TIN decoding process may allow for partial message recovery, where at least the user with the higher signal-to-interference- plus-noise ratio (SINR) value is successfully decoded. 2.3.2 Throughput and stability of slotted ALOHA Given a unit slot length, it is reasonable to define throughput as the average number of successfully delivered packets per slot. For an SA system without any collision resolution algorithms or retrans- missions, the throughput depends on the input data rate,λ, asλe−λ, which reaches its maximum atλ= 1, yielding 1/e≈0.3679 (following the Poisson traffic model proposed in Section 2.3.1). Thus, only about 36.8% of slots contain a non-collided transmission, while the remaining slots are either empty or experience collisions. To define stability, let us introduce a retransmission mechanism. When a transmitter has channel feedback, collisions can be detected immediately. In this case, the packet becomesbackloggedfor future retransmission. Recall that the number of transmitters is infinite, and a backlogged packet is not affected by subsequent messages. Different retransmission algorithms may influence the system’s throughput. Let us first specify the simplest retransmission policy: any backlogged packet is transmitted with probabilitypin the subsequent slot, independently of past slots and other packets. The value ofp can be adjusted based on collision statistics. Small values ofplead to high delays, whereas large values result in excessive collisions. This system can be represented as a Markov chain, where the state is the number of backlogged messages,k. Givenλandp, the set of transition probabilities can be easily derived [7]. It turns out that the resulting Markov chain is non-ergodic [57]. 38 1 2 34 5 s0 s2 s4 s8 s10 s15 timeTransmissions:s4s2s0s8s10s2s0s4s0s2s8s10−s8s10 1 2 3 4 5 Slot pair: · · ·Figure 2.5: Example of the tree-split algorithm, reproduced from [12]. (Top) Alignment of all stations into a tree. Active stationss 0,s2,s4,s8, ands 10are marked by circles. (Bottom) Sequence of transmissions during the collision resolution algorithm. Slots with collisions are marked by orange rectangles with active station indices, collision-free slots are represented by green",
    "of the tree-split algorithm, reproduced from [12]. (Top) Alignment of all stations into a tree. Active stationss 0,s2,s4,s8, ands 10are marked by circles. (Bottom) Sequence of transmissions during the collision resolution algorithm. Slots with collisions are marked by orange rectangles with active station indices, collision-free slots are represented by green rectangles, and empty slots are shown in grey. The slot pair index and the corresponding root node are indicated by colored numbers. Thedriftof the system is defined as the expected incrementD k(λ, p) in the number of backlogged packets for each statekduring a slot duration. WhenD k>0, the number of packets scheduled for retransmission is expected to increase. By analyzingD kfor different values ofk, we can identify regimes where the system becomes unstable, meaning the number of backlogged packets grows without bound. Consequently, the system’s throughput approaches zero. The problem of ALOHA stabilization was first studied in [58]. The authors examined a class of algorithms that controlpbased solely on collision feedback. The resulting control algorithm was stable forλ < 1/e. Note that forλ > 1/e, the drift value is always positive [7]. Hence, the throughput of the SA system is upper-limited by 1/e, and collisions remain a crucial throughput-limiting factor. In the next section, we describe advanced collision resolution algorithms that may increase the throughput of the SA system. 2.3.3 Lower and upper bounds on throughput in slotted ALOHA To achieve higher throughput and lower delay, the following modifications can be made to the retransmission strategy outlined above. First, the immediate transmission of a newly arrived packet can be delayed if previous collisions remain unresolved. Second, more advanced collision resolution policies can be employed. In this section, we briefly review various explored methods for throughput optimization. We begin with the tree-split algorithm proposed in [12, 59, 60]. The idea of this algorithm is to arrange all stations in a binary tree, as shown in Fig. 2.5.6When a collision occurs, the system enters a collision resolution regime. In this regime, all subsequent slots are grouped into pairs, and 6For simplicity, we consider the case where the number of stations is a power of two. 39 a tree-traversing algorithm (e.g., depth-first search) is initiated. The goal of this algorithm is to mark all leaf nodes (stations) as visited (i.e., collisions resolved). To achieve this, the algorithm starts at the root node. Stations from the left and right branches of the root transmit in the first and second slots, respectively. If a collision-free transmission or an empty slot occurs, all nodes connected to the corresponding branch are marked as visited (resolved). The tree-traversing algorithm continues splitting until all nodes are marked as visited. Subsequent modifications of tree-based algorithms, such as more than two groups at the initial collision resolution step, resulted in a throughput of 0.46 [61], which remains stable for smaller input rates. The second family of algorithms is based on the first-come, first-serve (FCFS) algorithms, where each arriving packet is marked with a timestamp, and packets whose timestamps are within a certain window are allowed to transmit [62]. The window edges move in",
    "0.46 [61], which remains stable for smaller input rates. The second family of algorithms is based on the first-come, first-serve (FCFS) algorithms, where each arriving packet is marked with a timestamp, and packets whose timestamps are within a certain window are allowed to transmit [62]. The window edges move in accordance with channel feedback. The state-of-the-art algorithm for the classical SA setup was proposed in [13], achieving a through- put of up to 0.4877. Finally, the state-of-the-art upper bound for classical SA throughput is given in [63]. 0.4877[13] ≤R[63] ≤0.5683.(2.10) Note that by leveraging the SIC technique, a throughput of 0.693 can be achieved using the tree- based algorithm, as reported in [64]. However, the use ofcodedSA, as presented in the next section, may further improve the system’s throughput. 2.3.4 Coded slotted ALOHA Let us introduce time diversity into the ALOHA system: a single transmission is followed by the transmission of areplicaof the original message [14], which is sent in a randomly selected slot within aframe. In this setup, the frame serves to separate different bursts and limit the distance between two replicas. This approach is known as contention resolution diversity slotted ALOHA (CRDSA). If one of the two replicas does not experience a collision, the position of the second replica can be determined from the successfully decoded message, allowing the second replica to be subtracted from another slot, potentially resolving additional collisions – a process known as the SIC step. This idea was further improved in [15], where an arbitrary number of replicas was allowed and chosen randomly from a specific distribution. All replicas are transmitted in randomly selected slots within a frame. The parameters of this distribution were optimized, significantly improving the resulting throughput, which can reach approximately 0.97 for large frames and close to 0.8 in practical implementations – a significant improvement over ordinary SA, as shown in (2.10). This method is known as IRSA. An example of IRSA is shown in Fig. 5.1 and Fig. 5.2 and described in Section 5.1. The transmission and decoding processes in the IRSA system can be described using a bipartite 40 graph, known as a Tanner graph. The vertex set of the graph consists of user nodes and slot nodes. An edge exists between a user node and a slot node if a transmission occurs from the corresponding user in the corresponding slot. The random family of these bipartite graphs can be characterized by a corresponding degree distribution. Hence, density evolution [65], similar to LDPC optimization, can be applied here. 2.3.5 Carrier sensing Carrier-sense multiple-access (CSMA) was proposed in [66]. The main idea of carrier sensing is to quickly detect when the slot is idle and immediately proceed to the next slot. This idle-detection time depends on the practical implementation of the system and may include hardware switching time, propagation delays, etc. There are two differences compared to the SA system described previously. The first is that an idle slot has a duration ofα≪1. The second is that a packet arriving during another transmission is immediately backlogged, and its transmission starts with",
    "system and may include hardware switching time, propagation delays, etc. There are two differences compared to the SA system described previously. The first is that an idle slot has a duration ofα≪1. The second is that a packet arriving during another transmission is immediately backlogged, and its transmission starts with probabilitypafter each subsequent idle slot. Packets arriving during an idle slot are transmitted in the next slot, as usual. The analysis of the system can be performed via a Markov chain [7]. The drift valueD kcan be expressed as follows: Dk=λα+λ\u0010 1−e−λα(1−p)k\u0011 −\u0012 λα+pk 1−p\u0013 e−λα(1−p)k. Forλ(1 +α)<1, the value ofD kreaches its minimum at p⋆=1−λ(1 +α) k−λ(1 +α). Dkis negative for all values ofk(withp⋆substituted) as soon as λ(1 +α)< e−1+λ. Applying a power series expansion over 1−λ, the throughput approaches one for smallα: λ <1−√ 2α. Moreover, within CSMA, the difference between slotted and pure ALOHA disappears, with the maximum throughput of pure ALOHA with CSMA being equal to 1−2√α[7]. 2.4 Many-access channels Finally, let us consider the information-theoretic approach, in which the number of users is allowed to grow with the blocklength. This line of research is the closest to the URA direction. Henceforth, we refer to this paradigm asmany-user information theoryand to the corresponding channels as many-access channels. 41 We present the many-access channel results in three steps, following their evolution in the literature. In the first step (see Section 2.4.1), the asymptotics over blocklengthn→ ∞were considered first, followed by the limit of the user countK→ ∞. Next, in Section 2.4.2, we consider the case where bothKandntend to infinity simultaneously, providing additional insights into the relationship betweenKandn. However, in this regime, each user expends infinite energy to send a message with a fixed number of information bits, leading to an infiniteE b/N0. Finally, this issue is addressed in Section 2.4.3, where the main conclusion is that achieving zero probability of joint decoding error becomes infeasible in this case. 2.4.1 Noiseless and noisy many-access BAC We begin with the paper [20], assuming that allKusers in the system are active. TheKmessages emanating from theKsources are encoded independently usingKbinary block codes7 C1,C2, . . . ,C K,C i⊆ {0,1}n,|C i|=M i of the same lengthn. The goal is to maximize the sum rate RΣ(K) =KX i=1Ri, R i=log2Mi n, i∈[K]. The authors consider a noiseless BAC, where the number of users increases with the blocklength. Thei-th user sends an integerX i∈ {0,1}, and the output symbolYis the real sum of theK inputs, i.e., the channel output is Y=XK i=1Xi∈ {0,1, . . . , K}. The first result is the capacity region for such a channel. Here, we provide only the sum rate inequality (dominant facet inequality): RΣ(K)≤C Σ(K) = max PX1⊗...⊗P XKI(X 1, . . . , X K;Y) =KX i=0\u0000K i\u0001 2Klog22K \u0000K i\u0001, where the maximization is performed over independent distributionsP Xi, and the maximum is achieved forP Xi= Bern(1/2),i∈[K]. The asymptotics can be summarized as follows. Theorem 2.2.The maximal achievable rate of aK-user uniquely decodable code for the binary K-user noiseless BAC is asymptotically equal to1 2log2(πeK/2)with increasingK.",
    "i\u0001 2Klog22K \u0000K i\u0001, where the maximization is performed over independent distributionsP Xi, and the maximum is achieved forP Xi= Bern(1/2),i∈[K]. The asymptotics can be summarized as follows. Theorem 2.2.The maximal achievable rate of aK-user uniquely decodable code for the binary K-user noiseless BAC is asymptotically equal to1 2log2(πeK/2)with increasingK. Finally, the authors proposed uniquely decodable codes for the many-access BAC. The key ingre- dient of the construction is the difference matrixDof sizeK×nover{0,1,−1}, where the rows ofDare linearly independent over{0,1,−1}. GivenD, it is possible to constructKuser codes C1,C2, . . . ,C Kthat are uniquely decodable8. Each user code consists of two codewords, i.e.,M i= 2, 7Here, we consider the case of different encoders or codebooks. 8Note that in this case, we have zero-error decoding. 42 i∈[K]. The most significant result is that the sum rate of such codes, RΣ(K) =K n= 1 +1 2log2n achievesR Σ(K) asymptotically, i.e., lim K→∞RΣ(K) CΣ(K)= 1. The authors also generalized the construction for noisy channels. In this case, the sum rate is given by RΣ(K) =K n= 1 +1 2log2n dmin, whered minis the minimalL 1distance of theK-user code, defined as dmin= min KX i=1ci−KX i=1c′ i 1, where the minimum is taken over all pairs (c 1, . . . ,c K)̸= (c′ 1, . . . ,c′ K) withc i,c′ i∈ Ci,i∈[K]. 2.4.2 Many-access GMAC Now, let us proceed with the inspirational papers of X. Chen, D. Guo, and their co-authors on many-access channels [67, 68, 69]. The authors proposed a new paradigm, referred to as many-user information theory, in which the number of users is allowed to grow with the blocklength. Notably, this is one of the first works to address both the partial activity case and the issue of a growing number of users as the blocklength increases. The paper [69] highlights an important observation: even in works that consider a growing number of users, the blocklength is typically sent to infinity before the number of users. Indeed, [20] follows exactly this approach. We note that while the capacity computed in this manner can still be used in the converse bound, it does not necessarily apply to the achievability bound. The reason is as follows: the argument that joint typicality holds with probability 1 as the blocklength grows to infinity does not directly extend to models where the number of users also grows to infinity. Thus, the achievability bound derivation must be reworked. Now, let us consider the model and the main result. LetKbe the total number of users in the system. The users share the same message set [M] but use different encodersf i: [M]S{0} →Rn. Each user is active with probabilityα(n), and both this probability and the message selection strategy are identical for all users (i∈[K]): Pr [W i=W] =\u001a1−α(n), W= 0, α(n)/M, W∈[M]. 43 Suppose each user accesses the channel independently with identical probabilityα(n)during any given block. The messages are encoded and sent via the Gaussian many-access channel: y=KX i=1fi(Wi) +z,(2.11) wherez∼ N(0,I n) is Gaussian noise. Note that∥f i(Wi)∥2≤Pn. If useriis inactive, it is assumed to transmit",
    "=\u001a1−α(n), W= 0, α(n)/M, W∈[M]. 43 Suppose each user accesses the channel independently with identical probabilityα(n)during any given block. The messages are encoded and sent via the Gaussian many-access channel: y=KX i=1fi(Wi) +z,(2.11) wherez∼ N(0,I n) is Gaussian noise. Note that∥f i(Wi)∥2≤Pn. If useriis inactive, it is assumed to transmit the all-zero codeword, i.e.,f i(0) =0. The authors focus on thejointprobability of error: P(n) J= Pr [dec(y)̸= (W 1, . . . , W K)], where the decoder must return zeros for users who were inactive. The main result is stated in [69, Theorem 1]. This theorem considers different regimes; for the reader’s convenience, we do not reproduce it in full but instead provide the result relevant to the regime of interest. We focus on the case where the average number of active users (K a) grows linearly with the blocklength (n), i.e., K(n) a=α(n)K(n)=µn, whereµis some constant. At the same time, the total number of users can scale faster, e.g., asn2. For this case, the symmetric message-length capacity (in bits) is given by: k(n)∼ 1 2µlog2(1 +µnP)−h(α(n)) α(n)! +, which means there exists a sequence of codebooks with message lengths (in bits) arbitrarily close tok nsuch that asn→ ∞, the average probability of errorP(n) Jvanishes. The capacity is achieved by i.i.d. Gaussian inputs. Note thatf(n)∼g(n)if and only if lim n→∞f(n) g(n)= 1. We use equivalence rather than equality, since ifk(n)is the message-length capacity, thenk(n)+ o(k(n)) is also considered capacity. Overview of the results.The expression fork nconsists of two parts: •The first term resembles the classical capacity expression and depends only on the average number of active users. •The second term represents the loss due to the need to identify active users and depends on the ratio of the average number of active users to the total number of users. 44 Example 2.1.Let us consider the example from [69]. AssumeP= 10dB andK(n) a=n/4. We consider three cases: (a)K(n)=n, (b)K(n)=n2and (c)K(n)=n3. The corresponding message-length capacities are: (a)k(n)∼2 log2(1 + 5n/2)−4h(1/4) (b)k(n)∼2 log2(1 + 5n/2)−log2(4en) (c)k(n)= 0. Remark 2.6(Infinite energy per bit).The authors of [69] assume a fixed powerP. However, the energy required to send one information bit tends to infinity asngrows. Indeed, consider the case where all users are active: K(n) a=K(n)=µn. The energy per information bit is given by: Pn 1 2µlog2(1 +µnP)→ ∞. Remark 2.7.Byenergy per bit, we consider the ratioE b/N0, whereE brepresents the energy required to transmit one information bit andN 0denotes the noise power spectral density. Through appropriate scaling of both signal and noise, we may assumeN 0= 1without loss of generality, making the quantitiesE bandE b/N0equivalent. Therefore, these terms may be used interchangeably throughout this monograph. Furthermore, givennchannel uses and a transmitpowerP, the total transmittedenergyequalsPn. 2.4.3 Finite energy and joint probability of error Recall that energy efficiency is of critical importance for massive MTC. Namely we are interested infiniteenergy per information bit. We have the following result [70]. Proposition 2.1.Assume the case where all users are active, i.e.,K a=K, and each user aims to transmitk= 1bit over the channel(2.11)with finite energyE. Then we have 1−P J≤Eloge+ log",
    "is of critical importance for massive MTC. Namely we are interested infiniteenergy per information bit. We have the following result [70]. Proposition 2.1.Assume the case where all users are active, i.e.,K a=K, and each user aims to transmitk= 1bit over the channel(2.11)with finite energyE. Then we have 1−P J≤Eloge+ log 2 logK. Thus, ifK→ ∞, then the success probability1−P J→0, implying that the users cannot reliably transmit even a single bit. Proof.First, let us show that the standard Fano-inequality-based converse does not work. We have (recalling thatM= 2) 1−P J≤n 2log\u0000 1 +K nE\u0001 + log 2 KlogM=1 2 log 2n Klog\u0012 1 +K nE\u0013 +1 K, 45 and we may obtain different relationships depending on the ratioK/n(e.g., in the caseK=µn). Now, let us introduce ageniethat provides us with the vector W′= (W′ 1, . . . , W′ K)∈ {0,1}K such that d(W,W′) = 1, whereW= (W 1, . . . , W K) represents the transmitted messages, andd(a,b) is the Hamming dis- tance between vectorsaandb. We note that the genie’s help reduces the number of hypotheses. Initially, there are 2Kpossible messages, but with the genie’s assistance, this number is reduced toK, meaning that we only need to determine the error position. Thus, 1−P J≤Prh U= ˆUi , whereUis the index of the user whose message was received in error. Next, we reformulate the problem in terms of the modified received signal: Y′=Y−KX i=1fi(W′ i) =f U(WU)−f U(W′ U) +z. The goal is now to identifyU. Consider the new codebook: C= [c 1, . . . ,c K], of sizen×K, where ci=fi(W′ i⊕1)−f i(W′ i), and note that∥c i∥2≤2E. Applying Fano’s inequality to this new problem, we obtain Prh U= ˆUi ≤n 2log\u0000 1 +2E n\u0001 + log 2 logK≤Eloge+ log 2 logK. Thus, the probability of joint decoding error cannot be made arbitrarily small under a finite energy constraint. Remark 2.8.Given these results, in the subsequent discussion, we switch from joint decoding to the PUPE criterion. The asymptotic results for finite energy are studied in Appendix F. 46 2.5 Outcomes In this monograph, we focus on uncoordinated multiple access, as this form of channel access is both natural and advantageous for massive MTC scenarios involving a large number of infrequently transmitting devices. Coordinated multiple access is a separate problem and falls beyond the scope of this monograph, although some tools from this line of research (e.g., decoding approaches) are employed within the URA framework. In this chapter, we examined different approaches to the MAC problem, discussing both information- theoretic and random-access methods. The former focuses on physical layer effects but does not account for the randomness of user activity. Moreover, it assumes a fixed number of users while the blocklength tends to infinity. In contrast, the latter provides deep insights into collision resolu- tion algorithms by considering the randomness of user activity, but most works largely ignore the impact of noise at the physical layer. Some papers do take noise into consideration (see, e.g., [15, Appendix]), but none of them aim to formulate the corresponding system requirements. To bridge this",
    "into collision resolu- tion algorithms by considering the randomness of user activity, but most works largely ignore the impact of noise at the physical layer. Some papers do take noise into consideration (see, e.g., [15, Appendix]), but none of them aim to formulate the corresponding system requirements. To bridge this gap, the URA paradigm was introduced in [5]. The URA framework not only addresses the computational challenges posed by a vast number of devices but also treats RA as a coding problem—incorporating both medium access protocols and physical layer effects. The URA paradigm extends previous work in several ways: it incorporates FBL performance, allows for an unbounded total number of users, and prioritizes energy per bit over the traditional notion of rate under vanishing error probability. At the same time, we emphasize that URA is an information-theoretic framework that offers a new perspective on random access, providing a fundamental benchmark to assess the performance of various uncoordinated access schemes. URA does not represent a new method of accessing a shared medium. The following chapters provide a detailed overview of the URA problem, covering fundamental limits, low-complexity schemes, and its connection to the CS problem. 47 48 Chapter 3 URA problem statement and compressed sensing interpretation Recall that the main problem is to provide multiple access to a massive number of uncoordinated and infrequently communicating devices. In this chapter, we highlight the most important aspects of this problem and provide the corresponding system model and information-theoretic formulation, as proposed by Y. Polyanskiy in [5]. 3.1 System model We consider the scenario of partial user activity. Assume that there areK tot≫1 users1in the system, but onlyK a≪K totof them are active at any given time. Throughout this chapter, we assume that the number of active users (K a) is fixed and known at the receiver. The papers [71, 72] extend these results to the scenario where the number of active users is random and unknown. This extension will be discussed briefly in Chapter 4. It is worth noting that this extension is a major aspect of any practical scheme, since the receiver lacks a priori knowledge of the number of active users. Instead, it must estimate this quantity from the received signal. All users utilize the same message set [M] and aim to transmitk= log2Mbits. Each user selects a message to transmit uniformly and independently of the other users. Communication occurs in a frame-synchronized manner, with each frame consisting ofnchannel uses. The main features of this problem formulation are as follows: 1.Large number of active users with short data packets.Unlike the classical MAC problem formulation, whereK ais fixed whilen, k→ ∞, we consider a scenario in whichkis fixed whileK aandnare large. 2.Users share the same encoder.Given the vast number of devices, assigning different encoders 1In what follows,K totis of no importance, and one may assumeK tot=∞. 49 to each user would result in prohibitive receiver complexity. The receiver would not know which decoder to use and, in the worst case, would need to try all of them. Therefore, a promising strategy is to employ",
    "1In what follows,K totis of no importance, and one may assumeK tot=∞. 49 to each user would result in prohibitive receiver complexity. The receiver would not know which decoder to use and, in the worst case, would need to try all of them. Therefore, a promising strategy is to employ a common encoderf: [M]→Rnfor all users, leading to a random-access scenario. A natural power constraint, ∥f(W)∥2 2≤nP, W∈[M], is also imposed. Since users are indistinguishable, the receiver is required only to recover the transmitted messages without identifying their senders. In other words, decoding is performed up to permutation.2Such schemes are referred to as unsourced random access (URA), since the source of the message is irrelevant. Users may include their identity as part of thek-bit payload, but this is not mandatory. For example, a fire sensor only needs to transmit the coordinates of a fire without an explicit identifier. 3.User-centric probability of error or PUPE.3Let T={W 1, W2, . . . , W Ka} denote the set of transmitted messages. The decoder outputs a setR ⊆[M], and we measure the probability of error as follows: Pe=E\u0014|T \\R| Ka\u0015 =1 KaKaX i=1Pr [W i̸∈ R].(3.1) TrackingP eis sufficient when the output list size is fixed (e.g., the usual assumption for bound derivations is|R|=K a). However, when|R|is a random variable (as in practical schemes), we also define thefalse alarm rate (FAR): Pf=E\u0014|R\\T | |R|\u0015 .(3.2) 4.Energy efficiency.Since the devices are autonomous and battery-powered, the goal is to minimize the energy per bit while ensuring a maximum tolerable PUPE ofP e≤ε: min s. t.P e≤εEb N0,whereEb N0=Pn 2k.(3.3) In this monograph, we focus on the Gaussian channel, as it provides key insights into the URA problem without unnecessary complications. The fading model and its main implications will be discussed briefly in Chapter 6. 2Note that we only consider channels that are permutation-invariant, allowing this type of decoding. 3To justify the choice of PUPE, see Proposition 2.1, which shows that achieving a small joint probability of error is infeasible. 50 Letx(i)=f(W i), fori∈[K a]. The output of the Gaussian channel,y∈Rn, is given by: y=KaX i=1x(i)+z,(3.4) wherez∼ N(0,I n) is the AWGN. Remark 3.1.In URA analysis, we focus on the non-asymptotic regime, as users utilize the same codebook of fixed size, and we cannot increase the number of users indefinitely (since|T | ≤M). We provide the asymptotic analysis of the bounds described in Chapter 4 in Appendix F. For this purpose, we shift to a different codebook scenario (see Section 2.4.3). Remark 3.2.Note that the factor2in(3.3)corresponds to a real-valued AWGN channel. In the case of a complex-valued channel (Chapter 6), this factor should be omitted. Remark 3.3.We note that URA does not introduce a new way of accessing the channel. For example, the ALOHA system presented in Section 2.3 is a good example of a URA scheme. Instead, URA provides a new information-theoretic model that incorporates both medium access protocols and physical layer effects, focusing on energy per bit rather than the more classical throughput and rate under vanishing error. This model applies to already existing schemes, such",
    "2.3 is a good example of a URA scheme. Instead, URA provides a new information-theoretic model that incorporates both medium access protocols and physical layer effects, focusing on energy per bit rather than the more classical throughput and rate under vanishing error. This model applies to already existing schemes, such as ALOHA. Remark 3.4.In this manuscript, we assume perfect synchronicity, as proposed in the original work [5]. We consider that synchronization is supported by additional mechanisms such as beaconing and proper frame structuring. In the case of perfect synchronicity, the analysis becomes clearer and more straightforward. At the same time, we note that keeping autonomous low-power devices synchronized is a challenging problem. Asynchronous URA has been addressed in various research papers [73, 74, 75, 76]; how- ever, even the fundamental limits for this setup remain unknown. We mention this as an interesting open problem in Chapter 7. 3.2 URA as an approximate support recovery problem In some situations, it is beneficial to represent sets4of messages as corresponding indicator vectors. Consider a multi-set: T={W 1, W2, . . . , W Ka}, W i∈[M], i∈K a. We can represent this set as a vector: u= [u 1, u2, . . . , u M]T, whereu idenotes the number of times messageiwas chosen or the multiplicity ofiinT. 4or multi-sets if the same message was chosen by multiple users. 51 Example 3.1.LetM= 5,K a= 8, and T={1,2,2,3,3,5,5,5}. The corresponding vectoruis given by: u= [1,2,2,0,3]T. It is worth mentioning that the URA problem formulation allows for a standard CS interpreta- tion [77, 78]. Recall thatMis the number of messages andnis the blocklength. We can represent the channel output as y=Xu+z,(3.5) where: •yis the channel output, representing a noisy mixture of users’ codewords, •X= [x 1, . . . ,x M] = [x i,j] is a codebook of sizen×MwithM= 2k, wherex W=f(W) for W∈[M], •urepresents the activity vector, andzis the AWGN vector. Note that|supp(u)| ≤K aandPM i=1ui=K a. The matrixXcan be viewed as a sensing matrix, anduis a sparse vector (with sparsity defined by the number of active users) to be reconstructed. More precisely, our problem is the approximate support recovery (ASR) problem [79], as we only need to determine the support ofuup to some distortion defined by the desired PUPE: Pe=E\u0014|supp(u)\\supp( ˆu)| Ka\u0015 ≤ε, where ˆuis the recovered activity vector or the indicator vector of the setR. Remark 3.5.The number of unique messages|T |can be less thanK a. AssumingW i∼Unif([M]), i∈[K a], we can estimate the probability of this event as follows: p′= Pr [|T |< K a] = 1−Ka−1Y i=0\u0012 1−i M\u0013 ≤\u0000Ka 2\u0001 M. In this monograph, we considerlog2M≈100bits and1≤K a≤500. For these parameters,p′ is negligible, allowing us to disregard the case where|T |< K aand thus work withu, ˆu∈ {0,1}M, where|supp(u)|=|supp( ˆu)|=K a. We establish a schematic correspondence between the URA and ASR problems in Fig. 3.1. The sensing matrix is represented by a codebook shared among all users. This matrix is multiplied by the activity vectoru(with nonzero elements marked by orange squares). The resulting vector, after being corrupted by noise, produces the",
    "We establish a schematic correspondence between the URA and ASR problems in Fig. 3.1. The sensing matrix is represented by a codebook shared among all users. This matrix is multiplied by the activity vectoru(with nonzero elements marked by orange squares). The resulting vector, after being corrupted by noise, produces the channel output. Remark 3.6.A key observation in related research is that the dimensionality of this problem is enormous—on the order of2100or greater. This characteristic makes the application of standard CS algorithms infeasible. 52 ×= Multiple Access ChannelJoint DecoderMessage 1 Encoder Message 2 Encoder Message 3 Encoder MessageK Encoder......Figure 3.1: Equivalence of the CS problem (top) and the same-codebook multiple-access problem (bottom). The CS problem is given by (3.5). Orange squares represent the nonzero elements of the users’ activity vector. This figure is reproduced from [80] . 3.3 Converse bounds In this section, we describe two converse bounds for the URA problem. The first is a single-user converse, with the only difference being that it accounts for the output list of messages. The second utilizes a capacity versus rate-distortion argument. Theorem 3.1(Single-user converse [80]).ConsiderK ausers transmitting messagesW i∈[M], i∈[K a], via a Gaussian channel withinnchannel uses, under a maximum tolerable PUPEε. Given that the decoder’s output list size isℓ 0, then nP≥\u0000 Q−1(ℓ0/M) +Q−1(ε)\u00012, Q(x) =+∞Z x1√ 2πe−y2/2dy,(3.6) whereQ−1(·)is the inverse of theQ-function defined above. Proof.We provide a sketch of the proof: 53 •In [31], it was shown that any single-user channel code over a Gaussian channel with param- eters (n, M, P) and error probabilityP e≜Pr[W̸= ˆW]≤εmust satisfy nP≥\u0000 Q−1(1/M) +Q−1(ε)\u00012. •This argument extends naturally to show that list-ℓ 0decodable codes (whereP e≜Pr[W̸∈ R]≤εand|R|=ℓ 0) must satisfy (3.6). •Symmetry argument: It suffices to obtain a lower bound on the probability that a particular user’s message is not in the decoded list. •Genie argument: Assume the decoder has access to the interference from all other users. The equivalent channel is given by: y′=x(1)+z, to which the bound above applies. Theorem 3.2(Multi-user converse [5]).ConsiderK ausers transmitting messagesW i∈[M], i∈[K a], via a Gaussian channel withinnchannel uses, under a maximum tolerable PUPEε. Given that the decoder’s output list size isℓ 0, then log2M≤1 (1−ε)\u0012n KaC(K aP) +h(ε) + (1−ε) log2ℓ0\u0013 , whereC(x) = 1/2log2(1 +x). Proof.Consider thei-th user. Letε i= Pr [W i̸∈ R]. Using Fano’s list inequality, we obtain: H(W i|y)≤h(ε i) + (1−ε i) log2ℓ0+εilog2(M−ℓ 0).(3.7) Summing inequalities (3.7) over alli∈[K a] and noting that H(W i|y) =H(W i)−I(W i;y), we obtain: KaX i=1I(W i;y)≥KaX i=1H(W i) −KaX i=1h(εi)− 1−KaX i=1εi! log2ℓ0 −KaX i=1εilog2(M−ℓ 0). 54 Note that: H(W i) = log2M,fori∈[K a], KaX i=1εi=K aε, KaX i=1h(εi)≥K ah(ε). Using the Markov chain: (W1, . . . ,W Ka)→(x(1), . . . ,x(Ka))→y→ R, we derive: KaX i=1I(W i;y)≤I(W 1,W2, . . . ,W Ka;y) (independent messages) ≤I(x(1),x(2), . . . ,x(Ka);y) (data processing ineq.) ≤nX j=1I(x(1) j,x(2) j, . . . ,x(Ka) j;yj) (memoryless channel) ≤nC(K aP). Remark 3.7.A very similar problem was considered in [79] and presented in [80]. The main difference is that [79, 80] considerTchosen uniformly from\u0000M Ka\u0001 variants",
    ",W Ka;y) (independent messages) ≤I(x(1),x(2), . . . ,x(Ka);y) (data processing ineq.) ≤nX j=1I(x(1) j,x(2) j, . . . ,x(Ka) j;yj) (memoryless channel) ≤nC(K aP). Remark 3.7.A very similar problem was considered in [79] and presented in [80]. The main difference is that [79, 80] considerTchosen uniformly from\u0000M Ka\u0001 variants (or equivalently, the indicator vectoru∈ {0,1}M, where|supp(u)|=K a). The converse presented above remains valid even when messages are repeated. For the regime of interest, the two converses coincide. We refer the reader to Section 4.6, where different achievability bounds are compared, highlighting the gap between achievability and converse bounds presented in Theorems 3.1 and 3.2. The results are shown in Fig. 4.6. Note that the converse is depicted as a single line, representing the maximum of the bounds from Theorems 3.1 and 3.2. 3.4 Parameters of interest We need to fix the parameters (n, k, K a). Consider a typical LoRa network: •Payload size:k≈100 bits. •A message transmitted using LoRa with a spreading factor of 11 occupies approximately k·211/11complex channel uses, resulting inn≈3×104real channel uses. 55 Following [5], we use the following parameters: •Frame length:n= 3×104(real channel uses), •User payload:k= 100 bits, •Number of active users:K a= 1, . . . ,500, •Target PUPE:ε∈ {0.001,0.05,0.1}. The goal is to find the minimalE b/N0in (3.3) such thatP e≤ε. We also note that users share a large number of channel uses compared to the number of information bits, leading to an individual coding rate of approximately 1/300. 56 Chapter 4 URA over Gaussian MAC: achievability bounds In this chapter, we consider achievability bounds for the URA over Gaussian MAC (G-URA). Specifically, we are interested in the tradeoff between energy efficiency (E b/N0) and the number of active users (K a). The term “achievability” implies that we do not account for decoding complexity and instead consider the potential capabilities under an infeasible decoding algorithm. We begin the chapter by defining the ML decoding rule and establishing a general setup for eval- uating achievability bounds, as presented in Section 4.1. Within this setup, we assume that the number of active users is known at the receiver. In Section 4.2, we introduce Gallager’sρ-trick and Fano’s trick – key components of the subsequent analysis. Next, in Section 4.3, we derive three achievability bounds. The first bound, presented by Y. Polyanskiy [5], is based on Gallager’sρ-trick (see Theorem 4.1). This bound has become a foundational result in URA research. The second bound is based on Fano’s trick (see Theorem 4.2). We find that this bound provides a similar energy efficiency estimate to the first one. However, a straightforward modification of this bound enables us to estimate energy efficiency under binary codebooks (see Theorem 4.4). Notably, we observe that switching from Gaussian codebooks to binary does not lead to a loss in achievable energy efficiency estimates. Next, we describe an achievability bound that combines both tricks. Originally designed to evaluate the performance of sparse regression codes (SPARCs), this bound is presented in Theorem 4.3. However, these results are also applicable to the URA problem. In Section 4.5, we discuss additional",
    "loss in achievable energy efficiency estimates. Next, we describe an achievability bound that combines both tricks. Originally designed to evaluate the performance of sparse regression codes (SPARCs), this bound is presented in Theorem 4.3. However, these results are also applicable to the URA problem. In Section 4.5, we discuss additional research on achievable energy efficiency analysis. We present results for a random number of active users, where energy efficiency depends on the probability of error and the false alarm rate (FAR), as discussed in Section 4.5.1. Finally, in Section 4.5.2, we explore the application of Gordon’s lemma to the URA problem. We conclude this chapter with a numerical analysis of the described bounds, as presented in Section 4.6. 57 4.1 Maximum likelihood decoding rule Recall thatT={W 1, W2, . . . , W Ka}is the set of transmitted messages, andR ⊆[M], with|R|= Ka, is the set of received messages. The decoder’s task is to recover the set of transmitted messages up to permutation. Note that Prh[ i̸=j{Wi=W j}i ≤\u0000Ka 2\u0001 M, which is negligible for the system parameters of interest (see Remark 3.5). Thus, we do not consider multi-sets in this section. Next, we introduce helpful notation. ForI ⊆[M], we define sI=X W∈If(W) =X W∈IxW. We now formulate the ML decoding rule: R= arg min R′⊆[M],|R′|=Ka∥y−s R′∥2.(4.1) Remark 4.1.We note that the decoder mentioned above is optimal for the joint error probability rather than for PUPE. A PUPE-optimal decoder should compute Pr [W∈ T |y]∝X T′:W∈T′p(y|s T′) Pr\u0002 T′\u0003 for allW∈[M], and then output the top-K amessages. The choice of the joint decoder was motivated by its suitability for analysis. 4.1.1 Probabilistic method,t-error events andP eestimate It is not possible to analyzeP efor a specific codebook. Therefore, we utilize the so-called proba- bilistic method [81] or random coding [82]. Specifically, we consider the ensembleGof codebooks Xspecified by the probability distributionP X1and compute Pe=E X[Pe(X)]. We can then assert that there exists a codebookX∗∈ G(M, n, P) such thatP e(X∗)≤P e. Due to symmetry when averaging over codebooks, we assume w.l.o.g. thatT= [K a]. LetC=TTR, M=T \\RandF=R\\Tbe the sets of correctly received, missed, and falsely detected messages, respectively (see Fig. 4.1). Following the approach of [5], we considert-error eventsE t={|M|=t}and use the following estimate: Pe≤KaX t=1t KaPr [E t] +p 0,(4.2) 1To utilize the symmetry property, we consider only ensembles with i.i.d. codewords. 58 Transmitted:T Received:RM=T \\R F=R\\TC=T/intersectiontextRMissed detections Correct detections Falsely detectedFigure 4.1: Correctly detected, missed, and falsely detected codewords. The set of transmitted messages has size|T |=K a. Throughout this chapter, we assume|R|=K afor all bounds discussed, which implies that the receiver knows the number of transmitted messages. In this case, we assume that|M|=|F|. where p0= Pr  [ i̸=j{Wi=W j} ∪ [ i∈[K a]{∥f(W i)∥2> Pn}   (4.3) is the probability that different users select the same codewords from the codebook or that the signal power exceedsPn. Thus, in what follows, we do not consider colliding messages. For ensembles of Gaussian codebooks considered in Section 4.3, the probability of power violation,p 0, is bounded by (4.6). For binary codebooks",
    "the probability that different users select the same codewords from the codebook or that the signal power exceedsPn. Thus, in what follows, we do not consider colliding messages. For ensembles of Gaussian codebooks considered in Section 4.3, the probability of power violation,p 0, is bounded by (4.6). For binary codebooks considered in Section 4.4, we havep 0= 0. Recall that the number of active users is assumed to be known at the receiver. Let us examine the error event in more detail. In the case of ML decoding, a decoding error occurs if there exists a set of messagesRsuch that the sum of the corresponding codewords is closer to the received sequenceythan the sum of the codewords corresponding to the transmitted messages T: ∥y−s T∥2≥ ∥y−s R∥2. Taking into account thaty=s T+z,s T=sM+sCands R=sF+sC, we obtain the following decoding error event: E(M,F) =n ∥z∥2− ∥sM−sF+z∥2≥0o .(4.4) Note that Et=[ M⊆T,F⊆[M]\\[K a]E(M,F). Let us begin with the naive approach and apply the union bound in a straightforward manner. We have Pr [E t] = Pr [ M,FE(M,F) =E X Pr [ M,FE(M,F) X   59 ≤\u0012Ka t\u0013\u0012M−K a t\u0013 EX\u0002 Pr\u0002 E(M′,F′) X\u0003\u0003 , whereM′= [t],F′= [K a+t]\\[K a]. The last step follows from the union bound and the symmetry property (as we are averaging over the codebook). We note that the second binomial coefficient is extremely large (recall thatMis on the order of 2100). Thus, the naive approach significantly overestimates the desired probability. In what follows, we describe several approaches to tighten the union bound. 4.2 Useful tricks to tighten the union bound In this section, we describe all the tools needed for the proofs. We begin with approaches to improve the union bound, as proposed by Gallager2[83] and Fano [84]. 4.2.1 Gallager’s trick Gallager’sρ-trick is a method to improve the union bound, which can be formulated as follows. LetE i, fori∈[m] be the events. Then, for any 0≤ρ≤1 we have Pr\"m[ i=1Ei# ≤ mX i=1Pr [E i]!ρ . It is reasonable to apply this method at intermediate steps in estimating conditional probabilities. Specifically, one needs to find a suitable random variableVsuch that Pr [E i|V]≤exp [−F(V)] for some functionF(V). Then theρ-trick leads to the following estimate: Pr\"m[ i=1Ei# ≤mρEV[exp [−ρF(V)]]. 4.2.2 Fano’s trick Let us explain the idea using a simple single-user case. LetC={x 1, . . . ,x M}and y=x 1+z, wherex 1∈ Candzis the noise vector. 2also known as Gallager’sρ-trick 60 Consider the ML or minimum Euclidean distance decoding. The error event isE=SM m=2Em, whereE m={∥y−x 1∥2≥ ∥y−x m∥2}. Let us consider why the union bound overestimates the probability. This occurs when severalx m are closer toythanx 1. Clearly, this situation becomes more likely when the norm of the noise is large. Fano’s method can be described as follows. Let us choose a so-called “good” regionB. We proceed as follows: Pr [E]≤Prh E\\ Bi + Pr [Bc],(4.5) and then apply the union bound for the first term only. In the single-user example, a reasonable choice isB={∥z∥2≤βn}for someβ >0. In the general case, the choice ofBposes a significant challenge.",
    "follows. Let us choose a so-called “good” regionB. We proceed as follows: Pr [E]≤Prh E\\ Bi + Pr [Bc],(4.5) and then apply the union bound for the first term only. In the single-user example, a reasonable choice isB={∥z∥2≤βn}for someβ >0. In the general case, the choice ofBposes a significant challenge. 4.3 Achievability bounds In this section, we present three achievability bounds. All of these bounds consider a Gaussian codebook and a paradigm of averaging over multiple codebooks generated from theensemble. To proceed, let us begin with the definition of the ensemble. Definition 4.1.LetG(M, n, P)be the ensemble of Gaussian codebooks of sizen×M, where each element is sampled i.i.d. fromN(0, P). The key difference between the approaches presented below lies in how the union bound is tightened. We utilize Gallager’sρ-trick [5], Fano’s trick [85], and their combination presented in [86]. We note that the problem and approaches considered in this section share many similarities with the optimal decoder analysis of SPARCs [86, Chapter 2]. FixP′< Pand considerG(M, n, P′). The following estimate is valid forp 0(see (4.3)) p0≤p0≜\u0000Ka 2\u0001 M+K aPr\" 1 nnX i=1ξ2 i>P P′# , ξii.i.d∼ N(0,1).(4.6) 4.3.1 The bound based on Gallager’sρ-trick We start with the bound that utilizes the Gallager’sρ-trick and the chain rule: Prx,y,z[E(x,y,z)] =E z\u0002 Ey|z\u0002 Prx|y,z [E(x,y,z)|y,z]\u0003\u0003 . In what follows, we work with independent random vectors, so there is no need to deal with expectations over conditional distributions. 61 Theorem 4.1(Y. Polyanskiy, [5]).FixP′< P. There exists a codebookX∗∈ G(M, n, P′) satisfying the power constraintP′and providingP eusing eq.(4.2), wherep 0is bounded by(4.6), andPr [E t]≤p t, where pt= inf 0≤ρ 1,ρ2≤1exp [−n(−ρ 1ρ2R1−ρ1R2+E 0(ρ1, ρ2))], R1=1 nlog\u0012M−K a t\u0013 , R 2=1 nlog\u0012Ka t\u0013 , E0(ρ1, ρ2) =1 2(ρ1a+ log(1−2bρ 1)), a=ρ 2log(1 + 2P′tλ) + log(1 + 2P′tµ), b=ρ 2λ−µ 1 + 2P′tµ, µ=ρ2λ 1 + 2P′tλ, λ=P′t−1 +√ D 4(1 +ρ 1ρ2)P′t, D= (P′t−1)2+ 4P′t1 +ρ 1ρ2 1 +ρ 2. Proof.If we look at (4.2), it is clear that we need to deal with Pr[E t], where the randomness is induced byzand the random matrixX. Our goal is to show that Pr[E t]≤p t, wherep tis given in the theorem statement. Let E(M) =[ F⊆[M]\\[K a]E(M,F). Let 0≤ρ 1, ρ2≤1, and we can represent Pr[E t] as follows: Pr [E t] =E z[Pr[E t|z]] =Ez\u0014 Pr\u0014[ M⊆[K a]E(M) z\u0015\u0015 ≤Ez\u0014\u0012 Pr\u0014[ M⊆[K a]E(M) z\u0015\u0013ρ1\u0015 (ρ-trick) ≤Ez\u0014\u0012X M⊆[K a]Pr [E(M)|z]\u0013ρ1\u0015 (union bound) =Ez\u0014\u0012X M⊆[K a]EsM[Pr [E(M)|z,s M]]\u0013ρ1\u0015 =Ez\u0014\u0012\u0012Ka t\u0013 EsM′\u0002 Pr\u0002 E(M′) z,sM′\u0003\u0003\u0013ρ1\u0015 ,(4.7) where the last transition is valid due to symmetry. W.l.o.g.,M′= [t] in the last expression and in what follows. Now consider Pr\u0002 E(M′) z,sM′\u0003 = Pr [ F⊆[M]\\[K a]E(M,F) z,sM′  62 ≤ Pr [ F⊆[M]\\[K a]E(M′,F) z,sM′  ρ2 (ρ-trick) ≤\u0012X F⊆[M]\\[K a]Pr\u0002 E(M′,F) z,sM′\u0003\u0013ρ2 (union bound) ≤\u0012\u0012M−K a t\u0013 Pr\u0002 E(M′,F′) z,sM′\u0003\u0013ρ2 ,(4.8) where the last transition is again due to symmetry. W.l.o.g.,F′= [K a+t]\\[K a] in the last expression and in what follows. We start with Pr [E(M′,F′)|sM,z]. In accordance with (4.4), we have Pr\u0002 E(M′,F′) z,sM′\u0003 = Prh ∥z∥2− ∥sM′−sF′+z∥2≥0 z,sM′i . Letλ >0. Applying the",
    "t\u0013 Pr\u0002 E(M′,F′) z,sM′\u0003\u0013ρ2 ,(4.8) where the last transition is again due to symmetry. W.l.o.g.,F′= [K a+t]\\[K a] in the last expression and in what follows. We start with Pr [E(M′,F′)|sM,z]. In accordance with (4.4), we have Pr\u0002 E(M′,F′) z,sM′\u0003 = Prh ∥z∥2− ∥sM′−sF′+z∥2≥0 z,sM′i . Letλ >0. Applying the Chernoff bound (Lemma G.1), we obtain Pr\u0002 E(M′,F′) z,sM′\u0003 ≤EsF′h exph λ\u0010 ∥z∥2− ∥sM′−sF′+z∥2\u0011ii . and the vectorszands M′are fixed. Using Corollary G.1, we get Pr\u0002 E(M′,F′) z,sM′\u0003 ≤exp [E 1(sM′,z)], where E1(sM′,z) =λ ∥z∥2−∥sM′+z∥2 1 + 2tP′λ! . Substituting this result into (4.8), we obtain Pr\u0002 E(M′) z,sM′\u0003 ≤\u0012M−K a t\u0013ρ2 exp [ρ 2E1(sM′,z)]. Taking here expectation3overs M′(see (4.7)), we get Pr\u0002 E(M′) z\u0003 ≤\u0012M−K a t\u0013ρ2 exph b∥z∥2−nai . Substituting this result into (4.7), we finally obtain Pr [E t|z]≤\u0012Ka t\u0013ρ1\u0012M−K a t\u0013ρ1ρ2 exph ρ1(b∥z∥2−na)i . Taking expectation overz, we obtain the theorem statement. Remark 4.2.One may ask whether the provided sequence of expectations is optimal. In the chain rule, we can use any sequence, for example, by first computing the expectation overz. Let us provide some intuition. There are\u0000M−K a t\u0001 possible choices forF, and this binomial coefficient is extremely large. Therefore, it is reasonable to start withs F, as done in the proof, since Gallager’s trick will hopefully significantly reduce this large coefficient. 3We again apply Corollary G.1. 63 sMFigure 4.2: Illustration of the ball presented in (4.9) forβ= 0 and different values ofαsuch that α/1−α∈ {0.1,0.5,1.0}. Each ball is represented by a green line, and a larger radius corresponds to a larger value ofα. The dashed line corresponds to the extreme caseα= 1. Forβ >0, the radius of each ball increases, and the dashed line shifts to the left. Note that the zero vector is always inside the ball for any 0< α≤1 andβ≥0. Hence, the intersection of these balls is never empty. 4.3.2 The bound based on Fano’s trick Let us fix 0≤α <1,β≥0. We introduce the following “good” region: B=\\ M⊆[K a]B(M),B(M) =n α∥sM+z∥2+βn >∥z∥2o .(4.9) Remark 4.3(Visualization of the “good” region).Let us consider a geometric interpretation of the region(4.9). Suppose the vectors Mis fixed (since we consider a union over all\u0000Ka t\u0001 missed codewords in the subsequent theorem proof). Thus, givens M, the condition(4.9)for a singleB(M) can be rewritten as follows (see Fig.4.2). For0< α <1, we have: n ∥z−v 0∥2< r2o ,v 0=α 1−αsM, r2=α∥sM∥2+βn(1−α) (1−α)2, which defines a ball. Note thatαcontrols both the centerv 0and the radiusrof the sphere, whileβaffects only the radius. Additionally, each ball contains the zero point; hence, their intersection is non-empty. Forα= 1, we have:( sT M·z>−∥sM∥2+βn 2) , α= 1, which defines a hyperplane. 64 Remark 4.4.Let us provide some comments on the choice of the “good” region: •Addings Cto the region description does not lead to a performance improvement, since cor- rectly received codewords do not appear in(4.4). However, the use ofs Cmay be beneficial in the case of fading, as shown in(6.12). •The region description does not includes Fto avoid a large binomial coefficient\u0000M−K a t\u0001 . Indeed, ifs Fwere included in(4.9), then calculatingPr [Bc]in",
    "a performance improvement, since cor- rectly received codewords do not appear in(4.4). However, the use ofs Cmay be beneficial in the case of fading, as shown in(6.12). •The region description does not includes Fto avoid a large binomial coefficient\u0000M−K a t\u0001 . Indeed, ifs Fwere included in(4.9), then calculatingPr [Bc]in eq.(4.5)would involve taking the complement of an intersection of a large number of events forF ⊆[M]\\[K a]. After applying a union bound, this large binomial coefficient would inevitably appear. Theorem 4.2(Achievability based on Fano’s trick [85]).FixP′< P. There exists a codebook X∗∈ G(M, n, P′)satisfying the power constraintP′and providingP eusing eq.(4.2), wherep 0is bounded by(4.6), andPr [E t]≤p t, where pt= inf α,β≥0(p1,t+p2,t), p1,t= inf u,v>0,λ A>0exp\u0014 −n\u0012 −R1−R 2+1 2log det (I 3−2A)−vβ\u0013\u0015 , p2,t= inf δ>0,λ B>0exp\u0014 −n\u0012 −R2+1 2log det (I 2−2δB) +δβ\u0013\u0015 , R1=1 nlog\u0012M−K a t\u0013 , R 2=1 nlog\u0012Ka t\u0013 , A= (α−1)v(αv−u)√ P′t u√ P′t (αv−u)√ P′t(αv−u)P′t uP′t u√ P′t uP′t−uP′t , B=\u00121−α−α√ P′t −α√ P′t−αP′t\u0013 . Byλ Aandλ B, we mean the minimum eigenvalues ofI 3−2AandI 2−2δBaccordingly. Proof.We start by applying Fano’s trick (4.5) forE t, whereBis given by (4.9). Let us start with Pr [E tTB]. We have Prh Et\\ Bi ≤Pr [ M,FE(M,F)\\ B(M)  ≤\u0012Ka t\u0013\u0012M−K a t\u0013 Prh E(M′,F′)\\ B(M′)i , whereM′= [t],F′= [K a+t]\\[K a]. The last transition is due to the union bound and symmetry. Consider Pr [E(M′,F′)TB(M′)]. Recall that E(M′,F′) =n ∥z∥2− ∥sM′−sF′+z∥2≥0o 65 and B(M′) =n α∥sM′+z∥2+βn >∥z∥2o . Let us introduce the vector ηηηT=\u0010 zT,sT M′/√ P′t,sT F′/√ P′t\u0011 , ηηη∼ N(0,I 3n). Using this notation, we can rewrite the eventsE(M′,F′) andB(M′) as follows: E(M′,F′) =\b ηηηTAeηηη≥0 and B(M′) =\b ηηηTArηηη+βn >0 , where Ae= 0−√ P′tIn√ P′tIn −√ P′tIn−P′tIn P′tIn√ P′tIn P′tIn−P′tIn , Ar= (α−1)I nα√ P′tIn0 α√ P′tIn αP′tIn0 0 0 0 . Now, we apply the Chernoff bound (Lemma G.1): Prh E(M′,F′)\\ B(M′)i ≤inf u,v>0Eηηηexp\u0002 ηηηTAnηηη+vβn\u0003 , whereA n=uA e+vA r. Using Lemma G.2 (withbequal to the zero vector), we obtain Prh E(M′,F′)\\ B(M′)i ≤inf u,v>0exp\u0014 −1 2log det (I 3n−2A n) +vβn\u0015 , whenλ min(I3n−2A n)>0. Let us note that the matrixA ncan be represented asI n⊗Aby reordering its columns and rows. So, we can represent (I 3n−2A n) asI n⊗(I 3−2A), and it is clear that −1/2log det (I 3n−2A n) =− n/2log det (I 3−2A). Thus, Pr [E tTB]≤p 1,t. Similarly, we deal with Pr [Bc]≤\u0012Ka t\u0013 Pr\u0002 Bc(M′)\u0003 ≤p2,t. This concludes the proof. 66 4.3.3 Combination of the tricks One may notice that Gallager’s and Fano’s tricks can be applied jointly. In this section, we present one possible variant, which is a straightforward modification of the bound for SPARCs provided in [86]. Theorem 4.3(Achievability based on the combination of Fano’s and Gallager’s tricks [86]).Fix P′< P. There exists a codebookX∗∈ G(M, n, P′)satisfying the power constraintP′and providing Peusing eq.(4.2), wherep 0is bounded by(4.6), andPr [E t]≤p t, where pt= inf α,τ≥0(p1,t+p2,t), p1,t= inf 0≤γ≤1exp [−n(−γR 1−R 2+E 1(γ))], p2,t= inf δ>0exp [−nE 2(δ)], R1=1 nlog\u0012M−K a t\u0013 , R 2=1 nlog\u0012Ka t\u0013 , E1(γ) =1 2\u0000 γlog(1 +P′t)",
    "a codebookX∗∈ G(M, n, P′)satisfying the power constraintP′and providing Peusing eq.(4.2), wherep 0is bounded by(4.6), andPr [E t]≤p t, where pt= inf α,τ≥0(p1,t+p2,t), p1,t= inf 0≤γ≤1exp [−n(−γR 1−R 2+E 1(γ))], p2,t= inf δ>0exp [−nE 2(δ)], R1=1 nlog\u0012M−K a t\u0013 , R 2=1 nlog\u0012Ka t\u0013 , E1(γ) =1 2\u0000 γlog(1 +P′t) + log\u0000 1−γ2(1−ρ2 e)\u0001 −γτ\u0001 , E2(δ) =1 2\u0000 log\u0000 1−δ2(1−ρ2 r)\u0001 +τδ\u0001 , ρ2 e=(1 +αP′t)2 (1 +α2KaP′)(1 +tP′), ρ2 r=1 1 +α2KaP′. Proof.Letα, β >0. In what follows, we demonstrate how to choose these constants. We start by applying Fano’s trick (4.5) forE t, where B=n β∥y−(1−α)s T∥2− ∥y−s T∥2+τn≥0o =n β∥z+αs T∥2− ∥z∥2+τn≥0o , and β=β′/(1 +α2KaP). Similar to the proofs of Theorems 4.2 and 4.1, we can write (0≤γ≤1) Prh Et\\ Bi ≤Pr [ M,FE(M,F)\\ B(M)  ≤\u0012Ka t\u0013 Ez,sT\u0014\u0012\u0012M−K a t\u0013 Prh E(M′,F′)\\ B sT,zi\u0013γ\u0015 . =\u0012Ka t\u0013\u0012M−K a t\u0013γ Ez,sTh\u0010 Prh E(M′,F′)\\ B sT,zi\u0011γi . 67 Recall that E(M′,F′) =n ∥z∥2− ∥sM′−sF′+z∥2≥0o . Proceeding further, Prh E(M′,F′)\\ B sT,zi ≤Prh β∥z+αs T∥2− ∥sM′−sF′+z∥2+τn≥0 sT,zi , where the last transition follows from the fact that Pr[ξ 1≥0, ξ 2≥0]≤Pr[ξ 1+ξ2≥0]. Applying the Chernoff bound withλ=1 24, we obtain Prh E(M′,F′)\\ B sT,zi ≤exp\" 1 2 β∥z+αs T∥2−∥sM+z∥2 1 +P′t! +τn 2−n 2log(1 +P′t)# . Raising the estimate to the powerγand proceeding with the expectation overzands T, we introduce the notation A= exphγτn 2−γn 2log(1 +P′t)i , and obtain Ez,sTh Prh E(M′,F′)\\ B sT,zii ≤AE z,sT\" exp\" γ 2 β∥z+αs T∥2−∥sM+z∥2 1 +P′t!## ≤AE ηηη1,ηηη2\u0014 exp\u0014γβ′ 2∥ηηη1∥2−γ 2∥ηηη2∥2\u0015\u0015 =Aexph −n 2log\u0000 1−γβ′+γ−γ2β′(1−ρ2 e)\u0001i , where the last transition follows from Corollary G.2, andρ eis defined as Cov(ηηη1,ηηη2) =E[η ηηT 1ηηη2] =ρ eIn, where ρ2 e=(1 +αP′t)2 (1 +α2KaP′)(1 +tP′).(4.10) Now consider Pr[Bc] = Prh β∥z+αs T∥2− ∥z∥2+τn <0i 4One can optimize overλto improve the bound, but we follow the original approach. 68 ≤Ez,sT\u0014 exp\u0014δ 2∥z∥2−δ 2β∥z−αs T∥2−δτ 2n\u0015\u0015 = exp\u0014 −δτn 2\u0015 Eηηη1,ηηη2\u0014 exp\u0014δ 2∥ηηη1∥2−δ 2β′∥ηηη2∥2\u0015\u0015 = exp\u0014 −δτn 2\u0015 exph −n 2log\u0000 1−δ+δβ′−δ2β′(1−ρ2 r)\u0001i , as ρ2 r=1 1 +α2KaP′. For simplicity, the authors of [86] choseβ′= 1. We follow the same choice but note that optimizing this parameter may further improve the bound. Thus, collecting all terms together and settingβ′= 1, we obtain the theorem statement. The final region is given by B=( ∥y−(1−α)s T∥2 1 +α2KaP− ∥y−s T∥2+τn≥0) =( ∥z+αs T∥2 1 +α2KaP− ∥z∥2+τn≥0) . Remark 4.5.The authors of [86] show thatα=t/K amaximizes the expression(4.10), resulting in ρ2 e=1 +t2 KaP′ 1 +tP′, ρ2 r=1 1 +t2 KaP′, which are used in the original theorem. However, as numerical results (see Section 4.6) show, further optimization ofαallows for better performance, particularly in the regime where the number of active usersK ais small. Throughout Theorems 4.1, 4.2, and 4.3, we considered different approaches to estimate the achiev- able energy efficiency for the URA setup. As we further demonstrate through numerical analysis in Section 4.6, all these bounds yield similar energy efficiency estimates, with the gap being no greater than 0.25 dB. However, the results presented in Theorem 4.2 can similarly be generalized to a binary codebook, as",
    "able energy efficiency for the URA setup. As we further demonstrate through numerical analysis in Section 4.6, all these bounds yield similar energy efficiency estimates, with the gap being no greater than 0.25 dB. However, the results presented in Theorem 4.2 can similarly be generalized to a binary codebook, as we demonstrate later in Theorem 4.4. Let us also recall the converse bounds previously defined in Theorems 3.1 and 3.2. As we further demonstrate, there is a gap between achievability and converse, with the difference being up to 1.2 dB. We refer the reader to Section 4.6 for a detailed discussion and comparison of the presented bounds. 69 4.4 The case of binary codebooks We note that the bounds from the previous section assume the use of Gaussian signaling (or codebook), which is not ideal for practical applications. Indeed, a Gaussian codebook may be suboptimal, especially in the case of short blocks, where different codewords may have significantly different energy levels. To overcome this issue, codewords can be sampled from apower shellor from a uniform distribution on the multidimensional sphere (see Appendix B.2.2), ensuring equal power for all codewords. Moreover, Gaussian codebooks may have limited practical applications, as storing such a codebook and generating the transmitted signal can be computationally complex. In this section, we address this problem and consider binary signaling (or BPSK modulation). We aim to answer a natural question: does binary signaling restrict energy efficiency? In other words, we seek to establish the fundamental limits for binary-input GMAC. This question was previously studied in [85], and we follow the description presented in that paper. We start with the definition of the binary codebook ensemble. Definition 4.2.LetB(M, n, P)be the ensemble of binary codebooks of sizen×M, where each element is sampled i.i.d. fromn −√ P,√ Po with probability1/2. Remark 4.6.Note that there is no need to check the power constraint for this ensemble as it is fulfilled by design. Now we are ready to formulate and prove the main result. Theorem 4.4(Achievability for binary codebook based on Fano’s trick [85]).There exists a code- bookX∗∈ B(M, n, P)providingP eusing eq.(4.2), wherep 0= 0, andPr [E t]≤p 1,t+p2,t, where p1,t=\u0012M−K a t\u0013\u0012Ka t\u0013 inf u,v>0 exp [−nζ(α, β, v)]× × tX m=−ttX f=−tρmρfexp [Pϕ(α, u, v, m, f)] n , where ζ(·) =1 2log (1−2v(α−1))−βv, ϕ(·) = 2(αvm−u(m−f))2 1−2v(α−1)+αvm2−u(m−f)2! , and p2,t=\u0012Ka t\u0013 inf δ>0\" exp [−nξ(α, β, δ)] tX m=−tρmexp [Pψ(α, δ, m)]!n# , where ξ(·) =1 2log (1−2δ(1−α)) +δβ, ψ(·) =δα2δ−1 1−2δ(1−α)m2, 70 ρi=(\u0000t 1 2(i+t)\u0001 2−t, i∈ {2j−t,∀j: 0≤j≤t} 0,otherwise with the following conditions holding: 1−2v(α−1)>0,1−2δ(1−α)>0. Proof.We utilize the approach from Theorem 4.2 with exactly the same good region (4.9) in Fano’s trick (4.5) forE t. We now show how to modify the proof for the case of a binary codebook. Let us start with Pr [E tTB]. We have Prh Et\\ Bi ≤\u0012Ka t\u0013\u0012M−K a t\u0013 Prh E(M′,F′)\\ B(M′)i , whereM′= [t],F′= [K a+t]\\[K a], and the events are defined as follows: E(M′,F′) =n ∥z∥2− ∥sM′−sF′+z∥2≥0o , B(M′) =n α∥sM′+z∥2+βn >∥z∥2o . The major difference from the proof",
    "binary codebook. Let us start with Pr [E tTB]. We have Prh Et\\ Bi ≤\u0012Ka t\u0013\u0012M−K a t\u0013 Prh E(M′,F′)\\ B(M′)i , whereM′= [t],F′= [K a+t]\\[K a], and the events are defined as follows: E(M′,F′) =n ∥z∥2− ∥sM′−sF′+z∥2≥0o , B(M′) =n α∥sM′+z∥2+βn >∥z∥2o . The major difference from the proof of Theorem 4.2 is thats M′ands F′are not Gaussian. Ex- panding the norms, we rewrite the events as E(M′,F′) =n −2 (s M′−sF′)Tz− ∥s M′−sF′∥2>0o , B(M′) =n (α−1)∥z∥2+ 2αsT M′z+α∥s M′∥2+βn >0o . Thus, we can estimate the probability Pr [E(M′,F′)TB(M′)] using the Chernoff bound for the joint events in the following way: Prh E(M′,F′)\\ B(M′)i ≤inf u,v>0Ez,sM′,sF′exph (α−1)v∥z∥2 +2\u0010 αvsT M′−u(s M′−sF′)T\u0011 z +αv∥s M′∥2−u∥s M′−sF′∥2+βvni . First, let us take the expectation overzwhile treatings M′ands F′as fixed. To do this, we apply Lemma G.2 and obtain Prh E(M′,F′)\\ B(M′)i ≤inf u,v>0EsM′,sF′exph −n 2log (1−2 (α−1)v) +2∥αvs M′−u(s M′−sF′)∥2 1−2 (α−1)v +αv∥s M′∥2−u∥s M′−sF′∥2+βvni .(4.11) 71 To take the expectation overs M′ands F′, let us consider sM′=\u0000 sM′,1, sM′,2, . . . , s M′,n\u0001 (fors F′, the arguments are similar), which is the sum oftcodewords, each satisfying the power constraintPfor every coordinate. Then, we observe that sM′,l∈n (2j−t)√ P,∀j: 0≤j≤to ,∀l∈[n]. Changing the sign ofjterms modifies the sum by 2j√ Pin absolute value. For instance, if allt terms initially have the value−√ Pand we randomly selectjterms to change to√ P, then the sum will be (2j−t)√ P. The number of ways to obtain the sums M′,l= (2j−t)√ P,∀j: 0≤j≤tis given by the binomial coefficient\u0000t j\u0001 . Since each of thetterms can independently take one of two values, the total number of possible combinations is 2t. Thus, the probability distribution ofs M′,lis: ρi= Prh sM′,l=i√ Pi =1 2t\u0012t i+t 2\u0013 fori∈ {2j−t,∀j: 0≤j≤t}and zero otherwise. Now, we note that Eh exph ∥sM′∥2ii =X (i1,i2,...,in)nY l=1ρilexp\u0002 i2 lP\u0003 = tX i=−tρiexp\u0002 i2P\u0003!n . Finally, applying this approach to (4.11), we obtain Pr [E tTB]≤p 1,t. Similarly, we have Pr [Bc]≤ p2,t. In Section 4.6, we provide a numerical comparison of this bound and find that it yields the same energy efficiency estimates as the bound for the Gaussian codebook presented in Theorem 4.2. 4.5 Further comments and discussion 4.5.1 Random number of active users All the bounds considered in this chapter assume thatK ais fixed and known to the receiver. The authors of [72] pose a very important and timely question: How do the fundamental limits change whenK aisrandomandunknownto the receiver? For this case, they derive the random coding bound (RCB), which is based on Gallager’s trick. Let us discuss the major differences in comparison to [5]. 72 We start with the decoding rule. Recall the rule from [5]: R= arg min R′⊆[M],|R′|=Ka∥y−s R′∥2, which is reasonable since the receiver knowsK a. The most straightforward way to generalize this rule is to consider: R= arg max R′⊆[M]( exp\" −∥y−s R′∥2 2# Pr[R′]) = arg min R′⊆[M]n ∥y−s R′∥2−2 log Pr[R′]o , where Pr[R′] is the prior distribution ofK a. The rule above is difficult to analyze because it requires considering all",
    "a. The most straightforward way to generalize this rule is to consider: R= arg max R′⊆[M]( exp\" −∥y−s R′∥2 2# Pr[R′]) = arg min R′⊆[M]n ∥y−s R′∥2−2 log Pr[R′]o , where Pr[R′] is the prior distribution ofK a. The rule above is difficult to analyze because it requires considering all possibleR′, which makes the union bound greatly overestimate the desired probability. To address this, the authors of [72] propose a two-stage approach. First, they estimateK ausing the following rule: ˆKa= arg max K∈[K l,Ku]m(y, K), wherem(y, K) is a suitably chosen metric, andK landK uare appropriately selected lower and upper bounds forK a. Then, given ˆKa, the receiver outputs: R= arg min R′⊆[M],K ≤|R′|≤K∥y−s R′∥2, whereK = max{K l,ˆKa−r}, K= min{K u,ˆKa+r}, andris a nonnegative integer referred to as thedecoding radius. We do not present the final theorem here but note that the techniques are very similar to those in [5]. However, in this case, one must consider bothP eandP fsince the output list size is a random variable. We discuss the bound for randomK awhen presenting the numerical results in Section 4.6. 4.5.2 Gordon’s lemma and achievability improvements Let us once again look at Fano’s approach and the good region from Theorem 4.2. Recall that we decided not to uses Fin the region description to avoid a large binomial coefficient\u0000M−K a t\u0001 . Are there any other ways to calculate the probability Pr [Bc] without using the union bound and the large binomial coefficient? In this section, we describe the approach from [87], which relies on Gordon’s inequality [88] for the expectation of the minimum of the Gaussian process. As shown in [85], the techniques from [87] can be reformulated as an instance of Fano’s method. 73 As an example, let us consider the following simplified region: B={∥s F∥ ≥p βn}. Recall that Pr [E t]≤Prh Et\\ Bi + Pr [Bc], and for the first term (Pr [E tTB]), we can proceed exactly as in the proof of Theorem 4.2. We omit this and only consider Pr [Bc]. We have Pr [Bc] = Pr [ F⊂[M]\\[K a]{∥sF∥<p βn}  = Pr\u0014 min F⊂[M]\\[K a]∥sF∥<p βn\u0015 . The latter term can be upper-bounded using concentration properties and Gordon’s inequality. Let us mention the main ingredients. Definition 4.1(Gaussian width).Given a closed setS ⊆Rd, its Gaussian widthw(S)is defined as w(S) =E\u0014 max x∈S{gTx}\u0015 , whereg∼ N(0,I d). Theorem 4.5(Gordon’s theorem, [88]).LetG∈Rk×dbe a random matrix with i.i.d. entries gi,j∼ N(0,1), i∈[k], j∈[d], andS ⊆Sd−1be a closed subset of the unit sphere inddimensions. Then E\u0014 max x∈S∥Gx∥\u0015 ≤ak+w(S), E\u0014 min x∈S∥Gx∥\u0015 ≥ak−w(S), wherea k=E[∥g∥],g∼ N(0,I k), andw(S)is the Gaussian width of the setS. Recall that ak=√ 2Γ((k+ 1)/2)/Γ(k/2)satisfies k√ k+ 1≤ak≤√ k. Lemma 4.1(Gaussian concentration, see e.g. [89, Corollary 3.3]).Letf:Rd→Rbe anℓ-Lipschitz function andg∼ N(0,I d). Then, Pr [f(g)≥E g[f] +t]≥1−e−t2 2ℓ2, Pr [f(g)≤E g[f]−t]≤e−t2 2ℓ2. 74 Lemma 4.2(Size of the maximum).Letg= [g 1, . . . ,g d]∼ N(0,Σ)andE[∥g i∥2] = 1fori∈[d]. Irrespective of the covariance structure, we have the following bound: E\u0014 max i∈[d]gi\u0015 ≤p 2 logd. Proof. E\u0014 max i∈[d]gi\u0015 =1 βE\u0014 log exp[βmax",
    "Pr [f(g)≥E g[f] +t]≥1−e−t2 2ℓ2, Pr [f(g)≤E g[f]−t]≤e−t2 2ℓ2. 74 Lemma 4.2(Size of the maximum).Letg= [g 1, . . . ,g d]∼ N(0,Σ)andE[∥g i∥2] = 1fori∈[d]. Irrespective of the covariance structure, we have the following bound: E\u0014 max i∈[d]gi\u0015 ≤p 2 logd. Proof. E\u0014 max i∈[d]gi\u0015 =1 βE\u0014 log exp[βmax igi]\u0015 ≤1 βE logX i∈[d]exp[βg i]  ≤1 βlogX i∈[d]E[exp[βg i]] =β 2+logn β. Takingβ= lognyields the lemma statement. Let us now return to our problem. Recall that we consider the case of a Gaussian codebookX. Let G=X [M]\\[K a]. The matrixGis of sizen×(M−K a), withg i,ji.i.d.∼ N(0, P′). Pr\u0014 min F⊂[M]\\[K a]∥sF∥<p βn\u0015 = Pr\u0014 min x∈{0,1}M−K a,∥x∥0=t∥Gx∥<p βn\u0015 ≤exp\u0012 −c2 2ℓ2\u0013 , where (x) += max{x,0}, c=\u0010 µ−p βn\u0011 +, and µ=E\u0014 min x∈{0,1}M−K a,∥x∥0=t∥Gx∥\u0015 ≥n√ P′t√n+ 1−s 2P′tln\u0012M−K a t\u0013 . Note that the functionF(G) = minx∈{0,1}M−K a,∥x∥0=t∥Gx∥isℓ-Lipschitz withℓ=√ t. Indeed, |F(G 1)−F(G 2)| ≤max x∈{0,1}M−K a,∥x∥0=t|∥G1x∥ − ∥G 2x∥| ≤max x∈{0,1}M−K a,∥x∥0=t[∥(G 1−G 2)x∥] ≤√ t∥(G 1−G 2)∥2,2≤√ t∥(G 1−G 2)∥F, where ∥A∥α,β≜sup x:∥x∥α≤1∥Ax∥β. 75 0 50 100 150 200 250 300−1−0.500.511.52RCB, Gaussian codebook, Theorem 4.1 RCB, Gaussian codebook, Theorem 4.2 RCB, Gaussian codebook, Theorem 4.3,α= t/Ka RCB, Gaussian codebook, Theorem 4.3, optimalα RCB, Binary codebook, Theorem 4.4 Converse: Theorems 3.1 and 3.2 The number of active usersK aEb/N0, dBFigure 4.3: AWGN MAC achievability bounds are presented fork= 100 information bits, a frame length ofn= 30000, and an error probability constraint ofP e<0.05. The converse bound is depicted as a single line, representing the maximum of the results from Theorems 3.1 and 3.2. We use the result of this lemma to analyze the asymptotic regime presented in Appendix F. This lemma proves to be highly efficient, and the resulting achievability bound coincides with the converse bound. However, we do not evaluate this lemma in the FBL regime, as it yields energy efficiency estimates several decibels higher than those presented below. 4.6 Numerical evaluation Let us consider a setup with a frame length ofn= 3×104real channel uses andk= 100 information bits transmitted by each active user. This setup was proposed in [5] and [90]. We begin with a known number of active users. We selectP e<0.05 and analyze the minimum energy per bit (E b/N0) as a function of the number of active users,K a. The RCB (Theorem 4.1, [5]) is represented in Fig. 4.3 by a dashed green line. A surprising observation is that the energy per bit remains nearly constant—almost as if only a single user were transmitting—until reaching a 76 0 50 100 150 200 250 300−10123456 Theorem 4.1, knownK a [72], RandomK a,Pf<10−1 [72], RandomK a,Pf<10−3 The number of active usersK aEb/N0, dBFigure 4.4: AWGN MAC achievability bounds are presented fork= 128 information bits, a frame length ofn= 19200, an error probability constraint ofP e<0.1, and a random number of active users. Results for different values ofP fare shown. A stricter FAR requirement leads to a higher requiredE b/N0. critical value ofK a(for the parameters from Theorem 4.1, this value is approximatelyK a≈150). Thus, the performance isnoise-limited. The key takeaway is that additional users can",
    "and a random number of active users. Results for different values ofP fare shown. A stricter FAR requirement leads to a higher requiredE b/N0. critical value ofK a(for the parameters from Theorem 4.1, this value is approximatelyK a≈150). Thus, the performance isnoise-limited. The key takeaway is that additional users can be accom- modated without increasing energy requirements until a critical threshold is reached. The primary reason for this effect is that the dominant probability, Pr [E t], in (4.2) corresponds tot= 1 when Kais small. However, asK aincreases, the last term,t=K a, becomes dominant due to the large combinatorial factor\u0000M−K a t\u0001 , which results in theinterference-limitedregime. Next, let us consider the RCB based on Fano’s trick (Theorem 4.2). The resulting energy efficiency is presented by a solid black line. As can be seen in Fig. 4.3, the results obtained for the Gaussian (Theorem 4.2) and binary (Theorem 4.4) codebooks are almost identical and very close to the original achievability bound from Theorem 4.1 (e.g., for 250 active users, the values are 1.210 dB, 1.211 dB, and 1.154 dB, respectively). The results for the RCB, based on a combination of tricks (Theorem 4.3), are shown by dashed 77 green and magenta lines forα=t/K aand the optimizedα, respectively. We highlight both curves to improve the original bound from Theorem 4.1 for large values ofK a. Next, let us consider a random number of active users [72]. For this bound, we evaluate the previously defined energy efficiency as a function of the average number of active users. We note that the number of active users follows a Poisson distribution. The main challenge here is the presence of two probabilities:P e(3.1) andP f(3.2). The results are presented forn= 19200,k= 100, andP e<0.1, as shown in Fig. 4.4. When the condition Pf<0.1 is imposed, the bound for a randomK a(depicted by a solid green line) demonstrates energy efficiency very close to that of the bound for a knownK a[5] (depicted by a black line). Surprisingly, imposing stricter limits onP f(e.g., 10−3instead of 10−1) results in an additional gap of approximately 2 dB. The achievability bound forP f<10−3is depicted by a dashed green line. Furthermore, the tran- sition between noise-limited and interference-limited regimes (caused by the behavior of different terms in (4.2)) becomes indistinguishable. Remark 4.7.A stricter FAR requirement leads to a higher requiredE b/N0. In the extreme case whereP f→1, we obtainE b/N0→0(or−∞dB). Indeed, in this scenario, the receiver can take the entire codebook as the list of decoded messages, leading toP e= 0andP f= 1. 78 Chapter 5 URA over Gaussian MAC: low-complexity schemes In this chapter, we address the problem of constructing low-complexity coding schemes for the URA over Gaussian MAC (G-URA). The main challenges we aim to overcome are as follows: •Ultra-low rate: if we look at Section 3.4, we observe that the coding rate is≈1/300 bits per channel use for typical values of parameters of interest. •Largecollision order1in a frame:K acan be as high as 500. •Same codebook. The existing MAC coding schemes are efficient in two opposite situations: 1. Large dimension,",
    "if we look at Section 3.4, we observe that the coding rate is≈1/300 bits per channel use for typical values of parameters of interest. •Largecollision order1in a frame:K acan be as high as 500. •Same codebook. The existing MAC coding schemes are efficient in two opposite situations: 1. Large dimension, or equivalently, codebook size, and a small collision order, typically not exceeding 2–4. 2. Large collision order and a small codebook size, typically on the order of 215. The latter case corresponds to the classical CS problem with standard decoding algorithms such as LASSO, non-negative least squares (NNLS), or OMP; see the description in Appendix B. Thus, the task of URA is to support a huge number of extremely low-bit-rate user streams, which appears to be much more complex than supporting a small number of users, each with a high bit rate. Finally, the same encoder assumption introduces additional challenges. Indeed, all low-complexity schemes described in Chapter 2 utilize single-user decoders (explicitly or implicitly). The same codebook and equal powers eliminate user diversity and thus do not allow relying on single-user decoders. 1In the G-URA setup, acollisionis understood as multiple simultaneous transmissions in the frame or slot, depending on the context, and theorder of collisionequals the number of simultaneous transmissions. 79 As an example, we consider the case of a two-user MAC, where users utilize LDPC codes. When LDPC codes are different2, the performance of the system is good and even close to the point on the dominant facet whenn→ ∞[52]. At the same time, when the same code is used, the system performs extremely poorly. We return to this case at the end of the chapter to provide some recent results and formulate open problems. Before we proceed with the detailed description, we formulate two main ideas behind all existing low- complexity schemes for the URA channel: (a) sparsifying the collisions and (b) splitting the high- dimensional problem into a number of low-dimensional ones. If we return to the CS interpretation (see eq. (3.5)), the task can be formulated as follows: find the sensing matrixXsuch that low- complexity algorithms do exist. See the examples of sensing matrices of URA low-complexity schemes in Appendix C. The question of low-complexity URA schemes for the GMAC is widely addressed in the literature. Below, we present the main techniques: •Schemes based on theT-fold coded SA protocol or ALOHA with multi-packet reception (Section 5.1). •Schemes based on IDMA techniques [91] were proposed in [92] (Section 5.2). •CCS approach [93] and modifications that includet-error correcting list-recoverable codes [94], SPARCs combined with the AMP algorithm [95], iterative approaches [96], where the inner AMP decoder and the outer tree decoder are allowed to exchange soft information within a joint message-passing algorithm (Section 5.3). •Random spreading and correlation-based energy detector with polar codes and equal power levels [97], polar codes and different power levels [98], LDPC codes and SIC within the decoding process [99] (Section 5.4). The presentation of low-complexity schemes is followed by a discussion on the applicability of the same linear codes to the G-URA problem in Section",
    "with polar codes and equal power levels [97], polar codes and different power levels [98], LDPC codes and SIC within the decoding process [99] (Section 5.4). The presentation of low-complexity schemes is followed by a discussion on the applicability of the same linear codes to the G-URA problem in Section 5.5. Finally, a numerical comparison of the presented schemes is provided in Section 5.6. The main results are summarized in Fig. 5.15. 5.1T-fold coded slotted ALOHA In this section, we focus on the IRSA protocol presented in Section 2.3.4 and analyze the achievable energy efficiency under PUPE constraints (3.3), instead of throughput. This protocol assumes that users send multiple replicas of the same packet (repetition), forming a subclass of coded SA protocols. A key aspect of the URA problem is the large number of devices, which leads to a high collision probability, making collision resolution necessary. 2Different codes can be created from one LDPC code by means of different interleavers, or one can consider two different cosets of the same LDPC code. 80 T-fold IRSA (or IRSA with multi-packet reception) enables the resolution of collisions up to order T. Recall that in the classical collision model described in Section 2.3.1, messages from a collided slot cannot be extracted. However, in an AWGN channel, the successful reception of multiple transmissions—up toT—may be possible with a suitable slot decoding algorithm. The details of this algorithm will be outlined throughout this section, depending on the particular scenario. The value ofTis determined by computational complexity limitations at the receiver. We begin with the IRSA protocol description in Section 5.1.1, followed by the DE analysis in Section 5.1.2. Next, we present aT-fold IRSA achievability bound formulated in Theorem 5.2. Some IRSA modifications adopted for practical schemes are introduced in Section 5.1.3, followed by an analysis of practical collision-resolution methods. These methods, based on LDPC codes [100] and polar codes [101], as well as the compute-and-forward strategy [102], which was applied to the URA setup in [90], are presented in Section 5.1.4. 5.1.1 BasicT-fold IRSA scheme In this section, we describe the basicT-fold IRSA protocol used in [100]. The main difference from previous works [15, 103, 104] is that we do not add pointers to the locations of the replicas. Instead, we determine the slot count and slot indices based on the message to be transmitted. Assume the frame is split intoLslots of sizen′=n/Lchannel uses. We now describe the main features of the transmission process: •The user chooses a messageW∼Unif ([M]), encodes it, and obtains a codewordf(W)∈Rn′. •Users repeat their codewords in multiple slots. To choose the slots, all users sharethe same slot-selection functiong: [M]→ {0,1}L, i.e., the codewordf(W) is transmitted in the slots with indices from supp (g(W)). •The functiongalso determines the number of replicasD: [M]→[L], whereD(W) = wt (g(W)). •The uniform message distribution induces the replica count distribution, i.e., the distribution of the random variableD(W), which is the same for all users. Remark 5.1.We note that the functionsg(·)andD(·)are deterministic functions of the message. This fact is crucial because the receiver does not know the positions of",
    "= wt (g(W)). •The uniform message distribution induces the replica count distribution, i.e., the distribution of the random variableD(W), which is the same for all users. Remark 5.1.We note that the functionsg(·)andD(·)are deterministic functions of the message. This fact is crucial because the receiver does not know the positions of multiple replicas until the message is decoded in at least one slot. Once the message is decoded, the receiver can determine from which slots the replicas of the decoded message should be removed and then perform the SIC step. Remark 5.2.In our analysis (see Section 5.1.2), we assume that the slot-selection functiong(·) is designed such that, for a given number of replicasd=D(W), the slot indices are selected uniformly from the\u0000L d\u0001 possible choices. In practical schemes, we constructg(·)to approximate this assumption as closely as possible. One possible approach is to use the messageWas a seed for a pseudo-random number generator. Once the message is recovered, the receiver sets the same seed and determines the replica locations. 81 Slot 1A User ASlot 2B User BSlot 3C User CSlot 4D User DSlot 5E User EFigure 5.1: Example of a bipartite graph (top) corresponding to the case of 5 active users trans- mitting in 5 slots (bottom). User-nodes are labeled A–E and have different colors. Slot-nodes are marked by numbers. The messages transmitted in different slots are represented by colored rectangles, with each color matching a different user. Bipartite graph representation.The transmission and decoding processes can be described using a bipartite graph (see Fig. 5.1), known as a Tanner graph [105]. The vertex set of this graph consists of the set of user-nodesU={u 1, u2, . . . , u Ka}, which represents the users, and the set of slot-nodesS={s 1, s2, . . . , s L}, which corresponds to the signals received in the slots. A user-node uiand a slot-nodes jare connected by an edge if and only if thei-th user transmitted a packet in thej-th slot. Following [65], we represent user-node degree distributions from both the node and edge perspectives using polynomials (or generating functions). Specifically, we introduce the polynomials: Λ (x) =LX i=1Λixi,andλ(x) =Λ′(x) Λ′(1)=LX i=1λixi−1,(5.1) where Λ idenotes the fraction of user-nodes with degreei, andλ idenotes the fraction of edges incident to user-nodes of degreei. Here, Λ′(x) represents the derivative with respect to the formal variablex. Note that Λ′(1) =LX i=1iΛi is the average degree of user-nodes. Example 5.1.Consider the graph in Fig.5.1. We have: Λ (x) =1 5x+2 5x2+1 5x3+1 5x4, and λ(x) =1 1 5+4 5+3 5+4 5\u00121 5+4 5x+3 5x2+4 5x3\u0013 =1 12+1 3x+1 4x2+1 3x3. Similar to (5.1), we define the slot-node degree distributions from the node perspectiveR(x) and 82 the edge perspectiveρ(x) as follows: R(x) =KaX i=0Rixi,andρ(x) =KaX i=1ρixi−1. Next, we compute the probability that a user selects any given slot (denoted by eventE). Since the process does not depend on specific user or slot indices, we omit them for simplicity. Let the user transmitdreplicas. Following Remark 5.2 (uniform slot selection), we obtain: Pr[E|D=d] =\u0000L−1 d−1\u0001 \u0000L d\u0001=d L, which implies Pr[E] =E D[Pr[E|D]] =Λ′(1)",
    "a user selects any given slot (denoted by eventE). Since the process does not depend on specific user or slot indices, we omit them for simplicity. Let the user transmitdreplicas. Following Remark 5.2 (uniform slot selection), we obtain: Pr[E|D=d] =\u0000L−1 d−1\u0001 \u0000L d\u0001=d L, which implies Pr[E] =E D[Pr[E|D]] =Λ′(1) L=GΛ′(1) Ka, whereG=K a/LandGΛ′(1) represents the average degree of slot-nodes. Thus, the slot-node distribution (from the node perspective) follows a binomial distribution: Bino\u0012 Ka,GΛ′(1) Ka\u0013 . That is, definingγ=GΛ′(1), we obtain: R(x) =KaX i=0\u0012Ka i\u0013\u0012γ Ka\u0013i\u0012 1−γ Ka\u0013Ka−i xi =\u0012 1−γ Ka\u0013Ka 1 +γ Kax 1−γ Ka!Ka .(5.2) Decoding.Now, let us describe a general approach to the decoding algorithm, which is based on two main procedures: 1. The slot decoding algorithm, which outputs the list of decoded3messages. 2. The SIC step, which relies on the functiong(·) and subtracts replicas (if present) of success- fully decoded messages. Clearly, after a single SIC step, the collision order will decrease in some slots. Hence, these steps may be iteratively repeated in different combinations with respect to different slots, depending on the particular decoding algorithm. We refer the reader to Section 5.1.4 for specific practical slot decoding algorithms. The example below considers a slot decoding sequence for the messages presented in Fig. 5.1. 3Note that this is an estimate of the transmitted list, so some messages can be missing and some false messages may be added by the decoder. The issue of false messages should be addressed by the decoder to avoid error propagation within the SIC process. One possible solution is to add control information (e.g. add the CRC) to the packet. 83 1 A2 B3 C4 D5 E 1 A2 B3 C4 D5 E 1 A2 B3 C4 D5 E 1 A2 B3 C4 D5 E 1 A2 B3 C4 D5 E Step 1 Step 2 Step 3 Step 4 Step 5Figure 5.2: Sequence of slot decoding followed by SIC steps applied to the case presented in Fig. 5.1 forT= 1. The bold line corresponds to the edge incident to the slot that can be decoded at the corresponding step. At the subsequent SIC step, all edges incident to the same user-node as the bold one will be removed. Resolved slots are marked with a white background, unresolved slots are marked with a gray background. Resolved users are marked with a color that matches Fig. 5.1. Example 5.2.Consider the example withK a= 5active users andL= 5slots, as presented in Fig.5.1. Assume the first user (A) sends a codeword in slots 1, 2, and 3; the second user (B) in slots 1, 2, 3, and 5; the third user (C) in slots 1 and 2; the fourth user (D) in slots 4 and 5; and the fifth user (E) in slot 2. As a result, there are 3 simultaneous transmissions in slot 1, 4 transmissions in slot 2, collisions of order 2 in slots 3 and 5, and the only collision-free slot is slot 4. Consider a decoder withT= 1(see Fig.5.2). The decoder searches for a collision-free slot, then decodes the message transmitted in this",
    "there are 3 simultaneous transmissions in slot 1, 4 transmissions in slot 2, collisions of order 2 in slots 3 and 5, and the only collision-free slot is slot 4. Consider a decoder withT= 1(see Fig.5.2). The decoder searches for a collision-free slot, then decodes the message transmitted in this slot and subtracts this message from all slots where it was replicated. There is a natural question: how does the decoder select the collision-free slot? The strategies may be different, but one of them is to try all slots in parallel with a decoder designed for T= 1. Another reasonable strategy is to select the slot with the minimal received energy. The SIC step begins after the successful decoding of slot 4 at step 1 (with all remaining slots marked gray, indicating slots with collisions) and decodes the message of user D. The corresponding edge in the bipartite graph is marked with a bold line. After the SIC step, all edges incident to the successfully decoded user (D, in this case) are removed, as all transmitted replicas are subtracted. At the second decoding step, slot 5 becomes collision-free, resulting in the successful decoding of user B. The third step resolves slot 3, allowing user A to be decoded. After the SIC step, slot 1 becomes collision-free. In the final step, user E, who transmitted in slot 2, can be decoded. For a decoder withT= 2, the decoding algorithm may behave differently. For instance, slots 3, 4, and 5 have a collision order not higher than two. Hence, these slots may be decoded first in any order. After the corresponding SIC steps, the collision order of slot 1 will be reduced to one (collision-free transmission), and slot 2 will have a collision order of two. Moreover, decoding slot 2 will be sufficient to extract all remaining messages in the frame. 84 5.1.2 Achievability bound forT-fold IRSA scheme Slot decoding Let us first note that, in order to obtain an achievability bound for the whole scheme, we do not restrict the complexity of slot decoding and instead use the random coding bounds described in Chapter 4. Consider a particular slot—w.l.o.g., let it be the first slot. Lety 1be the received signal ofn′ channel uses. We assume thatrusers transmit in the first slot. Recall thatkdenotes the number of information bits sent by each user and thatPis the transmit power. The random coding bound from Theorem 4.1 states that, in the random Gaussian ensembleG\u0000 2k, n′, P\u0001 (see Definition 4.1), there exists a codebookX∗such that 1 rrX i=1Pr (W i̸∈ R(y 1)|X∗) = Pr (W 1̸∈ R(y 1)|X∗) ≤p\u0000 n′, k, P, r\u0001 ≜EX[Pr (W 1̸∈ R(y 1)|X, r)]. The first equality holds due to the symmetry of users (it is sufficient to consider the probability that a particular user’s message is not in the decoded list). The last expectation is taken over the Gaussian ensemble. Here, we emphasizethe main problem—the bound assumes that the number of active users (r) is known. However, due to the randomness ofT-fold IRSA, the number of users transmitting in a",
    "that a particular user’s message is not in the decoded list). The last expectation is taken over the Gaussian ensemble. Here, we emphasizethe main problem—the bound assumes that the number of active users (r) is known. However, due to the randomness ofT-fold IRSA, the number of users transmitting in a particular slot is a random variable. Another issue is that the codebookX∗is constructed for a specific number of users, but we need a codebook that can resolve collisions for any orderr∈[T]. To address these issues, the authors of [106] propose shifting to blind decoding. Let T={W 1, . . . , W r} ⊂[M],where|T |=r, denote the set of transmitted messages. The blind ML decoding rule is given by: R= arg min R′⊆[M],|R′|≤T∥y1−sR′∥2.(5.3) Recall thatTis the maximum collision order that can be resolved. Theorem 5.1.FixP′andT. Then, the average (over the random Gaussian ensemble) per-user error probabilities can be calculated as follows forr∈[T]: EX[Pr (W 1̸∈ R(y 1)|X, r)]≤rX t=1t rpt(r, T), where pt(r, T) =T−r+tX ˆt=0exp\u0002 −nE\u0000 t,ˆt\u0001\u0003 ,(5.4) 85 E(t,ˆt) = max 0≤ρ,ρ 1≤1,λ>0[−ρ1ρ2R1−ρ1R2+E 0(ρ1, ρ2)], R1=1 nlog\u0012M−r ˆt\u0013 , R 2=1 nlog\u0012r t\u0013 , E0(ρ1, ρ2) =1 2(ρ1a+ log(1−2bρ 1)), a=ρ 2log\u0000 1 + 2P′ˆtλ\u0001 + log\u0000 1 + 2P′tµ\u0001 , b=ρ 2λ−µ 1 + 2P′tµ, µ=ρ2λ 1 + 2P′ˆtλ. Proof.The proof of this theorem follows the same structure as that of Theorem 4.1, with the main difference being in the summation limits of (5.4). We now need to choose a codebook that is effective for all collision orders up toT. Let us formally state this requirement. Statement 5.1.Let us choose positive valuesα i, fori∈[T], such thatPT i=1αi<1. In a random Gaussian ensemble, there exists a codebook ˜Xsuch that the following inequalities hold for allr∈[T]: Pr\u0010 W1̸∈ R(y 1) ˜X, r\u0011 ≤˜p(n, k, P, T, r) ≜1 αiEX[Pr (W 1̸∈ R(y 1)|X, r)]. Proof.We estimate the probability of a bad code—one for which the inequalities do not hold for at least oner. Applying Markov’s inequality and a union bound, we see that this probability is upper-bounded by TX i=1αi<1. Finally, we refer the reader to Section 4.5.1, where the problem of a random number of active users has been addressed. The results presented in Section 4.5.1 were developed later and can serve as an alternative approach to theT-fold IRSA achievability bound. Performance analysis via density evolution The iterative SIC procedure can be analyzed by means of the DE method proposed in [15, 107] for IRSA. This approach is, in fact, equivalent to the DE analysis for LDPC codes [65] over the erasure channel. We consider message passing decoding, where slot-nodes and user-nodes send outgoing 86 User nodeu Iteration 2 Iteration 1Figure 5.3: Computational graph: Neighborhood of user nodeufor 2 iterations. Slot node User node Root node xl yl yℓ xl yl yℓ xl yl yℓ· · · · · · · · ·yl+1 xl+1 xℓ r−1 i−1 i r−1 i−1 i r−1 i−1 i Figure 5.4: IRSA DE rules. Left: Messages to the slot node at intermediate iterationl, center: Messages to the user node at intermediate iterationl, right: Messages to",
    "yl yℓ xl yl yℓ· · · · · · · · ·yl+1 xl+1 xℓ r−1 i−1 i r−1 i−1 i r−1 i−1 i Figure 5.4: IRSA DE rules. Left: Messages to the slot node at intermediate iterationl, center: Messages to the user node at intermediate iterationl, right: Messages to the user node at the final iterationℓ. messages along each edge. Each message can take two possible values: either the recovered packet or an erasure4if the packet cannot be recovered. We consider the ensemble of Tanner graphsG(K a, L, λ(x), ρ(x)) corresponding to the multiple- access scheme withK ausers,Lslots, and the degree distributionsλ(x) andρ(x). We are interested in the decoding performance averaged over this ensemble in the limit asK a, L→ ∞. Note that in the limitK a→ ∞, the distribution (5.2) becomes a Poisson distribution, i.e. R(x) =ρ(x) =e−γ(1−x)=∞X r=1γr−1 (r−1)!xr−1=∞X r=1ρrxr−1, whereγ=GΛ′(1) should remain constant. Let us choose a slot-nodeu. Message passing takes place on the local neighborhood of this node. If we unroll the Tanner graph with the root at user-nodeu, we obtain the computation graph depicted in Fig. 5.3. In what follows, we use the fact that any neighborhood of constant depth inG(K a, L, λ(x), ρ(x)) is tree-like with probability one. We refer the reader to [65] for a detailed explanation. We follow the exposition from [106]. Before we proceed with the DE rules, we list the main assumptions: 4In what follows, we use the term “erased message”. 87 1. A code ˜Xconstructed in accordance with Statement 5.1 is used in the system. 2. If the collision order is greater thanT, no message can be recovered from the slot. If the collision order ist < T, each message is recovered with probability ˜p(n′, k, P, T, t). 3. The genie reveals information on false packets, i.e., such packets are excluded from the SIC process. Remark 5.3.Note that the genie assumption prevents the described bound from being a true achievability bound. This bound is only an optimistic estimate of the performance achievable within aT-fold IRSA scheme. Now let us write the DE rules. Byx landy l, we denote the probabilities that an outgoing message (see Fig. 5.4) from the user-node and the slot node, respectively, are erased during thel-th iteration. Statement 5.2.The DE rules are described in the following form: yl+1 = 1−ρ(1−x l)T−1X t=0\u0000 1−˜p\u0000 n′, k, P, T, t+ 1\u0001\u0001 ×(GL′(1)x l)t t!, xl=λ(y l),1≤l < ℓ, xℓ= Λ (y ℓ), where the function˜p(n′, k, P, T, r)is defined in Statement 5.1, and the initial condition isx 0= 1, which means that the user messages are erased at the beginning, and we observe only the noisy signal sums in the slots. Proof.Consider thel-th iteration. Let us start with theslot node. We want to calculate the erasure probability of the outgoing messagey l+1based on incoming messages that are erased with probabilitiesx l. Let us start with a slot node of degreer. We can recover the outgoing message (or equivalently, the packet) if there are no more thanT−15erased messages out ofr−1 incoming messages. Finally, the outgoing message is",
    "probability of the outgoing messagey l+1based on incoming messages that are erased with probabilitiesx l. Let us start with a slot node of degreer. We can recover the outgoing message (or equivalently, the packet) if there are no more thanT−15erased messages out ofr−1 incoming messages. Finally, the outgoing message is erased with probability pr= 1−min(r,T)−1X t=0\u0000 1−˜p\u0000 n′, k, P, T, t+ 1\u0001\u0001\u0012r−1 t\u0013 xt l(1−x l)r−1−t. Note thatρ ris the probability that the outgoing edge is connected to a slot node of degreer (see [65]), thus the total probability of the erased outgoing message can be calculated as yl+1=∞X r=1ρrpr. By changing the summation order, we obtain the result from the proposed statement. 5In accordance with the DE rules, the outgoing message is assumed to be erased, and thus the total number of erased messages is no more thanT. 88 Now proceed with theuser-node. Clearly, the outgoing message is erased if all incoming messages are erased. Thus, for the node of degreei, the outgoing message is erased with probability qi=yi−1 l, and the total probability of the erased outgoing message can be calculated as xl=∞X i=1λiqi=λ(y l). The root node should be considered separately. The only change is in the total probability cal- culation. Here, we need to use the probabilities for the user-node (rather than the edge) to be connected to a slot node of degreei. Thus, xℓ=∞X i=1Λiqi= Λ (y ℓ). Theorem 5.2.Let us fixP′,n′,Λ (x), andℓ. Then, theT-fold IRSA scheme with the code ˜X achieves the PUPE (asK a, L→ ∞) Pe≤xℓ+ Pr [ i̸=j{Wi=W j} . Remark 5.4.We note that, in the case of LDPC codes over the erasure channel DE, one wants to find the so-called threshold (for the erasure probabilityε), i.e., εthr= sup\u001a ε∈[0,1] : lim ℓ→∞xℓ= 0\u001b . In our case, the graph is infinite, but the slot is finite, and it is not possible to achievelim ℓ→∞xℓ= 0 due to the presence of the˜p(n′, k, P, T, r)function. Remark 5.5.Clearly, the average transmitted energy can be calculated asn′P′Λ′(1). Thus, the energy per information bit is given by the following expression: Eb N0=n′P′Λ′(1) 2k.(5.5) Our main goal is to minimize the required energy per bitE b/N0given thatP e≤ε. In Section 5.6.1, we utilize the described DE method to choose the system parameters:n′and Λ (x). 89 W= [W p, Wc] x(W) =/bracketleftbig fp(Wp), ϕ Wp(f(W c))/bracketrightbig Repeat,g(W) 1 2 3 4 5 6 L· · ·Figure 5.5: IRSA-S encoding process. The transmitted messageWis split into two parts:W p, which defines the preamblef p(Wp) and a transformϕ Wp(·), andW c, which is encoded using the same linear code with the encoding functionf(·), followed by a transformϕ Wp(·) (e.g., interleaving). The number of replicas and slot indices are determined by a functiong(W). Slots are represented by a row of green rectangles. Note that the entire message, including the preamble, is transmitted within each chosen slot. For clarity, we omit the user message index. 5.1.3T-fold IRSA modifications for the G-URA Recall the main problem: we need the same codebook scheme, while existing linear codes (such as LDPC and",
    "row of green rectangles. Note that the entire message, including the preamble, is transmitted within each chosen slot. For clarity, we omit the user message index. 5.1.3T-fold IRSA modifications for the G-URA Recall the main problem: we need the same codebook scheme, while existing linear codes (such as LDPC and polar codes) perform extremely poorly in this regime. We refer the reader to Section 5.5 for a detailed discussion of this issue. Hence, we require a nonlinear same-codebook approach. A straightforward method is to use preambles (as illustrated in Fig. 5.5 and 5.6) that define a transformation over the codewords of a linear code. Preamble detection can be considered as a CS problem. Once a preamble is detected, the decoder can recover this transformation and decode the linear code. In what follows, we refer to the IRSA presented in Section 5.1.1 as basic IRSA protocol (IRSA-B) and describe two strategies proposed in [100, 92], namely IRSA with per-slot preambles (IRSA-S) and IRSA with per-frame preambles (IRSA-F). IRSA with per-slot preambles In this variant, the base protocol remains unchanged, i.e., the replica count and slot selection are determined based on the message. The main modification lies in the word to be transmitted in the slot. Consider thei-th user. We split the message into two parts:W i= [W i,p, Wi,c], whereW i,p∈[M p], Wi,c∈[M c], andM=M pMc. Analogously, the slot is divided into two parts of lengthsn pandn c, 90 such thatn′=np+nc. Now, let us describe the word to be transmitted: •Within the firstn psymbols, the user sends the preamblef p(Wi,p), wheref p: [M p]→Rnpis the encoder of a well-designed CS code. Note that the size of this code should not be large (Mp≤215), as we apply standard CS decoding algorithms such as LASSO, NNLS, or OMP. We discuss these codes and their decoding algorithms in Appendix B. •Within the lastn csymbols, we transmit the user codewordf(W i,c) transformed byϕ Wi,p, wheref: [M c]→Rncis the user code encoder6, and the family of functionsϕ W:Rnc→Rnc, withW∈[M p], is introduced to “create” different codes. In what follows, the functionϕis implemented either as a permutation or as an addition with a shift vector, both determined byW p. Thus, the word transmitted in the slot is given by: x(W i) = [f p(Wi,p), ϕWi,p(f(W i,c))]. Now, we describe the decoding process. Analogous to the IRSA-B, the graph is not known on the receiver side and is reconstructed during the decoding process. The slot decoding process then proceeds as follows: 1. Select a slot (preferably the one with the smallest estimated collision order, e.g., based on energy estimation). 2. Decode the preamble part using a CS algorithm. The output of this algorithm includes ˆr– an estimate of the collision order – the set of preamble parts{ ˆWi,p}, and the set of functions {ϕˆWi,p}, wherei∈[ˆr]. 3. Decode the user messages and obtain{ ˆWi,c}. We discuss specific decoding algorithms for LDPC and polar codes in Section 5.1.4. 4. Perform the SIC step. As a result of steps 1–3, we obtain the set of message estimates{ ˆWi}, wherei∈[ˆr]. Use the functiong(·) to",
    "set of functions {ϕˆWi,p}, wherei∈[ˆr]. 3. Decode the user messages and obtain{ ˆWi,c}. We discuss specific decoding algorithms for LDPC and polar codes in Section 5.1.4. 4. Perform the SIC step. As a result of steps 1–3, we obtain the set of message estimates{ ˆWi}, wherei∈[ˆr]. Use the functiong(·) to remove replicas. 5. Remove the slot from the slot list. If the list of slots is non-empty, return to step 1. Remark 5.6.Note that since we use a different codebook scenario in step 3, we do not need to solve the message assembling problem. For each ˆWp, we either reconstruct ˆWcor encounter a decoding failure. IRSA with per-frame preambles In the previous variant, slot-wise preambles were used, which simplify the requirements for the CS code and decoder. Indeed, one needs to solve the following CS problem: yp=A pup+zp,(5.6) 6As previously, the encoder is the same for all users. 91 Wp Wc fp(Wp) g(W p) x(W) =φ Wp(f(W c)) Repeat Preamble 1 2 3 4 5 6 L· · ·MessageFigure 5.6: IRSA-F encoding process. The transmitted messageWis split into two parts:W p, which defines the preamblef p(Wp) and a transformϕ Wp(·), andW c, which is encoded using the same linear code with the encoding functionf(·), followed by a transformϕ Wp(·). The number of replicas and slot indices are determined by a functiong(W p). All preambles are sent in a dedicated slot, depicted in orange, whileφ Wp(f(W c)) is sent in the chosen slots, marked by green rectangles. For clarity, we omit the user message index. whereu p= (u p,1, . . . , u p,Mp) and the sparsity wt (u p) =r≤T. Thus, the lengthn pcan be small. At the same time, we add preambles to all the slots, and thus the actual overhead isLn pchannel uses. An illustration of the corresponding sensing matrix is given in Appendix C. Another preamble placement was proposed in [92]. Again, consider thei-th user and split the message into two parts:W i= [W i,p, Wi,c], whereW i,p∈[M p],W i,c∈[M c], andM=M pMc. However, the main differences are as follows: •The codeword placement and replica count depend only onW i,p. •The preamble of lengthn pis placed before the frame, so the total lengthnis divided between the preamble (n p) andLslots of length (n−n p)/L. Let us consider the decoding process. 1. Decode the preamble part using a CS decoder, i.e., solve problem (5.6), where up= (u p,1, . . . , u p,Mp) and the sparsity wt(u p) =K a. This problem is more challenging compared to the slot-wise CS problem, and thus a stronger CS code is required. 2. Reconstruct the graph and{ϕ ˆWi,p}fori∈[K a]. Note that this is the most significant difference compared to the IRSA-S case. If all preambles are recovered, the graph and code transformations are known. 92 3. Apply the IRSA-B decoder with the known graph. In this case, we can select slots with the minimal user population. Remark 5.7.We note that both protocols (IRSA-S and IRSA-F) assume an additional degree of freedom: namely, the preamble and codeword energies can be different. These",
    "transformations are known. 92 3. Apply the IRSA-B decoder with the known graph. In this case, we can select slots with the minimal user population. Remark 5.7.We note that both protocols (IRSA-S and IRSA-F) assume an additional degree of freedom: namely, the preamble and codeword energies can be different. These energies should be chosen to optimize system performance. The only requirement is the total energy constraint: IRSA-S:(P pnp+Pcnc)L′(1)≤Pn,(n c=n′−np=n/L−n p) IRSA-F:P pnp+PcncL′(1)≤Pn,(n c=n′= (n−n p)/L) 5.1.4 Collision resolution methods In this section we consider collision resolution methods, i.e. we focus on one slot of lengthn′real channel uses and collision resolution capability 2≤T≤10. In what follows we assumer≤Tusers that transmitted the codewordsx(1),x(2), . . . ,x(r)have collided in the slot of interest y=rX i=1x(i)+z,z∼ N(0,I n′).(5.7) Compute and forward, IRSA-B We begin with the first scheme proposed for G-URA in [90]. Although this scheme exhibits poor energy efficiency7compared to fundamental limits and other URA schemes, it incorporates inspiring ideas. The scheme relies on the compute-and-forward strategy [102], which aims to recover integer combinations of packets rather than the packets themselves. To illustrate this idea, consider the following example. Suppose we have a two-user GMAC, where the users wish to transmit messagesW 1andW 2by sending codewordsf(W 1) andf(W 2). Recall thatf: [M]→Rn′and that the energy constraints are given by∥f(W 1)∥2≤Pn′and∥f(W 2)∥2≤ Pn′. The channel output is given by y=f(W 1) +f(W 2) +z,z∼ N(0,I n′). The standard low-complexity decoding strategy utilizes a TIN step combined with an SIC step. This can be done in different ways, e.g., in a hard manner, in a soft manner (soft SIC), or through message passing between two TIN decoders. Nevertheless, the first TIN decoder deals with effective noise of energy (P+ 1)n′, which is complicated. At the same time, if f(W 1) +f(W 2) =f(W 1⊞W 2),(5.8) then the receiver can decodeW 1⊞W 2as in the single-user case, i.e., without interference. In general, the operation⊞can be any arbitrary group operation, i.e., we only need (M,⊞) to be a group, whereMis the closure of the set{W i}M i=1under the group operation⊞. 7We note that the authors of [90] consider pureT-fold ALOHA rather thanT-fold IRSA, which may be the root cause of its poor performance. 93 In what follows, we use a particular⊞operation. Namely, the messages are represented as binary vectors of lengthk, and the⊞operation is an element-wise real addition of such vectors. Clearly, we haveM=Zk. Assume (5.8) holds, then the set Λ ={f(u)}u∈Zkforms a group under real addition, andfis an isomorphism8between (Zk,+) and (Λ,+). Thus, we come tolatticesand lattice codes[108]. Let us introduce necessary definitions. Definition 5.1.Ann-dimensional lattice,Λ, is a discrete additive subgroup ofRn. A lattice can always be described using a generator matrixB∈Rn×n: Λ ={λ=Bu,u∈Zn}. Definition 5.2.The Voronoi regionV(λ)of a lattice pointλis the set of all points inRnthat are closer toλthan to any other lattice point. Definition 5.3.LetR ⊆Rn. In what follows, we refer toRas a shaping9region. A lattice code Cis a finite subset of a latticeΛ: C= Λ\\ R. The code consists of a finite subset ofMpoints from the original lattice: C={λ 1, λ2, . . .",
    "are closer toλthan to any other lattice point. Definition 5.3.LetR ⊆Rn. In what follows, we refer toRas a shaping9region. A lattice code Cis a finite subset of a latticeΛ: C= Λ\\ R. The code consists of a finite subset ofMpoints from the original lattice: C={λ 1, λ2, . . . , λ M}, whereλ i∈Λ,i∈[M]. Usually, lattice codes are constructed using nested lattices and are callednested lattice codes. Definition 5.4.A latticeΛ cis said to be nested in a latticeΛ fifΛ c⊆Λ f. We will sometimes refer toΛ cas the coarse lattice andΛ fas the fine lattice. Definition 5.5.LetΛ fbe a lattice such thatΛ c⊆Λ f, and letV c(0)be the 0-centered Voronoi region forΛ c. Then, C= Λ f\\ Vc(0) is a nested lattice code. Note that a nested lattice codeCis isomorphic to the quotient group Λ f/Λc, i.e.,Cforms a group under addition modulo Λ c. We note that the use of lattice codes for MACs is natural, as electromagnetic signals exhibit linear superposition. The illustration of the transmission scheme using nested lattice codes is presented in Fig. 5.7. The aim of lattice coding is to denoise the sum of messages. Note that only a single-user decoder is required to accomplish this task, which is a clear advantage of this approach. Assume successful 8We need to extend the domain offfrom [M] toZkbased on (5.8). 9We do not specify any particular requirements forRin this definition. Clearly, it is reasonable to chooseRfrom convex bounded sets. From energy considerations, the closerRis to the ball centered at0, the better. 94 + +z f(W 1)f(W 2)yFigure 5.7: Illustration of nested lattice codes for GMAC. denoising has been carried out. The second phase is to recover the transmitted messages from the denoised sum. For this purpose, one may use an outer code for thenoiselessadder channel. The only requirement for such a code is unique decodability: all the sums of up toTcodewords are different. See Section 2.1 for details. Now, let us describe the scheme from [90]. Encoding.We start with the two-phase encoding process: 1. Encode the messageWfor the adder channel: xad=fad(W), wheref ad: [M]→Fk′ p. 2. Encodex adwith the lattice code: x=f lc(xad), wheref lc:Fk′ p→Rn′. Let us describe the main components. Outer code. The technique proposed in [25] is as follows. LetH= [h 1, . . . ,h M] be the parity-check matrix of aT-error-correcting code overF p. SetC ad={h 1, . . . ,h M}. This construction ensures the desired property: all sums of up toTcodewords (or columns) are distinct. For practical construction, one can use a BCH code overF pwith low-complexity decoding algorithms (e.g., the Berlekamp-Massey algorithm). Inner code. For practical implementation, we need a high-dimensional lattice with a low-complexity decoding algorithm. The authors of [90] proposed utilizing the so-called Construction A [108], i.e., Λ =C lc+pZn, 95 wherepis a prime number andC lcis ap-ary error-correcting code with a low-complexity decoding algorithm. Remark 5.8.Note that for Construction A, we haveΛ f= ΛandΛ c=pZn. Hence, modulo-Λ c reduction is straightforward: it is just a component-wise modulo-poperation, with the result in the interval[0, p). Now, consider the received",
    "lc+pZn, 95 wherepis a prime number andC lcis ap-ary error-correcting code with a low-complexity decoding algorithm. Remark 5.8.Note that for Construction A, we haveΛ f= ΛandΛ c=pZn. Hence, modulo-Λ c reduction is straightforward: it is just a component-wise modulo-poperation, with the result in the interval[0, p). Now, consider the received signal (5.7) and recall that rX i=1x(i)=λ∈Λ, i.e., this sum is a lattice point. Decoding.The paper [90] does not specify the lattice code explicitly. Instead, the authors suggest computing y′=ymodp= (λ+z) modp=c+ (zmodp), wherec∈ C lc, and propose using the FBL achievability bound [31] to characterize the capabilities ofC lc. Here, we describe the algorithm for some low-complexity soft-input codeC lcoverF p(e.g., LDPC or a polar code can be used). 1. Lety= [y 1, . . . , y n′]. The input of theC lcdecoder is the a priori distribution vector D= [d 1,d2, . . . ,d n′], where di= [Pr(c i= 0|y i), . . . ,Pr(c i=p−1|y i)], i∈[n′]. First, we calculateDas follows: di,m= Pr(c i=m|y i) =1√ 2π+∞X j=−∞, (j=mmodp)exp[−(y i−j)2/2]. Note that in practical implementation, it is reasonable to sum overj∈[y i−∆, y i+ ∆] for some fixed ∆. 2. DecodeC lc. We obtain yac=rX i=1x(i) ac. 96 3. Decode the outer code for the noiseless adder channel. Taking into account that the code consists of the columns of the BCH parity-check matrix,y acis nothing more than a syndrome. Indeed, we have yac=Hs, wheresis the indicator vector of transmitted messages, i.e.,{W 1, . . . , W r}= supp(s). Thus, we arrive at the classical BCH code decoding problem. Note thatr≤Tand our code is aT-error-correcting code. Remark 5.9.The paper [90] focuses on the casep= 2, as binary codes are well-developed and significantly outperform non-binary ones in terms of soft decoding complexity. In what follows, we consider the casep= 2, in which caseDcan be replaced with the input log-likelihood ratio (LLR) vector. Remark 5.10.One may argue that BCH decoding has high complexity since the parity-check matrix Hhas sizen′×M(recall thatM= 2kandk= 100bits is of interest). Classical BCH decoding involves calculating the syndrome, which has linear complexity inM(thus, exponential complexity in k). However, there is no need to calculate the syndrome in our case, as this operation is performed in the channel, and we receive it directly. It can be shown (see [90]) that the complexity of BCH decoding isO(kT2log2(T) log log(T))operations inF2k. Remark 5.11.In the scheme described above, users transmit symbols from the set{0,√ 2P}(or equivalently,{0,1}under the power constraintP). In a practical implementation, it is more rea- sonable to use the set{−√ P,√ P}, which corresponds to a lattice coset. See [90] for further details. IRSA-S with LDPC codes In this section, we consider the IRSA-S scheme (presented in Section 5.1.3), which is based on LDPC codes [100]. We employ a joint iterative decoding algorithm with low computational com- plexity [109, 52]. Recalling the IRSA-S scheme, the slot is divided into two parts, such thatn′=n′ p+n′ cchannel uses. In the first part, we utilize BCH subcodes, as described in Appendix B.2.3, as a suitable candidate for the CS codebook.",
    "employ a joint iterative decoding algorithm with low computational com- plexity [109, 52]. Recalling the IRSA-S scheme, the slot is divided into two parts, such thatn′=n′ p+n′ cchannel uses. In the first part, we utilize BCH subcodes, as described in Appendix B.2.3, as a suitable candidate for the CS codebook. The preamble is recovered using the methods detailed in Appendix B. Now, let us focus on the joint decoding of the LDPC codes positioned in the lastn′ cchannel uses. We define different codebooks,C 1, . . . ,C r, which are derived from a common codebookCthrough random permutations based onϕ Wp. The received signal in the slot is given by (5.7), wherex(i)=τ\u0000 c(i)\u0001 is a BPSK-modulated codeword of each active user. To recover users’ codewords, we employ a decoder based on the iterative belief propagation (BP) algorithm, which is a specific case of the broader class of MPAs. The decoding procedure can be represented as a graph (factor graph) [110], shown in Fig. 5.8. There are three types of nodes in the graph. The LDPC codes of the users are represented by Tanner graphs with variable nodes (orange) and check nodes (blue). For the variable and check 97 Message 2 Message 1 yC1 C2Figure 5.8: The joint decoding algorithm and factor graph for the caser= 2 are illustrated. Orange circles and blue squares represent the variable and check nodes of the LDPC codesC 1 andC ∈, respectively. The messages exchanged between these nodes follow the standard decoding procedure of LDPC codes. Additionally, there are functional nodes, depicted as green triangles, that represent the received signaly. nodes in the subgraphs of different users, the message exchange rule follows the same procedure as in the single-user case (see [65]). Additionally, there is a third type of node in the graph – functional nodes (marked by green triangles). These nodes correspond to the elements of the received signaly. To fully specify the decoding algorithm, we need to describe the messages exchanged between the variable nodes of each user’s code and the functional nodes (Message type 1), as well as the messages from the functional nodes to the variable nodes of the users’ codes (Message type 2). Message type 1 (from functional nodes to LDPC codes).Following the principles of message-passing algorithms [65], the update rule to compute the messageµsent to thej-th variable node of thei-th user (j∈[n′ c],i∈[r]) from the functional nodeF jis given as follows. First, let us fix the index of the functional nodejand omit it for clarity (as thej-th functional node may only be connected to thej-th variable node of each user’s LDPC code; see Fig. 5.8). Let y=y jbe the signal received at thej-th position. Letb∈ {0,1}rrepresent a binary vector, where bicorresponds to the bit value of thei-th user’s codewordc(i). Also, introduce a function: η(b) =p(y|b) = exp  − y−rX i=1τ(b i)!2  ,(5.9) which represents the p.d.f. of the received signal conditioned onb, up to some constant multiplier that can be ignored when considering likelihood ratios. Note thatbcompletely defines the noiseless received signal. Letµ i→Fbe the message sent from thei-th",
    "a function: η(b) =p(y|b) = exp  − y−rX i=1τ(b i)!2  ,(5.9) which represents the p.d.f. of the received signal conditioned onb, up to some constant multiplier that can be ignored when considering likelihood ratios. Note thatbcompletely defines the noiseless received signal. Letµ i→Fbe the message sent from thei-th user’s variable node to the functional node. Letl i 98 represent the LLR value given by thei-th user’s LDPC decoder. Then, define: µi→F(0)≜Pr [b i= 0] =eli eli+ 1, µ i→F(1)≜1−µ i→F(0),(5.10) wherel icorresponds to message type 2. The values ofl iare initialized to zero and then updated by the iterative decoding algorithm. Similarly,µ F→iis the message sent from the functional node to thei-th user’s variable node, and µF→i(0) is given by: µF→i(β) =X b∈{0,1}r,bi=β η(b)×Y t̸=iµt→F(bt) , β∈ {0,1},(5.11) whereη(b) is given by (5.9), andµ t→F(·) is given by (5.10). The summation above has 2r−1terms, whereris the collision order. Consequently, the number of computations required to obtain the messages from the functional nodeF igrows exponentially with the number of users. Now, let us express the messages in terms of the LLRsl F→i: lF→i= log\u0012µF→i(0) µF→i(1)\u0013 ,(5.12) whereµ F→i(β) is given by (5.11). The valuel F→iis then passed as the input LLR to the single-user LDPC decoder. Note that an alternative approach to functional node processing is given by soft SIC (SoIC), as proposed in [111]. Soft interference represents the expected value of the codeword symbolEc(i), derived from (5.10) as follows (considering BPSK modulation): Ex(i)=√ P(µ i→F(0)−µ i→F(1)). Then, the LLR specified in (5.12) is calculated as the LLR for BPSK modulation with SoIC: lF→i= 2√ P y−rX t=1,t̸=iEx(t) , whereyis the received signal at the considered position, and 2√ Pycorresponds to the LLR of a BPSK-modulated signal with a power constraintP. Message 2 (decoding the LDPC code).After decoding the functional nodes and computing the LLRs for the bits, this information is used to decode the LDPC code. The user applies the MPA algorithm to the LDPC code, which can be either the Sum-Product or the Min-Sum algorithm [65]. The output of this algorithm updates the valuesl ipresented in (5.10). Finally, the message exchange schedule can be arbitrary. Functional node decoding (propagation of message type 1) may be followed by several decoding iterations of each single-user LDPC code. 99 To construct the LDPC codes, the modified protograph extrinsic information transfer (PEXIT) method from [112] is used. Here, only the significant differences from the single-user case are high- lighted. The multi-user Gaussian channel is not symmetric; therefore, the PEXIT method cannot be applied directly to the all-zero codeword. To address this issue, we considerchannel adapters from [113]. The resulting channel is symmetric, allowing us to use only the all-zero codeword for code construction. Note that the random adapters were used only for code construction. IRSA-F with polar codes Let us consider the IRSA-F scheme with polar codes employed in each slot [101]. The choice of polar codes is motivated by two reasons. First, polar codes [114] are a powerful tool for short code lengths under the successive cancellation list (SCL) decoding algorithm [115].",
    "construction. IRSA-F with polar codes Let us consider the IRSA-F scheme with polar codes employed in each slot [101]. The choice of polar codes is motivated by two reasons. First, polar codes [114] are a powerful tool for short code lengths under the successive cancellation list (SCL) decoding algorithm [115]. Second, as previously discussed in Section 2.2.3, polar codes exhibit capacity-achieving properties in MAC. In this section, we describe how polar codes can be used in GMAC in the FBL regime and present a joint successive cancellation (JSC) decoding algorithm. Consider Arıkan’s kernel and the correspondingpolar transformof sizen′= 2m: G2≜\u00141 0 1 1\u0015 , G n′≜G⊗m 2, where⊗denotes the Kronecker power. To construct an (n′, k) polar coset code, denote the set of frozen positions byF, with|F|=n′−k. Letu Fdenote the projection of the vectoruonto the positions inF. Now, we define apolar coset codeCas follows: C\u0000 n′, k,F,f\u0001 =n c=uTGn′ u∈ {0,1}n′,uF=fo . The users utilizedifferentpolar coset codesC i(n′, k,F i,fi),i= 1, . . . , r. Consider thei-th user. To send the information wordu(i), the user first encodes it using the codeC i(n′, k,F i,fi), obtaining a codewordc(i). This is then followed by BPSK modulation, resulting inx(i)=τ\u0000 c(i)\u0001 . We refer the reader to [101], where the choice of information and frozen positions, along with frozen bit values, has been carefully optimized. In this section, we discuss how to decode a superposition of polar coset codes in a slot. In what follows, we assume a collision of orderr. To specify the decoding algorithm, let us first consider how the channel output is represented. As in the joint LDPC decoding algorithm, we consider a received signal positiony, omitting the index jiny j. At this position, each of therusers may transmit either zero or one, resulting in 2rpossible transmitted signal values. These values can be indexed by a binary vectorb∈ {0,1}r, yielding 2r points. For the single-user case, the LLR represents a sufficient statistic for the received signal. Withr simultaneous transmissions, we instead operate with a p.m.f. specified overtuplesof bits of length r. The prior p.m.f. is determined by the received signalyat the given position as follows: µ(b)∝η(b), 100 GMACGMAC y1y2 + + u1 u2x1 x2v1 v2w1 w2User 1 User 2⇔ (u1, v1) (u2, v2)(x1, w1) (x2, w2) GMACGMAC + y1 y2Figure 5.9: Representation of the GMAC as a polar code overZr 2forr= 2 andn′= 2. whereη(·) is defined in (5.9). The p.m.f. specified above can be obtained for each received position. Let us denote the channel output as a matrixM= [µ 1, . . . , µ n′] of size 2r×n′, where thej-th column represents the p.m.f. valuesµ. To describe the JSC decoding procedure, we begin with a simple yet instructive example forn′= 2 (see Fig. 5.9), illustrating the key idea behind the proposed method. We observe that, instead of working with bits from different users and multiple polar codes, we can treat the problem as working with a single polar code overZr 2. In this example, we first decode a bit configuration (tuple) (u 1, v1) – the first bits of the",
    "proposed method. We observe that, instead of working with bits from different users and multiple polar codes, we can treat the problem as working with a single polar code overZr 2. In this example, we first decode a bit configuration (tuple) (u 1, v1) – the first bits of the users – followed by a tuple (u 2, v2) – the second bits of the users. Recall that the decoder operates with tuple distributionsMrather than probabilities of individual bits. To decode the tuple (u 1, v1), we first need to calculate the distribution of the sum of two random variables overZr 2. In what follows, we refer to this operation as thecheck-node operation (CNOP). This can be done via convolution, i.e., ˆµ 1=µ 1∗µ2. Since we work in the Abelian groupZr 2, there exists a Fourier transform (FT) Φ. In what follows, to perform a convolution, we use the fast Fourier transform (FFT)-based technique proposed in [116] for the case of LDPC codes over Abelian groups. Thus, the final rule is as follows: ˆµ1(b)∝Φ−1(Φ (µ 1)⊙Φ (µ 2)) (b)∀b∈Zr 2,(5.13) where⊙denotes element-wise multiplication. After calculating the p.m.f. ˆµ 1, we make a hard decision ˆb1, taking into account the values of frozen bits at this position. Once ˆb1is found, we proceed with thevariable-node operation (VNOP). The rule is given by: ˆµ2(b)∝µ 1\u0010 b+ˆb1\u0011 µ2(b)∀b∈Zr 2.(5.14) Finally, the hard decision ˆb2is made using ˆµ 2. Now let us proceed to the casen′>2. Similar to the single-user case, we consider a recursive decoding algorithm that relies on a polar code representation based on the (U, U+V) construction. 101 Algorithm 1Joint successive cancellation (JSC) decoding algorithm 1:functionJSC(C(n, k,F,f),M) 2:ifn= 1then▷Make a hard decision 3: ˆb←hard (F,f,M) 4:return ˆb,M 5:else▷Proceed recursively 6:C U,CV← C▷Perform a split using (5.15) 7:[M U,MV]←M▷Split into halves 8: ˆMU←CNOP (M U,MV)▷Per-column CNOP (5.13) 9: ˆBU,˜MU←JSC\u0010 CU,ˆMU\u0011 ▷DecodeC Urecursively 10: ˆMV←VNOP\u0010 MU,MV,ˆBU\u0011 ▷Per-column VNOP (5.14) 11:B V,˜MV←JSC\u0010 CV,ˆMV\u0011 ▷DecodeC Vrecursively 12: ˆB←h ˆBU⊕ˆBV,ˆBVi ▷Element-wise XOR 13:return ˆB,h ˜MU,˜MVi ▷All tuples of lengthn 14:end if 15:end function Let us define a polar code split procedure. Given a polar codeC, we specify two subcodesC Uand CVas follows: C(n, k,F,f)split→ C U(n/2, k U,FU,fU),C V(n/2, k V,FV,fV),(5.15) whereF U⊆[n/2],F V⊆ {n/2+ 1, . . . , n},F U∪ FV=F,f= (f UfV), andk=k U+kV. Now, let us specify the recursive decoding algorithm. We denote a matrixB= [b 1, . . . ,b n′] of size r×n′specifying the estimated bit tuples. The JSC is presented in Algorithm 1, where CNOP and VNOP operations are applied per column with respect to the input arguments and are denoted as functions CNOP (µ 1, µ2) and VNOP (µ 1, µ2,b), respectively. Finally,⊕denotes an element-wise modulo-two sum. Note that the structure of Algorithm 1 is exactly the same as that of the single- user polar code successive cancellation (SC) decoding algorithm, where single bits are replaced by bit tuples, and LLRs are replaced by probability mass functions (p.m.f.)µ. Remark 5.12.It is worth noting that we can easily improve the decoding procedure by using the SCL decoding method [115]. In other words,",
    "the single- user polar code successive cancellation (SC) decoding algorithm, where single bits are replaced by bit tuples, and LLRs are replaced by probability mass functions (p.m.f.)µ. Remark 5.12.It is worth noting that we can easily improve the decoding procedure by using the SCL decoding method [115]. In other words, we take into account not only the most probable path (which, in our case, consists of tuples) but alsoℓdifferent paths with the highest metric. To derive the path metric update, recall the hard decision step from Algorithm 1: ˆb←hard(F,f,M), which corresponds to the case wheren= 1. Hence, the matrixMrepresents a single p.m.f.µ. Thus, the path metric is updated by multiplying it withµ\u0010 ˆb\u0011 . 102 5.2 Sparse interleave division multiple-access In this section, we describe the scheme proposed in [92]. This scheme is very similar to IRSA-S with LDPC codes, as presented above. Specifically, it implements the idea of sparsifying collisions, inherent inT-fold IRSA, while also utilizing users’ LDPC codes. However, the major difference lies in the randomization of the locations of the LDPC codeword symbols. The scheme assumes random placement rather than slotted transmission. Slotted transmission is well-suited for the basic IRSA protocol, as the receiver does not know the transmission graph and reconstructs it on the fly. Knowing the slot locations enables the receiver to decode. Now, consider the IRSA-F protocol. The CS part (or preambles) allows the receiver to first reconstruct the graph and then perform decoding. In this case, the main drawbacks of the scheme from [100] are as follows: 1. Slotted transmission depends on the existence of high-performance short-length codes. As the number of active users increases, the scheme ensures that the slot length decreases. Short LDPC codes are known to perform poorly, while polar codes are good but lack flexibility in length adaptation. Thus, designing effective multi-user codes for short block lengths remains an open problem. 2. Once the message is decoded, its copies are peeled from other slots using SIC. Consequently, the decoding and peeling operations are separate. Moreover, peeling is performed in a hard decision manner. However, since the transmission graph is known, a joint message-passing decoder can be applied. 3. Slotted transmission is merely a specific interleaving strategy. The class of all possible per- mutations is much broader and potentially contains more effective solutions. The scheme from [92] addresses these issues. The authors demonstrate that a single sparse joint Tanner graph spanning all transmissions can significantly improve performance compared to the schemes in [100, 101]. Remark 5.13.The scheme in [92] can be interpreted as a sparse version of IDMA [91], adapted to the uncoordinated and unsourced MAC by incorporating an additional CS component. The sparsity ensures acceptable computational complexity when decoding over the joint graph. We also note that the idea of using sparse access sequences appeared in [45], although that work focused on short repetition codes. Now, let us describe the transmission process. Consider thei-th user and split the message into two parts:W i= [W i,p, Wi,c], whereW i,p∈[M p],W i,c∈[M c], andM=M pMc. Similar to the IRSA-F protocol: (a) the replica",
    "sparse access sequences appeared in [45], although that work focused on short repetition codes. Now, let us describe the transmission process. Consider thei-th user and split the message into two parts:W i= [W i,p, Wi,c], whereW i,p∈[M p],W i,c∈[M c], andM=M pMc. Similar to the IRSA-F protocol: (a) the replica count depends only onW i,p, and (b) the preamble of lengthn′ pis placed before the frame, so the total lengthnis allocated to the preamble (n p) and the remaining portion of lengthn−n pwhere users transmit their codewords. In what follows, we consider the case log2Mp=k pand log2Mc=k c, wherek p, kc∈N, with kp+kc=k. 103 1. The preamble is chosen using the preamble encoderf p: [M p]→Rnp. Recall that∥f p(Wp)∥2 2≤ Ppnpfor allW p∈[M p]. 2. All users utilize the same binary [n c, kc] LDPC code. The remainingk cmessage bits are encoded using this code, and thei-th user obtains the binary codewordc i. The user then performs BPSK modulation, equivalently expressed as ˜x(i)=τ(c(i)), τ(c(i)) = (τ(c(i) 1), . . . , τ(c(i) nc)). 3. LetL= (n−n p)/nc, which represents the maximum repetition count10. Applying the function ℓ: [M p]→[L], we determine the replica countℓ(W i,p). Once again, we emphasize that the replica count is a deterministic function ofW i,pand remains independent ofW i,c. At this step, we construct the word x(i)= [˜x(i),˜x(i), . . . , ˜x(i) | {z } ℓ(Wi,p),0], where the codeword ˜x(i)is repeatedℓ(W i,p) times and then appended with (n−n p)−ℓ(W i,p)nc zeros. Thus,x(i)has lengthn−n p. 4. Finally, we select the permutationπ Wi,pbased on theW i,pmessage part and transmit the word h fp(Wi,p), π Wi,p(x(i))i over the channel. Now, consider the decoding process: 1. Decode the preamble part using a CS decoder by solving the problem (5.6), whereu p= (up,1, . . . , u p,Mp) and the sparsity wt(u p) =K a. 2. Reconstruct the graph and extract{π ˆWi,p}fori∈[K a]. If all preambles are successfully recovered, the graph and code transformations are known. 3. Apply a joint message-passing decoder. The rules remain exactly the same as in Section 5.1.4, with the only difference being the graph structure. Remark 5.14.Similar to the IRSA-F protocol, we have Ppnp+PcncL′(1)≤Pn. Additionally, we highlight an approach to the URA problem that employs a tensor-based modula- tion method [117]. Given a large coherence block, this method is also applicable to the block fading model and scenarios where the receiver is equipped with multiple antennas. 10Recall that this scheme does not use slots. 104 W1 W2 ... WKax(1) 1 x(2) 1 x(Ka) 1 y1x(1) 2 x(2) 2 x(Ka) 2 y2· · · · · · ... · · · · · ·x(1) L x(2) L x(Ka) L yLLslots Inner encoderf I ChannelKaactive users Outer encoderf OFigure 5.10: CCS scheme. First, the outer code of lengthLover the alphabet [Q], with the encoder fO, is applied. Then, the inner encoderf Iis applied to each symbol of the outer code. Finally, each inner codeword is transmitted through the Gaussian channel (5.16). 5.3 Coded compressed sensing In this section, we describe an inspirational scheme from [118, 93]. A similar",
    "the alphabet [Q], with the encoder fO, is applied. Then, the inner encoderf Iis applied to each symbol of the outer code. Finally, each inner codeword is transmitted through the Gaussian channel (5.16). 5.3 Coded compressed sensing In this section, we describe an inspirational scheme from [118, 93]. A similar approach has already been used in CS and group testing literature [119, 120, 121, 122]. However, [93] presents the first application of this approach to the URA problem. Recall that the URA problem is a CS problem of immense dimension. The scheme from [93] utilizes the divide-and-conquer strategy, i.e., it splits the task into subtasks of smaller dimensions, solves the corresponding CS problems, and then assembles the results using an outer tree code. We note that a similar code construction, namely a convolutional code, was used in [123], but for a different single-user channel model (jamming channel or J-channel). The main drawback of the tree code-based scheme proposed in [93] is its inability to deal with errors, i.e., the codeword is not recovered if at least one of its fragments is lost. This drawback was addressed in [94]. Our description is based on the latter paper. Let us briefly describe a CCS scheme from [93]. The transmission scheme is shown in Fig. 5.10. The idea is to apply a divide-and-conquer strategy implemented via concatenated coding. Recall that a frame ofnreal channel uses is divided intoLslots of lengthn′. Consider thei-th user aiming to transmit a messageW i∈[M]. We use an outer code of lengthLover the alphabet [Q] with the encoderf O: [M]→[Q]L. First, we obtain a codewordx(i)= (x(i) 1, x(i) 2, . . . , x(i) L) =f O(Wi), wherex(i)∈[Q]L. Then, the inner encoderf I: [Q]→Cn′is applied to each symbolx(i) l,l∈[L]. The resulting codewords of the inner code are transmitted in the corresponding slots. Note that, in contrast to ALOHA protocol-based schemes, the user’s transmission occupies the entire frame (Lslots). For thel-th slot, we have yl=KaX i=1fI\u0010 x(i) l\u0011 +zl, l∈[L],(5.16) wherez l∼ N(0,I n′). To recover the transmitted codewords, we first solve a CS problem for each slot. Note that the 105 12345SymbolsSlots: 1 2 3 4 5 x(1), single error x(2), no errors x(3), no errorsFigure 5.11: Outer code and the list-recovery problem (Example 5.3, case B). Rectangles represent slots. Green circles correspond to correctly detected symbols, orange circles correspond to falsely detected symbols, and orange crosses correspond to missed symbols. Dashed lines represent outer code codewords. For example, a codewordx(1)is covered by the received lists in all but one position. dimensions of these problems are much smaller compared to the dimension of the original problem (see (3.4)). Thus, one can use standard CS algorithms. For further details, see Section 5.6.3. In the following example, we illustrate the transmission and the output of the inner decoder. Example 5.3.LetK a= 3,Q=L= 5and assume the codewords x(1)= (1,4,3,5,5), x(2)= (3,2,1,4,3), x(3)= (5,2,4,3,1). are transmitted. The channel output for each slot is described by(5.16). For example, for the third slot, we have the following channel output realization: y3=fI(3) +f I(1) +f I(4) +z 3.",
    "output of the inner decoder. Example 5.3.LetK a= 3,Q=L= 5and assume the codewords x(1)= (1,4,3,5,5), x(2)= (3,2,1,4,3), x(3)= (5,2,4,3,1). are transmitted. The channel output for each slot is described by(5.16). For example, for the third slot, we have the following channel output realization: y3=fI(3) +f I(1) +f I(4) +z 3. Next, we solve a CS problem for each slot and obtainY l⊆[Q],l∈[L]which represents the estimates of the sets ofQ-ary symbols transmitted in each slot. Let us consider two cases: Case A:There are no errors in the received lists. Thus, Y1={1,3,5}, Y2={2,4}, Y3={1,3,4}, Y4={3,4,5}, Y5={1,3,5}. We note that the decoder returns a set, and thus we have a list of size2for the second slot. There is no information about the symbols’ multiplicities. Case B:There are errors in the received lists. Let Y1={1,3,5}, 106 Y2={2,4,5}, Y3={1,4,5}, Y4={3,4,5}, Y5={1,3,5}. For the second slot, we observe a falsely detected symbol,5. For the third slot, the symbol3is lost, and the symbol5is falsely detected. The task of the outer code is to assemble the original codewords from the received lists. The lists may contain errors (missed and falsely detected symbols). This problem is known as the list-recovery problem [124]. We illustrate this process for Example 5.3, case B, in Fig. 5.11. 5.3.1 Channel for the outer code Let us start with the case with no errors in the output lists. Clearly, the resulting channelW Ais the channel without intensity information (A-channel) from [125], which is also called a hyperchannel in the literature (see [126]). Let the symbolsx(1),x(2), . . . ,x(Ka)∈[Q] be transmitted. Then, the channel output is Y(A)=Ka[ i=1x(i). The capacity of the A-channel is derived in [127]. If we consider indicator vectors of sets, this channel can be represented as a vector OR-channel. Our channelWis a concatenation of the A-channelW Awith the channelW Ethat introduces errors. Let us consider the channelW Ein more detail. The input of the channel is the set of transmitted symbolsY(A)⊆[Q]. LetY ⊆[Q] be the output set. We introduce the missed detection probability pmas the probability that the transmitted symbol is not in the received listY. The false alarm probabilityp fis the probability that some symbol that is not transmitted appears in the received list, i.e., forx∈[Q], pm= Prh x̸∈ Y|x∈ Y(A)i , pf= Prh x∈ Y|x̸∈ Y(A)i , where the channel operates independently on the elements. Example 5.4.Let us consider Example 5.3 and the second slot withY(A) 2={2,4}. Each element {2,4}can be missed independently with probabilityp m, and each element{1,3,5}can appear in the received listY 2independently with probabilityp f. The capacity of this channel is derived in Appendix E.1. 107 5.3.2 Random coding bound In this section, we present a RCB for the outer code. In what follows, we consider theensembleof codes. Definition 5.1.LetE 1(M, L)be the ensemble of codebooks of sizeM×L, where each element is sampled i.i.d. fromUnif ([Q]). Now, let us describe the decoding algorithm. Let Y= (Y 1, . . . ,Y L),Y l⊆[Q], i.e., the received sequence ofLsets, each set being an output of the channelW. We require the decoder11to output all the messagesW, such that d(Y,x)≤t,(5.17)",
    "sizeM×L, where each element is sampled i.i.d. fromUnif ([Q]). Now, let us describe the decoding algorithm. Let Y= (Y 1, . . . ,Y L),Y l⊆[Q], i.e., the received sequence ofLsets, each set being an output of the channelW. We require the decoder11to output all the messagesW, such that d(Y,x)≤t,(5.17) wherex=f O(W),d(Y,x) =|{l:x l̸∈ Yl}|. Theorem 5.3(Coded compressed sensing random coding bound [94]).There exists a codeC ∈ E1(M, L), such that Pe=LX i=t+1\u0012L i\u0013 pi m(1−p m)L−i,(5.18) and Pf≤KaX r=1\" νr(M−r)tX i=0\u0012L i\u0013 (1−µ r)iµL−i r# ,(5.19) whereµ ris given by(E.2)and νr=M! (M−r)!MKa\u001aKa r\u001b , where\bKa r is the Stirling number of the second kind. Proof.Let us start with the FAR. Recall thatTis the set of transmitted messages andR ⊆[M] is a received list. Let us introduce the events Er={|T |=r}, r∈[K a]. Note that the probability Pr [E r] of obtainingrunique original elements whenK aitems are taken with replacement from a sample of sizeMis equal toν r(see, e.g., [128]). We have Pf=KaX r=1νrPr [R\\T ̸=∅ |E r]. 11Here and in what follows, we consider the outer code only and thus omit the word “outer”. 108 Let us proceed with Pr [R\\T ̸=∅ |E r]. W.l.o.g., let us assume thatT= [r] and calculate the probability that some another message satisfies condition (5.17). Let us fix the message ˆW∈ [M]\\[r], and let ˆx=f O(ˆW). Recall (see Section 5.3.1), Pr [ˆx l∈ Yl|Er] =µ r, thus the probability of accepting the message ˆWis equal to Pr\"LX l=1ξl≤t# , whereξ li.i.d.∼Bern(1−µ r). Applying the union bound, we obtainP ffrom the theorem statement. Finally, note that as we utilize a single-user receiver,P eis just the probability that more thant errors in the transmitted codeword have occurred. In what follows, we are interested in codebooks of sizeM≈2100and utilize the following upper bound forP f. Corollary 5.1.The following inequality holds: Pf≤(M−K a)tX i=0\u0012L i\u0013 (1−µ Ka)iµL−i Ka+p′, where p′= Pr [|S|< K a] = 1−Ka−1Y i=0\u0012 1−i M\u0013 ≤\u0000Ka 2\u0001 M. 5.3.3t-tree code-based practical scheme Let us describe and analyze a practical code construction, which is a modification of the tree code. The code structure is the same as in [93], with a crucial difference: a decoder capable of correcting up toterrors. Code construction.Let us represent the user messageWas a binaryk-bit vectoruand split it into chunksuT= (uT 1, . . . ,uT L), such thatu lis of lengthb lbits,l∈[L], andLP l=1bl=k. Recall thatu [l]= (u 1, . . . ,u l), and letB l=Pl l′=1bl′. To construct the outer code, we choose the following encoding functionf O. xl=fO,l(u[l]), l∈[L],(5.20) wheref O,l:{0,1}Bl→[Q]. The main idea of the proposed code construction is that the symbol xlfor thel-th slot depends only on the message chunksu 1, . . . ,u l. This property simplifies the decoding process (see Section 5.3.3). 109 Linear codes are preferred for practical schemes. Thus, we construct the functionsf O,l(·),l∈[L] as follows. Letc∈N,Q= 2c. Let us fix a bijective mappingϕ:{0,1}c→[Q]. The major part of our construction is a binary linear code with a block upper-triangular generator matrix. G= G1,1G1,2G1,3. . .G 1,L 0G 2,2G2,3. . .G 2,L",
    "Linear codes are preferred for practical schemes. Thus, we construct the functionsf O,l(·),l∈[L] as follows. Letc∈N,Q= 2c. Let us fix a bijective mappingϕ:{0,1}c→[Q]. The major part of our construction is a binary linear code with a block upper-triangular generator matrix. G= G1,1G1,2G1,3. . .G 1,L 0G 2,2G2,3. . .G 2,L 0 0G 3,3. . .G 3,L .......... . .... 0 0 0. . .G L,L ,(5.21) whereG l′,l,l′, l∈[L], is a binary matrix of sizeb l′×c. The codewordx= (x 1, . . . , x L)∈[Q]Lis obtained as follows. We start with the binary vector c=uGand then obtain a codewordxby splittingcinto chunks of lengthcand applying the mappingϕ, i.e., xl=ϕ lX l′=1uT l′Gl′,l! , l∈[L]. Decoding.Recall that the goal of the decoder is to recover all the messagesu, such that d(Y,x)≤t, wherex=f O(u). We note thatu [l]uniquely definesx [l]for eachl∈[L]. In what follows, we writex [l]=fO(u[l]). This fact allows us to utilize a low-complexity decoding algorithm, which decodes the blocksu l sequentially. Let Vl=\b vl∈ {0,1}Bl:d(Y [l], fO(vl))≤t , l∈[L], which represents the list of messages at each decoding step. Let us consider thel-th decoding step. For each of the elementsv l−1∈ Vl−1, we consider all possible continuationsu l∈ {0,1}bl. We include the pathv l= (v l−1,ul) into the setV lifd(Y [l], fO(vl))≤t. See Algorithm 2 for the full description. Remark 5.15.As we see, Algorithm 2 is guaranteed to recover the transmitted message in case no more thanterrors have occurred. Remark 5.16.Note that the decoding complexity depends on|V l|,l∈[L]. Indeed, at thel-th decoding step we perform|V l−1|2blencodings. Taking into account that the encoding requiresB l×c additions in the binary field, we obtain the total decoding complexity ofc×\u0010PL l=1|Vl−1|2blBl\u0011 binary additions. See Appendix E.2 for a detailed analysis of the average number of decoding paths. 110 Algorithm 2t-tree linear code decoding algorithm Input:Y Output:V L ▷Decoded messages 1:V 0← ∅ 2:forl∈[L]do 3:V l← ∅ 4:forv l−1∈ Vl−1do▷For each element from the list 5:foru l∈ {0,1}bldo▷For each next block 6:v l←(v l−1,ul) 7:ifd(Y [l], fO(vl))≤tthen 8:V l← V lSvl 9:end if 10:end for 11:end for 12:end for 13:returnV L 5.3.4 Reed-Solomon code-based practical scheme RS codes combined with Guruswami–Sudan decoding algorithm are known to solve the list-recovery problem. In this section, we describe an RS-code-based practical scheme from [94]. We start with the necessary definitions. Recall thatF Qis the field withQelements. LetF Q[X] andF Q[X, Y] denote the rings of univariate and bivariate polynomials overF Q. Letβ 1, β2, . . . , β L∈FQ, withβ i̸=βjfori̸=j. We define an [nO=L, k O] RS codeCas follows: CRS≜{(f(β 1), f(β 2), . . . , f(β L)) :f(x)∈F Q[X],degf(x)< k O}. Let us consider the bivariate polynomial g(x, y) =∞X i=0∞X j=0gi,jxiyj∈FQ[X, Y]. We define the (w 1, w2)-weighted degree ofg(x, y) as follows. degw1,w2g(x, y) = max gi,j̸=0degw1,w2(xiyj), where the (w 1, w2)-weighted degree of the monomialxiyjequals tow 1i+w 2j. Note that the (1,1)-weighted degree is simply the degree of a bivariate polynomial. In what follows, we search for polynomials that pass through some point with multiplicitym. The bivariate polynomialg(x, y) passes through the point",
    "= max gi,j̸=0degw1,w2(xiyj), where the (w 1, w2)-weighted degree of the monomialxiyjequals tow 1i+w 2j. Note that the (1,1)-weighted degree is simply the degree of a bivariate polynomial. In what follows, we search for polynomials that pass through some point with multiplicitym. The bivariate polynomialg(x, y) passes through the point (β, α)∈F2 Qifg(β, α) = 0. Let us introduce the concept of root multiplicity. In the real field, the root multiplicity can be defined using partial derivatives, but for the finite field it is more challenging due to finite characteristic. Following [129], 111 we say that the polynomialg(x, y) passes through the point (β, α) with multiplicitymif the shifted polynomialg(x+β, y+α) contains a monomial of degree12mand does not contain a monomial of smaller degree. Naive approach.Let us apply the Guruswami–Sudan list recovery algorithm to our problem in a straightforward manner. We briefly explain the idea and refer the reader to [130] for details. Let us enumerate the elements of the fieldF Qin some order, i.e.,F Q={α 1, α2, . . . , α Q}. Encoding.Letk O=k/log2Q. Consider the user messageWas a vectorf= (f 0, . . . , f kO−1), where fi∈FQ, and introduce the information polynomialf(x) =PkO−1 i=0 fixi. The user codeword is x= (f(β 1), f(β 2), . . . , f(β L))∈ C RS. Decoding.Let us recall that the channel output isY= (Y 1, . . . ,Y L), whereY l⊆F Q. Let us introduce the following set of points: P={(β l, αi) :α i∈ Yl, l∈[L], i∈[Q]}. We assign a multiplicitym i,l∈Nto each point (β l, αi)∈ P. We note that multiplicities affect the decoding algorithm only. The largerm i,lare, the better the decoding performance is. At the same time, the decoding complexity grows withm i,l. We provide all the details below. To perform the decoding, we apply the Guruswami–Sudan algorithm. The input to this algorithm is the set of pointsPwith the corresponding multiplicitiesm i,l. The full description is given by Algorithm 3. Algorithm 3Guruswami–Sudan algorithm Input:L,k O, set of pointsPwith multiplicitiesm i,l Output:List of polynomialsf(x) 1:Interpolation. Find a bivariate polynomialg(x, y) of minimal (1, k O−1)-weighted degree that passes through each point (β l, αi),i∈[Q],l∈[L], with multiplicitym i,l. 2:Factorization. Find all the factors ofg(x, y) of the formy−f(x), where degf(x)< k O. Analysis.It is convenient to represent the setPwith corresponding multiplicities as a matrix M=\u0010 m′ i,l\u0011 of sizeQ×Las follows:m′ i,l=m i,lif (α i, βl)∈ Pandm′ i,l= 0 otherwise. Let us define the complexity of matrixMas C(M) =1 2QX i=1LX l=1m′ i,l(m′ i,l+ 1). Algorithm 3 is known (see [129, 131]) to includef(x) in the output list if (M,X)≥p 2(kO−1)C(M),(5.22) 12Here, we refer to the (1,1)-weighted degree. 112 x′ 1 x′ 2 x′ 3 · · · x′ L sx′ 1 sx′ 2 sx′ 3 · · · sx′ L Slot 1 Slot 2 Slot 3 SlotL · · ·s Inner code:RS code:User prefix: log2Qbits Frame lengthnFigure 5.12: Frame structure with slots consisting of RS code symbolsx′ l, wherel∈[L], and the prefixs. where (·,·) denotes the dot product of matrices, and the matrixX= (x i,l) corresponds to",
    "· sx′ L Slot 1 Slot 2 Slot 3 SlotL · · ·s Inner code:RS code:User prefix: log2Qbits Frame lengthnFigure 5.12: Frame structure with slots consisting of RS code symbolsx′ l, wherel∈[L], and the prefixs. where (·,·) denotes the dot product of matrices, and the matrixX= (x i,l) corresponds to the codewordx= (f(β 1), . . . , f(β L)), i.e.,x i,l= 1 ifα i=f(β l). This matrix has only one unit in each column. The following upper bound holds for the list size: L(M)≤s 2C(M) kO−1. Let us investigate the recovery condition (5.22) in more detail for the case when all the points from Phave the same multiplicity equal tom. Assume also that we have lists of sizeK ain each position. Then we have m(L−d(Y,x)) = (M,X)≥p (kO−1)m(m+ 1)K aL, and thus we can recover the codeword if the number of errorstsatisfies the inequality t=d(Y,x)≤L 1−r (kO−1) LKa(m+ 1) m! . As we can see, to have error-correcting capabilities, we must require the outer code rateR O≜ kO/L≤1/K a, which is infeasible even for a moderate number of users. Thus, our next goal is to reduce the order of collisions. Modified scheme.LetQ=q p×qandb p= log2(qp). We propose to useb pbit prefixess i, i∈[K a] to groupK ausers inq pgroups, ensuring an acceptable level of collisions within each group. Encoding.Consider the user aiming to transmit akbit messageW. Firstb CCRC bits are calculated and added to the message to suppress the FAR below the required threshold. Each user 113 encodesk+b Cbits by using an [L, k O] RS codeC′ RSover the alphabetF qand obtains the codeword x′∈ C′ RS. The user then generates the prefixs∼Unif([q p]). Consider the bijective mapping ϕ′: [qp]×[q]→[Q], which is common to all users. The resulting codewordx∈[Q]Lis calculated as follows: xl=ϕ′(s, x′ l), l∈[L]. The encoding process is illustrated in Fig. 5.12. Decoding.Prefixes split the set [Q] into non-intersecting rangesI i, where|I i|=q,i∈[q p]. We handle the rangesI iseparately. Note that by applyingϕ′−1and removing the prefix, we reduce the problem to the one described in Section 5.3.4, but with alphabetF qand a smaller collision order. 5.3.5 Further modifications The paper [95] continues this line of work and utilizes SPARCs combined with the AMP algorithm. A further modification of the CCS approach is presented in [96], where the inner AMP decoder and the outer tree decoder are allowed to exchange soft information within a joint MPA. In [132], the authors reduce complexity by utilizing the same sensing matrix as in [93]. The main difference lies in the use of a joint MPA (as in [96]) and the assumption that inner codewords are coupled via an outer code. Finally, the paper [133] proposes a coded demixing approach to enable the joint recovery of very high-dimensional signals that are sparse with respect to separate bases. We also note the papers [134, 135], which further investigate coding for the A-channel. In particular, the paper [134] proposes an interesting list-pruning algorithm that may be extremely helpful for tree-code decoding. The state-of-the-art CS-based solution proposed in [136] suggests eliminating the outer code entirely. The main",
    "to separate bases. We also note the papers [134, 135], which further investigate coding for the A-channel. In particular, the paper [134] proposes an interesting list-pruning algorithm that may be extremely helpful for tree-code decoding. The state-of-the-art CS-based solution proposed in [136] suggests eliminating the outer code entirely. The main idea is to use data from previous slots to customize the sensing matrix for subsequent slots. This scheme demonstrates the best energy efficiency among all CS-based approaches. 5.4 Random spreading Previously, we discussed IRSA and sparse IDMA schemes. Simply put, such schemes rely on a TDMA strategy to sparsify collisions. From the MAC literature, we know of one more technique— direct-sequence spread spectrum (DSSS), which serves as the basis for the CDMA method. This section is devoted to applying this strategy to the URA scenario. In what follows, we describe in detail the scheme from [97] and briefly discuss the improvements introduced in [98, 99]. Let us start with an informal description of the scheme. The payload corresponding to each active user is split into two parts. The first component acts as a preamble, selecting a spreading or signature sequence from a codebook of sequences with good correlation properties. The remaining bits are encoded using the user’s code. This codeword is then spread using the signature sequence chosen by the first part of the message. The decoding procedure is iterative, with each iteration consisting of four main steps: 114 W= [W i,p, Wi,c] A User Code a⊗xWp Wca x tFigure 5.13: The message is split into two parts,W pandW c. The componentW pis responsible for selecting a spreading sequence, whileW crepresents the message encoded by a user code. Spreading sequences are chosen from the matrixA, and the encoded vectortis given by (5.23). (a) an energy detector that utilizes the correlation properties of the signature sequences to identify the list of spreading sequences used, (b) a MMSE estimator that produces LLR estimates based on the spreading sequences, (c) a single-user decoding operation, and (d) a SIC step, resulting in a residual channel output. We note that the basic scheme relies on single-user decoding, which drastically reduces its com- plexity. The codebook of spreading sequences plays a crucial role in determining the scheme’s error perfor- mance. These sequences should exhibit good correlation properties or, equivalently, form a good CS code (see Appendix B for details on how to construct such codes). When the size of this code- book is large, active users are less likely to experience collisions in the space of signature sequences, a scenario that favors the use of a single-user decoder. However, the mutual coherence of such a codebook would be very high, adversely affecting the performance of the polar decoder. Con- versely, smaller codebooks possess better correlation properties but result in a higher probability of collisions between the signature sequences chosen by active users. This, in turn, renders single-user decoding ineffective for users whose signature sequences collide. Now, we proceed with a detailed description, starting with the encoding process. 5.4.1 Encoder Consider thei-th user. Similar to previous schemes (see Section",
    "in a higher probability of collisions between the signature sequences chosen by active users. This, in turn, renders single-user decoding ineffective for users whose signature sequences collide. Now, we proceed with a detailed description, starting with the encoding process. 5.4.1 Encoder Consider thei-th user. Similar to previous schemes (see Section 5.1.3), we split the message into two parts: Wi= [W i,p, Wi,c], whereW i,p∈[M p],W i,c∈[M c], andM=M pMc. Recall that the message partsW i,pandW i,c consist ofk pandk cbits, respectively, i.e.,M p= 2kpandM c= 2kc. The message partW i,pencodes the spreading sequencef p(Wi,p), wheref p: [M p]→Rnpis the encoder of some good CS code. Let us introduce the codebook (or sensing matrix) of CS code A=\u0002 a1, . . . ,a Mp\u0003 , 115 wherea W=fp(W) forW∈[M p]. The encoding process consists of selecting the column indexed byW i,pfrom the matrixA. In other words, the message partW i,pdetermines the choice of the spreading sequence. Throughout this work, we denote the spreading sequence chosen by thei-th user as a(i)≜aWi,p=fp(Wi,p). The message partW i,cis encoded into the user’s codewordx(i)=fc(Wi,c), wheref c: [M c]→Rnc. In the numerical analysis presented in Section 5.6.4, we consider a BPSK-modulated binary linear [nc, kc]-codeC, i.e., x(i)=τ(f c(uc)), whereu c∈ {0,1}kcis the information vector corresponding toW c. Throughout this discussion, fc(uc) andf c(Wc) are used interchangeably. Finally, the modulated codewordx(i)is spread using the chosen spreading sequencea(i)to produce the transmitted signal t(i)=x(i)⊗a(i),(5.23) where⊗denotes the Kronecker product operation. A graphical representation of the encoding process is shown in Fig. 5.13. Remark 5.17(Signal representation in matrix form).Let us transition to the matrix representa- tion. We have T(i)=a(i)\u0010 x(i)\u0011T ,(5.24) wheret(i)can be obtained by reshaping this matrix, i.e., by reading it column by column. Taking into account thatK ausers are transmitting simultaneously, we observe the following noisy signal mixture at the channel output Y=KaX i=1T(i)+Z,(5.25) whereZ∼ N(0,I np×nc). Remark 5.18.LetP={W 1,p, . . . , W Ka,p}. Consider the general case where some preambles may coincide, i.e.,|P|=r≤K aandP={j 1, j2, . . . , j r}, wherej 1< j2< . . . < j rare unique elements. Then, we have Y=A P˜X+Z,(5.26) whereA Pis formed fromAby selecting columns indexed byP, and ˜X= ˜xT 1 ˜xT 2... ˜xT r , and˜xlis the sum of the codewords of users that chose the preamblej l, i.e., ˜xl=X i:Wi,p=jlx(i), l∈[r]. 116 5.4.2 Decoder The iterative decoder consists of several components. First, an energy detector decodes the pream- ble parts of the transmitted messages, which are then mapped to columns ofAto identify the set of spreading sequences selected by active users. Since signature sequences are chosen solely based on preambles, two or more users select the same sequence whenever they share a common preamble. Based on the energy corresponding to a detected sequence, the energy detector also provides an estimate of the number of active users sharing that sequence. The MMSE estimator is then em- ployed to produce soft estimates of the signals corresponding to the detected sequences. These soft estimates are passed to the users’ decoders, and the recovered codewords are subtracted from the received signal in",
    "an estimate of the number of active users sharing that sequence. The MMSE estimator is then em- ployed to produce soft estimates of the signals corresponding to the detected sequences. These soft estimates are passed to the users’ decoders, and the recovered codewords are subtracted from the received signal in the spirit of SIC. The residual signal is then fed back into the energy detector for the next decoding iteration. This iterative decoding process continues until all transmitted messages are recovered or the number of decoded messages no longer improves between consecutive iterations. Let us examine this process in more detail. Detection of spreading sequences At this stage, we need to determine the set of spreading sequences that were transmitted. Recall that we are utilizing a good CS codebook; thus, the natural approach is to examine the correlations between the channel output and all possible spreading sequences (i.e., the columns of the sensing matrixA). One challenge in implementing this algorithm arises from (5.23), asx(i)is unknown at this stage of the decoding process. The optimal strategy, in terms of performance, would be to consider all possible codewordsx(i), but this approach is computationally infeasible. To address this, the authors of [97] proposed a suboptimal strategy. Assume we are considering a spreading sequencea13. We split the channel output inton′=nc/ggroups of lengthn pgas follows: yT=\u0002 yT 1,yT 2, . . . ,yT n′\u0003T. Now, to calculate thescoreofawe proceed as follows: S(a) =n′X i=1Si(a),whereS i(a) = max b∈{±1}g(b⊗a)Tyi. The group size is carefully chosen to balance error performance and computational complexity. The columns ofAare then sorted in descending order of their scores, and the detector outputs the top Ka+∆ sequences, where ∆ is a fixed small non-negative integer. We denote byDthe set of indices of these sequences. Notably,Dserves as an estimate of the set of message partsP. 13ais an arbitrary column of the matrixA; we omit the subscript as nothing depends on it. 117 Demodulation and decoding In this section, we describe the steps involved in decoding the messages corresponding to the detected sequences. Recall eq. (5.26) and note that we knowD, the estimate of the set of spreading sequencesP. We have Y=A D˜X+Z′,(5.27) whereZ′consists of the additive Gaussian noiseZand the interference from users with undetected spreading sequences. In what follows, we work under the assumption thatP ⊆ D, implying that Z′=Z. First, we apply the linear MMSE (LMMSE) estimator (see details in Appendix A) to obtain ˆX=AT DR−1Y,R= (A DAT D+Inp). The mean squared error (MSE) of this estimator is well approximated by Σ=I−AT DR−1AD,(5.28) where Σ≈diag\u0000 σ2 mse(1), σ2 mse(2), . . . , σ2 mse(D)\u0001 . In this context,σ2 mse(j) is the MSE in the estimate of the signal corresponding to sequencea jfor j∈ D. Assume the case when there are no repeating sequences, i.e.|P|=K a. The next step is to calculate input LLR sequences for the users’ decoders. Assuming the MSE is Gaussian, we proceed as follows: li=2 σ2 iˆxi, i∈[K a], where ˆxiis thei-th row of the matrix ˆX. Then, the calculated LLRs are passed to users’ codes. In [97], the authors",
    "i.e.|P|=K a. The next step is to calculate input LLR sequences for the users’ decoders. Assuming the MSE is Gaussian, we proceed as follows: li=2 σ2 iˆxi, i∈[K a], where ˆxiis thei-th row of the matrix ˆX. Then, the calculated LLRs are passed to users’ codes. In [97], the authors utilize single-user polar codes. The decoders can converge to a correct codeword, output a failure, or even produce a wrong decision. For the latter case, we assume the presence of a technique to discard such decisions (e.g., CRC). We denote byD∗⊆ Dthe collection of indices such that users’ codes are decoded successfully. The SIC removes the contributions from all the successfully decoded codewords ˆXD∗from the received signal to compute the residual Y−A D∗ˆXD∗. This residual is passed for the next decoding iteration. This process continues until all the trans- mitted messages are recovered successfully or there is no improvement between two consecutive rounds of the iterative process. 118 5.4.3 Discussion and further improvements Let us describe possible improvements suggested in the literature. Joint decoding.The scheme in [97] relies on single-user codes. Thus, if several users choose the same spreading sequence, the corresponding messages will be missed with a relatively high probability. A straightforward solution is to enlarge the set of spreading sequences, but in this case, we lose the good correlation properties. A better solution is to adopt joint decoding (in the spirit of Section 5.1.4 with LDPC or polar codes) to avoid the need for large-sized codebooks for the spreading sequences. The idea is as follows: for those active users whose signature sequences collide, we leverage a joint decoder that does not treat the heavy interference from colliding users as noise. We emphasize that, although the envisioned scheme utilizes joint decoding, it is computationally less burdensome than [101] because joint decoding is performed only for colliding users. Power diversity.It is well-known that power diversity improves the SIC process. The idea proposed in [98] is to divide the columns ofAintomgroups and assign different power levels to each. There arel kcolumns with power levelP kin thek-th group, withk∈[m]. The power levels for each group must be chosen in such a way that the average power constraint is satisfied. The proposed approach divides the active users into different groups. The encoding procedure in this scheme remains unchanged, while the decoding differs in the preamble detection part: the energy detector is replaced with a covariance-based detector. Namely, we form Σ =AT NY YTAN, whereA Nis obtained by scaling the columns of the codebook to 1 (after removing signatures of correctly decoded users) to prevent a higher detection probability for the sequences with greater power levels. The covariance-based detector outputsK a+∆ signatures corresponding to the largest diagonal elements of Σ. Simulations show that the proposed approach outperforms the existing methods, especially when the number of active users is large. SoIC.The authors of [99] noted that to apply the SIC procedure, we should decode the user code. At the same time, the information from non-converged decoders is not utilized, even though it may help the overall iterative",
    "outperforms the existing methods, especially when the number of active users is large. SoIC.The authors of [99] noted that to apply the SIC procedure, we should decode the user code. At the same time, the information from non-converged decoders is not utilized, even though it may help the overall iterative decoding process. The paper [99] proposes replacing polar codes with LDPC codes (since LDPC codes are much better in terms of soft output) and utilizing SoIC [43, 137, 138]. We also mention the paper [139], which describes DE analysis of iterative SoIC multi-user detection/decoding. Assume the user code provides us with the extrinsic information vectorγ= [γ 1, γ2, . . . , γ nc]. We calculate the expected values of the modulated symbols and remove them from the channel output, i.e. x= [E[x 1|γ1], . . . ,E[x nc|γnc]] = [tanh(γ 1/2), . . . ,tanh(γ nc/2)], 119 and then subtract them: Y−A DXD. This scheme is the state-of-the-art scheme for the G-URA. Notably, the proposed scheme outper- forms the RCB derived in Theorem 4.1 when the active population is less than 75 for parameters taken from [90]. Furthermore, the proposed scheme outperforms the schemes with joint decod- ing [97] and power diversity [98] when the active population exceeds 200 users. However, in a private discussion, the authors of this approach informed us that they were unable to validate the resulting energy efficiency curve (which will be discussed in Section 5.6). Hadamard-based spreading with convolutional codes.Finally, let us highlight an elegant scheme that considers spreading differently. All previously discussed spreading techniques are based on a Kronecker product (5.23). The authors of [140] propose a scheme based on theHadamard product, where the encoded codeword spread by the signature will not increase in length. The authors also use a slotted system, where users choose the transmission slot at random. To detect different signatures, dedicated pilot bits are inserted. The choice of the signature is also based on splitting the message into two parts, with a convolutional code considered as the user code. The final decision makes it straightforward to apply the Viterbi algorithm to a joint decoding problem. Despite its simplicity, the proposed solution offers quite good performance. 5.5 Comments on same linear codes As we know (Chapter 4), there exist codes that can operate in the G-URA. At the same time, the same BPSK-modulated linear codes (e.g., LDPC or polar codes) perform poorly in the G-URA. However, these codes could still be strong candidates for practical schemes, as binary linear codes are well-studied and have low-complexity soft decoding algorithms. Thus, as explained throughout this chapter, all low-complexity schemes rely on the following ap- proach: a) generate different codes from a single linear code (e.g., through permutations or shifts); b) append the transmitted codewords with a preamble that helps the receiver identify the correct permutation or shift. This strategy is indeed effective, but the use of a preamble introduces additional overhead. This naturally leads to the question:Are there linear codes that can operate in the G-URA? To better understand the problem, let us examine",
    "with a preamble that helps the receiver identify the correct permutation or shift. This strategy is indeed effective, but the use of a preamble introduces additional overhead. This naturally leads to the question:Are there linear codes that can operate in the G-URA? To better understand the problem, let us examine Fig. 5.14, which is also presented in [141, Figure 1]. This figure presents the results for the two-user G-URA, namely, y=x(1)+x(2)+z, wherex(1),x(2)∈ ±√ Pnandz∼ N(0, I n). 120 −10 −8 −6 −4 −2 0 2 4 610−410−310−210−1100 G1=/parenleftbigg1 0 1 0 1 1/parenrightbiggG2=/parenleftbigg1 0 1 0 0 1 0 1/parenrightbigg Es/N0, dBPUPE Single-user Two-userFigure 5.14: PUPE vs. SNR for two binary linear block codes over a BAC with AWGN. A toy example demonstrates two different linear codes with generator matricesG 1andG 2, followed by BPSK modulation. These codes exhibit similar performance in a single-user regime but significantly different performance in a multi-user regime. This result is presented in [141, Figure 1]. Two linear codes are compared:C 1, with generator matrixG 1, which is a [3,2] single-parity-check (SPC) code, andC 2, a [4,2] code with generator matrixG 2, which is the direct sum of two repetition codes of length 2. The block error probability of these codes in the absence of interference (i.e., single-user transmission) is depicted as a reference with dashed lines. For the multi-user case, the decoder outputs the unordered set of codewords ˆx(1),ˆx(2)that maxi- mizesp(y|x(1)+x(2)). We observe thatC 2performs better in the single-user setting but exhibits a high error floor in the multi-user scenario. Hence, the root cause of the error floor is multi-user interference rather than AWGN. Thus, let us focus on a simplified scenario of URA in a two-user noiseless BAC. Despite its simplicity, this setting proves to be particularly rich from a coding theory perspective. Here, we briefly discuss the results presented in [141], starting with the decoding algorithm. Since we are not considering noise, there is no need to work with the alphabet{±√ P}; instead, we use 121 the binary alphabet{0,1}. We now note that ML decoding over the BAC reduces to an erasure decoding problem. Assume we receivey∈ {0,1,2}n. Considering thej-th element ofy, we have three possible cases: 1.y j= 0 =⇒x(1) j= 0 andx(2) j= 0; 2.y j= 2 =⇒x(1) j= 1 andx(2) j= 1; 3.y j= 1 =⇒\u0010 x(1) j, x(2) j\u0011 ∈ {(0,1),(1,0)}; To handle the decoding process, we introduce an auxiliary vector ˜y, defined as follows: 1. ˜y j= 0 ify j= 0, 2. ˜y j= 1 ify j= 2, 3. ˜y j=∗ify j= 1. Notably, uncertainty arises only in case (3). Consequently, the decoder begins by constructing the listLof all codewordsxthat are compatible with the channel output. Specifically, defining the erasure positions asE={j:y j= 1}and the non-erasure positions asEc= [n]\\E, we obtain L′={x:x Ec=˜yEc}. The final step involves searching for all unordered codeword pairs{x 1,x2} ∈ L′×L′whose integer sum matchesy. If a unique solution exists, the decoder outputs this pair; otherwise, if multiple solutions exist, the decoder selects one at random. For the case of linear codes, the first step",
    "we obtain L′={x:x Ec=˜yEc}. The final step involves searching for all unordered codeword pairs{x 1,x2} ∈ L′×L′whose integer sum matchesy. If a unique solution exists, the decoder outputs this pair; otherwise, if multiple solutions exist, the decoder selects one at random. For the case of linear codes, the first step is straightforward. LetHbe the parity-check matrix of the users’ code. Then,L′is the set of solutions to the following system of linear equations: HExT E=HEcxT Ec.(5.29) We note that this system always has at least two solutions, implying that rank(H E)<|E|. One possible approach to solving this system is thepivotingstrategy: setting an arbitrary element (pivot) ofx Eto a value in{0,1}and then solving the resulting system. If rank(H E) =|E|−s, then there are 2s−1solutions. The authors of [141] make the following observations: 1. Any solution of (5.29) participates in exactly one valid pair. 2. Ifx(1)̸∈ L, thenx(2)is also not inL. 3. The probability of decoding error is given by Pe= 1−|E|X s=12−(s−1)Pr[rank(H E) =|E| −s]. 122 4. The number of valid codeword pairs computed by the decoder depends on the transmitted pair only through the support set of their difference. Let us formulate an auxiliary lemma from [141]: Lemma 5.1(All-zero codeword).Consider two users transmitting over the BAC using an[n, k] binary linear block codeC, and denote the transmitted codewords asx(1)andx(2). Then, Prh x(1)̸∈ L|x(1)=ci = Prh x(1)̸∈ L|x(1)=0i ,∀c∈ C. Note that the statement remains valid if we exchangex(1)andx(2). Lemma 5.1 implies that Pe= Prh x(1)̸∈ L|x(1)=0i , i.e., we can evaluate the PUPE of a binary linear block code under ML decoding by the special case where one of the two users transmits the all-zero codeword. Now, consider the case wherex(1)=0. In this case, we haveE= supp(x(2)), and (5.29) has exactly two solutions if and only ifx(2)isminimal. Definition 5.6.The codewordc∈ Cis calledminimalif it does not cover any other codeword, i.e., there does not existc′∈ Csuch thatsupp(c′)⊆supp(c). LetM(C) denote the set of minimal codewords inC. We can formulate the following statement: Pr[rank(H E)<|E| −1] = Pr[x(2)̸∈ M(C)]. As a result, minimal codes achieve zeroP eover a two-user BAC with the same-codebook constraint. Returning to Fig. 5.14, we observe that the [3,2] single-parity-check (SPC) code is a minimal code, meaning it consists only of minimal codewords. At the same time, the [4,2] code includes a non-minimal all-one codeword, which is the root cause of the error floor. Theorem 5.4(Converse for two-user BAC).Consider two users transmitting over the BAC with a[n, k]binary linear block code. Then, we have Pe≥1 2\u0012 1−n 2k−2\u0013 . Thus, the maximal achievable symmetric rate isR≤1/2. Proof.Letx(1)=0. We have Pe≥1 2Prh x(2)̸∈ M(C)i ≥1 2Prh wtHn x(2)o > n−k+ 1i 123 =1 2\u0010 1−Prh n−wt Hn x(2)o ≥k−1i\u0011 ≥1 2 1−E\u0002 n−wt H\b x(2) \u0003 k−1! (Markov’s inequality) =1 2\u0012 1−n 2k−2\u0013 . Remark 5.19.The following results show that transmission over the two-user BAC with linear block codes is fundamentally limited to a symmetric rate no larger than 1/2, in contrast to the maximum symmetric rate of 3/4achievable by nonlinear block codes over the two-user BAC. Remark 5.20.Note that the result stated",
    ". Remark 5.19.The following results show that transmission over the two-user BAC with linear block codes is fundamentally limited to a symmetric rate no larger than 1/2, in contrast to the maximum symmetric rate of 3/4achievable by nonlinear block codes over the two-user BAC. Remark 5.20.Note that the result stated in Theorem 5.4 extends to cosets of the linear code. The papers [141, 142] also address the question of whether it is possible to achieveR= 1/2via iter- ative decoding. It appears that for LDPC codes, the choice of the pivot14is of critical importance. If the pivot is selected randomly, then any irregular LDPC code ensemble has a non-vanishing error probability. If the pivot is selected optimally, then it is possible to attain vanishing PUPE. The paper [142] continues the investigation. In particular, the authors analyze the expected fraction of good pivots, compute optimized degree distributions, and provide a simple multi-edge type LDPC code construction that can provably achieve the two-user unsourced BAC limit for linear codes. In this section, we address the question of constructing the same codebook codes for the URA. All the schemes described in this chapter utilize preambles chosen from a small CS codebook. The preambles can be used in two different ways: •Same codes that are constructed as a concatenation of preambles and different linear codes (the interleaver or shift is chosen based on the preamble). •Same codes that are simply a concatenation of preambles. The main disadvantages are as follows: (a) preambles introduce additional overhead; (b) we cannot significantly increase the number of preambles (215is an upper bound due to complexity consider- ations). Thus, an important question arises: what are alternative approaches to constructing low-complexity same codes? This section considers a relatively simple scenario of a two-user BAC, but even in this case, it becomes evident that users cannot effectively utilize well-developed linear codes and their cosets. Non-linear codes are necessary to achieve the capacity (C= 3/4) of the two-user unsourced BAC. The design of such codes – where the main challenge is developing low-complexity decoders – remains an open and challenging problem. We can reformulate the problem as follows: we need a large CS codebook with a polynomial-time recovery algorithm. Some progress in this direction has been made in [143]. 14A good pivot is a variable node associated with a received ”erasure” symbol for which revealing its value allows recovering both transmitted messages, up to a vanishingly small fraction of residual erasures, by simple BCH decoding. 124 5.6 Numerical comparisons In this section, we present the results of numerical experiments that estimate the energy efficiency of the solutions described above. All previously introduced schemes assume a frame-synchronous transmission system. Energy efficiency is defined as the minimum energy spent per transmitted information bit,E b/N0, under the maximum tolerable PUPE, as defined in (3.3). Starting from [5, 90], a commonly used scenario for AWGN URA assumes a frame length ofn= 3×104real channel uses,k= 100 information bits, and a maximum tolerable PUPE ofε= 0.05. A numerical comparison is presented in Fig. 5.15 alongside state-of-the-art results. This figure illustrates the",
    "tolerable PUPE, as defined in (3.3). Starting from [5, 90], a commonly used scenario for AWGN URA assumes a frame length ofn= 3×104real channel uses,k= 100 information bits, and a maximum tolerable PUPE ofε= 0.05. A numerical comparison is presented in Fig. 5.15 alongside state-of-the-art results. This figure illustrates the energy efficiencyE b/N0of different schemes proposed in the literature as a function of the number of active users,K a. The latter term represents the number of messages sent within a single frame. This figure omits the first low-complexity scheme proposed in [90] because it demonstrated relatively low energy efficiency. We focus on four previously mentioned groups of algorithms. The first group is based on theT-fold IRSA (see Section 5.6.1). The second group follows a sparse IDMA approach (Section 5.6.2). The third group is based on a CCS approach (Section 5.6.3). Finally, we consider a family of random spreading algorithms presented in Section 5.6.4. Different families of algorithms are represented by different colors. As a reference, we have also included Polyanskiy’s achievability bound (presented in Theorem 4.1) and the IRSA achievability bound, formulated in Theorem 5.2. Theoretical bounds are marked by dashed lines. 5.6.1T-fold irregular repetition slotted ALOHA-based schemes T-fold irregular repetition slotted ALOHA achievability bound Let us start with the achievability bound for IRSA and numerically evaluate Theorem 5.2. The main objective is to select the polynomial Λ (see (5.1)) and determine the number of slots, or equivalently, the slot lengthn′: \b Λ (x), n′ = arg min Λ(x),n′\u0012Eb N0:Pe≤ε\u0013 , whereE b/N0is defined in (5.5). The optimization procedure was performed separately for each value ofK a. The resulting energy efficiency is represented by a green dashed line in Fig. 5.15 and corresponds toT= 4. The number of slots varies withK a, as shown in Appendix D forT= 1,2,4. Note that transitioning from a random coding approach to theT-fold IRSA results in a performance loss. However, all schemes based on theT-fold ALOHA with the same value ofTcan be considered as a reference. 125 0 50 100 150 200 250 30001234567891011T-fold IRSA (Section 5.1): T-fold IRSA bound, Theorem 5.2,T= 4 IRSA, LDPC [100],T= 4 IRSA, Polar [101],T= 8 Sparse IDMA (Section 5.2): low-density parity check [92] Polar with power diversity [144] Coded compressed sensing (Section 5.3): CCS RCB, Theorem 5.3,t= 0 Tree-code performance [93],t= 0 AMP+BP [96] Coded demixing [133],G= 2 Dynamic CS [136]Random spreading (Section 5.4.3): Polar, joint decoding [97] Power diversity [98] LDPC, SoIC [99] Random coding bound, Theorem 4.1 The number of active usersK aEb/N0, dBFigure 5.15: The minimumE b/N0required to achieve an error rate below 5% as a function of the active user count. Theoretical bounds are represented by dashed lines, while practical schemes are shown with solid lines. Different colors correspond to various families of algorithms described in Sections 5.1, 5.2, 5.3, and 5.4. In a private discussion, the authors of [99] informed us that they could not validate the resulting curve. Hence, we mark it with a thin line. 126 T-fold IRSA with LDPC codes and a joint decoding algorithm Consider the joint decoding of LDPC codes,",
    "Sections 5.1, 5.2, 5.3, and 5.4. In a private discussion, the authors of [99] informed us that they could not validate the resulting curve. Hence, we mark it with a thin line. 126 T-fold IRSA with LDPC codes and a joint decoding algorithm Consider the joint decoding of LDPC codes, as presented in Section 5.1.4. The authors of this scheme [100] performed an optimization search for system parameters as follows. Recall that this scheme relies on the IRSA-S approach (see Fig. 5.5), wherek pout ofkinformation bits are allocated to the preamble (required for proper permutation to enhance joint decoding), while the remaining kc=k−k pinformation bits are encoded using an LDPC code for each sequence transmitted within a slot. The authors found that a sensing matrix based on a BCH code exhibited better decoding perfor- mance compared to randomly generated sensing matrices. Additionally, they optimized the LDPC code length by applying the RCB from Theorem 4.1 to estimate the slot-level decoding error. Given the optimal slot length, a regular (3,6) LDPC code was selected. The resulting parameters of the scheme are:k p= 9,k c= 91, a preamble length ofn p= 63, and an LDPC code length ofn c= 394, followed by BPSK modulation. The search for the polynomial Λ (x) in (5.1) was restricted to a single parameterβ, with Λ (x) = βx+ (1−β)x2. The authors also limited the maximum number of replicas to two. The reasoning for this is provided in Appendix D: higher values ofTresult in optimal polynomials in (5.1) having fewer transmission attempts (i.e., lower-degree polynomials). Recall that the authors considered T= 4, and the polynomials presented in Table D.3 are of degree two. The energy efficiency of this scheme is depicted in Fig. 5.15 by a green line with×-shaped markers and corresponds to a maximum ofT= 4 simultaneous transmissions per slot. Note that there is a gap between this scheme and the achievability bound presented in Theorem 5.2. Nevertheless, it shows a significant improvement over [90], exceeding 10 dB forK a= 300. T-fold IRSA with polar codes and a joint decoding algorithm The next improvement was made by replacing LDPC codes with polar codes [101], as presented in Section 5.1.4. Moreover, switching to polar codes resulted in higher values ofTthat a joint decoder can successfully resolve. Inspired by [92], the IRSA-F (see Fig. 5.6) was utilized. This preamble has a length ofn p= 2000 and carriesk p= 15 information bits, which are dedicated to recovering the transmission graph and frozen-bit patterns for each polar code. The users employ (512,85) polar coset codes. The slot length is fixed for allK avalues, as it is challenging to assign an arbitrary length to the polar code. To choose the frozen positions, we utilized the proposed design procedure. We selected a common set of frozen tuples for all users, and the frozen bit values were chosen at random for each user, since using identical frozen values leads to poor performance. The list size isℓ= 64. At the same time, (512,85) polar coset codes with the JSC decoder can recover collisions of order up",
    "of frozen tuples for all users, and the frozen bit values were chosen at random for each user, since using identical frozen values leads to poor performance. The list size isℓ= 64. At the same time, (512,85) polar coset codes with the JSC decoder can recover collisions of order up toT= 8. The resulting energy efficiency is presented in Fig. 5.15 by a green line with circular markers. This scheme outperforms the LDPC-based scheme presented above and is very close to the IRSA achievability bound [106] (T= 4). Moreover, this scheme closely matches the sophisticated scheme 127 from Section 5.2. 5.6.2 Sparse interleave division multiple-access-based schemes The energy efficiency of the sparse IDMA scheme described in Section 5.2 is presented in Fig. 5.15 by a magenta line with circular markers. The authors chosek p= 15 bits for the preamble in the IRSA-F scheme, and the remainingk c= 85 bits were encoded using the LDPC code. The structure of the LDPC code was carefully optimized for each number of active usersK a. The choice of the coding rate is: •0.125 forK a= 25, . . . ,125, •0.25 forK a= 150, . . . ,200, •0.4 forK a= 225, . . . ,300. Each codeword appeared in the channel twice. The length of the preamble isn p= 2000. The CS design matrix uses np/2randomly chosen rows from the discrete Fourier transform (DFT) matrix. Then, the imaginary and real parts of this matrix are stacked together to form a real-valued sensing matrix. The resulting matrix is a good choice for CS-based preamble detection because it satisfies the restricted isometry property (RIP) with high probability [145]. The resulting energy efficiency shows better performance compared to the IRSA-based scheme. The plot presented in Fig. 5.15 corresponds to the case without SIC. The use of SIC provides an improvement of about 0.5 dB for small values ofK a≲100 and approximately 0.2 dB for largerK a values. This scheme was further improved in [144] and is known as on-off division multiple access (ODMA). Compared to the previously described scheme, there are three main differences. The first is that the IRSA-like scheme has been replaced by a single transmission without replicas. The second is the replacement of LDPC codes with polar codes. The third difference is power diversity: instead of transmitting with a fixed energy, a random energy is chosen by each user such that the average power constraint is satisfied. The positions where BPSK-modulated symbols of the polar-encoded message are transmitted are derived from the preamble. The choice of the preamble is given by the firstk pbits of the information message. Preamble detection is solved by a CS decoding algorithm. The authors have chosen the following parameters: •Preamble codebook size 2kp, wherek p= 12 forK a= 50,k p= 13 forK a≤150, andk p= 14 otherwise. •Polar codes of lengthn c= 512 bits forK a≤200 andn c= 256 otherwise. 128 The authors considered the CRC of size 16 bits and the SCL decoding algorithm with a list size of 128. The performance of this scheme is represented by a",
    "13 forK a≤150, andk p= 14 otherwise. •Polar codes of lengthn c= 512 bits forK a≤200 andn c= 256 otherwise. 128 The authors considered the CRC of size 16 bits and the SCL decoding algorithm with a list size of 128. The performance of this scheme is represented by a magenta line with triangular markers. 5.6.3 Coded compressed sensing-based schemes Numerical evaluation of Theorem 5.3 Let us start the numerical analysis of the CCS-based schemes with the RCB from Theorem 5.3 for t= 0, presented by a dashed orange line. The number of slots in a frame was optimized for each number of active users, and an OMP [146] decoding algorithm was utilized. The inner codebook is Gaussian and has a size of 215for each slot. The resulting energy efficiency is presented in Fig. 5.15 by a dashed orange line. t-tree code numerical evaluation Next, let us consider the performance of the tree-code scheme presented in Section 5.3.3 with t= 0. Recall that the caset= 0 was first considered in [93], and we follow these results in our presentation. The inner codebook size is 215forK a≥150, and 214forK a<150. The inner codebook is a subcode of the (2047,23) BCH code. The slot length equals 2047. The inner code was decoded by the NNLS algorithm. The number of slots is fixed and equals 11. Hence, the frame length equals 22517. The authors suggested transmittingk= 75 information bits, which results in a similar code rate of 100/30000 for fair comparison. The main problem was the allocation of information bits to each slot. When decoding each sub- sequent slot, all codeword candidates must be kept, and this number may dramatically grow [94]. Moreover, the final performance of the system may drastically degrade in the case of inappropriate information bit allocation. The information bit allocation has been carefully optimized, and the resulting performance is shown in Fig. 5.15 by an orange line with×-shaped markers. The distance between the RCB and the scheme is about 2 dB atK a= 150, and it gradually increases. Further improvements More sophisticated schemes that include interaction between inner and outer codes show signif- icantly better energy efficiency results. The results from [96] are shown by an orange line with square markers, and the results from [133] are shown by triangle markers. It is worth mentioning the last scheme, which does not use an outer code [136]. The outer code requires additional redundancy. The proposed solution eliminates this redundancy and makes the scheme the best-performing one whenK a>200. 129 Table 5.1: This is a summary of the encoding parameters used in [97] as functions of the number of active users. Ka kpkc=k−k pnp ncList size CRC size 25−75 9 91 29 1024 32 16 100−175 8 92 29 1024 32 16 200−225 9 91 59 512 32 12 250−300 10 90 117 256 32 10 5.6.4 Random spreading-based solutions In this section, we provide the numerical results of the practical schemes described in Section 5.4.3, namely joint decoding of polar codes, power diversity, and SoIC. Joint decoding of polar codes Let us",
    "9 91 59 512 32 12 250−300 10 90 117 256 32 10 5.6.4 Random spreading-based solutions In this section, we provide the numerical results of the practical schemes described in Section 5.4.3, namely joint decoding of polar codes, power diversity, and SoIC. Joint decoding of polar codes Let us start with polar codes and spreading [97]. As in the case of IRSA-F, the authors propose to select the spreading sequence based on the firstk pinformation bits. The length of the spreading sequencen sgenerates a trade-off between the interference mitigation capability and the single-user code rate, because the frame lengthn=n p×nc, andn cis the code length. The optimal parameters for each number of active users are presented in Table 5.1. As soon as the CRC-aided polar codes have been selected, the CRC size is also specified. The resulting energy efficiency is presented in Fig. 5.15 by a blue line with star-shaped markers. For a fixed value ofK a, the quantitiesn candn pare optimized empirically to minimize the energy per bit required to achieve a target probability of error. The spreading sequences were generated from a Gaussian codebook. Power diversity The next scheme [98] considers power diversity for spreading sequences that improves single pream- ble detection and subsequent SIC. The authors of [98] did not change the spreading sequence and code lengths (n c= 256,n p= 117), but varied the number of bits used to derive the spreading sequence:k p= 14 for 150≤K a<200,k p= 15 for 200≤K a<250, andk p= 16 forK a≥250. This choice of parameters results in a small probability of preamble collision. The decoding list size was substantially larger (512) compared to the previous solution (32). The spreading sequences were also generated from a Gaussian codebook, but all spreading sequences were split into several groups having different powers. The number of groups and power levels were optimized to improve the signal-to-interference-plus-noise ratio at each decoding step. The resulting energy efficiency is presented in Fig. 5.15 by a blue line with square markers. The curve starts fromK a= 150 because smallerK avalues have only a single power splitting group. 130 Soft SIC Finally, let us consider random spreading with a SoIC [99]. The spreading sequences are generated usingk p= 12 bits from the information message, and the length of the spreading sequence is np= 86. The LDPC code rate is 1/4. The structure of LDPC codes was optimized using a DE on protographs [112]. The performance of this scheme is presented by a blue line with circular markers in Fig. 5.15. 131 132 Chapter 6 Fading channels More realistic channel models, such as the Rayleigh fading channel, have also been considered in the literature. While the AWGN channel may be a suitable model for satellite communications when multipath propagation is limited, the Rayleigh fading channel is more appropriate for cellular communications, as it assumes a rich scattering environment. To operate in a fading channel, channel state information (CSI) must be acquired. However, estimating the channel for a large number of devices transmitting short packets is prohibitively difficult. Indeed, the best",
    "limited, the Rayleigh fading channel is more appropriate for cellular communications, as it assumes a rich scattering environment. To operate in a fading channel, channel state information (CSI) must be acquired. However, estimating the channel for a large number of devices transmitting short packets is prohibitively difficult. Indeed, the best way to estimate the channel is to include a preamble or reference sig- nals in the transmitted message. However, in the case of uncoordinated transmission, we must ensure that these reference signals remain nearly orthogonal. Unfortunately, orthogonality can be compromised by both short transmitted messages and a large number of simultaneously active users. Consequently, the URA model assumes the absence of the CSI at both the transmitters and the receiver. The works [147, 148, 149, 94] describe fundamental limits and practical schemes for single-antenna quasi-static Rayleigh fading channels. The most notable observation is that fad- ing increases the required energy per bit by approximately 10 dB under the same order of PUPE requirements (see Fig. 5.15 and Fig. 6.2). A. Fengler and G. Caire were the first to demonstrate that employing multiple antennas at the BS can significantly improve energy efficiency without increasing transmitter complexity [150]. Recall that the transmitters are autonomous, battery-powered devices and should be as simple as possible. The fundamental limits for URA with a MIMO receiver were established in [151, 152, 153]. Of particular importance is the scaling law derived in [154] and refined in [151]: withnchannel uses and a sufficiently large number of BS antennas (K a/L=o(1)), up toK a=O(n2) active users can be served amongK totpotential users. Practical receiver schemes have been extensively studied in the literature. The design of these schemes typically involves pilot-based channel estimation followed by decoding and SIC [154, 155], or a CCS approach combined with non-Bayesian activity detection [150], SIC [156], or the exploita- tion of slot-wise correlations [157]. The scheme proposed in [158] integrates these approaches and delivers state-of-the-art performance for the MIMO channel. 133 This chapter is organized as follows. In Section 6.1.1, we specify the channel model – a quasi-static Rayleigh fading MAC with a BS equipped with either a single or multiple receive antennas. To define the achievability bounds, we propose two decoding rules in Section 6.1.2: ML decoding and projection-based decoding. Furthermore, we show that projection-based decoding achieves theε- capacity. Next, in Section 6.2, we consider single-antenna bounds, and in Section 6.3, we describe known results for the multiple-antenna case. Finally, we conclude this chapter by discussing low- complexity schemes presented in Sections 6.4.1 and 6.4.2 for single-antenna and multiple-antenna scenarios, respectively. 6.1 Channel model 6.1.1 Rayleigh fading model The main cause of fading is multipath propagation. The receiver experiences interference of multiple transmitted signal copies. Each copy of the signal can experience random attenuation due to reflections from obstacles and random delays due to different propagation path length. Finally, a moving receiver may experience a Doppler spread, but this is not the case for the massive machine- type communications, where most transmitting devices are stationary or moving relatively slowly. The Rayleigh fading model corresponds to",
    "to reflections from obstacles and random delays due to different propagation path length. Finally, a moving receiver may experience a Doppler spread, but this is not the case for the massive machine- type communications, where most transmitting devices are stationary or moving relatively slowly. The Rayleigh fading model corresponds to a so-called rich scattering environment. When the number of scatterers becomes large and each reflection coefficient is random, the central limit theorem can be applied. Moreover, in such a rich scattering environment, there is no line-of-sight component, and the received power distribution becomes uniform over the angle-of-arrival (AoA). As a result, for a single-antenna receiver, the channel coefficient follows a circularly symmetric complex normal distribution, and the magnitude of this channel coefficient becomes Rayleigh- distributed. For a MIMO receiver, assuming a uniform power distribution over the AoA and a regular antenna array, the resulting channel coefficients at each receiving antenna follow the same distribution [34]. When the transmitting devices are stationary and operate in a slowly-varying environment, the re- sulting channel model becomes quasi-static. Furthermore, since each device transmits infrequently, the channel coefficient remains constant during a transmission but changes from block to block, with channel realizations being independent across different blocks. Moreover, the channel coef- ficients (under the aforementioned central limit theorem) follow a circularly symmetric complex normal distribution, meaning that the phase of the signal is uniformly distributed. Additionally, small synchronization errors can also be described by this phenomenon. The time-domain delay results in a phase shift of the signal in the frequency domain. On the other hand, orthogonal frequency-division multiplexing (OFDM) provides an elegant solution for frequency-domain channel equalization, as long as the length of the cyclic prefix exceeds the maxi- mum relative delay value [159]. However, OFDM signals have a large peak-to-average power ratio, which may lead to high energy consumption under linear amplification, potentially impacting bat- tery life. Therefore, we plan to focus on simpler (and constant-envelope) modulations at low rates. In this context, synchronization errors can partially be modeled as phase multipliers in the channel 134 coefficients. Now, let us formulate the URA problem for the fading channel scenario with a receiver equipped withLantennas. We assume that each transmitting device has a single transmit antenna. Let T=W 1, W2, . . . , W Kadenote the set of transmitted messages (using the same codebook with blocklengthn). The channel model can be described as follows. Y=XΦ(T)H+Z,(6.1) whereY= [y 1, . . . ,y L]∈Cn×Lis the channel output matrix,X= [x 1, . . . ,x M]∈Cn×Mwith xW=f(W), W∈[M], is the common codebook. Here,Φ(T)∈ {0,1}M×K arepresents the activity matrix, where each column contains a single non-zero element at the position corresponding to the user’s message. The matrixZ∈Cn×Ldenotes the AWGN matrix, with each element sampled i.i.d. fromCN(0,1). Finally,H∈CKa×Lis the matrix of fading coefficients, where each element is sampled i.i.d. fromCN(0,1). Note that the fading coefficients are independent of the codewords and the noise matrixZ. In what follows, we assume thatHis unknown to both the transmitters and the receiver (the unknown CSI scenario). As a result, the receiver observesLlinear combinations of",
    "of fading coefficients, where each element is sampled i.i.d. fromCN(0,1). Note that the fading coefficients are independent of the codewords and the noise matrixZ. In what follows, we assume thatHis unknown to both the transmitters and the receiver (the unknown CSI scenario). As a result, the receiver observesLlinear combinations of the transmitted messages, where the coefficients of these linear combinations are determined by the rows of the matrixH. 6.1.2 Decoding rules In the case of the AWGN channel model, we considered the set of codewords closest to the received signal, as described in (4.1). However, since the new channel model involves unknown CSI, the decoding rule must be modified. The first idea was proposed in [160]. In the absence of noise, the signal received by each antenna lies in the subspace spanned by the transmitted codewords, regardless of the fading coefficients. Thus, the most likely subset of transmitted codewords is the one that maximizes the projection of the received signal onto the subspace spanned by these codewords. As we will see later, the projection method ignores the prior distribution of fading coefficients. Additionally, the projection-based decoder has a limitation: it restricts the maximum number of active users to the blocklength, i.e.,K a< n. For the case of multiple antennas, as shown in [151], the maximum number of users that can be decoded may exceed the blocklength. To address this issue, an ML-based decoding rule was proposed in [151]. ML decoding rules [151, 152] estimate the transmitted codeword set by maximizing the conditional probability Pr [Y|X R′] =E H{Pr [Y|X R′,H]}, which is the expectation over the channel statistics. Note that the receiver does not know the channel realizations but may have access to the channel statistics in many scenarios. Let us denote the matrix composed of the codewords fromR′asX R′. The ML decoding rule is given by R= arg max R′⊂[M],|R′|=KaEH{Pr [Y|X R′,H]}.(6.2) 135 The idea of the projection decoder is to take not the expectation, but the maximum of the corre- sponding conditional probability, as described in [148]. The projection-based decoding rule is given by R= arg max R′⊆[M],|R′|=Kamax H{Pr [Y|X R′,H]}.(6.3) Note that the probability Pr [Y|X R′,H] is governed by Gaussian noise, as the conditioning results in a known linear combination of a candidate setX R′of codewords. Assuming Gaussian noise, we can rewrite (6.3) as R= arg min R′⊆[M],|R′|=Kamin H∥Y−X R′H∥2 F = arg min R′⊆[M],|R′|=Ka\u0010 ∥Y∥2 F− ∥P R′Y∥2 F\u0011 = arg max R′⊆[M],|R′|=Ka∥PR′Y∥2 F,(6.4) where the second equality follows from the fact that the received signalYis fixed. Here∥·∥2 F denotes the Frobenius norm, andP R′is the orthogonal projection onto the subspace spanned by the codewords fromR′. A comparison of (6.2) and (6.3) clarifies the previous statement that a projection-based decoding rule does not take channel statistics into account. 6.2 Single-antenna quasi-static Rayleigh fading MAC In this section, we present existing bounds for the single-antenna quasi-static Rayleigh fading MAC. First, we describe theε-capacity bound, which serves as a suitable capacity measure for quasi-static channels. Next, we describe the Shamai-Bettesh asymptotic bound, which provides insight into the corresponding bounds",
    "account. 6.2 Single-antenna quasi-static Rayleigh fading MAC In this section, we present existing bounds for the single-antenna quasi-static Rayleigh fading MAC. First, we describe theε-capacity bound, which serves as a suitable capacity measure for quasi-static channels. Next, we describe the Shamai-Bettesh asymptotic bound, which provides insight into the corresponding bounds in the finite blocklength regime. Finally, we consider the RCB for the FBL scenario (Theorem 6.2) and the converse bound (Theorem 6.3). 6.2.1 Capacity region, all-active users In the presence of fading, the capacity of the channel should be defined differently compared to Shannon’s formula for the AWGN channel. Consider a slow fading channel model [34], or a channel with a large coherence block. Our quasi-static model fits well with the definition of the slow fading model. For any prospective rate of reliable communication, there is a probability that a channel realization will be of such a small magnitude that the user will be unable to communicate reliably over this channel at the selected rate. Thus, in the slow-fading regime, anε-capacity should be introduced instead. Similarly, letC ε,Jdenote theε-capacity region, which can be defined for the case of all-active Ka[147] underjointdecoding. A rate tuple (R 1, . . . , R Ka) is said to beε-achievable [161] if 136 there is a sequence of codes whose rates are asymptotically at leastR isuch that the joint error is asymptotically smaller thanε. Cε,J={R= (R 1, . . . , R Ka) :∀i, R i≥0 andP 0(R)≤ε}, where P0(R) = Pr [ S⊂[K a]( log 1 +PX i∈S|Hi|2! ≤X i∈SRi) . Theorem 6.1(Projection decoding achievesC ε,J[147]).LetR∈C ε,J. ThenRisε-achievable through a sequence of codes with the decoder being the projection decoder(6.3). Nevertheless, in the FBL regime and under the PUPE metric, the projection decoder may be suboptimal. However, this type of decoder allows the achievability bound to be addressed, as presented in Theorem 6.5. 6.2.2 Shamai-Bettesh capacity bound There is another asymptotic bound (n→ ∞) for the PUPE in the case of symmetric rates and largeK a, the Shamai-Bettesh capacity bound from [162]. The idea is as follows: the joint decoder knows the realization of the fading coefficients, and users are ranked according to the strength of their fading coefficients. It first tries to decode all users. If it fails (i.e., if the rate vector is not inside the instantaneous full capacity region), it drops the user with the smallest fading coefficient and tries to decode the remainingK a−1 users. The dropped user then contributes to the noise. This process continues iteratively, and the fraction of users that were not decoded corresponds to the PUPE. Since the case under discussion involves largeK a, the order statistics of the absolute value of the fading coefficients crystallize (i.e., become almost non-random), and hence analytical expressions can be derived for the outage in terms of spectral efficiency (kK a/n) and total power. Note that the Shamai-Bettesh bound is only an achievable bound (i.e., it is not guaranteed to be tight) for the capacity under PUPE. It does not apply to our setting for two reasons. First, it assumes different",
    "for the outage in terms of spectral efficiency (kK a/n) and total power. Note that the Shamai-Bettesh bound is only an achievable bound (i.e., it is not guaranteed to be tight) for the capacity under PUPE. It does not apply to our setting for two reasons. First, it assumes different codebooks for different users, and second, it assumes asymptotically large blocklength. Note also that the asymptotic regime considered in the Shamai-Bettesh bound is as follows: first, nis taken to∞(under a fixedK a), and second,K ais also taken to infinity. However, based on studies of the non-fading channels [87], the correct asymptotic regime is to take bothK aandnto infinity at a fixed ratio [147]. 6.2.3 FBL regime, partial activity Let us formulate the achievability bound for a single-antenna URA under a quasi-static Rayleigh fading channel. We provide a simplified formulation and outline the main steps of the proof, 137 referring the reader to [148] for the complete proofs. As in the case of AWGN, we consider the event Pr [E t] (4.2), which represents exactlyterrors occurring. We assume a circularly symmetric Gaussian codebook, similar to Definition 4.1. Definition 6.1.LetG CN(M, n, P)be the ensemble of Gaussian codebooks of sizen×M, where each element is sampled i.i.d. fromCN(0, P). To estimate the PUPE, we must evaluate Pr [E t] fort∈[K a]. Similar to the AWGN case, we denote the probability of power violation and message collision asp 0. Theorem 6.2(Achievability bound for single-antenna case [148]).FixP′< P. There exists a codebookX∗∈ GCN(M, n, P′)satisfying the power constraintP′and providingP eusing eq.(4.2), wherep 0is bounded by(4.6), andPr [E t]≤p t, where pt≤inf δ>0\u0012\u0012Ka t\u0013 e−(n−K a)δ+p1,t\u0013 ,(6.5) where p1,t= Pr [ M⊂T |M|=t{GY,T,C,t ≥Vn,t} ,(6.6) GY,T,C,t =∥Y∥2− ∥P TY∥2 ∥Y∥2− ∥P CY∥2.(6.7) The Frobenius norm in(6.7)becomes a simple Euclidean norm for the single-antenna case, and Vn,t=e−(δ+R 1+st), s t=ln\u0000n−K a+t−1 t−1\u0001 n−K a, R 1=ln\u0000M−K a t\u0001 n−K a. The original formulation [148] of the theorem above assumed that the number of active users may differ from the intended list size at the receiver. This approach was inspired by the Shamai-Bettesh asymptotic bound described above (see Section 6.2.2). This approach may be beneficial in the case of largeK a: it may be better not to consider the weakest users but instead decode the remaining ones with a smaller probability of error. In the formulation above, we omit this assumption for simplicity and consider the case when the decoder tries to extract all active users. This theorem introduces a projection ratio (6.7), which depends on the choice of the correctly received codewords, and a union probability is taken in (6.6). This union over all choices can be replaced by simply selecting thet-weakest1codewords as missed, significantly reducing the computational complexity. To evaluate the achievability bound numerically, the tail probability of the projection ratio can be computed either by sampling or analytically (see the complete proof of this theorem in [148]). 1Or codewords that have the smallest received energy 138 The main step of this theorem’s proof avoids a large combinatorial term\u0000M−K a t\u0001 described in Section 4.1.1. This is done",
    "the projection ratio can be computed either by sampling or analytically (see the complete proof of this theorem in [148]). 1Or codewords that have the smallest received energy 138 The main step of this theorem’s proof avoids a large combinatorial term\u0000M−K a t\u0001 described in Section 4.1.1. This is done by observing that a projection of the fixed vector onto a random subspace generated by Gaussian vectors arises. The norm of this projection follows a beta distribution [147]. Let us rewrite the condition that exactlyterrors occurred conditioned on the channel coefficients, noise, and a set of transmitted codewords. By applying the union bound, we have Pr [E t|T,H,Z]≤Pr\"[ M[ FFF,C,t T,H,Z# ,(6.8) where FF,C,t=n ∥PC∪FY∥2>∥P C∪MY∥2o . Note that the unionS Mis taken over\u0000M−K a t\u0001 variants. Hence, the expectation overMshould be performed first. To perform this step, let us fix the set of correctly received codewordsCand show that the projection norm∥P C∪FY∥2is distributed as ∥PC∪FY∥2∼ ∥P CY∥2+ P⊥ CY 2 β(n−K a, t). Following the notation from [153],P CSF=PC+PC⊥,Fby a Gram-Schmidt procedure, where PC⊥,Fis a projection onto span\b P⊥ CXF , andP⊥ C=I−P C. Finally, under the fixedC,∥P C∪FY∥2is a random variable that depends only on falsely detected codewords. Moreover, PC⊥,FY 2 P⊥ CY 2∼β(n−K a, t) (6.9) is beta-distributed [163] as a projection of a fixed vector onto a random subspace spanned by span\b P⊥ CXF in the dimensionn−K a+t– the dimensionality of a subspace orthogonal to span{X C}. The final building block of the theorem proof is that the cumulative density function of 1−β(where βis beta-distributed) random variable is bounded by F1−β(x;n−K a, t)≤\u0012n−K a+t−1 t−1\u0013 xn−Ka,(6.10) and the resulting probability ofterrors occurring will be upper-bounded by Pr [E t|T,H,Z]≤E T,H,Z min  1,X C⊂T |C|=K a−te(n−K a)(st+R1)Gn−K a Y,T,C,t   . The parameterδin the theorem appears after applying Fano’s trick (see Section 4.2.2) on the formula above. To perform numerical evaluation of this bound, the following steps must be performed: 139 •SampleH, codewords fromT, andZ, •Evaluate the cumulative distribution function of (6.7). A simplification by choosingtweakest users rather than checking\u0000Ka t\u0001 variants can be considered, •Perform optimization overδ. Now let us describe a simple converse bound based on results from [164] and the meta-converse from [165]. Theorem 6.3(Multi-user, single-antenna converse [148]).Let Ln=nlog(1 +PG) +nX i=1\u0010 1− |√ PGZ i−√ 1 +PG|2\u0011 and Sn=nlog(1 +PG) +nX i=1 1−|√ PGZ i−1|2 1 +PG! , whereG=|H|2andZ ii.i.d.∼ CN(0,1). Then, for everynand0< ϵ <1, any(M, n−1, ϵ)code for the quasi-staticK aMAC satisfies log(M)≤log(K a) + log1 Pr [L n≥nγ n] whereγ nis the solution of Pr [S n≤nγ n] =ϵ. 6.3 Multi-antenna quasi-static Rayleigh fading MAC In this section, we consider the case where a BS is equipped with multiple antennas – the so-called MIMO scenario. As discussed previously, the projection-based decoder achieves theε-capacity in the single-antenna case. However, as shown in Section 6.3.1, the number of successfully detected users can exceed the frame length, i.e.,K acan be greater than the frame lengthnin the MIMO case. Consequently, whenK a> n, the projection-based decoding (6.3) will no longer work, as the subspace",
    "decoder achieves theε-capacity in the single-antenna case. However, as shown in Section 6.3.1, the number of successfully detected users can exceed the frame length, i.e.,K acan be greater than the frame lengthnin the MIMO case. Consequently, whenK a> n, the projection-based decoding (6.3) will no longer work, as the subspace spanned by the transmitted codewords coincides with the full signal space. To address this problem, the ML-based bound in (6.2) was proposed in [151]. Previously, we consid- ered the single-antenna case, where the approach relied on eliminating the large combinatorial term\u0000M−K a t\u0001 . However, in the proposed ML-based bound, this simplification does not lead to an effi- cient solution. Evaluating this bound requires sampling codewords from all possible sets: correctly detected codewordsC, falsely detected codewordsF, and missed codewordsM(see Fig. 4.1). On the other hand, a similar approach based on projection decoding (6.3) offers some improvements when the number of active usersK ais less thann. Nonetheless, deriving a projection-based achievability bound in a manner similar to the single-antenna case still does not yield an efficient solution. This is because the projection ratios (6.9) have an intractable distribution, requiring the handling of angles between random subspaces. 140 6.3.1 Scaling laws The benefits of multiple antennas were analyzed by Fengler et al. [150], where the authors examined the scenario ofactivity detection. A set of active users sends theirK arandomly chosen preambles (selected from a total ofK totpreambles) in a dedicated slot. Since detecting a single transmission in a massive MIMO regime requires accurate channel estimation, activity detection plays a crucial role in practical implementations. The goal of the receiver is to detect the subset of preambles selected for transmission and then proceed to the user’s signal detection step, where the CSI is obtained from the preambles. This problem is closely related to the URA problem. Given multiple antennas (L >1), the corresponding URA problem (6.1) can be formulated as a multiple measurement vector (MMV) problem in the context of CS [166] (see also Section 3.2). The scaling law proposed in [150] states that given Ka L≈o(1), the number of detectable users is O n2 log2\u0010 Ktot Ka\u0011 . Notably, this number can be significantly higher compared to the projection-based decoding algo- rithm, whereK a< n. 6.3.2 Achievability bounds for MIMO receiver In this section, we describe the achievability bound for the MIMO case based on random coding, as introduced in Section 4.1.1. Given the scaling law described above, there is a motivation to shift away from the projection-based decoding algorithm, which is limited byK a< n. As the number of receiver antennas increases, an ML-based decoding algorithm is chosen for the bound [151]. We consider a Gaussian codebook ensemble (see Definition 6.1) and recall the channel model (6.1). Suppose thechannel statistics, i.e., the distribution of channel coefficients – the elements ofH– are known. Then, conditioned onXΦ(T), the columns ofY, the signal vector received by each antenna, are independent and normally distributed: yi∼ CN\u0000 0,In+XΓXH\u0001 ,Γ=Φ(T)ΦH(T), where (·)Hdenotes the Hermitian transpose. LettingΣ=I n+XΓXH, we obtain the following p.d.f.: p(Y|XΦ(T)) =π−Ln|Σ|−Lexp\u0000 −tr\u0000 Σ−1YYH\u0001\u0001 . The corresponding",
    "of channel coefficients – the elements ofH– are known. Then, conditioned onXΦ(T), the columns ofY, the signal vector received by each antenna, are independent and normally distributed: yi∼ CN\u0000 0,In+XΓXH\u0001 ,Γ=Φ(T)ΦH(T), where (·)Hdenotes the Hermitian transpose. LettingΣ=I n+XΓXH, we obtain the following p.d.f.: p(Y|XΦ(T)) =π−Ln|Σ|−Lexp\u0000 −tr\u0000 Σ−1YYH\u0001\u0001 . The corresponding decoding function to be optimized is: g\u0000 Y,XΓXH\u0001 =Llog|Σ|+ tr\u0000 Σ−1YYH\u0001 .(6.11) 141 The decoder aims to find the set of active users that minimizes (6.11). In the subsequent analysis, we define the matrixΓformed by the message setSasΓ Sand denote (6.11) asg(Γ S). As before, we estimate the probability of the eventE t, in which exactlyterrors occur: Pr [E t] = Pr [E t,M,F ],E t,M,F =[ F[ M{g(Γ C∪F)≤g(Γ C∪M)}. Clearly, we can use the union bound to upper-bound the right-hand side. However, the union bound is known to overestimate the resulting probability. To tighten the bound, we use Fano’s trick, i.e., we introduce the following region: BM={Y:g(Γ T)≤αg(Γ C) +βnL},B=\\ MBM.(6.12) Using Fano’s trick, we upper-bound Pr [E t] as follows: Pr [E t] = Pr [E t,M,F ]≤Prh Et,M,F\\ Bi + Pr [Bc].(6.13) The main idea is as follows. We apply the union bound only whenYis within an allowed region, while we assume that Pr[E t] = 1 otherwise. This approach prevents overestimating the probability by avoiding the use of the union bound forYoutside the good region, where the union bound is effective. Theorem 6.4(ML-based achievability bound [151] for the same codebook [152]).FixP′< P and consider a receiver equipped withLantennas. There exists a codebookX∗∈ GCN(M, n, P′) satisfying the power constraintP′and providingP eusing eq.(4.2), wherep 0is bounded by(4.6), andPr [E t]≤p t, where pt≤inf 0≤α≤1,0≤β{q1,t(α, β) +q 2,t(α, β)},(6.14) where q1,t(α, β) =\u0012Ka t\u0013\u0012M−K a t\u0013 EX inf u≥0, r≥0, λmin(B)>0\u0010 eLrnβ·eLµ\u0011 ,(6.15) µ= (u−r) log|F T| −ulog|F R|+rαlog|F C| −log|B|, q2,t=\u0012Ka t\u0013 inf δ≥0EX\u0014γ(Lm, c δ) Γ (Lm)+ 1−γ(nL,(1 +δ)nL) Γ (Ln)\u0015 ,(6.16) cδ=Ln(1 +δ) (1−α)−αlog|F C|+ log|F T| −nβ αQm i=1λ1/m i, B= (1−u+r)I n+uF−1 RFT−rαF−1 CFT, wherem= min{n, t}. The matrixF Sis the covariance matrix corresponding to the codeword set S, given by FS=In+XΓ SXH. 142 By the notation above, FS=In+XSXH S. Finally,λ 1, . . . , λ mare the eigenvalues of the matrixF−1 CXΓMXHof rankm, arranged in decreasing order. In this theorem, the expectation is taken over a codebook ensemble. Thus, w.l.o.g., let us assume that the correctly received, missed, and falsely detected codewords (see Section 3.1 and Fig. 4.1) correspond to the firstK a+tcodewords of the codebookX [Ka+t]. Hence, we define the sets as follows: Transmimtted codewordsT=[K a], Received codewordsR=[K a+t]\\[t], Correctly received codewordsC=[K a]\\[t], Missed codewordsM=[t], Falsely detected codewordsF=[K a+t]\\[K a]. The idea is to first apply Fano’s trick (6.13). Then, for the first probability term, Pr [E t,M,FTB], a Chernoff bound can be applied (Lemma G.1). The proof ultimately results in an expectation over a codebook ensemble, which can be evaluated numerically. However, the minimum required number of samples remains unknown. Moreover, sampling falsely detected codewords may be challenging due to the large number of possible com- binations, given by\u0000M−K a",
    "can be applied (Lemma G.1). The proof ultimately results in an expectation over a codebook ensemble, which can be evaluated numerically. However, the minimum required number of samples remains unknown. Moreover, sampling falsely detected codewords may be challenging due to the large number of possible com- binations, given by\u0000M−K a t\u0001 . Theorem 6.5(Projection-based achievability bound [153] for the same codebook).FixP′< P and consider a receiver equipped withLantennas. There exists a codebookX∗∈ GCN(M, n, P′) satisfying the power constraintP′and providingP eusing eq.(4.2), wherep 0is bounded by(4.6), andPr [E t]≤p t, where Pr [E t]≤inf 0≤α≤1(p1,t+p2,t),(6.17) where p1,t=\u0012Ka t\u0013\u0012M−K a t\u0013 EX\u0014 inf u,v>0,λ D>0|I−DΣ|−L\u0015 ,(6.18) p2,t=\u0012Ka t\u0013 EX\u0014 inf δ>0,λ B>0|I−BΣ|−L\u0015 ,(6.19) where Σ=I n+XTXH T, D=uP R−uP T+αvP⊥ C−vP⊥ T, B=−αδP⊥ C+δP⊥ T. Here,λ Dandλ Bdenote the minimum eigenvalues ofI−DΣandI−BΣ, respectively. The expectations are taken overX T ∪R. The setsT,R, andCare defined above. The idea behind this theorem is similar to that of the previous one, but the decoding function (6.11) is replaced with the projection rule (6.3). Similar to the ML-based achievability, Fano’s trick is applied, followed by a Chernoff bound. Finally, the expectations over codewords must be evaluated. 143 6.3.3 Converse bound for MIMO receiver The converse bound described below is presented in [151, Theorem 9]. Theorem 6.6(No-CSI case converse [151]).Assume that there areK aactive users amongK potential users, each equipped with a single antenna, and that the number of BS antennas isL. Each user has an individual codebook of sizeMand lengthn. For massive random access in MIMO quasi-static Rayleigh fading channels with no CSI and knownK a, the minimum energy per bit required to satisfy the PUPE requirement in(3.1)can be lower-bounded as E∗ b,no-CSI,K a(n, M, ϵ)≥infnP log2M.(6.20) The infimum is taken over allP >0satisfying the following condition: (1−ϵ) log2M−h 2(ε)≤LC Ka−L KaEX\u0002 log2 IKa+XH TXT \u0003 ,(6.21) C= min\u001a nlog2(1 +K aP), K aMlog2\u0012 1 +nP M\u0013\u001b ,(6.22) where codewordsX Tare drawn fromG CN(M, n, P). The right-hand side of(6.21)can be further loosened to LC Ka−L Ka˜n−1X i=0\u0012 ψ(˜n−i) log2e+ log2\u0012 P+1 ˜n−i\u0013\u0013 , where˜n= min(K a, n), andψ(·)denotes Euler’s digamma function. The idea behind this theorem is based on Fano’s inequality, followed by a mutual information analysis inspired by [79]. 6.3.4 Numerical comparison of the proposed bounds In this section, we perform a numerical analysis of the proposed bounds for the scenario taken from [152]. The results are presented in Fig. 6.1. The ML bound shows better performance for Ka<400, but beyond this point, the projection-based bound demonstrates betterE b/N0, with a gap of approximately 1 dB. However, this gap vanishes asK a→n. This phenomenon is driven by the following: Given a similar setup, the PUPE estimate is deter- mined by individual terms corresponding to exactlyterrors, as shown in equations (6.14) and (6.17). In both equations, there is a large combinatorial term,\u0000M−K a t\u0001 , which leads to increased energy efficiency at highK avalues when the last term fort=K adominates in (4.2). In our case, this term starts dominating earlier in the ML bound. However, asK aapproaches the blocklengthn, the ML bound once again exhibits better",
    "there is a large combinatorial term,\u0000M−K a t\u0001 , which leads to increased energy efficiency at highK avalues when the last term fort=K adominates in (4.2). In our case, this term starts dominating earlier in the ML bound. However, asK aapproaches the blocklengthn, the ML bound once again exhibits better energy efficiency, as the projection-based bound is not applicable forK a> n. We also found that the projection-based bound provides a tighter estimation of the “region” prob- ability compared to the ML-based bound. Specifically, with the same parametersαin (6.17) 144 1 2 3 4 5 6 7 8 9 ×102−20−18−16−14−12−10−8−6−4−2024 The number of active usersK aEb/N0, dBML-based achievability, Theorem 6.4 Projection-based achievability, Theorem 6.5 Single-user achievability, [160] Single-user converse, [160] Multi-user converse, Theorem 6.6Figure 6.1: URA achievability bounds for the no-CSI setting with a frame length ofn= 1000 channel uses andk= 100 information bits. The BS is equipped withL= 64 antennas, and the target PUPE isP e≤10−3. ML-based and projection-based achievability bounds are marked by dashed blue and green lines, respectively. As a reference, we consider a single-user converse (marked by a yellow solid line) and a multi-user converse (marked by an orange line). 145 and (6.14), and the same set of samples, the probability (6.15) for the ML-based bound is al- ways smaller than its projection-based counterpart (6.18), whereas the probability (6.16) for the ML-based bound may be higher than the corresponding projection-based term (6.19). Finally, let us once again highlight a key drawback of both bounds – the lack of a rigorous analysis of the required number of samples. 6.4 Low-complexity receiver architectures Compared to the AWGN channel, the Rayleigh block-fading channel model assumes that channel coefficients are random (6.1). Nevertheless, this randomness can be leveraged as follows. For the single-antenna case, there is a natural diversity in received power. There always exists a user with the maximum received power and, likely, the highest SINR. Hence, a straightforward approach is to utilize TIN-SIC. Considering the quasi-static fading model, we assume that the channel coherence time is smaller than the frame length, which naturally leads to a slotted system, or SA. We assume that the fading coefficient remains constant within a slot but changes randomly and independently from slot to slot. In Section 5.1, we considered IRSA, where the main idea was to utilize time diversity by transmitting multiple copies of the same message in different slots. After successful decoding, the message can be subtracted from all other slots. Unfortunately, IRSA cannot be used in a fading scenario because subtraction requires channel estimation, which may have very low precision in the presence of other messages with higher received power. Hence, in the subsequent analysis (see Section 6.4.1), we consider aT-fold SA instead of IRSA. The analysis of SA is followed by an evaluation of CS-based schemes and their results. In the multiple-antenna case, the BS hasL >1 receive antennas (6.1). In this case, random channel vectors (of lengthL) become almost orthogonal, especially whenLis large. As a result, the number of simultaneously active users may increase significantly. However, channel estimation becomes more",
    "an evaluation of CS-based schemes and their results. In the multiple-antenna case, the BS hasL >1 receive antennas (6.1). In this case, random channel vectors (of lengthL) become almost orthogonal, especially whenLis large. As a result, the number of simultaneously active users may increase significantly. However, channel estimation becomes more challenging. To obtain accurate channel estimates, preambles are typically embedded within each slot or coherence block. Low-complexity schemes are presented in Section 6.4.2. 6.4.1 Single-antenna case In this section, we consider two main approaches: aT-fold SA and a CS-based approach. In the subsequent numerical analysis for the single-antenna case, we assumek= 100 information bits, a frame length ofn= 3×104complex channel uses, and a maximum tolerable PUPE value of ε= 0.1. 146 T-fold slotted ALOHA The main results are presented in Fig. 6.2. We begin with a TIN analysis, represented by an orange line. Similar to the AWGN case discussed in Chapter 1, this strategy is highly inefficient. Next, a joint decoder was introduced in [159, 148, 159]. The key idea of this approach is to jointly perform decoding and channel estimation to recover a linear combination of LDPC-encoded and BPSK-modulated messages. The resulting energy efficiency of this scheme forT= 4 is represented by a blue line. This energy efficiency was achieved by using two slot lengths, depending on the value ofK a. For smallK a, a longer slot of lengthn′= 400 was more efficient, whereas for largeK a, a shorter slot of lengthn′= 200 was preferable, as it reduces the maximum number of simultaneous transmissions in a slot. Having the slot lengthn′and the number of simultaneously active users in a slot,r, we can evaluate the PUPE within each slot for a givenT. Let us denote this PUPE value asp r,k,n′, wherekis the number of information bits. Note thatp r,k,n′can represent either a theoretical bound or the slot-level performance of a practical scheme. The final goal is to evaluate the PUPE for the entire frame. Remark 6.1(Evaluating per-frame PUPE given per-slot PUPE).Givenp r,k,n′, the per-frame PUPEp ecan be evaluated as follows. Assuming that each user selects a transmission slot randomly, the PUPE is given by: pe= 1−TX r=1\u0000 1−p r,k,n′\u0001\u0012Ka−1 r−1\u0013\u00121 L\u0013r−1\u0012 1−1 L\u0013Ka−r .(6.23) To evaluate the achievable energy efficiency of this scheme, we applied the achievability bound from Theorem 6.2 to the slot, followed by an assessment of the overall frame performance using eq. (6.23). The result is depicted by a dashed green line, representing the minimumE b/N0over all possible slot lengths for each value ofK a. During numerical analysis, we observed that the first codeword successfully decoded by the joint decoder typically has the highest received energy. Furthermore, given a known channel coefficient, this codeword can also be decoded using a TIN algorithm. This insight led to a modification of the scheme, replacing the joint decoder with a TIN-SIC decoder [168], where LDPC codes were substituted with polar codes due to their superior error-correcting performance for short blocks. We found that the polar code-based scheme exhibits better energy efficiency (black line). We employed a CRC-aided list decoding algorithm and did",
    "the scheme, replacing the joint decoder with a TIN-SIC decoder [168], where LDPC codes were substituted with polar codes due to their superior error-correcting performance for short blocks. We found that the polar code-based scheme exhibits better energy efficiency (black line). We employed a CRC-aided list decoding algorithm and did not use preambles for CSI estimation. Instead, assuming the transmitted signal is BPSK-modulated, we leveraged the Gaussian mixture structure of the received signal to retrieve CSI via a clustering algorithm. Another challenge was the presence of falsely detected codewords. To mitigate this, we increased the CRC size to 21 bits. The SIC step was implemented using the OMP algorithm (see Appendix B.1.4). 147 Table 6.1: Optimal slot countL(and outer code rateR O=k Llog2Q) for RCB Kat= 0t= 1t= 2t= 3t= 4t= 5 50 12 14 15 16 18 19 100 14 15 17 18 19 20 150 15 16 18 19 20 21 200 16 17 19 20 21 22 250 16 18 19 21 22 23 300 17 18 20 21 22 24 Coded compressed sensing In this section, we consider the CCS scheme presented in Section 5.3, now evaluated for a Rayleigh fading channel. Given the channel coherence time assumption, CCS also operates under a slot- ted transmission model. For each slot, we consider an inner codebook of sizeQ= 215. Larger inner codebook sizes improve energy efficiency but require significant computational resources for numerical evaluation. As previously discussed, we consider a setup withk= 100 information bits, a frame length of n= 3×104, and a slot length ofn′=n/L, whereLis the number of slots. Codewords of the inner code are generated with an i.i.d. uniform distribution over the (complex) power shell. We decode the inner code using OMP[146] and its MMSE-based extension[169]. Since OMP is a sequential algorithm, the number of output codewords equals the number of decoding steps, denoted asK 0. Numerical results are presented in Fig. 6.3, where we plot energy efficiency as a function of the active user countK afor different schemes. Energy efficiency is defined as the minimumE b/N0over K0,L, and other scheme-specific parameters/constraints, such that the PUPE satisfiesP e≤0.1 and the FAR satisfiesP f≤10−3. These additional parameters/constraints include the maximum average number of decoding paths for thet-tree code (6.24) and the user prefix size for the RS case. Let us start with the CCS-RCB analysis as presented in Theorem 5.3. The orange lines in the figure correspond to the CCS-RCB fort= 0, . . . ,5. Recall that the parametertrepresents the number of erasures in the outer-code codewords (see eq.(5.17) and the illustrative example presented inFig. 5.11). Fort= 5, there is a significant improvement inE b/N0(more than 10 dB forK a= 50) compared to thet= 0 case. When the number of active users is small, the scheme witht= 5 demonstrates better energy efficiency than aT-fold SA with polar codes from [168], which is known as the best practical solution for the quasi-static fading channel with a single antenna at the receiver. We also observe that higher values oftallow for better energy efficiency but support a smaller maximum",
    "witht= 5 demonstrates better energy efficiency than aT-fold SA with polar codes from [168], which is known as the best practical solution for the quasi-static fading channel with a single antenna at the receiver. We also observe that higher values oftallow for better energy efficiency but support a smaller maximum number of simultaneously active users. The main reason for this behavior is the FAR constraint. Indeed, as the number of active users grows, the FAR also increases (5.19). Moreover, the higher thetvalues, the faster the FAR grows. Suppressing the FAR requires more slots, which necessitates a more robust (smallerp m) inner code to guarantee lowP e(5.18). Ensuring more robust inner code performance under shorter slot lengths leads to inner code failure at some ˜Ka, and this ˜Kais smaller for higher values oft. Fort= 5, ˜Ka≈410, and fort= 0, ˜Ka≈540. The optimal slot count values are presented in Table 6.1 for different values oftandK a. 148 Table 6.2: Optimal slot countL(and outer code rateR O=k Llog2Q) achievability bound for the code from Corollary E.1. The maximum average number of pathsE[|V l|]≤v⋆= 210. Ka: 50 100 150 200 t= 0 13 (0.513) 14 (0.476) 15 (0.444) 16 (0.417) t= 1 27 (0.247) 34 (0.196) 37 (0.180) – t= 2 46 (0.145) 59 (0.145) – – t= 3 66 (0.101) – – – t= 4 85 (0.078) – – – t= 5 100 (0.067) – – – Table 6.3: Greedy bit allocation results forv⋆= 210. Ka Information bits pattern t= 0 50b= [15 11 9 8 9 8 9 8 9 8 6 0 0] 100 b= [15 10 8 8 7 8 8 8 8 8 8 4 0 0] 150 b= [15 9 7 7 8 7 7 8 7 7 8 7 3 0 0] 200 b= [15 8 7 7 7 6 7 7 7 7 7 7 6 2 0 0] t= 1 50b= [10 4. . .4|{z} 222 0 0 0] 100 b= [10 3. . .3|{z} 300 0 0] 150 b= [10 2 2 2 2 2 3 2 3 2 3. . .3|{z} 72 3. . .3|{z} 152 0 0 0] Next, we evaluated the converse bound derived in Theorem E.1. We determined the minimum Eb/N0(overK 0andL) such that (E.3) holds for different values ofK a. Additionally, we included the converse bound from Theorem 6.3 as a reference. The CCS converse (green line in Fig. 6.3) starts below the bound from Theorem6.3 (magenta line in Fig. 6.3) and intersects it atK a≈300. We consider the overall converse bound to be the region above both bounds. To evaluate the achievability bound for thet-tree code from Corollary E.1, the minimumE b/N0 search procedure must take the maximum average number of decoding paths (v⋆) into account as follows: minimizeE b/N0, subject to E[|V l|]≤v⋆, l∈[L],LX l=1bl=k, P e<0.1, P f<10−3,(6.24) whereE[|V l|] is the sum of (E.5) and (E.6) in accordance with (E.4). To solve this problem, an optimization overK 0andn′was performed jointly with a greedy information bits allocation, assigning the maximum number of information bits at each subsequent slotlwhile",
    "subject to E[|V l|]≤v⋆, l∈[L],LX l=1bl=k, P e<0.1, P f<10−3,(6.24) whereE[|V l|] is the sum of (E.5) and (E.6) in accordance with (E.4). To solve this problem, an optimization overK 0andn′was performed jointly with a greedy information bits allocation, assigning the maximum number of information bits at each subsequent slotlwhile keeping the constraintE[|V l|]≤v⋆. If the total number of allocated bitsLP l=1bl< k, we assumeP e= 1. The resulting energy efficiency is presented in Fig. 6.3 by blue lines fort= 0, . . . ,5 andv⋆= 210. 149 Table 6.4: System parameters for the RS-based solution. KaK0L b pRRS bC 50 53 53 9 0.3208 19 100 109 52 9 0.3269 19 150 167 45 9 0.3778 19 200 229 41 9 0.4146 19 Fort= 0, the result is very close to the CCS-RCB, but the difference becomes dramatic fort= 5. The constraintE[|V l|]≤v⋆= 210requires significantly more slots fort >0 compared to the CCS- RCB. The outer coding rates are presented in Table 6.2, and the optimal bits allocation is shown in Table 6.3. Fort= 5, one needsL= 100 slots forK a= 50, which is much higher compared to the CCS-RCB (L= 19 forK a= 50). A larger slot count makes it impossible to construct the t-tree code witht= 5 forK a>60. Finally, we evaluated the RS-based practical solution. For the RS scheme, we found the minimum Eb/N0overK 0,Land the prefix sizeb p(bits). We also adjusted the number of bitsb Cto suppress falsely detected messages, but during the simulations, we simply evaluatedb Cand corrected the Eb/N0. The resulting energy efficiency of the RS-based scheme is presented by green crosses in Fig. 6.3. The RS code parameters are presented in Table 6.4, whereR RSdoes not take the CRC into account (the total coding rate isR=R RS·RCRC, whereR CRC=k/(k+b C)). IncreasingK a requires both a longer prefix and a larger RS code length. These two requirements are contradictory because the RS code is constructed over the field of sizeq=Q/2bp, andq > L. On the other hand, increasing the prefix length decreasesq, making it impossible to increase the number of slots while fittingk= 100 bits into the frame. The slot count increase also weakens the inner-code performance. We note that the practical RS-based scheme operates over a larger outer code length compared to the CCS-RCB. 6.4.2 Multiple-antenna case For the multiple-antenna receiver, we consider a scenario with a frame length ofn= 3200. The channel coherence time is assumed to be at least as long as the proposed frame length. The BS is equipped withL= 50 antennas. To maintain consistency with results presented in the literature, we also consider an error rate constraint ofP e≤0.025. In this setup, employing multiple antennas at the receiver provides two key benefits. First, with Lantennas, receive beamforming can be used to enhance the received signal energy. Second, a large number of antennas introduces a proportionally larger number of degrees of freedom in the communication system [34], allowing for a significantly higher number of simultaneously active users. The most challenging aspect of the receiver is channel estimation. Since each user hasLfading",
    "to enhance the received signal energy. Second, a large number of antennas introduces a proportionally larger number of degrees of freedom in the communication system [34], allowing for a significantly higher number of simultaneously active users. The most challenging aspect of the receiver is channel estimation. Since each user hasLfading coefficients, the previously described clustering-based approach becomes inefficient. A straightfor- ward method is to allocate a portion of the available resources for channel learning and then use the resulting channel estimate to perform a TIN step, followed by SIC. This approach has been 150 implemented in [154]. Pilot detection is closely related to the CS problem. In the case of multiple receiver antennas, this problem is known as the MMV problem. The energy efficiency of the pilot- based scheme is shown in Fig. 6.4 as a light green line. As a reference, we have re-evaluated the achievability bounds presented in Fig. 6.1. The current state-of-the-art solution [158] integrates activity detection, single-user coding, pilot- and temporally decision-aided iterative channel esti- mation, decoding, MMSE estimation, and SIC. The energy efficiency of this scheme is given by a magenta line. Notably, there is a drastic improvement in energy efficiency compared to the single-antenna case. The resulting energy efficiency improves by approximately 10×log10LdB compared to the single- antenna case, due to receive beamforming. Additionally, the number of simultaneously active users increases: up toK a≈800 at a frame length ofn= 3200, compared toK a≈600 atn= 3×104. 151 0 100 200 300 400 500 60081012141618 TIN [148] Converse, Theorem 6.3T= 4, SA-FBL, Theorem 6.2,n 1≤400T= 4, LDPC-joint [167],n 1∈ {200,400} T= 14, Polar, TIN-SIC [168],n 1= 512 KaEb/N0, dBFigure 6.2: MinimumE b/N0required to achieve the PUPE below 10% (ε= 0.1) as a function of the active user count. Theoretical bounds are represented by dashed lines, while practical schemes are shown with solid lines. The green dashed line corresponds to the achievability bound from Theorem 6.2, where the slot lengthn′is chosen optimally using (6.23) forT= 4 andn′≤400. The dashed magenta line corresponds to the converse bound from Theorem 6.3. For practical schemes, we consider TIN,T= 4-fold SA with a joint decoder [148] (n′= 200 and 400 depending onK a), and the best-performing TIN-SIC scheme based on polar codes [168]. 152 0 100 200 300 400 500 6005101520253035 T= 14-fold ALOHA, [168]t= 3t= 4t= 5 t= 2 t= 1 t= 0 t= 4 t= 5t= 3t= 2t= 1t= 0 t= 4A modified RS scheme Converse, Theorem 6.3 CCS Converse, Theorem E.1 The number of active usersK aEb/N0, dBCCS-RCB t-tree codeFigure 6.3: Numerical results for the single-antenna quasi-static Rayleigh fading channel. The maximum tolerable PUPE isP e≤10−1, and FAR isP f≤10−3. ParametersK 0andn′are chosen to minimize the requiredE b/N0. The following curves are presented: CCS-RCB (see Theorem 5.3);t- tree code bounds fort= 0, . . . ,5 (see Corollary E.1), with the maximum average number of decoding paths equal toE[|V l|]≤v⋆= 210; a modified RS scheme from Section 5.3.4 (parameters taken from Table 6.4). A 14-fold SA practical scheme from [168] is added as a reference. Additionally, two converse bounds are",
    "fort= 0, . . . ,5 (see Corollary E.1), with the maximum average number of decoding paths equal toE[|V l|]≤v⋆= 210; a modified RS scheme from Section 5.3.4 (parameters taken from Table 6.4). A 14-fold SA practical scheme from [168] is added as a reference. Additionally, two converse bounds are provided: one from Theorem 6.3 and another for the CCS scheme, based on Fano’s inequality (Theorem E.1). 153 2 4 6 8 10 12 14 ×102−16−15−14−13−12−11−10−9−8−7−6 Projection-based achievability, Theorem 6.5FASURA, [158]Pilot-based scheme, [154] ML-based achievability, Theorem 6.4 Converse, Theorem 6.6Achievability, single-user, [164] Converse, single-user, [164] The number of active usersK aEb/N0, dBFigure 6.4: MinimumE b/N0required to achieve an error rate ofP e≤0.025 as a function of the active user count. Theoretical bounds are represented by dashed lines, while practical schemes are shown with solid lines. As a reference, single-user achievability and converse bounds are included, along with ML-based and projection-based multi-user bounds from Theorems 6.4 and 6.5. The frame length isn= 3200, withk= 100 information bits. The BS is equipped withL= 50 antennas. 154 Chapter 7 Open problems In this monograph, we have presented a comprehensive overview of the URA problem in noisy channels. The URA model provides an information-theoretic framework that accounts for FBL effects and energy efficiency. This framework enables the derivation of fundamental limits, facili- tates the comparison and optimization of existing uncoordinated access schemes, and supports the development of new ones (e.g. coded CS schemes). Despite the substantial progress made and the numerous results obtained, several open problems remain: •Are there any better “good” regions which improve the achievability bound based on the Fano’s trick?Gordon’s inequality seems to be useful as it improves the asymptotic bound [87]. Can this method improve finite-length results? •Is it possible to close the gap between achievability and converse bounds in the asymptotic regime (see Appendix F)?It seems counterintuitive that for high user density per channel use, the current achievability bounds coincide with the converse bound, whereas for low user density, we observe a gap of approximately 0.8 dB. •Is there any polynomial complexity coding scheme with non-linear user codes that outperforms preamble-based approaches?We note preamble-based approach is one of the methods to create non-linear codes. Let us briefly recall that the same codebook is constructed as follows: there areLlinear codesC 1,C2, . . . ,C L. The user randomly chooses the codebook and sends the codebook index and the codeword to the channel. The clear drawback of this scheme is the dependence on the preamble length on the number of active users and the requiredP e. •Are there better codes for the A-channel and A-channel with errors?The solutions from the literature are based either on the tree-coding or RS codes – the classes of codes suitable for the list recovery problem. In particular, it is interesting whether it is possible to modify classical LDPC or polar codes to work in this setup. Note the SCL decoder seems to be very close to the tree-code decoder, namely it recovers next symbol based on the results for the previous symbols. But there are no",
    "particular, it is interesting whether it is possible to modify classical LDPC or polar codes to work in this setup. Note the SCL decoder seems to be very close to the tree-code decoder, namely it recovers next symbol based on the results for the previous symbols. But there are no results on the use of polar codes for the A-channel. •Are there any other principles to construct sensing matrices with polynomial decoding algo- rithms?Standard CS decoding algorithms check all correlations which is impossible in high- 155 dimensions. One of the ideas behind this question in the CHIRRUP approach from [143], which utilizes binary chirps which are simply codewords in the second order Reed-Muller (RM) code. Can we go further while preserving polynomial complexity? •Is it possible to obtain closed-form expression of the bounds for the fading MACs with MIMO receiver (and avoid the expectation over the codebook)?The expected values need to be calculated in a precise manner, which is computationally expensive and probably not feasible. •Are there good low-complexity schemes for the MIMO URA setup which do not perform chan- nel estimation and do not use pilots? •General fading channels.One more open problem is the design of URA schemes for more general fading channels. Most schemes are designed for the quasi-static Rayleigh fading channel and rely on the quasi-static property. However, quasi-static fading is rarely observed in practice, especially over the relatively long blocklengths considered in URA. •Asynchronous URA.All the schemes and bounds presented in this monograph assume perfect per-frame synchronization. At the same time this condition is extremely difficult to fulfill as we consider low-power autonomous devices. The question of asynchronous MAC was considered in the literature [170], it is important to propose low-complexity schemes and bounds for this case. We mention several papers that may serve as useful starting points [171, 172, 173]. 156 Appendix A Minimum mean squared error estimation Consider the following Markov chain x→y→ ˆx, where ˆx=ˆx(y) is the estimate ofx. The goal is to minimize the MSE MSE=E[( ˆx−x)2]. The MMSE estimator is defined as the estimator that achieves the minimal MSE: ˆx∗(y) = arg min xMSE. It is known that, for a giveny, ˆx∗(y) =E[x|y]. In many cases, finding an analytical expression for the MMSE estimator is not feasible. Additionally, the numerical evaluation of the conditional expectation is computationally expensive. Thus, it is reasonable to consider a specific class of estimators – linear estimators, i.e., ˆx(l)(y) =Wy+b. The linear estimator is optimal if it minimizes the MSE within the class of linear estimators, i.e., solving (R∗,b∗) = arg min W,bMSE, where ˆx(l)(y) =Wy+b. 157 The optimal pair is given by W∗= Cov [x,y] (Cov [y,y])−1,(A.1) b∗=E[x]−W ∗E[y],(A.2) where Cov [a,b] =Eh (a−E[a]) (b−E[b])Ti . In what follows, we refer to the optimal linear estimator as the LMMSE estimator, given by ˆx(l) ∗(y) =W ∗y+b ∗. The MSE value achievable by the LMMSE estimator is given by MSE(l) ∗= trΣ, where Σ= Cov [x,x]−Cov [x,y] (Cov [y,y])−1Cov [y,x]. Now consider a linear observation process y=Ax+z, wherexandzare independent,z∼ N(0,I n),E[x] =µand Cov [x,x] =Γ. We have Cov",
    "the LMMSE estimator, given by ˆx(l) ∗(y) =W ∗y+b ∗. The MSE value achievable by the LMMSE estimator is given by MSE(l) ∗= trΣ, where Σ= Cov [x,x]−Cov [x,y] (Cov [y,y])−1Cov [y,x]. Now consider a linear observation process y=Ax+z, wherexandzare independent,z∼ N(0,I n),E[x] =µand Cov [x,x] =Γ. We have Cov [x,y] = ΓAT, Cov [y,y] = (AΓAT+In), and thus, ˆx(l) ∗(y) =ΓAT(AΓAT+In)−1(y−Aµ) +µ. Remark A.1.Ifx∼ N(µ,Γ), then the MMSE estimator coincides with the LMMSE estimator presented above. 158 Appendix B Standard CS codebooks and decoders Let us start with a noisy CS problem, also known as a sparse linear regression problem. The main task is to recover the sparse vectorugivennnoisy linear measurements of the formaT iu+z i, i∈[n]. That is, we have y=Au+z,z∼ N(0,I n),(B.1) whereu∈RM, and∥u∥0=t. Recall thatA∈Rn×Mis referred to as thesensing matrix. In most cases throughout this monograph, we are primarily interested in recovering only the support ofu, defined as supp(u) ={i:u i̸= 0}. Such problems are known assupport recovery problems. In this monograph, we encounter two instances of problem (B.1), namely: •Case A (GMAC):u∈ {0,1}M,∥u∥0=t; •Case B (Fading1MAC):u∈RM,∥u∥0=t; Remark B.1.The support recovery problem is not necessarily simpler than the general CS problem. The reasoning is as follows: suppose we know the supportI, then we can apply MMSE or linear MMSE estimators (see Appendix A) to obtain an estimate ˆuIthat minimizes the mean squared error, leading to a good overall estimate ˆu. In this chapter, we describe standard CS approaches, focusing on decoding algorithms and codebook design strategies for cases whereMis small. In particular, we considerM≤215. The elements of these codebooks serve as preambles in practical schemes, as discussed in Section 5. 1Strictly speaking, we should writeu∈CM, but we focus on the real case in this chapter. Note that the approaches remain largely the same. 159 B.1 Decoding algorithms B.1.1 Non-negative least squares Since we are dealing with additive white Gaussian noise (AWGN)z, one possible approach to solving problem (B.1) is to find a vectoruthat minimizes the residual norm: ˆu= arg min u∥y−Au∥2.(B.2) The problem above is convex and can be solved using standard algorithms, either analytically or via gradient-based methods. However, the solution (B.2) may contain negative elements in ˆu, which can be undesirable in some scenarios. To enforce non-negativity, the solution can be obtained through a non-negative least squares (NNLS) approach, which imposes an additional constraint: ˆu= arg min u≥0∥y−Au∥2, whereu≥0means thatu i≥0 for alli∈[M]. Since∥x∥2=xTx, the problem above can be reformulated equivalently as ˆu= arg min u≥0\u00121 2uTQu+cTu\u0013 ,Q=ATA,c=−ATy, which is a convex optimization problem (see [174]). B.1.2 LASSO: Sparse linear regression CS can be viewed as a linear regression problem. To enforce sparsity in the solution,ℓ 1-regularization can be applied: ˆu= arg min u∥y−Au∥2+λ∥u∥1. This regularized linear regression approach is known as LASSO [175]. The parameterλcontrols the sparsity of the solution. B.1.3 Approximate message passing AMP [176] is a family of low-complexity iterative algorithms used to solve a wide range of problems, including(B.1). In this section, we provide a simplified description from [136], listed in Algorithm 4. In the algorithm description, subscripts indicate iterations,⟨·⟩denotes the average",
    "the sparsity of the solution. B.1.3 Approximate message passing AMP [176] is a family of low-complexity iterative algorithms used to solve a wide range of problems, including(B.1). In this section, we provide a simplified description from [136], listed in Algorithm 4. In the algorithm description, subscripts indicate iterations,⟨·⟩denotes the average of a vector,η(·) is a nonlinear denoising function (see, e.g., [136]), andη′(·) represents the component-wise derivative. 160 Algorithm 4Approximate message passing (AMP) for (B.1) problem. 1:Input:A,y▷Design matrix, observed vector 2:˜y0=y▷Soft residual signal 3:ˆu0= 0▷Soft activity pattern estimate 4:fort= 1, . . . , Tdo▷RunTiterations 5: ˆut+1=ηt\u0000ˆut+AT˜yt\u0001 6: ˜yt+1=y−A ˆut+1+M n˜y η′\u0000ˆut+AT˜yt\u0001 7:end for 8:return ˆu The main idea of the algorithm is as follows. Consider the prior distribution of the elements ofu as p(u) =MY i=1p(u i) =MY i=1exp{−β|u i|} Given the Gaussian channel, let us consider the posterior distributionµ: µ(u) =1 ZnY i=1exp\u001a −β 2(yi−(Au)i)2\u001bMY i=1exp{−β|u i|}, whereZis a normalizing constant. To compute the posterior probabilities, an iterative sum-product algorithm on a dense graph can be used [176]. The idea of AMP is to apply the large system limit (M→ ∞) and sharpen the prior probability distribution asβ→ ∞[176]. Note that [176, Section V] also describes the iterative algorithm that solves a LASSO problem. The idea of AMP for Case B of the problem (B.1) is similar and is described in [177]. B.1.4 Orthogonal matching pursuit The idea of OMP is based on a SIC approach and the near-orthogonal property of the columns of random sensing matrices. The observed vectoryin (B.1) (case B) is a linear combination of the columns of the sensing matrixA. Thus, if these columns are nearly orthogonal, the concept of an energy detector from CDMA can be applied here. OMP is an iterative algorithm. At each iteration, it identifies the column of the design matrix that is most correlated with the received signal, adds the corresponding column to the set ofactivecolumns, and then performs cancellation of the already detected columns. The algorithm is specified in [146] and listed in Algorithm 5. The weight coefficients estimate should be calculated jointly for the entire set of detected columns ˆT, as the columns of the design matrixAmay not be orthogonal. When calculating the estimate of weights ˆh, we treat the set of design matrix columns as another matrix. Note that the OMP is also suitable for case A in (B.1), where ˆui= 1 fori∈ D, without the need to calculate a pseudoinverse. 161 Algorithm 5Orthogonal matching pursuit for (B.1) problem. 1:Input:A,y,t ▷Sensing matrix, observed vector, output list size 2:˜y=y▷Residual signal 3:D=∅▷Estimate of supp(u) 4:while|D|< tdo▷Run untiltcandidates detected 5:i= arg maxj∈[M]\\D yTai ▷Find the highest correlation coefficient 6:D=DS{i}▷Update the detected columns set 7: ˆuD=A† Dy▷Get weights estimate by pseudoinverse 8: ˜y=y−A DˆuD ▷update the residual signal 9:end while 10:return ˆD,ˆu B.2 Codebook design All the algorithms described above calculate correlations and thus rely on codebooks with good correlation properties. In this section, we describe several approaches to constructing such code- books. Our goal is to design a sensing matrixAsuch that|aT iaj|, fori, j∈[M] andi̸=j, is small. Recall also the energy constraint∥a",
    "Codebook design All the algorithms described above calculate correlations and thus rely on codebooks with good correlation properties. In this section, we describe several approaches to constructing such code- books. Our goal is to design a sensing matrixAsuch that|aT iaj|, fori, j∈[M] andi̸=j, is small. Recall also the energy constraint∥a i∥2≤Pn, fori∈[M]. In this section, we focus onP= 1, i.e., the columns ofAhave unit norms. The case of arbitraryPis obtained by multiplying the codebooks above by√ P. B.2.1 Gaussian codebook The most popular approach is to utilize the Gaussian codebook, i.e., each elementa i,jofAis sampled i.i.d. fromN(0,1−ε) for someε >0. We needεto satisfy the power constraint. Such codebooks have been proven to be effective for largen. Indeed, for anyi, j∈[M],i̸=j, we have 1 naT iajP→0. To be precise, we can use the following equality: aT iaj= ai+aj 2 2 − ai−aj 2 2 , where the vectorsη ηη1= (a i+aj)/2 andη ηη2= (a i−aj)/2 are independent. We note thatη ηη1,ηηη2∼ N(0,(1−ε)I n). Let us consider the variance: Var\u00141 naT iaj\u0015 =1 n2\u0010 Varh ∥ηηη1∥2i −Varh ∥ηηη2∥2i\u0011 =4(1−ε)2 n, 162 where the last equality follows from the fact that the variance of a chi-squared distribution withn degrees of freedom is 2n. Thus, the random variable1 naT iajis well-concentrated around 0. B.2.2 Spherical codebook To avoid power constraint issues, it is reasonable to use a spherical codebook. LetSn−1be the unit sphere inndimensions. The codewords are uniformly and independently sampled fromSn−1, i.e., aii.i.d∼Unif(Sn−1), i∈[M]. Remark B.2.The standard way to generate such a column is to sample ˜ai∼ N(0,I n)and then normalize the result asa i=˜ai/∥˜ai∥. It is easy to show that the resulting vector is distributed uniformly onSn−1. Note that for the conventional GMAC2[178], spherical codebooks have been shown to achieve a better second-order (dispersion) term in the asymptotic expansion of the achievable rate region as n→ ∞compared to Gaussian codebooks. However, it is not clear if this result is valid for the G-URA setup. For the URA setup in the case of the MIMO quasi-static Rayleigh fading channel, the authors of [179] demonstrated that the use of spherical codebooks is beneficial in the FBL regime. B.2.3 BCH subcodes The codebooks described in the previous sections are easy to generate and work well for largen. However, when considering the preamble design task, we are required to make the preambles as short as possible to avoid additional overhead. In this regime, Gaussian and spherical codebooks may not perform as well. To overcome this issue, we describe how to construct a codebook with good correlation properties for existing error-correction codes, particularly from BCH codes. Let us start with the [n, k]-BCH codeCthat correctsterrors. The columns ofAare to be chosen from the setX=x=τ(c) :c∈ C, whereτ(·) is a BPSK modulation. Let us consider the correlation properties, specifically calculating (i, j∈[M], i̸=j): xT ixj=1 2(∥xi∥2+∥x j∥2− ∥x i−xj∥2) =n−2d H(xi,xj). Thus, n−2wt max(C)≤xT ixj≤n−2wt min(C) =n−2(2t+ 1). An interesting observation is that we need to control not only the minimal weight (code distance) but also the maximal weight of the code. The ideal case is to use an equidistant",
    "(i, j∈[M], i̸=j): xT ixj=1 2(∥xi∥2+∥x j∥2− ∥x i−xj∥2) =n−2d H(xi,xj). Thus, n−2wt max(C)≤xT ixj≤n−2wt min(C) =n−2(2t+ 1). An interesting observation is that we need to control not only the minimal weight (code distance) but also the maximal weight of the code. The ideal case is to use an equidistant code. 2Different codebook case, all active users, fixedK a 163 Example B.1.For the[n= 63, k= 10, d= 27]-BCH code, we have −63≤xT ixj≤9 since the code contains the all-one codeword of weight63. It seems to be easy to solve our problem for the BCH code. We consider only a subcodeC 0⊂ C, where1̸∈ C 0. Let us consider the[n= 63, k= 9, d= 27]-BCH subcode. We have −9≤xT ixj≤9 since the maximal weight is equal to36. LetC 0be the desired subcode with dim(C 0) =k p. We construct the sensing matrixAwith ai=τ(c i), wherec i∈ C0. The size ofAisn×2kp. B.2.4 Codebook from the parity-check matrix of at-error-correcting code To obtain a good codebook, we need all the sumsP i∈Iai, whereI ⊂[M] and|I|=t, to be distinct and well-separated (to account for noise). Such codes are calledsuperimposed codes. In what follows, we present one of the possible approaches to constructing such codes. Let us utilize the technique proposed in [25]. LetH= [h 1, . . . ,h n] be the parity-check matrix of at-error-correcting code overF 2. Set ai=τ(h i), i∈[M]. We have the desired property: all sums of up totcolumns ofAare distinct. Example B.2.Consider a BCH code of lengthnthat correctsterrors. In this case, we can construct a codebook of size approximatelytlogn×n(since BCH codes are known to be quasi- perfect). B.2.5 Binary chirps In this section, we describe a codebook based on RM codes. Let us introduce the main definitions. Definition B.1(Algebraic power). xσ=\u001ax, σ= 1 1, σ= 0 Definition B.2(Algebraic normal form or Zhegalkin polynomial). f(x) =M σ∈{0,1}mbσxσ,xσ=xσ1 1·. . .·xσmm,deg(xσ) =∥σ∥0. 164 Note that each Boolean functionfhas a unique algebraic normal form representation. Definition B.3.The degree of the functionf(x)is defined as deg(f) = max σ:aσ=1deg(xσ). Definition B.4(Reed-Muller (RM) code).Letf:{0,1}m→ {0,1}be the Boolean function with marguments, and let Eval(f) = [f(σ 1), . . . , f(σ 2m)], whereσ i∈ {0,1}m,i∈[2m], then the RM code of orderris defined as follows: RM(m, r) ={Eval(f) : degf≤r}. The code is linear overF 2has lengthn= 2m, and dimensionk=Pr i=0\u0000m i\u0001 . Now, let us consider the codebook proposed in [143]. Let us start with the first-order RM code (or the case whenr= 1). Consider allfsuch that deg(f) = 13. These functions can be expressed as f(x) =bTxmod 2. Now, consider the modulated codeword. It can be represented as Eval\u0000 (−1)f\u0001 , which is equivalent to Eval\u0010 (−1)bTx\u0011 4. The functions ϕb(x) = (−1)bTx are called the Walsh functions,ϕ b:{0,1}m→R. These functions are orthogonal. However, we can construct only 2msuch functions. In [143], it is suggested to use the second-order RM codes. Again, the constant function is removed, and we consider ϕb,P(x) = (−1)bTx+1 2xTPx, whereb∈ {0,1}mand the matrixP∈ {0,1}m×mis symmetric and has zeroes on the main diagonal5. We set ai(b,P) = Eval(ϕ b,P), wherei(b,P) is the",
    "construct only 2msuch functions. In [143], it is suggested to use the second-order RM codes. Again, the constant function is removed, and we consider ϕb,P(x) = (−1)bTx+1 2xTPx, whereb∈ {0,1}mand the matrixP∈ {0,1}m×mis symmetric and has zeroes on the main diagonal5. We set ai(b,P) = Eval(ϕ b,P), wherei(b,P) is the function that returns the column index givenbandP. The size ofAis 2m×2m+(m 2). Finally, let us mention the main benefit of this codebook. The standard decoders (e.g., the OMP algorithm) calculate the correlation between the current measurement residual and every column, 3The reader may ask why the function of degree 0 was removed. The reason is exactly the same as in Section B.2.3 – the all-one codeword is removed to improve the correlation properties. 4Note that mod 2 may be omitted. 5We only consider the real codebook here, but note that the authors of [143] also suggest the complex codebook ϕb,P(x) =i2bTx+xTPx, wherePis symmetric, but diagonal elements are allowed to be non-zero. 165 selecting the one with the largest absolute value. This is anO(|C|) procedure and, therefore, computationally intractable for large codebook sizes. In contrast, the reconstruction algorithm proposed in [143] performs a small number of Walsh-Hadamard transforms to identify the matrix Prow by row, and subsequently identifies the vectorb. The overall complexity of the procedure for finding a codeword with maximum correlation isO(m22m), which is sub-linear in the size of the codebook. 166 Appendix C CS sensing matrices As mentioned in Chapter 3, the URA problem can be considered a CS problem. In this section, we illustrate the CS sensing matrices corresponding to the IRSA protocol presented in Section 5.1.3 and the CCS protocol presented in Section 5.3. Let us start with an IRSA-F protocol presented in Fig. 5.6 and consider the corresponding CS problem (5.6). Each user transmitsk= log2Minformation bits. The user messageW∈[M] is split intoW pandW c. Then,W pdetermines a preamble, while the remaining part,W c, is encoded using a code of lengthn c= (n−n p)/L. The encoded message is further replicated across multiple slots. The replica count and slot indices are determined by bothW pandW c. The resulting sensing matrix is illustrated in Fig. C.1. In the case of CCS, the sensing matrix construction procedure is presented in Fig. C.2. Within each slot, transmission is performed using an inner code with a codebook matrixAof sizen′×Q. Given that there areLslots in the frame, the sensing matrix construction begins by applying the direct productLtimes to the matrixA, resulting inA⊗Lof sizen′L×QL. Finally, onlyMrows of the resulting matrix are selected – forming a set of valid codewords for the outer code. 167 ...... · · ·· · ·· · ·· · · 123...Mp McM L×n cnp............Figure C.1: IRSA-F Sensing Matrix Example. The preamble length isn p, and the slot length is nc. Different colors represent different codewords of user messages. Each user message appearsM p times in the resulting sensing matrix, with varying replica counts and slot indices. 168 Outer code Codebook M· · ·21A⊗L MFigure C.2: CCS: sensing matrix. An example forL= 3 slots and a given outer code. Different colors represent",
    "colors represent different codewords of user messages. Each user message appearsM p times in the resulting sensing matrix, with varying replica counts and slot indices. 168 Outer code Codebook M· · ·21A⊗L MFigure C.2: CCS: sensing matrix. An example forL= 3 slots and a given outer code. Different colors represent different rows of the inner codebook matrixAof sizen′×Q. In this illustrative case, Q= 4. The matrix construction begins by combining all possible inner-code symbol combinations acrossLslots, forming the large matrixA⊗Lof sizen′L×QL(left). Then, the outer code selectsM valid outer codewords from theQLvariants. These valid codewords are highlighted with saturated colors on the left side of the figure, while the resulting CS matrix is shown on the right side. 169 170 Appendix D IRSA: replica count distribution Replica count distributions optimized using the density evolution procedure (over 10 iterations) are shown in Tables D.1, D.2, and D.3 forT= 1, 2, and 4, respectively. Recall that the replica count distribution is given by the polynomial Λ (x) (5.1), where the coefficient of thei-th degree term corresponds to the probability thatireplicas will be chosen. Notably, smaller values ofTrequire greater time diversity, which is reflected in the higher-degree terms of the replica count polynomial. On the other hand, the decoder forT= 4 can success- fully decode slots with high collision orders, making additional replicas unnecessary in this case. Moreover, fewer replicas reduce the overall system load and improve the energy efficiency of the transmission scheme. 171 Table D.1: Optimal node degree distribution andE b/N0(dB) forT= 1, 10 iterations KaΛ(x): Eb/N0, dB 250.0928x+0.9072x23.71 50 +1.0000x24.48 100 +1.0000x25.89 150 +0.6211x2+0.3789x37.17 200 +0.4781x2+0.5219x38.31 250 0.0706x+0.2011x2+0.7283x39.42 300 0.1297x+0.8703x310.52 350 0.1234x+0.8766x311.62 400 0.1184x+0.8816x312.76 450 0.1247x+0.7991x3+0.0763x413.90 500 0.1396x+0.6716x3+0.1889x415.05 550 0.1474x+0.5906x3+0.2620x416.20 600 0.1549x+0.5239x3+0.3212x417.37 Table D.2: Optimal node degree distribution andE b/N0(dB) forT= 2, 10 iterations KaΛ(x) Eb/N0, dB 251.0000x 1.63 500.4443x+ 0.5557x23.09 100 0.2099x+ 0.7901x24.00 150 0.1680x+ 0.8320x24.92 200 0.1382x+ 0.8618x25.88 250 0.1205x+ 0.8795x26.86 300 0.1008x+ 0.8992x27.86 350 0.0895x+ 0.9105x28.87 400 0.1206x+ 0.7609x2+ 0.1185x39.90 450 0.1609x+ 0.5953x2+ 0.2438x310.92 500 0.1867x+ 0.4916x2+ 0.3217x311.94 550 0.2061x+ 0.4160x2+ 0.3779x312.97 600 0.2184x+ 0.3639x2+ 0.4177x314.00 172 Table D.3: Optimal node degree distribution andE b/N0(dB) forT= 4, 10 iterations KΛ(x) Eb/N0, dB 251.0000x 0.53 501.0000x 1.10 100 0.5781x+ 0.4219x22.84 150 0.3987x+ 0.6013x23.54 200 0.3764x+ 0.6236x24.31 250 0.3620x+ 0.6380x25.13 300 0.3538x+ 0.6462x25.97 350 0.3479x+ 0.6521x26.83 400 0.3416x+ 0.6584x27.71 450 0.3349x+ 0.6651x28.60 500 0.3302x+ 0.6698x29.52 550 0.3269x+ 0.6731x210.45 600 0.3225x+ 0.6775x211.40 173 174 Appendix E Coded CS: further results E.1 Capacity of the channel for the outer code In this section, we estimate the capacity of the channelWpresented in Section 5.3.1. Recall Fig. 5.11 for an illustrative example. For simplicity, we will not perform optimization over all independent distributions ofx(i),i∈[K a]. Instead, we consider only the uniform distribution. Thus, we obtain an expression for the achievable rate rather than the true capacity. We have Iu=I(x(1), . . . ,x(Ka);Y) =H(Y)−H(Y|x(1), . . . ,x(Ka)),(E.1) wherex(i)i.i.d.∼Unif([Q]). Let Ω =|Y(A)|, then we have H(Y|x(1), . . . ,x(Ka)) =E Ω[H(Y|Ω)] =E Ω[Ωh(p m) + (Q−Ω)h(p f)] =E[Ω]h(p m) + (Q−E[Ω])h(p f) =Q 1−\u0012Q−1 Q\u0013Ka! h(pm) +Q\u0012Q−1 Q\u0013Ka h(pf), where the second equality follows from",
    "We have Iu=I(x(1), . . . ,x(Ka);Y) =H(Y)−H(Y|x(1), . . . ,x(Ka)),(E.1) wherex(i)i.i.d.∼Unif([Q]). Let Ω =|Y(A)|, then we have H(Y|x(1), . . . ,x(Ka)) =E Ω[H(Y|Ω)] =E Ω[Ωh(p m) + (Q−Ω)h(p f)] =E[Ω]h(p m) + (Q−E[Ω])h(p f) =Q 1−\u0012Q−1 Q\u0013Ka! h(pm) +Q\u0012Q−1 Q\u0013Ka h(pf), where the second equality follows from the following facts: the channelW Eoperates on elements independently,H\u0010 1{x∈Y|x∈Y(A)}\u0011 =h(p m) andH\u0010 1{x∈Y|x̸∈Y(A)}\u0011 =h(p f). The fourth equality follows from E[Ω] =X x∈[Q]Eh 1{x∈Y(A)}i =QPrh 1∈ Y(A)i =Q 1−\u0012Q−1 Q\u0013Ka! . 175 The exact calculation ofH(Y) is more complicated. Let us introduce the notation µr=\u0012 1−\u0012Q−1 Q\u0013r\u0013 (1−p m) +\u0012Q−1 Q\u0013r pf (E.2) and use the following estimate: H(Y)≤X x∈[Q]H\u0000 1{x∈Y}\u0001 =Qh(Pr [1∈ Y]) =Qh(µ Ka). We note that the estimates above are quite simple and can be found in [95]. These results are useful for formulating the following theorem. Theorem E.1(Outer channel converse, [94]).ConsiderK ausers transmitting messagesW i∈[M], i∈[K a], over the channelWwithinLchannel uses, under a maximum tolerable PUPEP e. Under the following conditions: (a) the users employ a uniform input distribution, and (b) the decoder output list size is equal toℓ 0, the following inequality holds: log2M≤1 (1−P e)\u0012LIu Ka+h(P e) + (1−P e) log2ℓ0\u0013 ,(E.3) whereI uis given by(E.1). Proof.Consider thei-th user. We have the following Markov chain: Wi→x(i)→Y→ R, wherex(i)∈[Q]L,Y= (Y 1, . . . ,Y L),Yl⊆[Q],l∈[L], and|R|=ℓ 0. Letε i= Pr [W i̸∈ R]. Using Fano’s list inequality, we have (3.7), repeated below H(W i|Y)≤h(ε i) + (1−ε i) log2ℓ0+εilog2(M−ℓ 0). Summing the inequalities (3.7) fori∈[K a] and using the fact that H(W i|Y) =H(W i)−I(W i;Y), along with the data processing inequality I\u0010 x(i);Y\u0011 ≥I(W i;Y), we obtain KaX i=1I\u0010 x(i);Y\u0011 ≥KaX i=1H(W i) −KaX i=1h(εi)− 1−KaX i=1εi! log2ℓ0 176 −KaX i=1εilog2(M−ℓ 0). Finally, since H(W i) = log2M,fori∈[K a], KaX i=1I\u0010 x(i);Y\u0011 ≤LI u,KaX i=1εi=K aPe, and KaX i=1h(εi)≥K ah(Pe), we obtain the result stated in the theorem. E.2t-tree code: the average number of paths Recall the practical scheme based on linear codes, as presented in Section 5.3.3. In this section, we analyze the FAR and the average decoding complexity. Note that at each decoding stepl∈[L], the list of messagesV lcan be expressed as the following disjoint union: Vl=V(c) lG V(f) l, l∈[L],(E.4) whereV(c) lrepresents the beginnings of transmitted messages, andV(f) lcorresponds to falsely alarmed messages. We begin by calculatingE[|V(c) l|] andE[|V(f) l|] forl∈[L]. To do so, we apply random coding to the following ensemble. Definition E.1.The elements of the ensembleE 2(b1, . . . , b L, L)are obtained by randomly selecting the generator matrixGwith the structure defined by(5.21), i.e., the elements of each matrixG l′,l, where1≤l′≤l≤L, are sampled i.i.d. from theBern(1/2)distribution. Theorem E.2.Consider the ensembleE 2(b1, . . . , b L, L). LetM l= 2Bl. The following bounds hold forl∈[L]: E[|V(c) l|] =v(c) l≜M lρlλl,(E.5) E[|V(f) l|]≤v(f) l≜M ll−1X j=0ρjλj,(E.6) 177 where λj=\u0012 1−1 Mj+1\u0013Ka −\u0012 1−1 Mj\u0013Ka , j∈[l−1], λ0=\u0012 1−1 M1\u0013Ka , λl= 1−\u0012 1−1 Ml\u0013Ka ,(E.7) and ρj=X 0≤x≤j 0≤y≤l−j x+y≤t\u0012j x\u0013\u0012l−j y\u0013 px m(1−p m)j−xγy 1γl−j−y 2 , where γ1=\u0012Ka Q\u0013 pm+\u0012 1−1 Q\u0013 (1−p f), and",
    "l|] =v(c) l≜M lρlλl,(E.5) E[|V(f) l|]≤v(f) l≜M ll−1X j=0ρjλj,(E.6) 177 where λj=\u0012 1−1 Mj+1\u0013Ka −\u0012 1−1 Mj\u0013Ka , j∈[l−1], λ0=\u0012 1−1 M1\u0013Ka , λl= 1−\u0012 1−1 Ml\u0013Ka ,(E.7) and ρj=X 0≤x≤j 0≤y≤l−j x+y≤t\u0012j x\u0013\u0012l−j y\u0013 px m(1−p m)j−xγy 1γl−j−y 2 , where γ1=\u0012Ka Q\u0013 pm+\u0012 1−1 Q\u0013 (1−p f), and γ2=\u0012Ka Q\u0013 (1−p m) +\u0012 1−1 Q\u0013 pf. Proof.Assume that the messages u(1),u(2), . . . ,u(Ka)(E.8) were transmitted. Let ˆube an information word and define ˆx[l]=fO(ˆu[l]). In what follows, we assume ˆuto be fixed, while (E.8) are chosen uniformly at random. Introduce the r.v. D=d(Y [l],ˆx[l]) and the events Ej=Ka\\ i=1Ec i,j, j∈[l], whereE i,j={ˆu[j]=u(i) [j]}fori∈[K a]. Note that the sequence of events satisfiesE 1⊆E 2⊆. . .⊆ El. Observe that ˆu[l]is included inV(c) lif it was chosen by at least one user (eventEc l) andD≤t, and is included inV(f) lif it was not chosen (eventE l) andD≤t. Thus, we have E[|V(c) l|] =M lPr [D≤t, Ec l], E[|V(f) l|] =M lPr [D≤t, E l]. Calculation ofE[|V(c) l|].Note that Pr [Ec l] =λ lsince there areM lpossibilities for eachu(i) [l],i∈[K a], and Pr [D≤t|Ec l] =ρ l=tX i=1\u0012l i\u0013 pi m(1−p m)l−i. 178 Multiplying byM l, we obtain (E.5). Estimation ofE[|V(f) l|].The main difference compared to the proof of Theorem 5.3 is as follows. The beginning of the information word ˆu[l]may coincide with the beginning of one of the transmitted information words. In this case, the beginnings of the codewords will also coincide, which must be accounted for in the analysis. Introduce the eventsE′ jindicating that the longest match length is equal toj, i.e., E′ j=E j+1\\Ej, j= 0, . . . , l−1,whereE 0≜∅.(E.9) We note thatE l=Fl−1 j=0E′ j, and thus Pr [D≤t, E l] =l−1X j=0Pr\u0002 D≤t|E′ j\u0003 ·Pr\u0002 E′ j\u0003 . According to (E.9), the probability Prh E′ ji =λj, whereλ jis given by (E.7). Now consider Prh D≤t|E′ ji . Clearly, Prh ˆxl′∈ Y(A) l′|E′ ji = 1,forl′∈[j]. Thus, an error can only occur due to missed detection, and the result is determined by i.i.d. r.v.s ξl′∼Bern(p m). Consider a slotl′∈[l]\\[j]. Unlike in Theorem 5.3, the symbolsx(i) l′are not independent due to the linear mappingf O,l′. Consequently, we apply the following bounds: 1 Q≤Prh ˆxl′∈ Y(A) l′|E′ ji ≤Ka Q, l′∈[l]\\[j]. Hence, Pr\u0002 ˆxl′̸∈ Yl′|E′ j\u0003 ≤γ1,Pr\u0002 ˆxl′∈ Yl′|E′ j\u0003 ≤γ2, forl′∈[l]\\[j]. Under the conditionE′ j, the r.v.Dcan be expressed as follows: D=jX l′=1ξl′+lX l′=j+1ψl′, whereξ l′∼Bern(p m) andψ l′∼Bern(˜p). The following bounds hold: ˜p≤γ 1and 1−˜p≤γ 2. Finally, we note that Prh D≤t|E′ ji =ρj. Combining the obtained results, we obtain the theorem statement. 179 Corollary E.1.There exists a codeC ∈ E 2(b1, . . . , b L, L), such that Pe=LX i=t+1\u0012L i\u0013 pi m(1−p m)L−iandP f≤v(f) L, wherev(f) Lis given by(E.6). Proof.The proof forP eis exactly the same as in Theorem 5.3. To estimateP f, we apply Markov’s inequality and use Theorem E.2. We have Pf= Pr [|R\\T | ≥1]≤E[|R\\T |] =E[|V(f) L|]≤v(f) L. 180 Appendix F Asymptotics Let us consider asymptotic regime as described in Section 2.4.3, wheren→ ∞andK a→ ∞",
    "proof forP eis exactly the same as in Theorem 5.3. To estimateP f, we apply Markov’s inequality and use Theorem E.2. We have Pf= Pr [|R\\T | ≥1]≤E[|R\\T |] =E[|V(f) L|]≤v(f) L. 180 Appendix F Asymptotics Let us consider asymptotic regime as described in Section 2.4.3, wheren→ ∞andK a→ ∞ such, thatK a=µn, whereµrepresents density of users per channel use, and the number of bits transmitted by each user remains fixed atk= log2M. As shown, in such a setup, it makes sense to consider only the case where each user has a different codebook of sizeM. In what follows, we will be interested in the fundamental trade-off between the user densityµand minimal required energy per bit: \u0012Eb N0\u0013 min= inf\u001anP 2 log2M\u001b , where the infimum is taken over all (n, M, P) for which there existK a=µncodebooks, each of sizeM, that are decodable with PUPE≤ϵ. To formulate the asymptotic bounds, it is convenient to introduce the following notation of the total energyP tot=K aP, so that Ptot= 2Eb N0µlog2M. Thus,P totdeterminesEb N0and is fixed. Additionally, lett=θK a, thenPt=PK aθ=θP tot. F.1 Converse bound Let us consider the converse bound from [5]. In this case, we have the best of the following two bounds. The first one is given by Fano’s inequality: (1−ϵ)µlog2M≤1 2log2(1 +P tot) +µh(ϵ),(F.1) whereh(ϵ) =−ϵlog2(ϵ)−(1−ϵ) log2(1−ϵ) is the binary entropy function. 181 The second bound follows from the fact that each user transmits only finitely many bits, log2M [31, Theorem 2] log2M≤ −log2Q s Ptot µ+Q−1(1−ϵ)! ,(F.2) whereQ−1(·) denotes the inverse of the standard Gaussian tail functionQ(·). For both bounds, we need to determine such minimalEb N0that corresponding inequality holds and then select the maximal among them. F.2 Achievability bounds Now, let us consider the achievability bounds for the asymptotic regime. Recall the PUPE definition from (4.2) Pe≤KaX t=1t KaPr [E t] +p 0. It is clear that in this case,p 0= 0 due to concentration theorem and different codebooks. Let us rewrite the notation of PUPE in the following form for the fixedϵ >0 (omittingp 0) ˜Pe≤KaX t=⌊ϵK a⌋t Kaexp [−nE t]. and consider the following exponent E= lim n→∞−ln ˜Pe n ≥lim n→∞−1 nlnKaX t=⌊ϵK a⌋t Kaexp [−nE t] ≥lim n→∞−1 nlnKaX t=⌊ϵK a⌋exp [−nE t] ≥lim n→∞−1 nln\u0012 Kamax ⌊ϵKa⌋≤t≤K a{exp [−nE t]}\u0013 =E min= min ϵ≤θ≤1Eθ where the intervalϵ≤θ≤1 is justified by the fact that ensuringE min>0 in the asymptotic regime guarantees that PUPE≤ϵ. Thus, for the fixedϵ >0, the fundamental tradeoff ofEb N0vs.µis defined by the following condition: Emin= min ϵ≤θ≤1Eθ>0. 182 In other words, for the fixedϵandµ,we need to find minimal\u0010 Eb N0\u0011 min, such that this condition holds. To formulate asymptotic achievability bounds, we introduce some helpful notations. Consider the binomial coefficientsR 1andR 2, used in the bounds formulation of the Section 4.3, in the asymptotic regime. Since we consider different codebooks,R 1=1 nlog\u0000M−K a t\u0001 is replaced by1 nlog (M−1)t. Thus, ˜R1= lim n→∞1 nln (M−1)t= lim n→∞t nln (M−1) =θµln (M−1) and ˜R2= lim n→∞R2= lim n→∞1 nln\u0012Ka t\u0013 = lim n→∞1 nln\u0012Ka θKa\u0013 =µH(θ), whereH(θ) =−θln (θ)−(1−θ) ln",
    "Section 4.3, in the asymptotic regime. Since we consider different codebooks,R 1=1 nlog\u0000M−K a t\u0001 is replaced by1 nlog (M−1)t. Thus, ˜R1= lim n→∞1 nln (M−1)t= lim n→∞t nln (M−1) =θµln (M−1) and ˜R2= lim n→∞R2= lim n→∞1 nln\u0012Ka t\u0013 = lim n→∞1 nln\u0012Ka θKa\u0013 =µH(θ), whereH(θ) =−θln (θ)−(1−θ) ln (1−θ) is entropy function. Moreover, lim n→∞1 −nln (exp [−nE 1] + exp [−nE 2]) = min{E 1, E2}. Now, we are ready to formulate the achievability bounds obtained in Section 4.3 in the asymptotic regime. For Theorem 4.1, we have Eθ= max 0≤ρ 1,ρ2≤1h −ρ1ρ2˜R1−ρ1˜R2+E 0(ρ1, ρ2)i ,(F.3) where E0(ρ1, ρ2) =1 2(ρ1a+ log(1−2bρ 1)), a=ρ 2log(1 + 2λθP tot) + log(1 + 2µθP tot), b=ρ 2λ−µ 1 + 2µθP tot, µ=ρ2λ 1 + 2λθP tot, λ=θPtot−1 +√ D 4(1 +ρ 1ρ2)θPtot, D= (θP tot−1)2+ 4θP tot1 +ρ 1ρ2 1 +ρ 2. For Theorem 4.2, we can write Eθ= max α,β≥0min\u0010 ˜E1,˜E2\u0011 ,(F.4) where ˜E1= max u,v>0,λ ˜A>0\u001a −˜R1−˜R2+1 2log det\u0010 I3−2˜A\u0011 −vβ\u001b , ˜E2= max δ>0,λ ˜B>0\u001a −˜R2+1 2log det\u0010 I2−2δ ˜B\u0011 +δβ\u001b , ˜A= (α−1)v(αv−u)√θPtotu√θPtot (αv−u)√θPtot (αv−u)θP tot uθP tot u√θPtot uθP tot−uθP tot , 183 ˜B=\u00121−α−α√θPtot −α√θPtot −αθP tot\u0013 , andλ ˜Aandλ ˜Bare the minimum eigenvalues ofI 3−2˜AandI 2−2δ ˜Bas previous. Finally, for Theorem 4.3, we obtain Eθ= max α,τ>0minn ˜E1,˜E′ 2o ,(F.5) ˜E1= max 0≤γ≤1n −γ˜R1−˜R2+E 1(γ)o , ˜E2= max δ>0{E2(δ)}, E1(γ) =1 2\u0000 γlog(1 +θP tot) + log\u0000 1−γ2(1−ρ2 e)\u0001 −γτ\u0001 , E2(δ) =1 2\u0000 log\u0000 1−δ2(1−ρ2 r)\u0001 +τδ\u0001 , ρ2 e=(1 +αθP tot)2 (1 +α2Ptot)(1 +θP tot), ρ2 r=1 1 +α2Ptot. In [87], the best asymptotic achievability bound was obtained by applying Gordon’s lemma (see Section 4.5.2): Eθ=−˜R1−˜R2+1 2ln (1 + 2λθP tot) +λψ(θ, µ) 1 + 2λθP tot−λ,(F.6) where λ=θPtot+q (θPtot)2+ 4ψ(θ, µ)2−2 4θPtot, ψ(θ, µ) =p 1 +θP tot−γ(θ)p µPtot, γ(θ) =1√ 2πexp\u0014 −1 2\u0000 Q−1(θ)\u00012\u0015 . F.3 Numerical results Let us consider a setup with a PUPE constraint ofϵ= 10−3andk= 100 information bits trans- mitted by each user. In Fig. F.1, we analyze the minimum energy per bit (E b/N0) as a function of the user density per channel use,µ. Surprisingly, the energy per bit remains nearly constant until reaching a critical value ofµ(for the converse bound, this value is approximatelyµ≈0.006). The behavior of Theorems 4.1, 4.2, and 4.3 is almost the same in both the finite-length and asymptotic regimes. Specifically, Theorems 4.1 and 4.2 outperform Theorem 4.3 for small values ofµ, but the latter performs better for larger values ofµ. 184 0.000 0.005 0.010 0.015 0.0200123456 The density of users per channel use,µEb/N0, dBConverse: eq. (F.1) and (F.2) Achievability bound: eq. (F.3) for Theorem 4.1 Achievability bound: eq. (F.4) for Theorem 4.2 Achievability bound: eq. (F.5) for Theorem 4.3 Achievability bound: eq. (F.6) from [87]Figure F.1: Asymptotic bounds forϵ= 10−3andk= 100. 185 Interestingly, Theorem 4.2 loses to Theorem 4.1 for large values ofµin the asymptotic regime, although they almost coincide in the finite-length regime. It is also noteworthy that Theorem 4.3 achieves the converse bound for large values ofµ. The best achievability bound is the one from [87], although it slightly",
    "185 Interestingly, Theorem 4.2 loses to Theorem 4.1 for large values ofµin the asymptotic regime, although they almost coincide in the finite-length regime. It is also noteworthy that Theorem 4.3 achieves the converse bound for large values ofµ. The best achievability bound is the one from [87], although it slightly underperforms compared to Theorems 4.1 and 4.2 at small values ofµ. The most interesting observation is the gap of approximately 0.8 dB between the converse bound and the achievability bounds for small values of user density, although, the bounds coincide for larger values of user density. 186 Appendix G Some useful lemmas In this chapter, we provide an overview of some useful lemmas that are used throughout this monograph. We present the Chernoff bound (Lemma G.1) and a closed-form solution for the expectation of a quadratic form exponent (Lemma G.2). Lemma G.1(Chernoff bound, [180]).Letχ 1andχ 2be arbitrary random variables. Then, for any u, v >0, the following bounds hold: Pr [χ 1≥0]≤E χ1[exp (uχ 1)] and Pr [χ 1≥0, χ 2≥0]≤E χ1,χ2[exp (uχ 1+vχ 2)]. Lemma G.2(Theorem 3.2a.1, [181]).Letη ηη∼ N(0,I n),bbe an arbitrary vector of lengthn,A be a symmetric matrix of sizen×n. IfI n−2Ais positive definite, then Eηηηexp\u0002 ηηηTAηηη+bTηηη\u0003 = = exp\u0014 −1 2log det (I n−2A) +1 2bT(In−2A)−1b\u0015 . Corollary G.1.Letz∼ N(0,I n), and letbbe a fixed vector of lengthn. Then, for anya >0 andγ >−1 2a, we have Ezexph −γ √az+b 2 2i =exph −γ∥b∥2 1+2aγi (1 + 2aγ)n 2. Corollary G.2.Letz= [z 1,z2]∼ N(0,Γ)with Γ=\u00141ρ ρ1\u0015 . Then, for anyλ 1, λ2satisfyingλ 1λ2ρ2>(λ 1−1) (1 +λ 2), we have Ez1,z2exp\u0014λ1 2z2 1−λ2 2z2 2\u0015 =1 (1−λ 1+λ2−λ1λ2(1−ρ2))1 2. 187 Lemma G.3([181]).Letx∼ CN(0,Σ), and letAbe a Hermitian matrix. IfI−AΣis positive definite, then Ex\u0002 exp\u0000 xHAx\u0001\u0003 =|I−AΣ|−1. 188 Bibliography [1] Ericsson. Ericsson mobility report. November 2023. Technical report, Ericsson, 2023. [2] Dean Anthony Gratton.The handbook of personal area networking technologies and protocols. Cambridge University Press, USA, 2013. [3] Alireza Maleki, Ha H. Nguyen, Ebrahim Bedeer, and Robert Barton. A tutorial on chirp spread spectrum modulation for LoRaWAN: basics and key advances.IEEE Open Journal of the Communications Society, 5:4578–4612, 2024. [4] Patrick Agostini, Jean-Francois Chamberland, Federico Clazzer, Johannes Dommel, Gianluigi Liva, Andrea Munari, Krishna Narayanan, Yury Polyanskiy, Slawomir Stanczak, and Zoran Utkovski. Evolution of the 5G new radio two-step random access towards 6G unsourced MAC, 2024. [5] Yury Polyanskiy. A perspective on massive random-access. InProc. IEEE Int. Symp. Inf. Theory, pages 2523–2527, 2017. [6] Claude E. Shannon. Two-way communication channels. in Proc. 4th Berkeley Symp. Math. Stat. Probab. 1, 611-644 (1961)., 1961. [7] R. Gallager. A perspective on multiaccess channels.IEEE Trans. Inf. Theory, 31(2):124–142, 1985. [8] Rudolf Ahlswede. Multi-way communication channels. InProc. IEEE Int. Symp. Inf. Theory, Tsahkadsor, Armenia, USSR, 1973. [9] H Liao. A coding theorem for multiple access communications. InProc. IEEE Int. Symp. Inf. Theory, 1972. [10] Hosein Nikopour and Hadi Baligh. Sparse code multiple access. InProc. IEEE 24th Annual International Symposium on Personal, Indoor, and Mobile Radio Communications, pages 332–336, 2013. [11] Lawrence Roberts. ALOHA packet system with and without slots and capture.ACM SIG- COMM Computer Communication Review,",
    "InProc. IEEE Int. Symp. Inf. Theory, 1972. [10] Hosein Nikopour and Hadi Baligh. Sparse code multiple access. InProc. IEEE 24th Annual International Symposium on Personal, Indoor, and Mobile Radio Communications, pages 332–336, 2013. [11] Lawrence Roberts. ALOHA packet system with and without slots and capture.ACM SIG- COMM Computer Communication Review, 5:28–42, 04 1975. [12] J. Capetanakis. Tree algorithms for packet broadcast channels.IEEE Trans. Inf. Theory, 25(5):505–515, 1979. 189 [13] B. S. Tsybakov and N. B. Likhanov. Some new random multiple-access algorithms.Prob. Peredachi Inform., 21:134–153, 1985. [14] Enrico Casini, Riccardo De Gaudenzi, and Oscar Del Rio Herrero. Contention resolution diversity slotted ALOHA (CRDSA): an enhanced random access scheme for satellite access packet networks.IEEE Trans. Commun., 6(4):1408–1419, 2007. [15] Gianluigi Liva. Graph-based analysis and optimization of contention resolution diversity slotted ALOHA.IEEE Trans. Commun., 59(2):477–487, 2011. [16] Enrico Paolini, Gianluigi Liva, and Marco Chiani. Coded slotted ALOHA: a graph-based method for uncoordinated multiple access.IEEE Trans. Inf. Theory, 61(12):6815–6832, 2015. [17] P. Erd¨ os and A. R´ enyi. On two problems of information theory.Publications of Mathematical Institute of Hngarian Academy of Sciences, 8:241–254, 1963. [18] Staffan S¨ oderberg and H. S. Shapiro. A combinatory detection problem.The American Mathematical Monthly, 70(10):1066–1070, 1963. [19] B. Lindstr¨ om. On a combinatory detection problem.I. A Magyar Tudom´ anyos Akad´ emia Matematikai Kutat´ o Int´ ezet´ enek K¨ ozlem´ enyei, 9 (1-2):195–207, 1964. [20] Shih-Chun Chang and E. Weldon. Coding forT-user multiple-access channels.IEEE Trans. Inf. Theory, 25(6):684–691, 1979. [21] G` erard Cohen, Simon Litsyn, and Gilles Z` emor. BinaryB 2-sequences: a new upper bound. Journal of Combinatorial Theory, Series A, 94(1):152–155, 2001. [22] P. Erd¨ os and P. Tur´ an. On a problem of Sidon in additive number theory, and on some related problems.Journal of the London Mathematical Society, s1-16(4):212–215, 1941. [23] Bernt Lindstr¨ om. Determination of two vectors from the sum.Journal of Combinatorial Theory, 6(4):402–407, 1969. [24] Bernt Lindstr¨ om. OnB 2-sequences of vectors.Journal of Number Theory, 4(3):261–265, 1972. [25] I. Bar-David, E. Plotnik, and R. Rom. Forward collision resolution – a technique for random multiple-access to the adder channel.IEEE Trans. Inf. Theory, 39(5):1671–1675, 1993. [26] T. Ericson and L. Gyorfi. Superimposed codes inRn.IEEE Trans. Inf. Theory, 34(4):877–880, 1988. [27] Z. Furedi and M. Ruszinko. Superimposed codes are almost big distance ones. InProc. IEEE Int. Symp. Inf. Theory, pages 118–, 1997. [28] A.. D’yachkov and V. Rykov. On a coding model for a multiple-access adder channel.Prob. Peredachi Inform., 17(2):94–104, 1981. [29] Or Ordentlich and Ofer Shayevitz. A VC-dimension-based outer bound on the zero-error capacity of the binary adder channel. InProc. IEEE Int. Symp. Inf. Theory, pages 2366– 2370, 2015. 190 [30] Yury Polyanskiy, H. Vincent Poor, and Sergio Verd´ u. Channel coding rate in the finite blocklength regime.IEEE Trans. Inf. Theory, 56(5):2307–2359, 2010. [31] Yury Polyanskiy, H. Vincent Poor, and Sergio Verd´ u. Minimum energy to sendkbits through the gaussian channel with and without feedback.IEEE Trans. Inf. Theory, 57(8):4880–4902, 2011. [32] Ebrahim MolavianJazi and J Nicholas Laneman. On the second-order cost of TDMA for Gaussian multiple access. InProc. IEEE Int. Symp. Inf. Theory, pages 266–270, 2014. [33] Abbas El Gamal",
    "Sergio Verd´ u. Minimum energy to sendkbits through the gaussian channel with and without feedback.IEEE Trans. Inf. Theory, 57(8):4880–4902, 2011. [32] Ebrahim MolavianJazi and J Nicholas Laneman. On the second-order cost of TDMA for Gaussian multiple access. InProc. IEEE Int. Symp. Inf. Theory, pages 266–270, 2014. [33] Abbas El Gamal and Young-Han Kim.Network information theory. Cambridge University Press, 2011. [34] David Tse and Pramod Viswanath.Fundamentals of wireless communication. Cambridge University Press, 2005. [35] S. Verd´ u. Minimum probability of error for asynchronous Gaussian multiple-access channels. IEEE Trans. Inf. Theory, 32(1):85–96, 1986. [36] Ruxandra Lupas and Sergio Verd´ u. Linear multiuser detectors for synchronous code-division multiple-access channels.IEEE Trans. Inf. Theory, 35(1):123–136, 1989. [37] Michael Honig, Upamanyu Madhow, and Sergio Verd´ u. Blind adaptive multiuser detection. IEEE Trans. Inf. Theory, 41(4):944–960, 1995. [38] M. Rupf and J.L. Massey. Optimum sequence multisets for synchronous code-division multiple-access channels.IEEE Trans. Inf. Theory, 40(4):1261–1266, 1994. [39] P. Viswanath and V. Anantharam. Optimal sequences and sum capacity of synchronous CDMA systems.IEEE Trans. Inf. Theory, 45(6):1984–1991, 1999. [40] Mahesh K Varanasi and Tommy Guess. Optimum decision feedback multiuser equalization with successive decoding achieves the total capacity of the Gaussian multiple-access chan- nel. InConference Record of the Thirty-First Asilomar Conference on Signals, Systems & Computers, volume 2, pages 1405–1409, 1997. [41] D.N.C. Tse and S.V. Hanly. Linear multiuser receivers: effective interference, effective band- width and user capacity.IEEE Trans. Inf. Theory, 45(2):641–657, 1999. [42] Sergio Verd´ u and S. Shamai. Spectral efficiency of CDMA with random spreading.IEEE Trans. Inf. Theory, 45(2):622–640, 1999. [43] Xiaodong Wang and H.V. Poor. Iterative (turbo) soft interference cancellation and decoding for coded CDMA.IEEE Trans. Commun., 47(7):1046–1061, 1999. [44] A. Montanari and D. Tse. Analysis of belief propagation for non-linear problems: the example of CDMA (or: how to prove Tanaka’s formula). InProc. IEEE Inf. Theory Workshop, pages 160–164, 2006. [45] Reza Hoshyar, Ferry P. Wathan, and Rahim Tafazolli. Novel low-density signature for syn- chronous CDMA systems over AWGN channel.IEEE Trans. Signal Process., 56(4):1616–1626, 2008. 191 [46] Bixio Rimoldi and R¨ udiger Urbanke. A rate-splitting approach to the Gaussian multiple- access channel.IEEE Trans. Inf. Theory, 42(2):364–375, 1996. [47] E. S ¸a¸ soˇ glu, E. Telatar, and E. M. Yeh. Polar codes for the two-user multiple-access channel. IEEE Trans. Inf. Theory, 59(10):6583–6592, 2013. [48] E. Arıkan. Polar coding for the Slepian-Wolf problem based on monotone chain rules. In Proc. IEEE Int. Symp. Inf. Theory, pages 566–570, 07 2012. [49] S. ¨Onay. Successive cancellation decoding of polar codes for the two-user binary-input MAC. InProc. IEEE Int. Symp. Inf. Theory, pages 1122–1126, 07 2013. [50] E. Abbe and E. Telatar. Polar codes for them-user multiple access channel.IEEE Trans. Inf. Theory, 58(8):5437–5448, 2012. [51] H. Mahdavifar, M. El-Khamy, J. Lee, and I. Kang. Achieving the uniform rate region of general multiple access channels by polar coding.IEEE Trans. Commun., 64(2):467–478, 2016. [52] A. Amraoui, S. Dusad, and R. Urbanke. Achieving general points in the 2-user Gaussian MAC without time-sharing or rate-splitting by means of iterative coding. InProc. IEEE Int. Symp. Inf. Theory, pages 334–, 2002. [53] Shrinivas Kudekar and Kenta Kasai. Spatially coupled codes",
    "by polar coding.IEEE Trans. Commun., 64(2):467–478, 2016. [52] A. Amraoui, S. Dusad, and R. Urbanke. Achieving general points in the 2-user Gaussian MAC without time-sharing or rate-splitting by means of iterative coding. InProc. IEEE Int. Symp. Inf. Theory, pages 334–, 2002. [53] Shrinivas Kudekar and Kenta Kasai. Spatially coupled codes over the multiple access channel. InProc. IEEE Int. Symp. Inf. Theory, pages 2816–2820, 2011. [54] Norman M. Abramson. The ALOHA system: another alternative for computer communica- tions. InProc. AFIPS Fall Joint Computing Conference, volume 37 ofAFIPS Conference Proceedings, pages 281–285. AFIPS / ACM, 1970. [55] Anders E. Kalor, Osama A. Hanna, and Petar Popovski. Random access schemes in wireless systems with correlated user activity. InProc. IEEE 19th International Workshop on Signal Processing Advances in Wireless Communications (SPAWC), pages 1–5, 2018. [56] Federico Clazzer, Enrico Paolini, Iacopo Mambelli, and ˇCedomir Stefanovi´ c. Irregular repe- tition slotted ALOHA over the Rayleigh block fading channel with capture. InProc. IEEE International Conference on Communications, pages 1–6, 2017. [57] M. Kaplan. A sufficient condition of nonergodicity of a Markov chain (corresp.).IEEE Trans. Inf. Theory, 25(4):470–471, 1979. [58] B. Hajek and T. van Loon. Decentralized dynamic control of a multiaccess broadcast channel. IEEE Trans. Autom. Control, 27(3):559–569, 1982. [59] J. Hayes. An adaptive technique for local distribution.IEEE Trans. Commun., 26(8):1178– 1186, 1978. [60] B. S. Tsybakov and V. A. Mikhailov. Free synchronous packet access in a broadcast channel with feedback.Prob. Peredachi Inform., 14:259–280, 1978. [61] James L. Massey.Collision-resolution algorithms and random-access communications, pages 73–137. Springer Vienna, Vienna, 1981. 192 [62] B. S. Tsybakov and V. A. Mikhailov. Random multiple packet access: part-and-try algorithm. Prob. Peredachi Inform., 16:305–317, 1980. [63] B. S. Tsybakov and N. B. Likhanov. Upper bound on the capacity of a random multiple-access system.Prob. Peredachi Inform., 23:224–236, 1987. [64] Yingqun Yu and Georgios B. Giannakis. High-throughput random access using successive interference cancellation in a tree algorithm.IEEE Trans. Inf. Theory, 53(12):4628–4639, 2007. [65] Tom Richardson and Ruediger Urbanke.Modern coding theory. Cambridge University Press, New York, NY, USA, 2008. [66] L. Kleinrock and F. Tobagi. Packet switching in radio channels: part i - carrier sense multiple-access modes and their throughput-delay characteristics.IEEE Trans. Commun., 23(12):1400–1416, 1975. [67] Xu Chen and Dongning Guo. Gaussian many-access channels: definition and symmetric capacity. InProc. IEEE Inf. Theory Workshop, pages 1–5, 2013. [68] Xu Chen and Dongning Guo. Many-access channels: the Gaussian case with random user activities. InProc. IEEE Int. Symp. Inf. Theory, pages 3127–3131, 2014. [69] Xu Chen, Tsung-Yi Chen, and Dongning Guo. Capacity of Gaussian many-access channels. IEEE Trans. Inf. Theory, 63(6):3516–3539, 2017. [70] Y Polyanskiy. Modern aspects of multiple access for IoT (4 lectures).https://people.lids. mit.edu/yp/homepage/data/SkolTech18-MAC-lectures.pdf, 2018. [Online]. [71] Khac-Hoang Ngo, Alejandro Lancho, Giuseppe Durisi, and Alexandre Graell i Amat. Massive uncoordinated access with random user activity. InProc. IEEE Int. Symp. Inf. Theory, pages 3014–3019, 2021. [72] Khac-Hoang Ngo, Alejandro Lancho, Giuseppe Durisi, and Alexandre Graell i Amat. Un- sourced multiple access with random user activity.IEEE Trans. Inf. Theory, 69(7):4537–4558, 2023. [73] V. K. Amalladinne, K. R. Narayanan, J. Chamberland, and D. Guo. Asynchronous neighbor discovery using coupled compressive sensing. InProc. IEEE",
    "Theory, pages 3014–3019, 2021. [72] Khac-Hoang Ngo, Alejandro Lancho, Giuseppe Durisi, and Alexandre Graell i Amat. Un- sourced multiple access with random user activity.IEEE Trans. Inf. Theory, 69(7):4537–4558, 2023. [73] V. K. Amalladinne, K. R. Narayanan, J. Chamberland, and D. Guo. Asynchronous neighbor discovery using coupled compressive sensing. InProc. IEEE International Conference on Acoustics, Speech and Signal Processing, pages 4569–4573, 2019. [74] Alexander Fengler, Alejandro Lancho, Krishna Narayanan, and Yury Polyanskiy. On the advantages of asynchrony in the unsourced MAC, 2023. [75] Xu Chen, Lina Liu, Dongning Guo, and Gregory W. Wornell. Asynchronous massive access and neighbor discovery using OFDMA.IEEE Trans. Inf. Theory, 69(4):2364–2384, 2023. [76] Alexis Decurninge, Paul Ferrand, and Maxime Guillaud. Massive random access with tensor- based modulation in the presence of timing offsets. InProc. IEEE Global Telecommunications Conference, pages 1061–1066, 2022. 193 [77] D.L. Donoho. Compressed sensing.IEEE Trans. Inf. Theory, 52(4):1289–1306, 2006. [78] Emmanuel J. Cand` es, Justin K. Romberg, and Terence Tao. Stable signal recovery from in- complete and inaccurate measurements.Communications on Pure and Applied Mathematics, 59(8):1207–1223, 2006. [79] Galen Reeves and Michael C. Gastpar. Approximate sparsity pattern recovery: information- theoretic lower bounds.IEEE Trans. Inf. Theory, 59(6):3451–3465, 2013. [80] J.-F. Chamberland, K. Narayanan, and Y Polyanskiy. Unsourced multiple access (UMAC): information theory and coding (tutorial).https://people.lids.mit.edu/yp/homepage/ data/isit2021_umac_tutorial.pdf, 2021. [Online]. [81] Paul Erd˝ os and Joel Spencer.Probabilistic methods in combinatorics. Academic Press, Inc., New York, 1974. [82] C. E. Shannon. A mathematical theory of communication.The Bell System Technical Journal, 27(3):379–423, 1948. [83] R. Gallager. A simple derivation of the coding theorem and some applications.IEEE Trans. Inf. Theory, 11(1):3–18, 1965. [84] R.M. Fano.Transmission of information: a statistical theory of communication. MIT Press Classics. MIT Press, 1961. [85] Anton Glebov, Pavel Rybin, Kirill Andreev, and Alexey Frolov. Energy efficiency of unsourced random access over the binary-input gaussian channel.IEEE Commun. Lett., 27(9):2313– 2317, 2023. [86] Ranmji Venkataramanan, Sekhar Tatikonda, and Andrew Barron. Sparse regression codes. Foundations and Trends in Communications and Information Theory, 15(1-2):1–195, 2019. [87] Ilias Zadik, Yury Polyanskiy, and Christos Thrampoulidis. Improved bounds on Gaussian MAC and sparse regression via Gaussian inequalities. InProc. IEEE Int. Symp. Inf. Theory, 2019. [88] Y. Gordon. On Milman’s inequality and random subspaces which escape through a mesh in Rn. In Joram Lindenstrauss and Vitali D. Milman, editors,Geometric Aspects of Functional Analysis, pages 84–106, Berlin, Heidelberg, 1988. Springer Berlin Heidelberg. [89] Venkat Chandrasekaran, Benjamin Recht, Pablo A. Parrilo, and Alan S. Willsky. The convex geometry of linear inverse problems.Foundations of Computational Mathematics, 12(6):805– 849, 2012. [90] Or Ordentlich and Yury Polyanskiy. Low complexity schemes for the random access Gaussian channel. InProc. IEEE Int. Symp. Inf. Theory, pages 2528–2532, 2017. [91] Li Ping, Lihai Liu, Keying Wu, and W.K. Leung. Interleave division multiple-access.IEEE Trans. Wireless Commun., 5(4):938–947, 2006. 194 [92] Asit Kumar Pradhan, Vamsi K. Amalladinne, Avinash Vem, Krishna R. Narayanan, and Jean-Francois Chamberland. Sparse IDMA: A joint graph-based coding scheme for unsourced random access.IEEE Trans. Commun., 70(11):7124–7133, 2022. [93] Vamsi K. Amalladinne, Jean-Francois Chamberland, and Krishna R. Narayanan. A coded compressed sensing scheme for unsourced multiple access.IEEE Trans. Inf. Theory, 66(10):6509–6533, 2020. [94] Kirill Andreev, Pavel",
    "Vem, Krishna R. Narayanan, and Jean-Francois Chamberland. Sparse IDMA: A joint graph-based coding scheme for unsourced random access.IEEE Trans. Commun., 70(11):7124–7133, 2022. [93] Vamsi K. Amalladinne, Jean-Francois Chamberland, and Krishna R. Narayanan. A coded compressed sensing scheme for unsourced multiple access.IEEE Trans. Inf. Theory, 66(10):6509–6533, 2020. [94] Kirill Andreev, Pavel Rybin, and Alexey Frolov. Coded compressed sensing with list recov- erable codes for the unsourced random access.IEEE Trans. Commun., 70(12):7886–7898, 2022. [95] Alexander Fengler, Peter Jung, and Giuseppe Caire. SPARCs for unsourced random access. IEEE Trans. Inf. Theory, 67(10):6894–6915, 2021. [96] Vamsi K. Amalladinne, Asit Kumar Pradhan, Cynthia Rush, Jean-Francois Chamberland, and Krishna R. Narayanan. Unsourced random access with coded compressed sensing: inte- grating AMP and belief propagation.IEEE Trans. Inf. Theory, 68(4):2384–2409, 2022. [97] Asit Kumar Pradhan, Vamsi K. Amalladinne, Krishna R. Narayanan, and Jean-Francois Chamberland. Polar coding and random spreading for unsourced multiple access. InProc. IEEE International Conference on Communications, pages 1–6, 2020. [98] Mohammad Javad Ahmadi and Tolga M. Duman. Random spreading for unsourced MAC with power diversity.IEEE Commun. Lett., 25(12):3995–3999, 2021. [99] Asit Kumar Pradhan, Vamsi K. Amalladinne, Krishna R. Narayanan, and Jean-Francois Chamberland. LDPC codes with soft interference cancellation for uncoordinated unsourced multiple access. InProc. IEEE International Conference on Communications, pages 1–6, 2021. [100] Avinash Vem, Krishna R. Narayanan, Jean-Francois Chamberland, and Jun Cheng. A user- independent successive interference cancellation based coding scheme for the unsourced ran- dom access Gaussian channel.IEEE Trans. Commun., 67(12):8258–8272, 2019. [101] E. Marshakov, G. Balitskiy, K. Andreev, and A. Frolov. A polar code based unsourced random access for the Gaussian MAC. InProc. IEEE 90th Vehicular Technology Conference (VTC2019-Fall), pages 1–5, 2019. [102] Bobak Nazer and Michael Gastpar. Compute-and-forward: harnessing interference through structured codes.IEEE Trans. Inf. Theory, 57(10):6463–6486, 2011. [103] M. Ghanbarinejad and C. Schlegel. Irregular repetition slotted ALOHA with multiuser de- tection. InProc. 10th Annual Conference on Wireless On-demand Network Systems and Services, pages 201–205, 03 2013. [104] ˇC. Stefanovi´ c, E. Paolini, and G. Liva. Asymptotic performance of coded slotted ALOHA with multipacket reception.IEEE Commun. Lett., 22(1):105–108, 2018. [105] R Tanner. A recursive approach to low complexity codes.IEEE Trans. Inf. Theory, 27(5):533– 547, 1981. 195 [106] A. Glebov, N. Matveev, K. Andreev, A. Frolov, and A. Turlikov. Achievability bounds for T-fold irregular repetition slotted ALOHA scheme in the Gaussian MAC. InProc. IEEE Wireless Communications and Networking Conference (WCNC), pages 1–6, 2019. [107] K. R. Narayanan and H. D. Pfister. Iterative collision resolution for slotted ALOHA: An optimal uncoordinated transmission policy. InProc. 7th International Symposium on Turbo Codes and Iterative Information Processing, pages 136–139, 4 2012. [108] J.H. Conway, N.J.A. Sloane, E. Bannai, R.E. Borcherds, J. Leech, S.P. Norton, A.M. Odlyzko, R.A. Parker, L. Queen, and B.B. Venkov.Sphere packings, lattices and groups. Grundlehren der mathematischen Wissenschaften. Springer New York, 2013. [109] J. Boutros and G. Caire. Iterative multiuser joint decoding: unified framework and asymptotic analysis.IEEE Trans. Inf. Theory, 48(7):1772–1793, 2002. [110] F. R. Kschischang, B. J. Frey, and H. Loeliger. Factor graphs and the sum-product algorithm. IEEE Trans. Inf. Theory, 47(2):498–519, 2001. [111] Xiaojie Wang, Sebastian Cammerer, and Stephan Ten Brink. Near-capacity detection",
    "and G. Caire. Iterative multiuser joint decoding: unified framework and asymptotic analysis.IEEE Trans. Inf. Theory, 48(7):1772–1793, 2002. [110] F. R. Kschischang, B. J. Frey, and H. Loeliger. Factor graphs and the sum-product algorithm. IEEE Trans. Inf. Theory, 47(2):498–519, 2001. [111] Xiaojie Wang, Sebastian Cammerer, and Stephan Ten Brink. Near-capacity detection and decoding: code design for dynamic user loads in Gaussian multiple access channels.IEEE Trans. Commun., 67(11):7417–7430, 2019. [112] G. Liva and M. Chiani. Protograph LDPC codes design based on EXIT analysis. InProc. IEEE Global Telecommunications Conference, pages 3250–3254, 11 2007. [113] A. Bennatan and D. Burshtein. Design and analysis of nonbinary LDPC codes for arbitrary discrete-memoryless channels.IEEE Trans. Inf. Theory, 52(2):549–583, 2006. [114] E. Arıkan. Channel polarization: a method for constructing capacity-achieving codes for symmetric binary-input memoryless channels.IEEE Trans. Inf. Theory, 55(7):3051–3073, 2009. [115] Ido Tal and Alexander Vardy. List decoding of polar codes.IEEE Trans. Inf. Theory, 61(5):2213–2226, 2015. [116] A. Goupil, M. Colas, G. Gelle, and D. Declercq. FFT-based BP decoding of general LDPC codes over abelian groups.IEEE Trans. Commun., 55(4):644–649, 2007. [117] Alexis Decurninge, Ingmar Land, and Maxime Guillaud. Tensor-based modulation for un- sourced massive random access.IEEE Wireless Commun. Lett., 10(3):552–556, 2021. [118] V. K. Amalladinne, A. Vem, D. K. Soma, K. R. Narayanan, and J. Chamberland. A cou- pled compressive sensing scheme for unsourced multiple access. InProc. IEEE International Conference on Acoustics, Speech and Signal Processing, pages 6628–6632, 2018. [119] G. Cormode and S. Muthukrishnan. Combinatorial algorithms for compressed sensing. In Proc. 40th Annual Conference on Information Sciences and Systems, pages 198–201, 2006. [120] Hung Q. Ngo, Ely Porat, and Atri Rudra. Efficiently decodable compressed sensing by list-recoverable codes and recursion. InProc. 29th International Symposium on Theoretical Aspects of Computer Science, volume 14, pages 230–241, 2012. 196 [121] Anna C. Gilbert, Martin J. Strauss, Joel A. Tropp, and Roman Vershynin. One sketch for all: fast algorithms for compressed sensing. InProc. of the 39th Annual ACM Symposium on Theory of Computing, pages 237–246, 2007. [122] P. Indyk and M. Ruzic. Near-optimal sparse recovery in theL 1norm. InProc. 49th Annual IEEE Symposium on Foundations of Computer Science, pages 199–207, 2008. [123] K. Zigangirov, S. Popov, and V. Chepyzhov. Nonbinary convolutional coding in channels with jamming.Prob. Peredachi Inform., 31(2):169–183, 1995. [124] Venkatesan Guruswami.List decoding of error-correcting codes. Lecture Notes in Computer Science (LNCS, volume 3282), Springer Berlin, Heidelberg, 2002. [125] Shih-Chun Chang and J. Wolf. On theT-userM-frequency noiseless multiple-access channel with and without intensity information.IEEE Trans. Inf. Theory, 27(1):41–48, 1981. [126] L. A. Bassalygo and V. V. Rykov. Multiple-access hyperchannel.Prob. Peredachi Inform., 49(4):299–307, 2013. [127] L. A. Bassalygo and M. S. Pinsker. Evaluation of the asymptotics of the summarized ca- pacity of anM-frequencyT-user noiseless multiple-access channel.Prob. Peredachi Inform., 36(2):91–97, 2000. [128] Ronald L. Graham, Donald Ervin Knuth, and Oren Patashnik.Concrete mathematics: a foundation for computer science. Addison-Wesley, Reading, MA, second edition, 1994. [129] V. Guruswami and M. Sudan. Improved decoding of Reed-Solomon and algebraic-geometry codes.IEEE Trans. Inf. Theory, 45(6):1757–1767, 1999. [130] Vladimir Sidorenko and Robert Fischer. Low-complexity list decoding of Reed-Solomon coded pulse position modulation. InProc. 9th International ITG Conference on Systems,",
    "foundation for computer science. Addison-Wesley, Reading, MA, second edition, 1994. [129] V. Guruswami and M. Sudan. Improved decoding of Reed-Solomon and algebraic-geometry codes.IEEE Trans. Inf. Theory, 45(6):1757–1767, 1999. [130] Vladimir Sidorenko and Robert Fischer. Low-complexity list decoding of Reed-Solomon coded pulse position modulation. InProc. 9th International ITG Conference on Systems, Commu- nication and Coding, pages 1–6, 2013. [131] R. Koetter and A. Vardy. Algebraic soft-decision decoding of Reed-Solomon codes.IEEE Trans. Inf. Theory, 49(11):2809–2825, 2003. [132] Jamison R. Ebert, Vamsi K. Amalladinne, Jean-Francois Chamberland, and Krishna R. Narayanan. A hybrid approach to coded compressed sensing where coupling takes place via the outer code. InProc. IEEE International Conference on Acoustics, Speech and Signal Processing, pages 4770–4774, 2021. [133] Jamison R. Ebert, Vamsi K. Amalladinne, Stefano Rini, Jean-Francois Chamberland, and Krishna R. Narayanan. Coded demixing for unsourced random access.IEEE Trans. Signal Process., 70:2972–2984, 2022. [134] Alejandro Lancho, Alexander Fengler, and Yury Polyanskiy. Finite-blocklength results for the A-channel: applications to unsourced random access and group testing. InProc. 58th Annual Allerton Conference on Communication, Control, and Computing (Allerton), pages 1–8, 2022. 197 [135] William W. Zheng, Jamison R. Ebert, Stefano Rini, and Jean-Francois Chamberland. Coding for the unsourced A-channel with erasures: the linked loop code. InProc. 31st European Signal Processing Conference (EUSIPCO), pages 1534–1538, 2023. [136] Ehsan Nassaji and Dmitri Truhachev. Dynamic compressed sensing approach for unsourced random access.IEEE Commun. Lett., 28(7):1644–1648, 2024. [137] A. Lampe and J.B. Huber. On improved multiuser detection with iterated soft decision interference cancellation. InProc. IEEE Communications Theory Mini-Conference (Cat. No.99EX352), pages 172–176, 1999. [138] H. El Gamal and E. Geraniotis. Iterative multiuser detection for coded CDMA signals in AWGN and fading channels.IEEE J. Sel. Areas Commun., 18(1):30–41, 2000. [139] G. Caire and R. M¨ uller. The optimal received power distribution of IC-based iterative mul- tiuser joint decoders. InProc. 39th Annu. Allerton Conf. on Communications, Control and Computing, 2001. [140] A. Korhan Tanc and Tolga M. Duman. Massive random access with trellis-based codes and random signatures.IEEE Commun. Lett., 25(5):1496–1499, 2021. [141] Gianluigi Liva and Yury Polyanskiy. On coding techniques for unsourced multiple-access. InProc. 55th Asilomar Conference on Signals, Systems, and Computers, pages 1507–1514, 2021. [142] Alexander Fengler, Gianluigi Liva, and Yury Polyanskiy. Sparse graph codes for the 2-user unsourced MAC. InProc. 56th Asilomar Conference on Signals, Systems, and Computers, pages 682–686, 2022. [143] Robert Calderbank and Andrew Thompson. CHIRRUP: a practical algorithm for unsourced multiple access.Information and Inference: A Journal of the IMA, 9(4):875–897, 2019. [144] Mert Ozates, Mohammad Kazemi, and Tolga M. Duman. Unsourced random access using ODMA and polar codes.IEEE Wireless Commun. Lett., 13(4):1044–1047, 2024. [145] Ishay Haviv and Oded Regev. The restricted isometry property of subsampled Fourier matri- ces. InProc. of the Twenty-Seventh Annual ACM-SIAM Symposium on Discrete Algorithms, SODA ’16, page 288–297, USA, 2016. Society for Industrial and Applied Mathematics. [146] T. T. Cai and L. Wang. Orthogonal matching pursuit for sparse signal recovery with noise. IEEE Trans. Inf. Theory, 57(7):4680–4688, 2011. [147] Suhas S. Kowshik and Yury Polyanskiy. Fundamental limits of many-user MAC with finite payloads and fading.IEEE Trans. Inf. Theory, 67(9):5853–5884, 2021. [148] S. S. Kowshik,",
    "Applied Mathematics. [146] T. T. Cai and L. Wang. Orthogonal matching pursuit for sparse signal recovery with noise. IEEE Trans. Inf. Theory, 57(7):4680–4688, 2011. [147] Suhas S. Kowshik and Yury Polyanskiy. Fundamental limits of many-user MAC with finite payloads and fading.IEEE Trans. Inf. Theory, 67(9):5853–5884, 2021. [148] S. S. Kowshik, K. Andreev, A. Frolov, and Y. Polyanskiy. Energy efficient coded random access for the wireless uplink.IEEE Trans. Commun., 68(8):4694–4708, 2020. [149] Ehsan Nassaji, Murwan Bashir, and Dmitri Truhachev. Unsourced random access over fad- ing channels via data repetition, permutation, and scrambling.IEEE Trans. Commun., 70(2):1029–1042, 2022. 198 [150] Alexander Fengler, Saeid Haghighatshoar, Peter Jung, and Giuseppe Caire. Non-Bayesian activity detection, large-scale fading coefficient estimation, and unsourced random access with a massive MIMO receiver.IEEE Trans. Inf. Theory, 67(5):2925–2951, 2021. [151] Junyuan Gao, Yongpeng Wu, Shuo Shao, Wei Yang, and H. Vincent Poor. Energy efficiency of massive random access in MIMO quasi-static Rayleigh fading channels with finite blocklength. IEEE Trans. Inf. Theory, 69(3):1618–1657, 2023. [152] Junyuan Gao, Yongpeng Wu, Tianya Li, and Wenjun Zhang. Energy efficiency of MIMO massive unsourced random access with finite blocklength.IEEE Wireless Commun. Lett., 12(4):743–747, 2023. [153] Kirill Andreev, Daria Ustinova, and Alexey Frolov. Unsourced random access with the MIMO receiver: projection decoding analysis.IEEE Wireless Commun. Lett., pages 1–1, 2023. [154] Alexander Fengler, Osman Musa, Peter Jung, and Giuseppe Caire. Pilot-based unsourced random access with a massive MIMO receiver, interference cancellation, and power control. IEEE J. Sel. Areas Commun., 40(5):1522–1534, 2022. [155] Mohammad Javad Ahmadi and Tolga M. Duman. Unsourced random access with a massive MIMO receiver using multiple stages of orthogonal pilots. InProc. IEEE Int. Symp. Inf. Theory, pages 2880–2885, 2022. [156] Vamsi K. Amalladinne, Jean-Francois Chamberland, and Krishna R. Narayanan. Coded compressed sensing with successive cancellation list decoding for unsourced random access with massive MIMO, 2021. [157] Volodymyr Shyianov, Faouzi Bellili, Amine Mezghani, and Ekram Hossain. Massive un- sourced random access based on uncoupled compressive sensing: another blessing of massive MIMO.IEEE J. Sel. Areas Commun., 39(3):820–834, 2021. [158] Michail Gkagkos, Krishna R. Narayanan, Jean-Francois Chamberland, and Costas N. Georghiades. FASURA: a scheme for quasi-static fading unsourced random access channels. IEEE Trans. Commun., 71(11):6391–6401, 2023. [159] K. Andreev, S. S. Kowshik, A. Frolov, and Y. Polyanskiy. Low complexity energy efficient random access scheme for the asynchronous fading MAC. InProc. IEEE 90th Vehicular Technology Conference (VTC2019-Fall), pages 1–5, 9 2019. [160] Wei Yang, Giuseppe Durisi, Tobias Koch, and Yury Polyanskiy. Quasi-static multiple-antenna fading channels at finite blocklength.IEEE Trans. Inf. Theory, 60(7):4232–4265, 2014. [161] Te Sun Han. An information-spectrum approach to capacity theorems for the general multiple-access channel.IEEE Trans. Inf. Theory, 44(7):2773–2795, 1998. [162] I Bettesh and S Shamai. Outages, expected rates and delays in multiple-users fading channels. InProc. of the 2000 Conference on Information Science and Systems, volume 1, 2000. [163] Jørgen Nielsen. The distribution of volume reductions induced by isotropic random projec- tions.Advances in Applied Probability, 31(4):985–994, 1999. 199 [164] Wei Yang, Giuseppe Durisi, Tobias Koch, and Yury Polyanskiy. Quasi-static SIMO fading channels at finite blocklength. InProc. IEEE Int. Symp. Inf. Theory, pages 1531–1535, 2013. [165] Yury Polyanskiy.Channel coding: non-asymptotic",
    "Jørgen Nielsen. The distribution of volume reductions induced by isotropic random projec- tions.Advances in Applied Probability, 31(4):985–994, 1999. 199 [164] Wei Yang, Giuseppe Durisi, Tobias Koch, and Yury Polyanskiy. Quasi-static SIMO fading channels at finite blocklength. InProc. IEEE Int. Symp. Inf. Theory, pages 1531–1535, 2013. [165] Yury Polyanskiy.Channel coding: non-asymptotic fundamental limits. Princeton University, 2010. [166] Jie Chen and Xiaoming Huo. Theoretical results on sparse representations of multiple- measurement vectors.IEEE Trans. Signal Process., 54(12):4634–4643, 2006. [167] S. S. Kowshik, K. Andreev, A. Frolov, and Y. Polyanskiy. Energy efficient random access for the quasi-static fading MAC. InProc. IEEE Int. Symp. Inf. Theory, pages 2768–2772, 2019. [168] K. Andreev, E. Marshakov, and A. Frolov. A polar code based TIN-SIC scheme for the unsourced random access in the quasi-static fading MAC. InProc. IEEE Int. Symp. Inf. Theory, pages 3019–3024, 2020. [169] S. Sparrer and R. F. H. Fischer. MMSE-based version of OMP for recovery of discrete-valued sparse signals.Electronics Letters, 52(1):75–77, 2016. [170] Alexander Fengler, Alejandro Lancho, Krishna Narayanan, and Yury Polyanskiy. On the advantages of asynchrony in the unsourced MAC. InProc. IEEE Int. Symp. Inf. Theory, pages 2523–2528, 2023. [171] J. Hou, J.E. Smee, H.D. Pfister, and S. Tomasin. Implementing interference cancellation to increase the EV-DO Rev A reverse link capacity.IEEE Commun. Mag., 44(2):58–64, 2006. [172] N. Abramson. VSAT data networks.Proc. of the IEEE, 78(7):1267–1274, 1990. [173] Oscar del Rio Herrero and Riccardo De Gaudenzi. A high efficiency scheme for quasi-real- time satellite mobile messaging systems. InProc. 10th International Workshop on Signal Processing for Space Communications, pages 1–9, 2008. [174] Stephen Boyd and Lieven Vandenberghe.Convex optimization. Cambridge University Press, 03 2004. [175] Christopher M. Bishop.Pattern recognition and machine learning (information science and statistics). Springer, 1 edition, 2007. [176] David L. Donoho, Arian Maleki, and Andrea Montanari. Message passing algorithms for compressed sensing: I. motivation and construction. InProc. IEEE Inf. Theory Workshop, pages 1–5, 2010. [177] Sundeep Rangan. Generalized approximate message passing for estimation with random linear mixing. InProc. IEEE Int. Symp. Inf. Theory, pages 2168–2172, 2011. [178] Recep Can Yavas, Victoria Kostina, and Michelle Effros. Gaussian multiple and random access channels: finite-blocklength analysis.IEEE Trans. Inf. Theory, 67(11):6983–7009, 2021. [179] Junyuan Gao, Yongpeng Wu, Giuseppe Caire, Wei Yang, and Wenjun Zhang. Unsourced random access in MIMO quasi-static Rayleigh fading channels with finite blocklength. In Proc. IEEE Int. Symp. Inf. Theory, pages 3213–3218, 2024. 200 [180] T.M. Cover and J.A. Thomas.Elements of information theory. Wiley-Interscience, New York, second edition, 2006. [181] A. M. Mathai and S.B. Provost.Quadratic forms in random variables: theory and applica- tions. Marcel Dekker, New York, 1992. 201"
  ]
}