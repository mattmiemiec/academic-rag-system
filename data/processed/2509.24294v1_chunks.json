{
  "filename": "2509.24294v1.pdf",
  "total_chunks": 23,
  "text_length": 73947,
  "chunks": [
    "LOGOS: LLM-DRIVENEND-TO-ENDGROUNDED THEORYDEVELOPMENT ANDSCHEMAINDUCTION FORQUALITATIVERESEARCH Xinyu Pi∗, Qisen Yang∗, Chuong Nguyen∗ University of California, San Diego, La Jolla, CA, USA {xpi,qsyang,chn021}@ucsd.edu ABSTRACT Grounded theory offers deep insights from qualitative data, but its reliance on expert-intensive manual coding presents a major scalability bottleneck. Current computational tools stop short of true automation, keeping researchers firmly in the loop. We introduce LOGOS, a novel, end-to-end framework that fully au- tomates the grounded theory workflow, transforming raw text into a structured, hierarchical theory. LOGOS integrates LLM-driven coding, semantic cluster- ing, graph reasoning, and a novel iterative refinement process to build highly reusable codebooks. To ensure fair comparison, we also introduce a principled 5-dimensional metric and a train-test split protocol for standardized, unbiased evaluation. Across five diverse corpora, LOGOS consistently outperforms strong baselines and achieves a remarkable88.2%alignment with an expert-developed schema on a complex dataset. LOGOS demonstrates a powerful new path to de- mocratize and scale qualitative research without sacrificing theoretical nuance. 1 INTRODUCTION Grounded theory (GT) is one of the de facto methodologies for producing theories that emerge di- rectly from empirical data, rather than being imposed by pre-existing frameworks (Glaser & Strauss, 2017a). Unlike deductive approaches, which begin with a hypothesis and test its validity, grounded theory embraces inductive reasoning—building conceptual categories and theoretical explanations bottom-up. This makes it especially powerful for uncovering latent mechanisms, hidden structures, and recurring patterns in complex patterns & phenomena that might otherwise resist formalization. Historically, GT has been tremendously fruitful, generating useful theoretical frameworks in ed- ucation, management, psychology, communication, politics, sociology, and many other domains (Glaser & Strauss, 2017b; Corbin & Strauss, 1988; Corbin, 2003; Gioia & Chittipeddi, 1991). GT features three key processes: (1) Open coding, where one freely describes the properties ob- served on every data point. For disambiguation, note that “code” here means the tag, label imposed on a data point to describe some aspects of its properties. (2) Axial coding, where one merges the codes into semantic clusters, producing high-level descriptions for each cluster, and refines the previous open codes to improve the code reusability. (3) Selective coding, where one cleans up the codebook and reasons about the relationships between codes and connects the hierarchical codebook elements into a logically cohesive theory, producing insights into the research problem. Schema in- duction (Gick & Holyoak, 1983), a term originating from cognitive science, describes a similar process where humans identify the overlapping, recurring problem representations across different problem instances. In this paper, we use the terms “grounded theory development” and “schema induction” interchangeably without rigid differentiation. From a methodological perspective, computer scientists—especially in natural language processing and computer vision—often engage ininformalgrounded theory practices. This typically shows up in the “qualitative analysis” or “error categorization” subsections that appear near the end of experi- ment sections, even if researchers do not explicitly acknowledge it as such. To produce this section, ∗Equal contribution 1arXiv:2509.24294v1 [cs.CL] 29 Sep 2025 researchers typically need to manually examine a remarkable number of pairs of input-output to dis- cover the hidden common patterns. From these discoveries, they propose a formalized category or standard where",
    "researchers do not explicitly acknowledge it as such. To produce this section, ∗Equal contribution 1arXiv:2509.24294v1 [cs.CL] 29 Sep 2025 researchers typically need to manually examine a remarkable number of pairs of input-output to dis- cover the hidden common patterns. From these discoveries, they propose a formalized category or standard where individual observations can fit comfortably into (e.g., error categories, improvement patterns). One of the most formal grounded theory studies is Cemri et al. (2025), which produces great insights into reasons whymulti-agent system fails. In other tasks, such as robustness-related pitfall identifications (Ribeiro et al., 2020), question decomposition (Wolfson et al., 2020), and on- tologies of NLP reasoning tasks (Pi et al., 2022b), grounded theory alike approaches also generate fruitful outcome. In some sense, even though there are admittedly many abundant back-and-forth it- erations,conceptual and theoretical framework are usually developed first, then computer scientists embody and animate the static-metaphysical conceptualization by programming workflow. Despite the desirability of the grounded theory approach, practical costs can be quite expensive. Developing a grounded theory usually requires a group of experts to read through the entire corpus and manually perform open, axial, and selective coding. For example, Cemri et al. (2025) deployes 6 experts, each one spent more than 20 hours, only to mannually examine and code a small 200 dat- apoint corpus consists of execution traces from 7 multi-agent frameworks. Significantly more time is required for code merging, codebook cleanup, discussion for conflict resolution, and theorization. However, existing attempts at computer-aided grounded theory remain partial and limited. Com- mercial tools accelerate retrieval and organization but stop short of genuine interpretive synthesis (e.g.,v NVivo, MAXQDA). Academic systems, while pushing automation further, still presuppose expert supervision at each critical juncture - validating emergent codes, distilling implicit meanings, and establishing codebook topologies (Gao et al., 2024; 2023; ¨Ubellacker, 2024; Gao et al., 2025; Lam et al., 2024). Even the most advanced frameworks produce valuable scaffolds but ultimately fall short of delivering a fully autonomous, domain-agnostic pipeline. This leaves a persistent gap between the promise of scalable grounded theory and the reality of high expert labor costs. To empower the qulitative research processes in computer science and broader humanistic and so- cial science researchers, we strives to automate the grounded theory developemt processes to make it accessible for everyone. In this paper, we introduceLOGOS, our general-purpose, domain-agnostic, and end-to-end solution for grounded theory development.LOGOSfaithfully automates the canon- ical open, axial, and selective coding processes, scaling them through an LLM-powered pipeline that integrates semantic clustering, conflict-aware graph construction, and iterative codebook refine- ment.LOGOSdemonstrates excellent human-alignment, with asurprisingly high expert-schema matching rate of88.2%on the Multi-agent System Failure corpus from Cemri et al. (2025). We also devise a standardizable statistical metric without any reliance on human evaluation for fair comparison of qualities of different end-to-end generated codebooks when expert codebook is un- available. Specifically, we propose a novel5−dimensional measurement scale following the most principled desiderata of codebooks, which highlights codebookreusability, semantic fittness, se- mantic coverage, parsimony, and consistency. The other side of our novelty is the way we apply our statistical metric: unlike",
    "different end-to-end generated codebooks when expert codebook is un- available. Specifically, we propose a novel5−dimensional measurement scale following the most principled desiderata of codebooks, which highlights codebookreusability, semantic fittness, se- mantic coverage, parsimony, and consistency. The other side of our novelty is the way we apply our statistical metric: unlike previous approaches (e.g. (Lam et al., 2024; Gao et al., 2025)) that essentailly overfit the codebook on the entire corpus before evaluation, we perform train-test split, fitting the codebook on the train set, and evaluate only on the test set. Overall, from a statistical learn- ing perspective, we contribute a evaluation methodology with less statistical bias in codebook quality estimation. Under this standarized metric,LOGOSsurpasses4other competent end-to-end coding- based and RAG-based schema induction workflows with a remarkable margin on five datasets from diverse domains. 2 RATIONALE ANDCONCEPTUALIZATION Problem Formulation.Given a research questionQand qualitative corpusD={d 1, . . . , d N} (e.g., interview transcripts, feedbacks, operation traces, et), grounded theory development is the construction process of acodebookΣto (i) name recurring structures and phenomena, (ii) organize them into a coherent relational structure, and (iii) support a question-focused report. CodebookΣ = (C,R).C={c 1, . . . , c K}denotes theunstructured code collection. A code is a short descriptive label—much like a Twitter hashtag (e.g., “frustration of UI”, “team communication problem”)—that tags a segment of data with its salient property for later analysis.R⊆ C×Cdenotes the relationships between pairs of code. In this work, we limit the scope of code-wise relationship 2 Embed C C C C C C C C C C C C ? OpenCodin g ? Retrieval Datapoint Datapoint Datapoint C1 C 2 C 3 C 7 C 8 C 9 OpenCodebook LLM OpenCoding ...... ...... Corpus Top 1 0% Pairs Code Clusters Code Relation Classifier Similarity Matrix Graph Construction Hierarchical Codebook LLM High-Level Coding C C C C C C C C C C C C C C C C C C C C C C C Retrieval-based Refinement Code Relationship Pairs ...... C1 C 8 C 2 C 9 C 3 C 7 C 6 C 8 C1 C 5 C C C C C C C C C C C C C C C C C C C C C C C Hierarchical Codebook Datapoint C1 C 2 C 3 C C C C C C Code Candidates Fitting on Train Set (Iterative Refinement) Prediction on Test Set (Retrieval-based Coding) ? Codebook revision ? Candidate Selection C 4 C 5 C 6Figure 1: The codebook fitting and prediction mechanism in theLOGOSworkflow overview. Re- trieval based refinement during training shares the same workflow as retrieval based coding. to hierarchical relationship:c i→cjmeans semantic subsumption (“is-a”, a partial order),c i↔cj means semantic equivalence (same meaning),c i⊥cjmeans orthogonality (qualitatively disjoint phenomena). The final codebook is constructed from organizing codes into a semantic hierarhy. An optional research summaryA=g(Q,Σ)can be produced from the codebook. 5 Highest Desiderata of Codebooks.An execellent codebook should be: (1) maximallyreusable and generalizablebecause flexible aggregation and multi-view clustering (e.g. via logic operations) relies on high code-sharing rate across datapoints; (2) maximallyaccurate and descriptiveto",
    "constructed from organizing codes into a semantic hierarhy. An optional research summaryA=g(Q,Σ)can be produced from the codebook. 5 Highest Desiderata of Codebooks.An execellent codebook should be: (1) maximallyreusable and generalizablebecause flexible aggregation and multi-view clustering (e.g. via logic operations) relies on high code-sharing rate across datapoints; (2) maximallyaccurate and descriptiveto faith- fully capture the essence of recurring patterns across the corpus; (3) maximallycomprehensiveto cover every important aspect of datapoints and corpus. (4) maximallyparsimoniousto minimize the number of codes and the semantic redundancy across the codebook. (5) maximallyconsistentacross the seen and unseen datapoints (assuming they follow independent idential distributions) to ensure that past observed schematic distributions and structures generalize to the future. The Necessity of Datapoint-level Interpretation.Code generation is essentially an interpretation process of the datapoint. Consider the case where our goal is to identify failure patterns and causa- tions of a multi-agent system. Each datapoint in our corpus is a task execution trace from diverse domains: software engineering, data analyis, Kaggle compeition, interaction with everyday apps and services, scientific reasoning, and more. Naive clustering based on the semantic embeddings make datapoints from similar task domains, rather than the traces with similar failure reasons, to be pushed together. Failure patterns that should have been put into the same category, such as inter-agent mis- coordination, communication protocol errors, and task stopping criterion misidentificaiton issues, are not appearing in the same cluster. Hence, attempting to induce a common failure pattern from thesemantic clusterswill likely result in the “garbage in, garbage out” situation. The interpretation process, which can be viewed as a non-linear transformation of a datapoint’s syntactic, semantic, and pragmatic attributes (in this case, identifying a datapoint’s failure reason and abstracting it out from the datapoint-specific task domains), is usually inevitable for complex grounded theory de- velopment. Heavy reasoning, advanced natural language understanding, and systematic expertise external to the datapoint might be required for performing interpretation, necessitating an LLM to perform such non-trivial transformations. 3 METHOD 3.1 THELOGOS FRAMEWORK Upon the problem conceptualization and formulation, we describeLOGOS, our implementational- level realization of automated grounded theory development. Step 1 - Chunking & Open Coding.Given a corpus and a research question Q, we divide the text into chunks of 2048 words, with an overlap of 200 words between consecutive chunks. Then we applyQwen3-32Bto generate 20 codes conditioned on the research question Q. We carefully design our prompt so that the generated codes reflect the key insights of the document while remain- ing non-overlapping and unambiguous. This maps to the open coding process in common grounded theory development. 3 Step 2 - Embedding & Clustering.We then embed the codes withQwen3-embed-0.6Band use K-means with a Silhouette and variance score-based selection of K, to gather the codes into semantic clusters. We apply mini-batch K-means (batch size =1000) for larger codebooks. Step 3 - High-level Code GenerationAfter generating the open codes and the clustering step, and we prompt a LLM to generatekhigh-level code that describes the gist of the cluster. We add all such high-level codes into the codebook, which later shall be discriminated by the code classifier. Step 2 and",
    "Step 3 - High-level Code GenerationAfter generating the open codes and the clustering step, and we prompt a LLM to generatekhigh-level code that describes the gist of the cluster. We add all such high-level codes into the codebook, which later shall be discriminated by the code classifier. Step 2 and 3 together corresponds the axiel coding procedure Step 4 - Code Pair Relation Classification.Inside each cluster, we perform a code merging process (corresponding to axial coding). Conceptually, there are 4 possible relationships for an arbitrary pair of codesAandB: (1)A− →B: A issemantically subordinateto B - e.g. “writing code with cursor”, is a semantic subclass of “using AI-assisted programming tool”; (2)B− →A: B issemantically subordinateto A, i.e., the reverse direction. (3)B↔A: A is(near) semantically equivalentto B Pi et al. (2022a). For example, “building mutual trust with patients” v.s.“cultivating rapport in the patient–provider relationship” are highly equivalent and can be merged into one code. Implementationally, we distill a studentQwen3-4B-basemodel from theQwen3-32Bteacher model to classify the code pair relationship; (4)A⊥B: A isorthogonalto B, which means that A is qualitatively different from B, and there is no semantic containment relationship in either direction. We perform LoRA finetuning, with the language modeling head of theQwen-4B-basemodel replaced to a 4-category classification head. The distilled model is trained on around500kpairs generated from wikipedia articles, where we generate open codes and annotate the code pairs with the teacher model. We report the performance of different settings of the classifier in the Appendix. For each cluster, we construct a pairwise cosine similarity matrix for the codes. From the matrix, we keep only entries scoring between the interval[0.5,0.90], and then select the top10%ranking entries from the filtered set. Finally, we apply the distilled model to the filtered pairs. The rest are automatically treated asorthognal. With this approach, we reduce the infeasible corpus-levelO(n2) computation cost to cluster-size levelO(m2), wherem << n. Step 5 - Graph Construction.With the code pair relationships obtained from the previous step, we construct a hierarchical code graph. Starting from an empty matrix with codebook size by codebook size, we iteratively add code pair relationships into the graph. For each relation we add, we also activelyinferall possible relationships from the existing ones based on 2 inference rules: (1) transitivity rule - fromA− →BandB− →C, we can inferA− →C; (2) equivalence rule - from X↔YandY↔Zwe can inferX↔Z. To implement the active inference, we maintain a queue and carry breadth-first-search (BFS), popping the leading node each time and apply the two deduction rules and add its relatives into the queue. In realistic running, it is possible that the code pair relation classification label conflicts with the infered label. We resolve any conflicts by the deduction-first principle, produced by our inference engine over the classification results. If two deduction results conflicts, then we keep the deduction result from the previous round. Step 6 - Codebook Clean-Up.After we get the classification result, we perform the following cleanup for the previous dirty codebook: (1) First, wemergeall of the ”mutual” pairs by replacing all the pairs in the group with the one with the highest-score Score=w",
    "keep the deduction result from the previous round. Step 6 - Codebook Clean-Up.After we get the classification result, we perform the following cleanup for the previous dirty codebook: (1) First, wemergeall of the ”mutual” pairs by replacing all the pairs in the group with the one with the highest-score Score=w n·Sfreq+wi·Sin-deg, whereS freqis global frequency (number of datapoints the code appeared in) andS in-deg is the incoming degree for each code. For example, suppose we haveA↔B↔C↔D, and maxScore(A, B, C, D) =D, then we simply replace all occurrences ofA, B, CwithDand ad- just global frequency and incoming degree correspondingly. (2) Second, we subsume all of the low-frequency codes (in our case, we filter out all the codes which appear less than6times.) into their parent codes if applicable, and drop those orphan codes below the frequency threshold. For example, if we haveA− →B, freq(A) = 1, then we will replace codeAwithB. 3.2 ITERATIVECODEBOOKREFINEMENTMECHANISM After the first iteration, we have a sparse codebook. To make the codebook useful (i.e., datapoints with overlapping features or patterns can be aggregated via shared codes), the goal is to improve the resuability of the codebook. For this goal, we design iterative codebook refinement mechanism that replaces codes from the previous iteration with best-matching alternative in the codebook. 4 Workflow.Each iteration proceeds in four stages: (1)Candidate Generation: up to10candidates are generated for each of the (≤20) codes in the previous codebook; (2)Pool Assembly & Pruning: all candidates are aggregated, deduplicated, and pruned to≤200; (3)LLM-based Revision: the datapoint and candidate pool are passed to the LLM to propose a refined set of≤20codes; (4) Output Validation: the result is parsed and validated. Candidate Generation.For a code connected in the relation graph, we retrieve (a) up to5seman- tically similar codes (similarity≥0.6), ranked by a hybrid score Score=w s·Ssemantic +wf·Sfreq-norm , whereS semantic ∈[0.6,1.0]andS freq-norm is global frequency (number of datapoints the code ap- peared in) normalized to[0,1]; and (b) up to5graph-based codes (parents, children, siblings), ranked by frequency. For unconnected codes, we retrieve the top10scoring codes from semantic code retrieval process. If fewer candidates exist, we keep the available set. Candidate Pool.Across≤20previous codes, this yields at most200candidates. After deduplica- tion, we rank by the hybrid score and prune to the top200. The final pool can be represented either as a flat list or a dictionary keyed by original codes. Prompt Design.The LLM prompt is structured into four sections: (1) role & goal (refine codebook, prioritize reuse); (2) datapoint text; (3) candidate pool (≤200); (4) instructions requiring a JSON list output of≤20codes, marking any novel ones with “NEW:”. We impose a10ktoken constraint. Constraints.The design ensures that: no more than20codes per datapoint, no more than200 candidates, only codes with similarity≥0.6are included, and pruning is always controlled by hybrid ranking. Graph retrieval considers only one layer up/down; unconnected codes fall back to semantic retrieval. Edge cases are naturally bounded by these constraints. Validation.To ensure correct iterative refinement process, two conditions must be met: (1) LLM outputs have≤20 codes and (2) each new code must be correctly mapped to its respective datapoint. Additionally, it is preferred",
    "layer up/down; unconnected codes fall back to semantic retrieval. Edge cases are naturally bounded by these constraints. Validation.To ensure correct iterative refinement process, two conditions must be met: (1) LLM outputs have≤20 codes and (2) each new code must be correctly mapped to its respective datapoint. Additionally, it is preferred that LLM ouputs contain a mixture of old codes (from previous iteration) and new codes (that LLM identifies as missing to fully make sense of the input data). 3.3 STATISTICALMETRICS FORCODEBOOKQUALITY Following the 5 principled desiderata of codebook discussed in Section 2, we introduce our com- putational operalization for each of the dimensions in this subsection. Following the standard train- test-split protocol in machine learning, with codebook fitting done on the train set, we perform code prediction on the test set via a retrieval-based selection algorithm similar to the codebook update in iterative refinement procedure. After that, we calculate the following metrics of the test codebook. Reusability.Defined as the ratio of used codes to all codes: Reusability=#used codes #all codes. This measures the practical utility of a codebook and ranges in[0,1]. Descriptive Fitness.A score assigned by a large language model (LLM) in the range of 1–10, that quantifies the extent to which selected codes properly describe a datapoint (even if partially). For example, describing a resturant review that complains about delivery speed as “parking difficulty” would be considered improper. We rescale fitness score to[0,1]for final score. Since calculating the semantic fittness for the entire test set might be computationally expensive, we recommend doing sampling based estimation. The same sampling-based scoring applies to calculation of coverage. Descriptive Coverage.Similarly LLM-scored in the range of 1–10,coverage evaluates to what extend do all the essential aspects of a datapoint relevant to the research question are captured by the assigned codes. For instance, describing a resturant review that complains both “food serving speed” and “parking difficulty” only as “parking difficulty” misses the other essential side of the complaint, and thus is partial and incomplete. In this sense, a set of code can be proper but partial – two relatively orthognal dimensions. We also rescale coverage score to[0,1]for final score. 5 Table 1: Performance of different methods. Method AliAbdaal Podcast Abstracts MAS Math Failure OpenCoding2.762 2.915 2.420 2.594 2.286 LLOOM2.615 2.527 2.463 2.462 2.629 GraphRAG2.443 2.352 2.428 2.588 1.922 LightRAG2.352 2.408 2.091 2.568 1.956 Logos (Iter-1) 2.810 2.958 2.206 2.703 2.303 Logos (Best) 3.002 3.169 2.495 2.831 2.647Figure 2: Statistical metrics breakdown. ReusabilityFitnessCoverage Parsimony Consistency00.20.40.60.81Average ScoreOpenCode LLOOM GraphRAG LightRAG LOGOS-1 LOGOS-Best Parsimoniousness.A structural measure capturing semantic redundancy among codes: Parsimoniousness= 1−2 n(n−1)X i<jcos(c i, cj), wherenis the number of codes andcos(c i, cj)is the cosine similarity betweenc iandc j. This penalizes highly similar or redundant code pairs, encouraging compact yet expressive codebooks. Consistency / Stability.To measure generalization across datasets, we compute the Jensen– Shannon Divergence (JSD) between the empirical code distributions on the train and test sets: Stability= 1−JSD(P∥Q), wherePandQdenote the respective distributions. A higher stability score indicates that the code- book maintains consistency across data splits. Notice that this metric is under the assumption that train and",
    "datasets, we compute the Jensen– Shannon Divergence (JSD) between the empirical code distributions on the train and test sets: Stability= 1−JSD(P∥Q), wherePandQdenote the respective distributions. A higher stability score indicates that the code- book maintains consistency across data splits. Notice that this metric is under the assumption that train and test set are independent, identical distribution. The Final Composite Metric.In practice, these individual scores can be combined into a weighted sum to provide a single goodness-of-fit score for the codebook. Metrics reflecting se- mantic adequacy, such as descriptive fitness and coverage, may be given higher weight relative to structural measures like parsimony and consistency. Since reusability is essential for performing aggregation and multi-view clustering of the dataset, it also makes sense to assign higher weight to reusability as well. For our current work, we use equal weight for simplicity. 4 EXPERIMENT ANDDISCUSSION 4.1 DATASET We evaluate the performance of LOGOS across diverse domains using five datasets: (1)Ali Abdaal transcripts: A collection of full-text transcripts collected from YouTube videos by the million- subscriber creator Ali Abdaal. This dataset contains 500 documents with an average length of 4,204 words. (2)Podcast transcripts: We adopt the same dataset used by Edge et al. (2024), consisting of transcripts from the podcastBehind the Tech with Kevin Scott. The corpus is segmented into text chunks of 2,048 words with a 200-word overlap between consecutive chunks. (3)Abstracts dataset: A set of 210 randomly sampled UIST paper abstracts spanning the years 1989–2018 used by Lam et al. (2024). (4)Multi-Agent System (MAS) failure records: A dataset of multi-agent system failure trajectories introduced by Cemri et al. (2025), containing 785 LLM-annotated trajec- tories with lengths ranging from 1,262 to 71,640 words. We use a subset of 230 programming task datapoints for experiment 1. (5)Math failure dataset: Solutions to GSM8K math problems (Cobbe et al., 2021) generated by Qwen-32B. Incorrect solutions were filtered out, yielding 316 records with an average length of 500 words. 4.2 EXPERIMENT1 - STATISTICALMETRICSCOMPARISONS We report the distributional metrics of all approaches (reuseability, fitness, covereage, parsimonious- ness, and consistency) introduced in Section 3.3. For all datasets, we report the summed statistical metrics. We choose four competent baselines in our study: (1)OpenCodingis the simplest one, where we apply LLM-generated open codeing for each datapoint as the baseline. There is no iter- ation and no axiel or selective coding. We aggregate the codes to produce the final codebook, and discard codes below a minimum-frequency. (2)LLOOMis an reimplementation of the pipeline from Lam et al. (2024) to make it fit onto our datasets. Specifically, we drop the text extraction part, 6 and tune the hyperparameters like number of open code per datapoint and clustering size. We keep the high-level codes generated from the code clusters as the final codebook, and discard the open codes, as the original workflow. (3)GraphRAGis the off-the-shelf GraphRAG pipeline. We only change the question prompt to enforce the LLM to produce a 100-item codebook from all commu- nities. (4)LightRAGis the off-the-shelf LightRAG pipeline, with similar question adaptation. From Table 1,LOGOSis consistently the best-performing method. To better understand the perfor-",
    "codes, as the original workflow. (3)GraphRAGis the off-the-shelf GraphRAG pipeline. We only change the question prompt to enforce the LLM to produce a 100-item codebook from all commu- nities. (4)LightRAGis the off-the-shelf LightRAG pipeline, with similar question adaptation. From Table 1,LOGOSis consistently the best-performing method. To better understand the perfor- mance, we also provide the metric breakdown of each dimension of our proposed statistical metric, shown in Figure 2. From the results, we could observe thatOpenCodingandLLOOMare like two extremities – OpenCoding greatly “overfits” to the training set, with a lot of sparse and non-reusable datapoint-specific codes (for example, on Ali Dataset,OpenCodeproduces15827.6unique codes for each research question on average). The global average reusability score forOpenCodingis as low as0.209, and the global average fittness and coverage forOpenCodingis0.641and0.672, respectively. In contrast,LLOOMleaves only the cluster-specific high-level codes, which delivers extreemly high reusability rate (0.921), at the sacrifice of semantic adequacy (LLOOMhas a fittness score of0.482and a coverage score of0.463). In their middle ground,LOGOSnicely reconcile the reusability and semantic adequacy, delivering almost the reusability score (0.892) asLLOOM, without significant sacrifice of semantic fittness (0.538) and coverage (0.565). Besides, we can also clearly observe thatGraphRAGandLightRAGare not good at codebook generation without non-trivial modification of the original workflow, especially when the research question requires advanced interpretations of the datapoint. Their reusability is not on par withLLOOMandLOGOS, with significantly worse semantic adequancy. Last, but not leastLOGOSmaintains high-ranking parsimony and consistency. 4.3 EXPERIMENT2 - EFFECTIVENESS OFLOGOS ITERATIVEREFINEMENT Figure 3: Breakdown of five distributional metrics dimensions and codebook size variations. To understand how much the iterative refinement mechanism helps improve the codebook quality, we run LOGOS for 10 iterations on theAliAbdaal,Podcast, andAbstractsdataset. We show the reusability, descriptive fittness, descriptive coverage, parimoniousness, and consistency scores across iterations as a line plot in Figure 3. As we can see, the reusability rate of the codes gradually rises across iterations, at the cost of gradually descreasing semantic adequacy (i.e., codebook fittness and coverage). This suggests that the sparsity issue of LLM-generated open code gets increasingly betters, with the overly-detailed, datapoint-specific codes gradually replaced by more generalizable 7 and reuseable higher-level codes (the codebook size demonstrates a decreasing trend). Parsimony remains relative stable, whereas consistency demonstrates a decreasing pattern across iterations. 4.4 EXPERIMENT3 - CASESTUDY: GLOBALSENSE-MAKINGQUESTIONANSWERING Root causes: misread/misused constraints ? misapplied arithmetic ops throughout ? shaky proportional reasoning (wrong base, no chaining)? ?times more? confusion (multiplicative vs additive)? inconsistent units & values (generic defaults vs given data)? failure to use problem-specific parameters ? aggregation errors (dividing by days not student-days, double counts)? capacity/total miscalculation ? sequence/time mismanagement (step dependencies ignored; awake vs total time; avg month days overgeneralized)? domain slip in interest math (wrong basis/mechanics)? no validation loop (solution not checked against constraints)? correct computations on incorrect inputs ? ultimately, cumulative effect: inaccurate totals, broken logic flow, and answers that contradict the problem context. LOGOS Contradiction summary : ?Lou ate half the cookies? = 4 ? original jar = 8? Removals tracked: Lou Sr = 3 (Day 1) + 1 (Day 2) = 4? Lou Jr hides 7? total removed = 11? but only 8",
    "logic flow, and answers that contradict the problem context. LOGOS Contradiction summary : ?Lou ate half the cookies? = 4 ? original jar = 8? Removals tracked: Lou Sr = 3 (Day 1) + 1 (Day 2) = 4? Lou Jr hides 7? total removed = 11? but only 8 existed ? impossible? Root error = misreading Debra?s statement : ?half of the cookies out of the jar? was taken as half of the original jar, not half of the cookies that were out (i.e., already removed) at Debra?s observation? With the correct scope (half of removed, not of original), the counts need re-framing; without it, totals contradict ? Refs: [KG] Cookies; [KG] Mathematical Contradiction; [DC] unknown_source. LightRAG Dataset contains no explicit math problems, proposed solutions, or incorrect results to analyze ? Numerical entries (e.g., transactions, savings plans, classroom splits) are descriptive, not tasks? No evidence of a solution attempt or error to evaluate [Data: Reports (1, 3, 5, 12, 22, +?)]? While arithmetic/logical reasoning could be implied (totals, divisions), no process is documented and no mistakes indicated ? Without a specific problem + solution, we cannot diagnose failure modes or cite errors [Data: Reports (1, 3, 22, 35, +?)]? Bottom line: dataset lacks the required components?defined problem, proposed solution, wrong result?so failure analysis isn?t possible ; numbers are descriptive [Data: Reports (1, 3, 5, 12, 22, +?)]. GraphRAG Figure 4: On Math Failure dataset, GraphRAG and LightRAG fails to capture failure errors because no relevant information is extracted. In contrast, LOGOS successfully deliver a sensemaking answer. GraphRAG and LightRAG studies a new family of questions which they address as “global sense- making questions”. Their defining difference is that relevant information for global questions dissi- pate across the entire corpus and is more than spans and entities. For example, consider the question “What insights do leaders give on allocating budget for tech development?”, A single interview only contain one leader’s insight for very specific industry sectors and cannot fully answer the question. Dozens of such relevant information need to be combined, integrated, and synthesized into the final answer (open-ended, no ground truth). Schema induction question can be understood as a subspecies of global-level sensemaking question with special research value. It primarily focuses onverbally distilling and abstracting the common- alities, structural similarities, and recurring patternsfrom the entire corpus. However, unlike those global information-synthesis questions that can be readily resolved by using entity and relation extraction based knowledge graph , schema induction requires heavy interpreta- tion beyond extraction. To show case the qualitative and paradigmatic limitation of GraphRAG and LightRAG, we experiment onMath Failure Dataset, with global question “What are LLMs’ failure patterns in mathematical reasoning.”) From the results we show in Figure 4, we can easily observe that GraphRAG and LightRAG cannot generate sense-making answer for the research questions at all. After mannually examining the knowledge graph from the two RAG approaches, we find that the reason is that:failure patterns, which are much more not-readily-extractable logical dependencies, operation procedures, formula choice and value filling, are out of the knowledge graph.Nodes and edges in",
    "sense-making answer for the research questions at all. After mannually examining the knowledge graph from the two RAG approaches, we find that the reason is that:failure patterns, which are much more not-readily-extractable logical dependencies, operation procedures, formula choice and value filling, are out of the knowledge graph.Nodes and edges in the knowledge graphs are primarly about the entities and semantic relationships between them, which could not afford answering the schema-induction question. In constrast, LOGOS suc- cessfully identifies the recurring patterns and summarize them into a sense-making final answer. 4.5 EXPERIMENT4 - CASESTUDY: ALIGNMENT WITHHUMANGROUNDTRUTH Figure 5: Code match heatmap.Our primary goal of buildingLOGOSis to liberate mannual labors. To see whetherLOGOScan truly reach high agreement with human expert annotators, we compare theLOGOSgener- ated codebook with the expert ground-truth (GT) schema on the MAS dataset. After 5 iterations ofLOGOS, our codebook pro- duces a fine-grained codebook with size286(with a hierarchical structure). Since the GT codebook only has a size of17, we perform LLM-based aggregation of our codebook to generate 30 clusters. For each clusters, we generate3high-level codes that 8 describes the theme of the cluster. After this, we directly dump the clusters-codes along with the GT codebook together into a LLM to do matching. For each of the code from the GT codebook, we count as a successful match as long as it matches with at least one of the30clusters fromLOGOS. The final matching rate can be as high as88.2%.1This suggests thatLOGOShas encouraing potentials to emancipate human labors in grounded theory developement and schema induction processes. 5 RELATED WORK Computer-Aided Grounded Theory DevelopmentThe high cost of qualitative research has mo- tivated a decades-long effort to offload parts of the coding and sense-making pipeline onto software. Commercial tools such as NVivo, MAXQDA, and Condens accelerate the mechanical step of re- trieval—searching for keywords and bulk-applying a priori codes—but stop short of interpretive work. Academic efforts, especially within the HCI community, move beyond keyword matching to- ward automation that still foregrounds expert judgment. Cody Rietz & Maedche (2021) exemplifies this approach by supporting user-defined rules and semi-automatic tagging, keeping the analyst in the loop for every interpretive decision. Recently, researchers have started exploring how to leverage the power of Large Language Models to facilitate qualitative analysis (Schroeder et al., 2025). Col- labCoder (Gao et al., 2024) and CoAICoder (Gao et al., 2023) demonstrate that large language mod- els can scaffold distributed teams, though they primarily treat the LLM as a conversational partner rather than an autonomous analyst. AcademiaOS ( ¨Ubellacker, 2024) automates the Gioia method’s choreography—open coding, axial coding, and theory generation—but still requires scholars to val- idate each emergent construct. MindCoder (Gao et al., 2025), the most recent system and closest to our aims, introduces a reasoning-chain architecture that produces transparent analytical traces. Yet, even in this case, experts remain responsible for distilling implicit meanings from raw codes. In contrast,LLOOMLam et al. (2024) offers an end-to-end pipeline that moves from an unannotated corpus to a comprehensive codebook. Our work follows the same motivation asLLOOMbut advances it further by constructing a finer-grained hierarchical codebook through iterative",
    "in this case, experts remain responsible for distilling implicit meanings from raw codes. In contrast,LLOOMLam et al. (2024) offers an end-to-end pipeline that moves from an unannotated corpus to a comprehensive codebook. Our work follows the same motivation asLLOOMbut advances it further by constructing a finer-grained hierarchical codebook through iterative refinement. Automated Theoretical Induction for Specialized DomainsAbundant works have been done specifically for fully-automatedeventschema induction in recent years (Li et al., 2020; 2023; 2022; Jin et al., 2022; Du, 2022). The recurring methodology here is to represent events as traditional knowledge graphs (exclusively consider actions and named entities as proper nodes, together with strong inductive bias on the edges) and perform reasoning with graph neural networks. Cheng et al. (2024) follows a similar formalism but targets a narrower domain of the EV battery supply chain. Metrics in this line are usually based on next-event prediction (e.g., as edge type classification). Similarly, policy researchers have also tried to use LLM to summarize themes from large amount of text materials (Fang et al., 2025; Wang et al., 2025). These works, although making explicit attempts to align recurring entities, relations, and actions from individual datapoints in the corpus, make strong assumptions about the domains (e.g., riots and wars, political and economic events), ontology (schemas are exclusively about events), and topology (as a knowledge graph with the specialized formalism).LOGOS’s attempt is to break all of these assumptions and deliver a general- purpose schema induction system with full automation. Dror et al. (2023) similarly focuses on event schema induction, but directly generates a schema via sampling from LLM, which is not quite applicable to long-tail or emerging domains that LLM are less familiar with. 6 CONCLUSION LOGOS closes a long-standing gap between retrieval-heavy tooling and true interpretive synthesis for grounded theory. It delivers an end-to-end, domain-agnostic pipeline which simulates the open →axial→selective coding processes via semantic clustering, relation-aware graphs, and iterative refinement. Together, we deliver a standardiable 5-dimensional codebook quality statistical metric, along with a train/test protocol. Empirically, LOGOS outperforms coding- and RAG-based baselines on5corpora and attains88.2%alignment with expert schemas on MAS, indicating real potential to cut expert labor without discarding nuance. Current limits primarily reside in the limitation of code- book typology, which only consider semantic hierarchy. We plan to consider richer causal/temporal relations in the future, with better computaional cost optimzation (e.g. LLM routing). 1We provide the complete mapping from cluster names to ground truth codebook in Appendix A.1. 9 REFERENCES Mert Cemri, Melissa Z. Pan, Shuyi Yang, Lakshya A. Agrawal, Bhavya Chopra, Rishabh Tiwari, Kurt Keutzer, Aditya Parameswaran, Dan Klein, Kannan Ramchandran, Matei Zaharia, Joseph E. Gonzalez, and Ion Stoica. Why do multi-agent llm systems fail?, 2025. URLhttps://arxiv. org/abs/2503.13657. Zhi-Qi Cheng, Yifei Dong, Aike Shi, Wei Liu, Yuzhi Hu, Jason O’Connor, Alexander G. Haupt- mann, and Kate S. Whitefoot. Shield: Llm-driven schema induction for predictive analytics in ev battery supply chain disruptions, 2024. URLhttps://arxiv.org/abs/2408.05357. Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, and John Schulman. Training verifiers to solve math",
    "mann, and Kate S. Whitefoot. Shield: Llm-driven schema induction for predictive analytics in ev battery supply chain disruptions, 2024. URLhttps://arxiv.org/abs/2408.05357. Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, and John Schulman. Training verifiers to solve math word problems, 2021. URLhttps://arxiv. org/abs/2110.14168. Juliet M. Corbin. The body in health and illness.Qualitative Health Research, 13(2):256–267, 2003. doi: 10.1177/1049732302239603. Juliet M. Corbin and Anselm Strauss.Unending work and care: Managing chronic illness at home. Jossey-Bass, 1988. Rotem Dror, Haoyu Wang, and Dan Roth. Zero-shot on-the-fly event schema induction. In Andreas Vlachos and Isabelle Augenstein (eds.),Findings of the Association for Computational Linguis- tics: EACL 2023, pp. 705–725, Dubrovnik, Croatia, May 2023. Association for Computational Linguistics. doi: 10.18653/v1/2023.findings-eacl.53. URLhttps://aclanthology.org/ 2023.findings-eacl.53/. Xinya et al. Du. RESIN-11: Schema-guided event prediction for 11 newsworthy scenarios. In Han- naneh Hajishirzi, Qiang Ning, and Avi Sil (eds.),Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics, pp. 54–63, Hybrid: Seattle, Washington + Online, July 2022. Association for Computational Linguistics. doi: 10.18653/v1/ 2022.naacl-demo.7. URLhttps://aclanthology.org/2022.naacl-demo.7/. Darren Edge, Ha Trinh, Newman Cheng, Joshua Bradley, Alex Chao, Apurva Mody, Steven Truitt, Dasha Metropolitansky, Robert Osazuwa Ness, and Jonathan Larson. From local to global: A graph rag approach to query-focused summarization.arXiv preprint arXiv:2404.16130, 2024. Hanming Fang, Ming Li, and Guangli Lu. Decoding China’s Industrial Policies.SSRN Electronic Journal, 2025. ISSN 1556-5068. URLhttps://www.ssrn.com/abstract=5078043. Jie Gao, Kenny Tsu Wei Choo, Junming Cao, Roy Ka-Wei Lee, and Simon Perrault. CoAIcoder: Examining the Effectiveness of AI-assisted Human-to-Human Collaboration in Qualitative Anal- ysis.ACM Trans. Comput.-Hum. Interact., 31(1):6:1–6:38, November 2023. ISSN 1073-0516. doi: 10.1145/3617362. URLhttps://dl.acm.org/doi/10.1145/3617362. Jie Gao, Yuchen Guo, Gionnieve Lim, Tianqin Zhang, Zheng Zhang, Toby Jia-Jun Li, and Si- mon Tangi Perrault. Collabcoder: a lower-barrier, rigorous workflow for inductive collaborative qualitative analysis with large language models. InProceedings of the 2024 CHI Conference on Human Factors in Computing Systems, pp. 1–29, 2024. Jie Gao, Zhiyao Shu, and Shun Yi Yeo. Mindcoder: Automated and controllable reasoning chain in qualitative analysis.arXiv preprint arXiv:2501.00775, 2025. Mary L. Gick and Keith J. Holyoak. Schema induction and analogical transfer.Cognitive Psychol- ogy, 15(1):1–38, 1983. doi: 10.1016/0010-0285(83)90002-6. Dennis A Gioia and Kumar Chittipeddi. Sensemaking and sensegiving in strategic change initiation. Strategic management journal, 12(6):433–448, 1991. Barney Glaser and Anselm Strauss.Discovery of grounded theory: Strategies for qualitative re- search. Routledge, 2017a. Barney G Glaser and Anselm L Strauss.Awareness of dying. Routledge, 2017b. 10 Xiaomeng Jin, Manling Li, and Heng Ji. Event schema induction with double graph autoen- coders. In Marine Carpuat, Marie-Catherine de Marneffe, and Ivan Vladimir Meza Ruiz (eds.), Proceedings of the 2022 Conference of NAACL, pp. 2013–2025, Seattle, United States, July 2022. Association for Computational Linguistics. doi: 10.18653/v1/2022.naacl-main.147. URL https://aclanthology.org/2022.naacl-main.147/. Michelle S. Lam, Janice Teoh, James A. Landay, Jeffrey Heer, and Michael S. Bernstein. Concept induction: Analyzing unstructured text with high-level concepts using lloom. InProceedings of the CHI Conference on Human Factors in Computing Systems, CHI ’24, pp. 1–28. ACM, May 2024. doi: 10.1145/3613904.3642830. URLhttp://dx.doi.org/10.1145/3613904. 3642830. Manling Li, Qi Zeng, Ying Lin, Kyunghyun Cho, Heng Ji, Jonathan May, Nathanael Chambers, and",
    "Michael S. Bernstein. Concept induction: Analyzing unstructured text with high-level concepts using lloom. InProceedings of the CHI Conference on Human Factors in Computing Systems, CHI ’24, pp. 1–28. ACM, May 2024. doi: 10.1145/3613904.3642830. URLhttp://dx.doi.org/10.1145/3613904. 3642830. Manling Li, Qi Zeng, Ying Lin, Kyunghyun Cho, Heng Ji, Jonathan May, Nathanael Chambers, and Clare V oss. Connecting the dots: Event graph schema induction with path language mod- eling. In Bonnie Webber, Trevor Cohn, Yulan He, and Yang Liu (eds.),Proceedings of the 2020 EMNLP, pp. 684–695, Online, November 2020. Association for Computational Linguis- tics. doi: 10.18653/v1/2020.emnlp-main.50. URLhttps://aclanthology.org/2020. emnlp-main.50/. Manling Li, Sha Li, Zhenhailong Wang, Lifu Huang, Kyunghyun Cho, Heng Ji, Jiawei Han, and Clare V oss. The future is not one-dimensional: Complex event schema induction by graph mod- eling for event prediction, 2022. URLhttps://arxiv.org/abs/2104.06344. Sha Li, Ruining Zhao, Manling Li, Heng Ji, Chris Callison-Burch, and Jiawei Han. Open-domain hierarchical event schema induction by incremental prompting and verification, 2023. URL https://arxiv.org/abs/2307.01972. Xinyu Pi, Bing Wang, Yan Gao, Jiaqi Guo, Zhoujun Li, and Jian-Guang Lou. Towards robustness of text-to-SQL models against natural and realistic adversarial table perturbation. In Smaranda Muresan, Preslav Nakov, and Aline Villavicencio (eds.),Proceedings of the 60th ACL, pp. 2007– 2022, Dublin, Ireland, May 2022a. Association for Computational Linguistics. URLhttps: //aclanthology.org/2022.acl-long.142/. Xinyu Pi, Wanjun Zhong, Yan Gao, Nan Duan, and Jian-Guang Lou. Logigan: Learning logical reasoning via adversarial pre-training.NeurIPS 2022, 2022b. doi: 10.48550/arXiv.2205.08794. Marco Tulio Ribeiro, Tongshuang Wu, Carlos Guestrin, and Sameer Singh. Beyond accuracy: Be- havioral testing of NLP models with CheckList. In Dan Jurafsky, Joyce Chai, Natalie Schluter, and Joel Tetreault (eds.),Proceedings of the 58th Annual Meeting of ACL, pp. 4902–4912, On- line, July 2020. doi: 10.18653/v1/2020.acl-main.442. URLhttps://aclanthology.org/ 2020.acl-main.442/. Tim Rietz and Alexander Maedche. Cody: An ai-based system to semi-automate coding for qualita- tive research. InProceedings of the 2021 CHI conference on human factors in computing systems, pp. 1–14, 2021. Hope Schroeder, Marianne Aubin Le Qu ´er´e, Casey Randazzo, David Mimno, and Sarita Schoenebeck. Large Language Models in Qualitative Research: Uses, Tensions, and Intentions. InProceedings of the 2025 CHI Conference on Human Factors in Computing Systems, CHI ’25, pp. 1–17, New York, NY , USA, April 2025. URLhttps://dl.acm.org/doi/10.1145/ 3706598.3713120. Maggie Wang, Ella Colby, Jennifer Okwara, Varun Nagaraj Rao, Yuhan Liu, and Andr ´es Monroy- Hern ´andez. PolicyPulse: LLM-Synthesis Tool for Policy Researchers. InProceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems, CHI EA ’25, pp. 1–17, New York, NY , USA, April 2025. URLhttps://dl.acm.org/doi/10. 1145/3706599.3720266. Tomer Wolfson, Mor Geva, Ankit Gupta, Matt Gardner, Yoav Goldberg, Daniel Deutch, and Jonathan Berant. Break it down: A question understanding benchmark, 2020. URLhttps: //arxiv.org/abs/2001.11770. Thomas ¨Ubellacker. Academiaos: Automating grounded theory development in qualitative research with large language models, 2024. URLhttps://arxiv.org/abs/2403.08844. 11 A APPENDIX A.1 ONEVALUATINGSCHEMAALIGNMENT The evaluation in Section 4.5 shows high conceptual alignment (88.2%) with the expert-developed ground-truth (GT) schema, which we frame as recall and coverage; althoughLOGOSproduced 30 clusters versus 17 expert codes, a conventional precision metric is both hard to define and method- ologically less relevant for grounded theory. The goal is conceptual containment rather than replica- tion: GT",
    "conceptual alignment (88.2%) with the expert-developed ground-truth (GT) schema, which we frame as recall and coverage; althoughLOGOSproduced 30 clusters versus 17 expert codes, a conventional precision metric is both hard to define and method- ologically less relevant for grounded theory. The goal is conceptual containment rather than replica- tion: GT is exploratory, and different researchers naturally produce schemas at different abstraction levels. What matters is that expert-identified concepts are captured within LOGOS’s more fine- grained, many-to-one mappings—for example, an expert’s broad “External Tool Error” may rea- sonably decompose into clusters such as C20 (Authentication and credential handling errors) and C21 (External API misuse assumptions) within our codebook. “Unmatched” clusters are often a feature, not a bug, surfacing novel insights, finer-grained distinctions, or alternative abstractions that augment human analysis. For this reason, precision is less important: it presumes that unmatched outputs are errors, whereas in exploratory coding surplus concepts add nuance and reveal overlooked patterns. Prioritizing recall/coverage better reflects the purpose of grounded theory—to comprehen- sively map the conceptual landscape—while penalizing lower precision would mischaracterize the value of detailed discovery. Cluster Names C1:Specification compliance failures C2:Role and responsibility violations C3:Repetition and looping errors C4:Context and memory breakdowns C5:Stop-condition and termination awareness gaps C6:Clarification and information-seeking failures C7:Task focus and objective drift C8:Peer and external input disregarded C9:Reasoning–action inconsistency C10:Premature stopping before validation C11:Missing or skipped verification steps C12:Incorrect or faulty verification methods C13:Quantitative reasoning and calculation errors C14:Constraint and requirement misinterpretations C15:Misunderstanding of fixed facts or premises C16:Handling of incomplete or underspecified data C17:Ethical, legal, and normative reasoning gaps C18:Missing edge cases or special-case handling C19:Debugging, error detection, and self-correction weaknesses C20:Authentication, authorization, and credential handling errors C21:Misuse or incorrect assumptions about external APIs C22:Mishandling of complex data structures and relationships C23:Exception handling and reporting deficiencies C24:Testing and coverage insufficiencies C25:Ambiguity interpretation and resolution weaknesses C26:Overgeneralized or misapplied heuristic reasoning C27:Inadequate rigor in proofs and formal reasoning 12 C28:Weak synthesis or integration of intermediate results C29:Overconfident but incorrect assertions C30:Limited breadth in exploration or search FC Categories→Cluster Sets.Higher-level FC categories mapped to the broadened cluster set (one-to-many). •FC-1 (Specification Issues)→C01, C02, C14, C15 •FC-2 (Inter-Agent Misalignment)→C06, C07, C08, C09, C25 •FC-3 (Task Verification)→C10, C11, C12, C24, C19 Ground Truth FM Items→Clusters. •FM-1.1 (Disobey task specification)→C01, C14, C15 •FM-1.2 (Disobey role specification)→C02, C01 •FM-1.3 (Step repetition)→C03 •FM-1.4 (Loss of conversation history)→C04, C16 •FM-1.5 (Unaware of termination conditions)→C05, C25 •FM-2.1 (Conversation reset)→missing (no cluster assigned) •FM-2.2 (Fail to ask for clarification)→C06, C25 •FM-2.3 (Task derailment)→C07, C26 •FM-2.4 (Information withholding)→missing (no cluster assigned) •FM-2.5 (Ignored other agent’s input)→C08, C25 •FM-2.6 (Reasoning–action mismatch)→C09, C28 •FM-3.1 (Premature termination)→C10, C19 •FM-3.2 (No or incomplete verification)→C11, C24 •FM-3.3 (Incorrect verification)→C12, C13, C27 Currently Unused Clusters: •C17:Ethical, legal, and normative reasoning gaps •C18:Missing edge cases or special-case handling •C20:Authentication, authorization, and credential handling errors •C21:Misuse or incorrect assumptions about external APIs •C22:Mishandling of complex data structures and relationships •C23:Exception handling and reporting deficiencies •C29:Overconfident but incorrect assertions •C30:Limited breadth in exploration or search A.2 DISTILLEDCLASSIFIERRESULTS Since the performance of the distilled classifier determinantly impacts the quality and consistency of the constructed",
    "credential handling errors •C21:Misuse or incorrect assumptions about external APIs •C22:Mishandling of complex data structures and relationships •C23:Exception handling and reporting deficiencies •C29:Overconfident but incorrect assertions •C30:Limited breadth in exploration or search A.2 DISTILLEDCLASSIFIERRESULTS Since the performance of the distilled classifier determinantly impacts the quality and consistency of the constructed graph, we also carry out extensive experiments to improve its performance. We attempted to fine-tune various models with different approaches, and record all results in Table 2. From the results, the general observation is that: (1) doing global fine-tuning results in similar performance as doing LoRA fine-tuning; and (2) Using a larger model significantly improves the performance. Our Wikipedia training corpus consist of 350k code pairs generated from English Wikiepdia, using the same embedding plus taking top30%highest cosine similarities pipeline as inLOGOS. On this corpus, we observe a serious label imbalance issue. The pairs labeled “mutual” account for only 13 approximately10%of those with other labels. Therefore, we also attempted the label smoothing technique and the oversampling-based balancing technique. Results show that the balancing tech- nique is effective in our label-imbalance case. Model Acc F1 Macro F1 Micro Balanced Acc MiniLM-L12 (33M) 0.536 0.507 0.536 0.626 Roberta-focal-loss 0.722 0.654 0.722 0.734 Modern-Bert-full 0.723 0.665 0.723 0.694 Roberta-large-full 0.740 0.674 0.740 0.735 Roberta-MNLI-full 0.730 0.664 0.730 0.733 Roberta-large-LoRA 0.719 0.649 0.728 0.728 Qwen3-0.6B 0.766 0.711 0.766 0.715 Qwen3-4B-it 0.803 0.747 0.802 0.742 Qwen3-4B-base 0.804 0.745 0.804 0.759 Qwen3-4B-balanced 0.814 0.815 0.814 0.812 Table 2: Model performance comparison across Accuracy, F1 Macro, F1 Micro, and Balanced Accuracy. All models are trained on a single A100 GPU with using theHuggingFace AutoModelforClassificationframework with the following hyperparameters: Label smoothing was applied with a factor of0.1. Whenever applicable, focal loss gamma was set to2.0. A weighted sampler was used for class balancing. Training was performed for10epochs with a learning rate of2×10−4, per-device training batch size of256, and per-device evaluation batch size of512. The LoRA configuration employed a rankr= 16,α= 32, dropout rate of0.05, bias set tonone, and targeted modules includedq proj,k proj,v proj, ando proj, withscore modules preserved. A.3 CODEFREQUENCIES PERDATASET ANDQUESTION A.3.1 PAPERABSTRACTSDATASETQUESTIONS ANDTOP25 FREQUENTCODES: •Q1:What are the problem framings and research gaps identified within the UIST abstracts? This question aims to identify the common ways that authors in the UIST community frame their research. It explores the recurring themes and narratives used to establish the signif- icance of their work, such as addressing technological limitations, filling gaps in existing research, or enabling new forms of interaction. By looking at the collection of abstracts, you can identify the shared understandings of what constitutes a ”problem” in this research community. Bridging physical-digital. . .Enabling novel interactio. . . User-centered evaluation . . .Development of novel inpu. . . Enabling seamless connect. . .Empirical validation of i. . .User study validation of . . . User study validation of . . . Innovating novel interact. . .Enhancing user experience. . . Enabling dynamic spatial . . . Bridging physical and dig. . . Overcoming traditional in. . . Facilitating seamless phy. . .Enabling real-time feedba. . . Bridging physical-digital. .",
    "validation of . . . User study validation of . . . Innovating novel interact. . .Enhancing user experience. . . Enabling dynamic spatial . . . Bridging physical and dig. . . Overcoming traditional in. . . Facilitating seamless phy. . .Enabling real-time feedba. . . Bridging physical-digital. . . Integration of physical o. . . Integration of novel visu. . .Innovation in input devic. . .Enhancing human-device in. . .Integration of Gesture Re. . . Enabling tactile, eyes-fr. . .Innovating input methods . . . Bridging physical and dig. . . Innovating interaction me. . .02040 Paper Abstracts - Q1 (Top 25)Prevalence •Q2:What are the forms of research contributions claimed across the abstracts? This ques- tion seeks to categorize the main contributions presented in the abstracts. It helps in under- standing the landscape of research outputs, distinguishing between new systems, interac- tion techniques, fabrication methods, empirical studies, or theoretical frameworks that are the primary focus of the research. This will map the terrain of innovation at UIST and show where the collective research effort is concentrated. 14 Real-Time Interaction Tec. . .Design flexibility for us. . .Empirical validation thro. . .User study-driven perform. . . Integration of physical a. . .Design challenges in cust. . . Facilitating finger-based. . .Design implications for t. . . Integration of Physical a. . .Real-Time Feedback Mechan. . .User interface design for. . .Realtime interaction fram. . . Real-time interaction tec. . .Framework for user-define. . .Empirical validation of s. . . User interface optimizati. . .Enhanced exploration of c. . .Interactive physical-digi. . .Integration of computer v. . . Design variations for two. . .Development of tangible i. . . Integration of advanced f. . . System adaptability to di. . . Context-aware interaction. . . Empirical validation of p. . .02040 Paper Abstracts - Q2 (Top 25)Prevalence •Q3:What are the foundational methods that underpin the research in the abstracts? This question focuses on identifying the core method, technological, material, and computa- tional building blocks that enable the presented research. It aims to reveal trends in the use of specific methods, hardware, software approaches, or fabrication techniques that are frequently cited as being central to the innovations described across the dataset. Empirical validation of r. . .User study validation of . . .Development of intuitive . . .User-Centered Evaluation . . .Human-Computer Interactio. . . System design and impleme. . .Innovative interaction te. . .Development of Intuitive . . .Reduction of implementati. . . User interface prototypin. . . Interactive system archit. . .User study for method eva. . . Gestural input methods fo. . . User experience evaluatio. . . Real-time physical-digita. . .Modular component-based d. . .Real-time interaction bet. . .Innovative engineering of. . . Empirical validation of i. . . Physical-digital integrat. . .Modular system design for. . . Design of input devices f. . . Design implications for t. . . Real-time interaction pro. . .Modular component-based d. . .010203040 Paper Abstracts - Q3 (Top 25)Prevalence •Q4:What are the user roles and paradigms of interaction implied in the abstracts?",
    "Physical-digital integrat. . .Modular system design for. . . Design of input devices f. . . Design implications for t. . . Real-time interaction pro. . .Modular component-based d. . .010203040 Paper Abstracts - Q3 (Top 25)Prevalence •Q4:What are the user roles and paradigms of interaction implied in the abstracts? This question investigates how the ”user” is conceptualized in the research. It explores the different ways users are expected to interact with the proposed systems and technolo- gies—whether as active creators, performers, collaborators, or passive consumers of in- formation—and what these roles suggest about the underlying assumptions and values of the research. This can reveal the models of human-computer interaction being explored and promoted. 15 Real-Time Processing for . . . Hybrid Physical-Digital I. . .Dynamic adaptation to use. . . Task-oriented interaction. . .Seamless integration of p. . .Dynamic Interface Adaptat. . . Real-Time Virtual Feedbac. . . Context-aware interaction. . .Dynamic System Adaptation. . .User-centered interaction. . .Innovative input method d. . . User-Centered Spatial Int. . . User-Centered Interaction. . . Hybrid physical-digital i. . .Dynamic interface adaptat. . . Integration of physical g. . . User-centered spatial int. . .User study validation of . . .User-Centered Evaluation . . .Physical-digital hybrid i. . .Collaborative Multi-User . . . Seamless integration of p. . . Support for exploratory d. . . User-Centric Spatial Inte. . .Seamless Integration of P. . .02040 Paper Abstracts - Q4 (Top 25)Prevalence •Q5:What are the evaluation strategies and validation methods employed to demonstrate the contributions? This question aims to understand how the UIST community validates its research claims. It focuses on identifying the methodologies used to evaluate novel systems and techniques, such as controlled user studies, technical benchmarks, expert reviews, or illustrative case studies. Analyzing these methods will shed light on the community’s stan- dards of evidence and what is considered a robust demonstration of a research contribution. Technical validation thro. . .Technical demonstration o. . . Technical feasibility dem. . . Technical validation thro. . .Prototype-based system de. . . Empirical validation thro. . .Implementation-based vali. . .Integration of multiple f. . .Design of multi-touch int. . .Dynamic user interface as. . . Design space exploration . . . Hybrid physical-digital i. . . Use of controlled user st. . . Technical validation thro. . .Technical innovation thro. . .Illustrative case study d. . .User-Centered Interface D. . .Technical implementation . . .Evaluation through implem. . . User interface as a dynam. . . Demonstration of practica. . . Empirical validation of s. . . User interface innovation. . .Technical benchmarking ag. . . Research contribution thr. . .050100 Paper Abstracts - Q5 (Top 25)Prevalence A.3.2 PODCASTDATASETQUESTIONS ANDTOP25 FREQUENTCODES: •Q1:How are different technological and scientific domains characterized and intercon- nected within the conversations? This question seeks to understand the mental models of the tech landscape presented by the guests. Rather than just listing topics, it focuses on the language used to describe various fields, the relationships drawn between them (e.g., AI and biology), and which areas are framed as foundational, emerging, or peripheral.",
    "This question seeks to understand the mental models of the tech landscape presented by the guests. Rather than just listing topics, it focuses on the language used to describe various fields, the relationships drawn between them (e.g., AI and biology), and which areas are framed as foundational, emerging, or peripheral. This reveals the conceptual structure of the tech world as seen by its leaders. 16 Interdisciplinary converg. . .Synthesis of personal pas. . .Cultural impact of democr. . . Interdisciplinary Synergy. . .Democratization of techni. . .Empowerment through hands. . .Interdisciplinary problem. . .Legacy of foundational te. . . Democratization of techni. . .Interdisciplinary collabo. . .Interdisciplinary problem. . . Interdisciplinary converg. . . Resilience through iterat. . .Need-Driven Adoption of E. . .Interdisciplinary integra. . .Mentorship shaping career. . . Democratization of techno. . .Interdisciplinary converg. . .Learning through failure . . . Interdisciplinary synergy. . .Interplay between technic. . .Mentorship and peer influ. . . Interplay between technic. . .Democratization of progra. . . Historical context of tec. . .050100150 Podcast - Q1 (Top 25)Prevalence •Q2:What are the narratives and visions for the future of technology and science as artic- ulated by the guests? This question aims to identify the recurring ways in which thought leaders speculate about and envision the future. It explores the common themes, hopes, and anxieties they express regarding long-term technological trajectories and their potential so- cietal impact. The goal is to synthesize the collective imagination and forecasting present across the interviews, looking for shared optimistic or cautionary tales. Interdisciplinary approac. . . Interdisciplinary collabo. . . Interdisciplinary collabo. . .Balancing innovation with. . . Long-term societal impact. . . Interdisciplinary approac. . .Resilience Through Iterat. . .Long-term societal implic. . . Ethical considerations in. . .Interdisciplinary approac. . . Curiosity as a driver of . . . Ethical considerations in. . .Interplay between technol. . . Interdisciplinary Synergy. . .Interplay between persona. . . Long-term societal impact. . . Long-term societal impact. . . Long-term societal implic. . . Long-term societal implic. . . Societal implications of . . .Ethical frameworks for re. . . Interdisciplinary approac. . .Human-AI collaboration as. . . Democratizing access to a. . . Interplay between persona. . .020406080100 Podcast - Q2 (Top 25)Prevalence •Q3:What are the ways technological and societal challenges are framed? This question investigates the shared understanding of ‘what ´s broken’ and ‘how to fix it.’ It focuses on identifying patterns in how problems—whether technical, ethical, or social—are defined. The analysis should capture who or what is held responsible for these challenges (e.g., market forces, lack of regulation, historical inertia). 17 Dynamic interplay between. . . Balancing innovation with. . . Adaptation to evolving te. . . Interdisciplinary knowled. . . Need for interdisciplinar. . .Interdisciplinary approac. . . Societal implications of . . .Public engagement in tech. . . Need for long-term societ. . . Curiosity as a driver of . . .Importance of social conn. . . Understanding natural int. . . Interdisciplinary collabo. . .Perspective is key in eva. . . Integration of creativity.",
    ". . Societal implications of . . .Public engagement in tech. . . Need for long-term societ. . . Curiosity as a driver of . . .Importance of social conn. . . Understanding natural int. . . Interdisciplinary collabo. . .Perspective is key in eva. . . Integration of creativity. . .Interdisciplinary problem. . . Ethical considerations in. . . Interdisciplinary collabo. . . Ethical responsibility in. . .Importance of long-term s. . . Technological evolution o. . . Long-term societal planni. . . Ethical responsibility in. . .Human-centered design of . . .Interplay between creativ. . .050100150 Podcast - Q3 (Top 25)Prevalence •Q4:How do the guests conceptualize the ecosystem of technological innovation, partic- ularly the interplay between academic research, industry development, and commercial application? This question explores the different models of progress and innovation dis- cussed in the podcast. It aims to uncover the various perspectives on how new ideas are born, developed, and scaled. The analysis should focus on the perceived roles, tensions, and synergies between fundamental research in academia and applied work in industry, revealing the underlying philosophies about how technological advancement happens. Transformative impact of . . .Impact of mentorship and . . . Dynamic interplay of rese. . .Synergy between personal . . .Empowerment through techn. . .Interdisciplinary exchang. . .Long-term vision in techn. . .Academic-industry synergy. . .Resilience through intrin. . .Interplay between academi. . . Personal motivation susta. . .Technological tools expan. . . Inclusive innovation thro. . .Dynamic interplay between. . .Creative risk-taking lead. . . Interdisciplinary collabo. . .Long-Term Vision in Techn. . . Impact of early exposure . . .Mentorship in bridging ac. . .Mentorship nurtures emerg. . .Role of interdisciplinary. . .Ethical and societal impl. . . Interplay between artisti. . .Public Engagement as Cata. . .Cross-disciplinary collab. . .020406080100 Podcast - Q4 (Top 25)Prevalence •Q5:What are the personal and professional motivations that drive these thought leaders? This question seeks to build a composite picture of the values and driving forces behind the work of leaders in science and technology. It involves analyzing the stories guests tell about their careers, their passions, and what they find meaningful. This can reveal a ”tax- onomy of purpose,” identifying threads like intellectual curiosity, entrepreneurial ambition, humanitarian goals, or a desire to build elegant systems. 18 Interdisciplinary approac. . .Belief in the power of ed. . . Interdisciplinary approac. . .Interdisciplinary problem. . .Long-term vision for tran. . . Curiosity-driven explorat. . . Resilience through iterat. . . Interdisciplinary collabo. . .Bridging technical comple. . . Strategic vision for long. . . Interdisciplinary collabo. . .Democratizing understandi. . . Interdisciplinary Synergy. . . Interdisciplinary Synergy. . .Bridging technical and ar. . . Mentorship as catalyst fo. . . Interdisciplinary collabo. . .Interdisciplinary synergy. . .Technology as a tool for . . . Ethical considerations in. . .Influence of personal exp. . . Interdisciplinary approac. . .Belief in the Power of Ed. . . Bridging creative passion. . .Democratizing access to k. . .050100150 Podcast - Q5 (Top 25)Prevalence A.3.3 ALIABDAALDATASETQUESTIONS ANDTOP25 FREQUENTCODES: •Q1:What core motivations",
    "as a tool for . . . Ethical considerations in. . .Influence of personal exp. . . Interdisciplinary approac. . .Belief in the Power of Ed. . . Bridging creative passion. . .Democratizing access to k. . .050100150 Podcast - Q5 (Top 25)Prevalence A.3.3 ALIABDAALDATASETQUESTIONS ANDTOP25 FREQUENTCODES: •Q1:What core motivations or needs seem to drive the speaker’s messages across multiple videos? This question asks deeper needs or motivations the speaker articulates or implies repeatedly throughout the dataset. It is not about cataloging explicit reasons (e.g., “produc- tivity tools”), but uncovering fundamental drivers like autonomy, personal growth, or emo- tional reassurance. It involves inductively coding references to why ideas are presented, and comparing across episodes to surface an emergent overarching category. Autonomy through financia. . . Autonomy in self-directed. . . Efficiency in knowledge a. . . Purpose-driven content cr. . .Personal growth through s. . .Autonomy in creative expr. . . Redefining success throug. . . Cultivating a sense of ac. . . Intrinsic motivation over. . .Authenticity in content c. . . Adaptive learning strateg. . .Autonomy through self-dir. . . Efficiency in information. . .Efficiency in knowledge r. . . Strengthening interperson. . .Redefining success beyond. . . Continuous learning and s. . . Promoting work-life balan. . . Fostering creativity and . . .Empowerment through knowl. . .Emotional satisfaction fr. . .Desire for control over d. . .Need for contextual decis. . . Inspiring creative confid. . . Influence of lifestyle on. . .02468 AliAbdaal - Q1 (Top 25)Prevalence •Q2:How does the speaker construct authority and credibility in their narrative across the videos? This question explores how the speaker positions themselves as trustworthy or knowledgeable—not by counting statements, but by examining patterns such as personal anecdotes, credentials, data citations, or collaborative language. It asks: “What strategies recur that help the speaker convey credibility?” The goal is to develop a conceptual category of how credibility is built conversationally across the dataset. 19 Leveraging personal exper. . . Validating audience’s str. . .Emphasizing practical app. . . Leveraging personal journ. . . Utilizing personal experi. . .Offering actionable, prac. . .Creating a supportive com. . . Using relatable personal . . .Promoting actionable advi. . . Actionable advice with re. . . Highlighting practical ap. . . Positioning self as conti. . . Constructs credibility th. . .Leveraging personal exper. . . Positioning self as a con. . .Utilizing metaphors to si. . .Highlighting real-world a. . . Validating audience strug. . . Utilizing relatable perso. . .Validating audience exper. . . Positioning Oneself as a . . .Validating audience conce. . .Encouraging incremental p. . .Storytelling to illustrat. . .Using metaphors to simpli. . .0200400 AliAbdaal - Q2 (Top 25)Prevalence •Q3:What conceptual framing does the speaker consistently apply to challenges or ob- stacles discussed? This question invites identification of how the speaker discusses strug- gles—not as isolated events, but through recurring conceptual lenses like “growth,” “pro- cess,” “inevitable learning curves,” or “systemic support.” It asks: “What unifying concep- tual frame does the speaker apply to adversity?” Analysis across transcripts should",
    "or ob- stacles discussed? This question invites identification of how the speaker discusses strug- gles—not as isolated events, but through recurring conceptual lenses like “growth,” “pro- cess,” “inevitable learning curves,” or “systemic support.” It asks: “What unifying concep- tual frame does the speaker apply to adversity?” Analysis across transcripts should surface a category that explains the general interpretive approach to challenges. Reframing failure as a le. . . Intentional Time Allocati. . .Systemic support for sust. . . Cultivating a process-ori. . .Systemic Support for Sust. . . Systemic support for sust. . . Cultivating a Process-Ori. . . Strategic time allocation. . . Intentional time allocati. . .Strategic Time Allocation. . . Iterative learning throug. . .Reframing failure as a le. . .Systemic support for sust. . . Cultivating a mindset of . . .Creating pathways through. . . Learning as a continuous . . .Cultivating a growth mind. . . Systemic support for sust. . .Cultivating a Growth Mind. . . Iterative improvement thr. . .Process-oriented growth m. . . Intrinsic motivation as c. . .Process-Oriented Growth M. . .Systemic Support for Sust. . .Enjoyment as Intrinsic Mo. . .0100200 AliAbdaal - Q3 (Top 25)Prevalence •Q4:In what ways does the speaker integrate or reference external sources (books, studies, tools), and what does this reveal about their epistemic stance? This question examines how external information is woven into the narrative—for example: as inspiration, validation, critique, or synthesis—thereby revealing whether the speaker leans toward evidence-based reasoning, personal interpretation, or community endorsement. By comparing integration patterns across the dataset, an underlying communicative strategy or epistemic stance can be inferred. 20 Reframing success beyond . . . Synthesizing personal exp. . . Utilizing personal experi. . .Using personal experience. . . Synthesizing personal and. . . Reflective questioning of. . . Encouraging self-reflecti. . .Framing content creation . . .Leveraging personal exper. . .Promoting incremental pro. . .Rejection of traditional . . . Utilizing digital tools f. . . Utilizing digital tools f. . .Synthesizing personal exp. . . Rejection of superficial . . .Leveraging personal exper. . . Encouraging intrinsic mot. . . Encouraging iterative pra. . .Emphasizing long-term inv. . . Validation through real-w. . . Recontextualization of su. . .Emphasizing consistency a. . . Contextual adaptation of . . . Promoting intrinsic motiv. . . Integration of productivi. . .0100200300 AliAbdaal - Q4 (Top 25)Prevalence •Q5:What recurring metaphorical or thematic language does the speaker use to communi- cate abstract concepts, and what conceptual schema emerges from those metaphors? This question encourages examination of language for consistent metaphoric or thematic pat- terns—such as “habits as bricks,” “mind as a garden,” or “productivity as flow”—and asks: “What cognitive frames or schemas do these metaphors evoke?” Rather than listing indi- vidual metaphors, the focus is on identifying broader conceptual categories they construct, such as “growth as cultivation” or “momentum as river,” thereby revealing the speaker’s underlying worldview or interpretive framework. Learning as Iterative Pro. . . Intentional Time Allocati. . .Learning as Continuous Pr. . . Digital Tools as Cognitiv. . . Intentional time",
    "is on identifying broader conceptual categories they construct, such as “growth as cultivation” or “momentum as river,” thereby revealing the speaker’s underlying worldview or interpretive framework. Learning as Iterative Pro. . . Intentional Time Allocati. . .Learning as Continuous Pr. . . Digital Tools as Cognitiv. . . Intentional time allocati. . .Intentional Time Allocati. . .Skill Development as Incr. . . Learning Through Iterativ. . .Learning as continuous pr. . . Cognitive Offloading via . . . Digital tools as cognitiv. . .Learning as iterative pro. . .Productivity as Structure. . .Productivity as Sustainab. . .Growth through iterative . . . Cognitive offloading via . . . Productivity as Sustainab. . .Intentional Time Investme. . . Content Creation as Itera. . . Intentional vs. Unintenti. . .Time Allocation as Resour. . .Time Management as Strate. . . Growth Through Iterative . . .Learning as Continuous Jo. . . Enjoyment as Intrinsic Mo. . .0100200 AliAbdaal - Q5 (Top 25)Prevalence A.3.4 MAS FAILURESDATASETQUESTIONS: •Q1:Why does the multi-agent system fail to complete the task? A.3.5 MATH FAILURESDATASETQUESTIONS: •Q1:Why does the proposed solution to this math problem fail, or what mistakes cause the incorrect result? A.4 ETHICALSTATEMENTS We used LLM (GPT, Gemini) to improve the sentence and grammar for writing the abstract, intro- duction, experiments, and conclusion sections of the paper. All text are mannually written and LLM only helps with word choice and grammar. We also used LLMs to generate python codes to produce the figures in this paper. We mannually checked the numbers to ensure they are entered correctly. 21"
  ]
}