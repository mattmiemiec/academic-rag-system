{
  "filename": "2509.12407v1.pdf",
  "total_chunks": 18,
  "text_length": 51391,
  "chunks": [
    "Spectra of random graphs with discrete scale invariance Alessio Catanzaro1,2,3, Rajat Subhra Hazra4, Diego Garlaschelli1,2 1IMT School for Advanced Studies, Lucca, Italy 2Instituut-Lorentz for Theoretical Physics, Leiden University, The Netherlands 3Universit` a di Palermo, Palermo, Italy and 4Mathematical Institute, Leiden University, The Netherlands. Random graphs defined by an occurrence probability that is invariant under node aggregation have been identified recently in the context of network renormalization. The invariance property requires that edges are drawn with a specific probability that, in the annealed case, depends on a necessarily infinite-mean node fitness. The diverging mean determines many properties that are uncommon in models with independent edges, but at the same time widespread in real-world networks. Here we focus on the leading eigenvalues and eigenvectors of the adjacency matrix of the model, where thennodes are assigned a Pareto(α)-distributed fitness with 0< α <1. We find that the leading eigenvalues are all of order√n, alternate in sign and are located at the intersection between the real axis and a logarithmic spiral in the complex plane, which we characterize analytically in terms of the Gamma function. We also calculate the associated eigenvectors, finding that they display complex- valued scaling exponents and log-periodicity, which are signatures of discrete scale invariance. In contrast with the typical finite-rank behaviour of random graphs with finite-mean variables, we find that a growing number of the leading eigenvalues emerges from the bulk, whose edge extends up to order√nand therefore reaches the same scale as that of the structural eigenvalues. Many models have been proposed to reproduce the het- erogeneous structure ubiquitously observed in real-world networks. Among these, a wide class of random graph models assigns a weight (or fitness, or hidden variable) xito each vertexi(i= 1, nwherenis the number of nodes) from a usually fat-tailed distributionρ(x), and connects pairs of verticesiandjwith a probabilityp ij that is a certain positive functionf(x i, xj) [1–4]. Recently, in the context of network renormalization [5], a specific such model that complements the heterogeneity of nodes with an invariance principle under graph coarse- graining has been identified [6–9]. In this so-called (an- nealed) Multi-Scale Model (MSM), one may group nodes into equally sized ‘supernodes’, each inheriting the sum of the fitness of its members, and impose that both the connection probabilityp ij=f(x i, xj) and the fitness dis- tributionρ(x) remain unchanged in their functional form, while their parameters follow exact renormalization rules. In other words, aggregating nodes into supernodes ac- cording to any homogeneous partition – and connecting two supernodes whenever there is a connection between any of their constituent nodes – defines a coarse-grained version of the graph, governed by an occurrence proba- bility that has the same functional form as that of the original graph, up to a rescaling of the parameters [6, 8]. This renormalization scheme does not rely on any underlying geometry or distance notion between nodes. This stands in contrast to geometric renormalization ap- proaches [10, 11], where the nodes to be merged need be spatially proximate, and a preliminary definition of met- ric distance is needed. Rather, when nodes are merged into",
    "scheme does not rely on any underlying geometry or distance notion between nodes. This stands in contrast to geometric renormalization ap- proaches [10, 11], where the nodes to be merged need be spatially proximate, and a preliminary definition of met- ric distance is needed. Rather, when nodes are merged into supernodes of equal cardinality, the invariance re- quirement in the MSM is closer in spirit to the concept of discrete scale invariance [12], whose consequences for the graph properties have not been investigated so farand are one of our main focuses here. In particular, we are interested in the spectral proper- ties [13] of the MSM, which turn out to be quite unique due to he peculiar structure of the fitness. Indeed, the requirement that the node fitness is a positive random (‘annealed’) variable that is stable under addition im- plies that it has anα-stable distribution with infinite mean (0< α <1) [6, 8], where classical random matrix results [13–19] break down. When a symmetric random matrix is decomposed into a low-rank informative part plus noise, strong signals can produce eigenvalue outliers outside the bulk spectrum, as first shown in [20]. In net- works, such outliers reveal structures like communities or hubs [13, 21]. While infinite-mean regimes have been studied for L´ evy matrices [22–24], random graphs add further randomness from adjacency realizations, not cap- tured by those approaches. Our goal is to shed light on the surprising behaviour of the eigenmodes of the adja- cency matrix in this infinite-mean regime, which follows from discrete node aggregation invariance. Preliminaries.The annealed MSM is an inhomoge- neous random graph onnnodes, each nodeibeing as- signed a positive weightx i, sampled independently from anα-stable distributionρ α(x), hence with power-law tails decaying asx−1−αfor 0< α <1 [6]. In this regime ofα, every moment ofρ α(x) diverges. Givenx iandx j, the probability that an edge exists betweeniandjis pij=fn(xi, xj) = 1−exp(−ε nxixj), i, j= 1, n(1) ifi̸=jandp ii= 0 ifi=j, where the parameterε nmay be chosen to scale withnin a desired way. Under an ar- bitrary homogeneous partition whereby thennodes are aggregated into supernodes (each with the same number of participating nodes), the form of bothp ij=fn(xi, xj)arXiv:2509.12407v1 [math.SP] 15 Sep 2025 2 andρ α(x) is unchanged, up to a parameter shift in the latter – reflecting the fact that the fitness of a supernode is the sum of the fitnesses of its constituent nodes [6, 8]. Sinceρ(x) for positiveα-stable variables is not known in closed-form (except forα= 1/2), for analytical tractabil- ity we follow [8] and consider a pure Pareto(α) distribu- tion with the same tail as anα-stable distribution: ρα(x) =α x−1−α0< α <1 (2) forx≥1, andρ α(x) = 0 otherwise. We also consider εn=n−1/αas a scaling that allows the graph to be arbitrarily large while remaining sparse, allowing precise asymptotic calculations for largen[8]. In this regime, the tail of the expected degree distributionP(k) decays as k−2irrespective of the value ofα, the expected link den- sity is of order lnn/n, while the average local clustering coefficient remains finite [6, 8] – which are all widespread properties found",
    "sparse, allowing precise asymptotic calculations for largen[8]. In this regime, the tail of the expected degree distributionP(k) decays as k−2irrespective of the value ofα, the expected link den- sity is of order lnn/n, while the average local clustering coefficient remains finite [6, 8] – which are all widespread properties found in real-world networks. Realized versus expected matrix.We denote the real- ized adjacency matrix of the graph asA, whereA ijis a Bernoulli variable:A ij= 1 with probabilityp ijand 0 otherwise. Note thatAis symmetric andA ii= 0. By construction, the expectation ofA(conditioning on the realized weights) is the matrixP=E[A|{x i}] with entriesP ij=pij=fn(xi, xj) and captures the determin- istic, structural signal imposed by the weights, while the actualAcan be seen as a noisy realization of that signal. Indeed, a central idea in our analysis is to decompose the adjacency matrix into the sum of an expected compo- nent and a fluctuation component, and then use Random Matrix Theory (RMT) intuition to separate the spectrum into bulk and outlier components. Let us write: A=⟨A⟩+ (A− ⟨A⟩) =P+H,(3) whereH=A−Pis the zero-mean noise matrix. By construction,Pis a dense matrix (encoding for the struc- ture of the network) with a highly skewed pattern due to the heavy-tailedx i, whereasHcaptures the randomness of edge realizations. If the matrixPwere of small, fi- nite rank andHwere a ‘typical’ random matrix with a bounded spectral distribution, then standard results show that each eigenvalue ofPabove a certain magni- tude would detach from the continuous spectrum ofH. This phenomenon, rigorously characterized in spiked ran- dom matrix theory, underlies applications like spectral clustering [25–27]. In our case,Pis not finite-rank: as we showin Supplementary Information (SI), we find ev- idence of an ‘effective’ rank of order lnn. In this sense, we are close in spirit to recent results such as Ref. [28], that are hinting at the fact that generalized BBP tran- sitions could be happening even when the rank of the perturbation matrix is growing aso(n). An illustration of the typical spectra ofAandPis provided in Fig. 1. Our main goal is the characterization of these spectra and the associated eigenvectors, with a specific attention to the outlier modes carrying structural information. FIG. 1. The full spectrum ofA, a single realization of the network adjacency matrix fromP, withn= 104andα= 0.5. In the top panel the histogram (blue) ofA. We see separation into atomic delta densities and a central, continuous bulk. In the bottom panel we show the separation of the spectrum into two regimes, the outliers being those ofAin blue, and ofPin orange. We also superimpose in green the eigenvalue histogram ofH, that replicates the bulk behaviour ofA. Leading eigenmodes from the expected matrix.We are interested in the solution of the eigenmode equation [13] Pvk=λkvkk= 1, n(4) with|λ 1| ≥ |λ 2| ≥ ··· ≥ |λ n|. Denoting thei-th entry of each eigenvectorv kasv(i) k, we can rewrite Eq.(4) as nX j=1pijv(j) k=λkv(i) ki= 1, n k= 1, n(5) Note that, sincePis real and symmetric, its eigenvalues are real. Also note that any two verticesi, jwith the same realized weightx i=xjare statistically equivalent, as their (expected)",
    "n|. Denoting thei-th entry of each eigenvectorv kasv(i) k, we can rewrite Eq.(4) as nX j=1pijv(j) k=λkv(i) ki= 1, n k= 1, n(5) Note that, sincePis real and symmetric, its eigenvalues are real. Also note that any two verticesi, jwith the same realized weightx i=xjare statistically equivalent, as their (expected) properties in the graph depend only on the weightx. Similarly, ifx i=xjthen thei-th andj- th entries of each eigenvectorv kwill be equal:v(i) k=v(j) k. This allows us to writev(i) k=νk(xi) whereν k(x) must be a continuous function of the weightx. For large enough n, Eq.(5) can be recast as the integral expression Πα,n[νk(x)] =λk nνk(x).(6) whereν k(x) is an eigenfunction (with eigenvalueλ k/n) of the integral operator Πα,n[g(x)]≡Z+∞ 0dy ρ α(y) (1−e−εnxy)g(y),(7) corresponding to the eigenvectorv k(with eigenvalueλ k) of the original matrixP. A natural normalization for νk(x) will emerge from the calculations that follow. If an eigenfunctionν k(x) is found, a convenient way to go back to the actual eigenvector entryv(j) kis the following. We first order all vertices so thatx 1≤x2≤ ··· ≤x n. Then, since a pure Pareto(α) variable can be represented as a 3 uniform random variable, raised to the power−1/α, in the interval [0,1], we arrive at the relationx j= (n/j)1/α (we will use this relation as an alternative, deterministic assignment of the fitness of nodes to produce a ‘noise-free’ power law distribution even for finiten). Finally, v(j) k=νk(xj) =ν k\u0012n1/α j1/α\u0013 j= 1, n k= 1, n.(8) Largest eigenvalue and principal eigenvector.We start with the principal componentk= 1. From Perron- Frobenius theorem,λ 1is be positive andv 1has all entries of the same sign. We will set the normalization ofv 1in such a way that all its entries are positive, so thatν 1(x) is a positive-valued function. When evaluating the oper- ator 7 on the eigenfunction, the multiplication ofρ α(x) byν 1(x) formally generates a modified, effective distri- bution of the weights. We then look for an eigenfunction such thatν 1(x)ρ α(x) =ρ β(x) is again a Pareto pdf with a new indexβ. This is obtained for the eigenfunction ν1(x) =β αxα−β, β∈R+.(9) Settingg(x) =ν 1(x) into Eq. (7), we get Πα,n[ν1(x)] = 1−φ β(εnx) (10) where we have introduced the Laplace Transform (LT) φαof the Pareto-αdensity, defined as φα(t)≡Z+∞ 0dx ρ α(x)e−tx=αZ+∞ 1dx x−1−αe−tx, (11) and we have exploited the normalization property Z+∞ 0dy ρ α(y)ν 1(y) =Z+∞ 0dy ρ β(y) = 1.(12) The above expression sets our normalization forν 1(x), which is the analogous of theℓ 1normPn i=1|v(i) 1|= 1 for the original eigenvectorv 1. An important asymptotic property ofφ β(t) (see SI) is that, for 0≤β≤1, 1−φ β(t)∼tβΓ(1−β), t→0+.(13) This allows us to confirm thatν 1(x) is asymptotically an eigenfunction, for a suitable choice ofβ. Indeed, applying Eq. (13) into Eq. (10), we can recast Eq. (6) as Πα,n[ν1(x)]∼(ε nx)βΓ(1−β) =λ1 nβ αxα−β(14) (provided we identifyβ≡α−β, i.e.β=α/2) to find λ1=α βΓ (1−β)n εβ n=−αΓ\u0010 −α 2\u0011 n1/2.(15) This square-root growth ofλ 1can be confirmed via actual computations on the matrixPitself (see Fig. 2). Using Eq. (8), we also obtain all the eigenvector entries as",
    "recast Eq. (6) as Πα,n[ν1(x)]∼(ε nx)βΓ(1−β) =λ1 nβ αxα−β(14) (provided we identifyβ≡α−β, i.e.β=α/2) to find λ1=α βΓ (1−β)n εβ n=−αΓ\u0010 −α 2\u0011 n1/2.(15) This square-root growth ofλ 1can be confirmed via actual computations on the matrixPitself (see Fig. 2). Using Eq. (8), we also obtain all the eigenvector entries as v(j) 1=ν1(xj) =1 2xα/2 j=1 2\u0012n j\u00131/2 j= 1, n.(16) This is also confirmed numerically later on.Next eigenvalues.We now turnk >1. Let us prelim- inarily introduce auxiliary complex-valued test functions ν± k(x) of the form still given by Eq. (9), withβ∈C: ν± k(x) =β± k αxα−β± k, β± k≡γk±iω k∈C(17) whereγ k=ℜ[β± k]∈Rand±ω k=ℑ[β± k]∈Rare the real and imaginary parts ofβ± k, respectively. Note that β+ kandβ− kare complex conjugate. Just likeρ β(x)≡ ν1(x)ρ α(x) is a Pareto pdf with modified (real) index β, which has the same tail behaviour of a stable dis- tribution with indexβ,ρβ± k(x)≡ν± k(x)ρ α(x) is for- mally a generalized Pareto distribution with the same ‘tail behaviour’ as the recently defined stable distribu- tions with complex-valued indexβ± k[29, 30]. As we now show, these complex-valued scaling exponents generate log-periodicity, as typically found in systems with dis- crete scale invariance [12]. Indeed, in SI we find fork≥1: νk(x) =1 2\u0002 Γ(1−β− k)ν+ k(x) + Γ(1−β+ k)ν− k(x)\u0003 (18) withγ k=α/2 (for allk) and associated eigenvalues λk= (−1)kα Γ\u0010 −α 2+iω k\u0011 n1/2,(19) where the values ofω kare defined implicitly via argh Γ\u0010 −α 2+iω k\u0011i =ωk αlnn−kπ, k∈N 0.(20) Note thatk= 1 andω 1= 0 is a solution, coinciding with what we have already found in Eqs. (9) and (15) for the principal eigenmode. Graphically,λ 1and all the other eigenvaluesλ k(k >1) correspond to the intersections between the real axis and the two logarithmic spirals σ±(ω)≡ −αΓ(−α/2∓iω)n1/2±iω/α(21) defined parametrically in the complex plane for any real valueω≥0 (see SI). In particular, plottingℑ[σ±(w)] FIG. 2. Largest eigenvalueλ 1ofPversus the numbern of nodes, with weights{x i}n i=1either sampled i.i.d. from a Pareto distribution (in red, averaged over 5 samples) or as- signed deterministically asx i= (n/i)1/α(in blue), compared with the analytic result in Eq. (15) (in black). Hereα= 0.5. 4 versusℜ[σ±(w)] generates two spirals, both starting at λ1>0 forω= 0 and then shrinking clockwise (σ−) and counterclockwise (σ+) forω >0, crossing the real line at the next eigenvaluesλ 2,λ3,. . .which alternate in sign. The admissible valuesω kdefined by Eq. (20) are precisely those realizing the intersections. A comparison between these intersections (forσ+) and the actual eigenvalues computed directly onPfor givennandαis illustrated in Fig. 3 and in SI. Unfortunately, calculating the exact valuesω kdefined by the non-invertible Eq. (20) is not possible fork >1. However, in SI we derive the following approximate expression (valid for 1< k≲lnn): ωk≈αkπ+ϕ α lnn, ϕ α≡arg Γ[−α/2 +iω α] (22) whereω α≡q α 2(1 γ−α 2) (γ≈0.5772 being the Euler- Mascheroni constant). Equation (22) will prove useful to determine how fast|λ k|decays askgrows. Next eigenvectors.We now turn to the eigenvectors fork >1. Pluggingω kinto Eq. (18), we get νk(x) =xα/2 αℜh\u0010α 2−iω k\u0011 Γ\u0010 1−α 2−iω k\u0011 xiωki . (23) Using Eq. (8), we",
    "γ−α 2) (γ≈0.5772 being the Euler- Mascheroni constant). Equation (22) will prove useful to determine how fast|λ k|decays askgrows. Next eigenvectors.We now turn to the eigenvectors fork >1. Pluggingω kinto Eq. (18), we get νk(x) =xα/2 αℜh\u0010α 2−iω k\u0011 Γ\u0010 1−α 2−iω k\u0011 xiωki . (23) Using Eq. (8), we re-express the eigenvector entries as v(j) k=rn jα2ℜ \u0010α 2−iω k\u0011 Γ\u0010 1−α 2−iω k\u0011\u0012n j\u0013iωk α . (24) Sincexiωk=eiωklnxandjiωk/α=ei(ωk/α) lnj, the struc- ture of the above eigenfunctions and eigenvectors is os- cillating, log-periodic in their arguments (xandjrespec- tively), and modulated by a power-law profile (xα/2and FIG. 3. Comparison between the actual real-valued eigenval- ues (red) of the expected adjacency matrixPand the pre- dicted eigenvalues obtained as the intersection between the real axis and the logarithmic spiral orspira mirabilis(blue) defined from Eq. (21). Heren= 104andα= 0.5.j−1/2respectively). In Fig. 4 and in SI we show that our analytically derived log-periodic formula tracks the actual eigenvectors of bothPandAremarkably well for smallk. These eigenvectors do not display traditional delta-like localization, as they are broadly supported on a wide range of weight percentiles with largest amplitude around the hub node (j= 1), followed by power-law de- cayj−1/2(see also SI). Askgrows large enough (below and in SI we provide evidence that this happens fork growing withnbut of order at most lnn), we find a de- parture of the eigenvectors ofAfrom those ofP, due to the entrance of the associated eigenvalues into the ran- dom bulk where eigenvectors are expected to be more uniformly spread and less structured. Bulk of the spectrum.As we have seen in Fig. 1 for the eigenvalues and from Fig. 4 for the eigenvectors (plus more illustrations in SI), there is a value ofkbeyond which the spectral properties ofPare no longer able to describe those ofA. We refer to this as the ‘entrance’ into the random bulk, i.e. the noisy part of the spectrum gen- erated primarily by the fluctuation ofH=A−P. The analysis of this part of the spectrum is highly non-trivial, and eludes the purposes of this Letter. Nevertheless, in SI we show how an analytic characterization of this region is possible using RMT methods. In particular, we show that the classic form of the Dyson self-consistency equa- tion for the resolvent is still in place and the usual cav- ity method yields the same structure of a non-standard method based on Poisson Processes and representation FIG. 4. Plot of eigenvector entriesv(j) kversusj, for the first 9 eigenvectorsk= 1, . . . ,9 (from left to right and top to bottom), forn= 104andα= 0.5. Blue dots correspond to the actual eigenvectors entries ofP, while red solid lines represent the corresponding predicted entries from Eq. (24). Orange dots are the entries of the eigenvectors ofA, and we can see that in the outlier regime they are well predicted byP and hence the ones we obtained analytically. We also notice a breakpoint inkafter which the eigenvalues ofAare no more described by those ofP, which are still predicted by Eq. (24). 5 FIG. 5. Edge of the bulk of the spectrum versus the number nof nodes.",
    "they are well predicted byP and hence the ones we obtained analytically. We also notice a breakpoint inkafter which the eigenvalues ofAare no more described by those ofP, which are still predicted by Eq. (24). 5 FIG. 5. Edge of the bulk of the spectrum versus the number nof nodes. Isolated points are the actual edge eigenvalues (largest eigenvalue ofH, averaged over 10 realizations), for various values ofα. The dashed line is the upper bound√n/2. of stable laws, which is well suited for our special regime of weights. What we are mainly interested in here is the estimation of where the signal ‘meets’ the bulk. In partic- ular, we look for an upper bound for the spectral norm of H, whose elementsH ij=A ij−Pijare independent but not identically distributed random variables in the range [−1,1], the variance ofH ijbeingp ij(1−p ij). The study of such so-called random matrices with a variance pro- file, or structured random matrices, is of great interest in the mathematical ecology community, and has fostered a lively discussion in the mathematical literature [31–38]. In particular, we are interested in the bound derived in [37], that can be extended to matrices with entries hav- ing a different subgaussian distributions, like the centered Bernoulli of our case. In SI we show that for our case the bound for the spectral norm ofHcan be attained as ||H||≲√n 2+1 4√ lnn≃√n 2.(25) In Fig. 5 we show that the square root growth (that is commonplace in Wigner matrices) seems to be the right one, and that the coefficient coming from the maximiza- tion of the row/column sum of the variance profile ma- trix is already a quite good envelope for all values ofα. Nonetheless this crude bound needs refinement, at least to include the dependence onα. This calls for the full characterization of the bulk spectrum, which we leave to future work. What is important for our purposes here is noticing that the edge of the bulk lives on the same scale√nas the leading eigenvalues given by Eq. (19). Since the prefactor of√nfor those outliers decays exponen- tially withω k(and, via Eq. (22), withk/lnn– see SI), we see that the bulk will necessarily ‘eat out’ the leading eigenvalues for some value ofkof order at most lnn. Final Remarks.In this Letter, we provided a char- acterization of the spectral properties of the Multi-Scale Model (MSM) in the infinite-mean regime (0< α <1), which has been recently identified as an annealed random graph model that is exactly invariant under node aggre-gation [6, 8]. This invariance is a key concept in the field of network renormalization [5], but its connection with discrete scale invariance and the associated idea of com- plex scaling exponents [12, 39] had not been investigated so far. We showed that the leading eigenvalues of the expected adjacency matrixPscale as√nand accurately proxy the outlier eigenvalues (whose number is grow- ing and of order at most lnn) of the realized adjacency matrixA. Remarkably, these outliers have an approxi- mately constant spacing on a logarithmic scale of their indexkand can be identified as the",
    "leading eigenvalues of the expected adjacency matrixPscale as√nand accurately proxy the outlier eigenvalues (whose number is grow- ing and of order at most lnn) of the realized adjacency matrixA. Remarkably, these outliers have an approxi- mately constant spacing on a logarithmic scale of their indexkand can be identified as the intersection between the real axis and aspira mirabilisin the complex plane, a self-similar object naturally emerging in presence of complex scaling exponents and stable laws with complex stability index [29, 30]. We also derived a closed-form ex- pression for the outlier eigenvectors, showing they are de- localized but biased toward high-weight nodes. The lead- ing eigenvectors beyond the principal (Perron–Frobenius) one exhibit log-periodic oscillations, a feature naturally produced by discrete scale invariance [12, 39, 40] which is here present in the property that the same random graph model describes exactly (up to a parameter rescaling) any coarse-grained version of the original graph, where sets of nodes of the same cardinality are aggregated into supern- odes [6, 8]. Our results qualitatively confirm the findings of [21, 41], while partially extending them to the regime of infinite-rank perturbations of random matrices as in more recent attempts [28, 42]. In summary, the MSM il- lustrates how infinite-mean heterogeneity generates spec- tral phenomena far from classical paradigms. Open di- rections include testing the universality of the√nscal- ing and log-periodicity across other networks and models. More broadly, our results provide a framework for under- standing spectra in multi-scale and heavy-tailed systems, and lay the ground for future work in these fields. Acknowledgements.This publication is part of the project “Redefining renormalization for complex net- works” with file number OCENW.M.24.039 of the research programme Open Competition Domain Sci- ence Package 24-1, which is (partly) financed by the Dutch Research Council (NWO) under the grant https://doi.org/10.61686/PBSEC42210. This work is also supported by the European Union - NextGenera- tionEU and funded by the Italian Ministry of Univer- sity and Research (MUR) - National Recovery and Re- silience Plan (Piano Nazionale di Ripresa e Resilienza, PNRR), projects “Strengthening the Italian RI for Social Mining and Big Data Analytics” (SoBigData.it, grant IR0000013, DN. 3264, 28/12/2021), “Reconstruction, Resilience and Recovery of Socio-Economic Networks” (RECON-NET, EP FAIR 005 - PE0000013 “FAIR” - PNRR M4C2 Investment 1.3), “A Multiscale integrated approach to the study of the nervous system in health and disease” (MNESYS, PE0000006, DN. 1553, 11/10/2022). 6 [1] G. Caldarelli, A. Capocci, P. De Los Rios, and M. A. Munoz, Scale-free networks from varying vertex intrinsic fitness, Physical review letters89, 258702 (2002). [2] D. Garlaschelli and M. I. Loffredo, Fitness-dependent topological properties of the world trade web, Physical review letters93, 188701 (2004). [3] R. Van Der Hofstad,Random graphs and complex net- works, Vol. 1 (Cambridge university press, 2017). [4] R. Van Der Hofstad,Random graphs and complex net- works, Vol. 2 (Cambridge university press, 2024). [5] A. Gabrielli, D. Garlaschelli, S. P. Patil, and M. ´A. Ser- rano, Network renormalization, Nature Reviews Physics , 1 (2025). [6] E. Garuccio, M. Lalli, and D. Garlaschelli, Multiscale network renormalization: Scale-invariance without geom- etry, Physical Review Research5, 043101 (2023).",
    "complex net- works, Vol. 2 (Cambridge university press, 2024). [5] A. Gabrielli, D. Garlaschelli, S. P. Patil, and M. ´A. Ser- rano, Network renormalization, Nature Reviews Physics , 1 (2025). [6] E. Garuccio, M. Lalli, and D. Garlaschelli, Multiscale network renormalization: Scale-invariance without geom- etry, Physical Review Research5, 043101 (2023). [7] M. Lalli and D. Garlaschelli, Geometry-free renormal- ization of directed networks: scale-invariance and reci- procity, arXiv preprint arXiv:2403.00235 (2024). [8] L. Avena, D. Garlaschelli, R. S. Hazra, and M. Lalli, Inhomogeneous random graphs with infinite-mean fitness variables, arXiv preprint arXiv:2212.08462 (2022). [9] R. Milocco, F. Jansen, and D. Garlaschelli, Multi-scale node embeddings for graph modeling and generation, arXiv preprint arXiv:2412.04354 (2024). [10] G. Garcia-Perez, M. Boguna, and M. A. Serrano, Multi- scale unfolding of real networks by geometric renormal- ization, Nature Physics14, 583 (2018). [11] M. Boguna, I. Bonamassa, M. De Domenico, S. Havlin, D. Krioukov, and M. ´A. Serrano, Network geometry, Na- ture Reviews Physics3, 114 (2021). [12] D. Sornette, Discrete-scale invariance and complex di- mensions, Physics reports297, 239 (1998). [13] P. Van Mieghem,Graph spectra for complex networks (Cambridge university press, 2023). [14] F. Benaych-Georges and A. Knowles, Lectures on the local semicircle law for wigner matrices, arXiv preprint arXiv:1601.04055 (2016). [15] Z. Bai and J. W. Silverstein,Spectral analysis of large dimensional random matrices, Vol. 20 (Springer, 2010). [16] I. J. Farkas, I. Der´ enyi, A.-L. Barab´ asi, and T. Vicsek, Spectra of “real-world” graphs: Beyond the semicircle law, Physical Review E64, 026704 (2001). [17] L. Poley, T. Galla, and J. W. Baron, Eigenvalue spectra of finely structured random matrices, Physical Review E 109, 064301 (2024). [18] J. W. Baron, T. J. Jewell, C. Ryder, and T. Galla, Eigen- values of random matrices with generalized correlations: A path integral approach, Physical Review Letters128, 120601 (2022). [19] F. Chung, L. Lu, and V. Vu, Spectra of random graphs with given expected degrees, Proceedings of the National Academy of Sciences100, 6313 (2003). [20] J. Baik, G. Ben Arous, and S. P´ ech´ e, Phase transition of the largest eigenvalue for nonnull complex sample covari- ance matrices, Annals of Probability (2005). [21] R. R. Nadakuditi and M. E. Newman, Spectra of random graphs with arbitrary expected degrees, Physical Review E—Statistical, Nonlinear, and Soft Matter Physics87, 012803 (2013).[22] P. Cizeau and J.-P. Bouchaud, Theory of l´ evy matrices, Physical Review E50, 1810 (1994). [23] F. Benaych-Georges, A. Guionnet, and C. Male, Central limit theorems for linear statistics of heavy tailed random matrices, Communications in Mathematical Physics329, 641 (2014). [24] G. B. Arous and A. Guionnet, The spectrum of heavy tailed random matrices, Communications in Mathemati- cal Physics278, 715 (2008). [25] X. Zhang, R. R. Nadakuditi, and M. E. Newman, Spec- tra of random graphs with community structure and ar- bitrary degrees, Physical review E89, 042816 (2014). [26] F. Krzakala, C. Moore, E. Mossel, J. Neeman, A. Sly, L. Zdeborov´ a, and P. Zhang, Spectral redemption in clustering sparse networks, Proceedings of the National Academy of Sciences110, 20935 (2013). [27] C. Bordenave, M. Lelarge, and L. Massouli´ e, Non- backtracking spectrum of random graphs: community",
    "042816 (2014). [26] F. Krzakala, C. Moore, E. Mossel, J. Neeman, A. Sly, L. Zdeborov´ a, and P. Zhang, Spectral redemption in clustering sparse networks, Proceedings of the National Academy of Sciences110, 20935 (2013). [27] C. Bordenave, M. Lelarge, and L. Massouli´ e, Non- backtracking spectrum of random graphs: community detection and non-regular ramanujan graphs, in2015 IEEE 56th Annual Symposium on Foundations of Com- puter Science(IEEE, 2015) pp. 1347–1357. [28] I. Afanasiev, L. Berlyand, and M. Kiyashko, Asymptotic behavior of eigenvalues of large rank perturbations of large random matrices, arXiv preprint arXiv:2507.12182 (2025). [29] I. Alexeev, Stable random variables with complex stabil- ity index, i, Theory of Probability & Its Applications67, 335 (2022). [30] I. Alexeev, Stable random variables with complex stabil- ity index, ii, Theory of Probability & Its Applications67, 499 (2023). [31] R. Van Handel, On the spectral norm of gaussian ran- dom matrices, Transactions of the American Mathemat- ical Society369, 8161 (2017). [32] R. Lata la, Some estimates of norms of random matrices, Proceedings of the American Mathematical Society133, 1273 (2005). [33] S. Riemer and C. Sch¨ utt, On the expectation of the norm of random matrices with non-identically distributed en- tries, Electron. J. Probab18, 1 (2013). [34] D. Cheliotis and M. Louvaris, The limit of the operator norm for random matrices with a variance profile, Elec- tronic Journal of Probability30, 1 (2025). [35] F. Benaych-Georges, C. Bordenave, and A. Knowles, Spectral radii of sparse random matrices, inAnnales de l’Institut Henri Poincar´ e-Probabilit´ es et Statistiques, Vol. 56 (2020) pp. 2141–2161. [36] F. Benaych-Georges, C. Bordenave, and A. Knowles, Largest eigenvalues of sparse inhomogeneous erd˝ os–r´ enyi graphs, The Annals of Probability47, 1653 (2019). [37] A. Bandeira and R. van Handel, Sharp nonasymptotic bounds on the norm of random matrices with indepen- dent entries, The Annals of Probability44, 2479 (2016). [38] R. Van Handel, Structured random matrices, Convexity and concentration , 107 (2017). [39] J. McWhirter and E. R. Pike, On the numerical inver- sion of the laplace transform and similar fredholm inte- gral equations of the first kind, Journal of Physics A: Mathematical and General11, 1729 (1978). [40] N. Ostrowsky, D. Sornette, P. Parker, and E. Pike, Ex- ponential sampling method for light scattering polydis- persity analysis, Optica Acta: International Journal of Optics28, 1059 (1981). 7 [41] F. Benaych-Georges and R. R. Nadakuditi, The eigenval- ues and eigenvectors of finite, low rank perturbations of large random matrices, Advances in Mathematics227, 494 (2011). [42] J. Huang, Mesoscopic perturbations of large random ma- trices, Random Matrices: Theory and Applications7, 1850004 (2018). [43] DLMF,NIST Digital Library of Mathematical Functions, https://dlmf.nist.gov/, Release 1.2.4 of 2025-03-15, f. W. J. Olver, A. B. Olde Daalhuis, D. W. Lozier, B. I. Schneider, R. F. Boisvert, C. W. Clark, B. R. Miller, B. V. Saunders, H. S. Cohl, and M. A. McClain, eds. [44] R. LePage, M. Woodroofe, and J. Zinn, Convergence to a stable distribution via order statistics, The Annals of Probability , 624 (1981). 1 SUPPLEMENTARY INFORMATION accompanying the paper “Spectra of random graphs with discrete scale invariance” by A. Catanzaro, R.S. Hazra and",
    "S. Cohl, and M. A. McClain, eds. [44] R. LePage, M. Woodroofe, and J. Zinn, Convergence to a stable distribution via order statistics, The Annals of Probability , 624 (1981). 1 SUPPLEMENTARY INFORMATION accompanying the paper “Spectra of random graphs with discrete scale invariance” by A. Catanzaro, R.S. Hazra and D. Garlaschelli ASYMPTOTICS OF THE LAPLACE TRANSFORM We begin by explicitly computing the action of our integral operator on the functionν 1(x): Πα,n[ν1(x)] = 1−φ β(εnx) = 1−Z+∞ 1dy ρ β(y)e−εnxy = 1−βZ+∞ 1dy y−1−βe−εnxy = 1−βZ+∞ εnxdt\u0012t εnx\u0013−1−βe−t εnx = 1−β (εnx)−βZ+∞ εnxdt t−1−βe−t = 1−β (εnx)−βΓ(−β, ε nx),(S1) where we have made the change of variablesε nxy→tand introduced the incomplete Gamma function Γ(z, s), which has the following definition and asymptotic relation with the (complete) Gamma function Γ(z)≡Γ(z,0) forℜ[z]<0: Γ(z, s)≡Z+∞ sdt tz−1e−t∼Γ(z) +sz z, s→0+.(S2) Since in our caseℜ[z] =−α/2<0, the use of the above relation is justified. Plugging Eq. (S2) into Eq. (S1), we obtain forε nx→0+: Πα,n[ν1(x)]∼1−β (εnx)−β\u0014 Γ(−β)−(εnx)−β β\u0015 =−β(ε nx)βΓ(−β) = (ε nx)βΓ(1−β) (S3) which is the relation used in the main text in the casek= 1. EIGENVALUES FORk >1 We will use the fact that the Gamma function of the complex conjugate of its argument is the complex conjugate of the Gamma function. The discussion in the previous section extends to complex-valued parametersβ± k=γk±iω k, leading to the following generalization of Eq. (S3): Πα,n[ν± k(x)]∼(ε nx)β± kΓ(1−β± k).(S4) Given the candidate eigenfunctionν k(x) =ℜ\u0002 Γ(1−β− k)ν+ k(x)\u0003 , Eq. (S4) leads to the following asymptotics: Πα,n[νk(x)]∼1 2Γ(1−β+ k) Γ(1−β− k)h (εnx)β+ k+ (ε nx)β− ki = Γ(1−β+ k) 2ℜh (εnx)β+ ki .(S5) 2 To enforce the eigenvector equationΠ α,n[νk(x)] =λk nνk(x), the above expression has to equal λk nνk(x) =λk 2nαh Γ(1−β− k)β+ kxα−β+ k+ Γ(1−β+ k)β− kxα−β− ki =λk nαℜh Γ(1−β− k)β+ kxα−β+ ki .(S6) This requires eitherβ+ k≡α−β+ kandβ− k≡α−β− k, which would however retrieve the casek= 1 that we have already considered for the largest eigenvalue (β± k=γk=α/2 andω k= 0, sinceα∈R), orβ+ k≡α−β− kandβ− k≡α−β+ k, which still leads toγ k=α/2 (for allk) but puts no restriction onω k, so thatβ± k=α/2±iω k. The defining restriction onω kis obtained by matching the other terms in Eqs. (S5) and (S6), yielding the two simultaneous conditions λk=−αΓ\u0010 −α 2∓iω k\u0011 n1/2±iω k/α=−αΓ\u0010 −α 2∓iω k\u0011 n1/2e±i(ω k/α) lnn.(S7) Since the right-hand sides of the above expression are complex conjugates of each other, the two simultaneous con- ditions ensure thatλ kis real, as required for the eigenvalues of a symmetric matrix. This means thatω khas to be such that arg [λ k] = 0, πmodulo 2π, i.e. argh Γ\u0010 −α 2+iω k\u0011i =ωk αlnn−kπ, k∈N,−π≤argh Γ\u0010 −α 2+iω k\u0011i <+π,(S8) which coincides with Eq. (20) in the main text. Note that the (necessarily real-valued) eigenvaluesλ k(k≥1) can be found graphically as the intersections between the real axis and the two spirals σ±(ω)≡ −αΓ\u0010 −α 2∓iω\u0011 n1/2e±i(ω/α) lnn(S9) defined parametrically in the complex plane by extending theω kin Eq.(S7) to any real valueω≥0. See Fig. S1 for an illustration of this result, for three",
    "real-valued) eigenvaluesλ k(k≥1) can be found graphically as the intersections between the real axis and the two spirals σ±(ω)≡ −αΓ\u0010 −α 2∓iω\u0011 n1/2e±i(ω/α) lnn(S9) defined parametrically in the complex plane by extending theω kin Eq.(S7) to any real valueω≥0. See Fig. S1 for an illustration of this result, for three representative values of the indexα= 0.2,0.5,0.8. When the solutions forω k that realize Eq. (S8) (or equivalently the intersections) are inserted into Eq.(S7), they produce all the eigenvalues as λk= (−1)kα Γ\u0010 −α 2+iω k\u0011 n1/2,(S10) proving the expression in the main text, which nicely extends the expression forλ 1to valuesk >1. Graphical inspection Unfortunately, Eq. (S8) cannot be solved explicitly forω k, except fork= 0 (for which there is no solution for ω0) andk= 1, for whichω 1= 0 is a solution, leading indeed to the valueλ 1when inserted into Eq.(S10): indeed, Γ\u0000 −α 2\u0001 <0, so that arg Γ\u0000 −α 2\u0001 =−πsolves Eq. (S8) fork= 1 andω 1= 0. The solutions fork >1 can be inspected graphically, either as the aforementioned intersections between the real axis and the complex spiral, or as the intersections between the two curves defined as the l.h.s. and r.h.s. of Eq. (S8). Specifically, the l.h.s. defines the function f(ω)≡arg Γ\u0010 −α 2+iω\u0011 ,(S11) while the r.h.s. defines the family of straight lines gk(ω)≡ωlnn α−kπ, k≥0.(S12) The solutionsω kto Eq. (S8) are the values at the intersections f(ωk) =g k(ωk), k≥0.(S13) In Fig.S2 we plotf(ω) andg k(ω) for a few small values ofk. The plot confirms that there is no intersection point ω0fork= 0, while the intersection fork= 1 is found atω 1= 0, for whichf(ω 1) =g 1(ω1) =−π. What is more useful from the graphical inspection is that the next few intersections for 1< k≤k∗occur at a range of valuesω k close to some valueω αat whichf(ω) has a stationary point and varies very slowly around the corresponding value ϕα≡f(ω α), which is approximately a local ‘plateau’ for the function (the valuek∗is defined such that fork > k∗ 3 FIG. S1. Comparison between the actual real-valued eigenvalues (red) of the expected adjacency matrixP, obtained by solving Eq. (S8) numerically, and the predicted eigenvalues obtained as the intersection between the real axis and the logarithmic spiral σ+(blue) defined in Eq. (S9). Heren= 104andα= 0.2,0.5,0.8 from top to bottom. 4 the valuef(ω k) is away from the plateau). We can therefore approximate the solutionsω kfor the first few values k= 2,3, . . . , k∗as the points at whichg k(ω) intersects the constant linef(ω)≈ϕ α, and replace Eq. (S13) with ϕα≈gk(ωk),1< k≤k∗.(S14) which, using Eq. (S12), is solved by the values ωk≈αkπ+ϕ α lnn, ϕ α≡f(ω α),1< k≤k∗.(S15) To complete our characterization of these approximate solutions, we need to estimate bothk∗andω α. Estimation ofω α We start from the determination ofω α. Since the latter is defined as a stationary point off(ω), we look for its value by calculating the derivativef′(ω) and requiringf′(ωα) = 0, or more precisely: ∂ ∂ωarg Γ\u0010 −α 2+iω\u0011 ω=ω α= 0.(S16) We now rearrange the identityz=|z|eiargz=√z¯z eiargz(valid for every complex",
    "We start from the determination ofω α. Since the latter is defined as a stationary point off(ω), we look for its value by calculating the derivativef′(ω) and requiringf′(ωα) = 0, or more precisely: ∂ ∂ωarg Γ\u0010 −α 2+iω\u0011 ω=ω α= 0.(S16) We now rearrange the identityz=|z|eiargz=√z¯z eiargz(valid for every complex numberz, where ¯zis the complex conjugate ofz) to express argz=−ilnz |z|=i 2ln¯z z.(S17) FIG. S2. Graphical Solution of Eq. (S8). In orange, the functionf(ω) defined in Eq. (S11), while the straight linesg k(ω) defined by Eq. (S12) are in red, withkfrom 0 to 10. The dashed red line corresponds tog 0(ω), which has no intersectionω 0withf(ω). The solid red line at its immediate right isg 1(ω), which intersectsf(ω) at the exact valueω 1= 0 wheref(ω 1) =g 1(ω1) =−π. Further on the right, the next straight linesg k(ω) (withk >1) are illustrated in light red. The solution to Eq. (S8) for these values ofkcan be obtained graphically where the orange and light red lines meet. In this regime,f(ω) can be approximated as the horizontal linef(ω)≈ϕ α≡f(ω α) (blue line), where the valueω αis the stationary point such thatf′(ωα) = 0. The horizontal line is no longer a good approximation forf(ω k) for largerk, but that is already the regime for which the value of Γ\u0000 −α 2+iω k\u0001 (plotted in green) is exponentially suppressed, as one can verify from Eqs. (S32). 5 Ifz= arg Γ\u0000 −α 2+iω\u0001 , we get arg Γ\u0010 −α 2+iω\u0011 =i 2lnΓ\u0000 −α 2−iω\u0001 Γ\u0000 −α 2+iω\u0001=i 2ln Γ\u0010 −α 2−iω\u0011 −i 2ln Γ\u0010 −α 2+iω\u0011 .(S18) In order to be able to differentiate the above expression with respect toω, we need a closed-form expression for ln Γ(z) (also called the ‘log-Gamma function’), which is available as follows: ln Γ(z) =−γz−lnz++∞X m=1hz m−ln\u0010 1 +z m\u0011i ,(S19) where γ≡lim m→+∞\" −lnm+mX l=11 l# = 0.5772. . .(S20) is the Euler-Mascheroni constant. Using Eq. (S19) withz=−α/2±iωinto Eq. (S18), we arrive at arg Γ\u0010 −α 2+iω\u0011 =−γω−arg\u0010 −α 2+iω\u0011 ++∞X m=1hω m−arg\u0010 m−α 2+iω\u0011i .(S21) Now, in order to differentiate with respect toωas prescribed by Eq. (S16), we preliminarily calculate ∂ ∂ωarg\u0010 m−α 2+iω\u0011 =i 2∂ ∂ωln\u0012m−α 2−iω m−α 2+iω\u0013 =m−α 2\u0000 m−α 2\u00012+ω2,(S22) where we have used Eq. (S17) again. Using the above expression into Eq. (S21), we obtain ∂ ∂ωarg Γ\u0010 −α 2+iω\u0011 =−γ+α 2\u0000α 2\u00012+ω2++∞X m=1\" 1 m−m−α 2\u0000 m−α 2\u00012+ω2# .(S23) Now, imposing Eq. (S16) translates into the following: −γ+α 2\u0000α 2\u00012+ω2α++∞X m=1\" 1 m−m−α 2\u0000 m−α 2\u00012+ω2α# = 0,(S24) which, if the sum is truncated to any finite order form, can be solved algebraically forω α. In general, the number of solutions of the above equation (i.e. stationary points of the functionf) may depend onα. How many (and how closely) such solutions are recovered after truncating the sum will depend on the order of truncation. For our purposes here (i.e. identifying the first stationary point as shown in Fig. S2), we simply truncate to zeroth order and neglect the sum altogether, to get the condition −γ+α 2\u0000α 2\u00012+ω2α= 0,(S25) which is solved by the single",
    "truncating the sum will depend on the order of truncation. For our purposes here (i.e. identifying the first stationary point as shown in Fig. S2), we simply truncate to zeroth order and neglect the sum altogether, to get the condition −γ+α 2\u0000α 2\u00012+ω2α= 0,(S25) which is solved by the single (positive) value ωα≡s α 2\u00121 γ−α 2\u0013 .(S26) This finally allows us to compute ϕα≡f(ω α) =f s α 2\u00121 γ−α 2\u0013! ,(S27) which, when inserted into Eq. (S15), produces our approximate solutions forω kto Eq. (S8) with 1< k≤k∗. A comparison between the actual solutionsω kof Eq. (S8) and the approximate solutions given in (S15) is shown in Fig. S3, confirming a very good agreement, especially for smaller values ofα. Note that our only following use of these approximate solutions is the approximate proportionality betweenω kandk, which is used below to prove the exponential decay of the prefactor of the leading eigenvalues withk. This linearity only requires thatf(ω) is sufficiently flat around some valueϕ αbefore Γ\u0000 −α 2+iω\u0001 is exponentially suppressed (see Fig. S2). A more accurate estimate ofϕ αwould improve the estimate ofϕ αused in Eq. (S15) (hence improving the slope of the predicted lines in Fig. S3), but not modify the approximate proportionality betweenω kandk, which is all we need in what follows. 6 FIG. S3. Values ofω kas a function ofk. The isolated points are the actual, numerical solutions of Eq. (S8), forα= 0.2,0.5,0.8 (in blue, orange and green respectively). The solid lines are the approximate linear solutions defined by Eq. (S15) withk >1 (plus the exact solutionω 1= 0) for the same values ofα= 0.2,0.5,0.8 (and same colors). Exponential decay of the prefactor of the leading eigenvalues We now turn to the estimation of the order ofk∗. Let us consider the Stirling approximation [43, (5.11.9)] for the absolute value of the Gamma function: |Γ(a+ib)| ∼√ 2π|b|a−1 2e−π|b| 2,(S28) wherea, b∈R. Choosinga=−α/2 andb=ω k≥0, this implies Γ\u0010 −α 2+iω k\u0011 ∼√ 2π ω−α+1 2 ke−πωk 2,(S29) showing an exponential decay with increasingω k. This exponential decay is visible in Fig. S2. If we further use the expression we derived in Eq. (S15) for the approximate solutionsω kfor 1< k≤k∗, we see that the above behaviour translates into an exponential decay as a function ofk/lnn: Γ\u0010 −α 2+iω k\u0011 ∼√ 2π\u0012 αkπ+ϕ α lnn\u0013−α+1 2 e−απ 2kπ+ϕ α lnn,1< k≤k∗.(S30) Looking at Fig. S2, we see that whenk≳k∗(i.e. when the intersections betweenf(ω) andg k(ω) depart from the approximate plateau of constant heightϕ α), the value of Γ\u0000 −α 2+iω\u0001 is already exponentially suppressed. Therefore Eq. (S30) indicates thatk∗is of order lnn. Obviously, the magnitude of the corresponding eigenvalueλ kofP, which is given by Eq. (S10), is also exponentially (ink/lnn) suppressed: |λk|=α Γ\u0010 −α 2+iω k\u0011 √n(S31) ∼α√ 2πn\u0012 αkπ+ϕ α lnn\u0013−α+1 2 e−απ 2kπ+ϕ α lnn.(S32) This means that, fork=O(lnn), the approximation in Eq. (S15) breaks down, but on the other hand the corresponding values ofλ kbecome exponentially small. This is also where, moving from the expected matrixPto a realized random matrixA, the randomness will create noisy eigenvalues ‘eating",
    "α lnn\u0013−α+1 2 e−απ 2kπ+ϕ α lnn.(S32) This means that, fork=O(lnn), the approximation in Eq. (S15) breaks down, but on the other hand the corresponding values ofλ kbecome exponentially small. This is also where, moving from the expected matrixPto a realized random matrixA, the randomness will create noisy eigenvalues ‘eating up’ the eigenvalues ofP. Indeed, generalized BBP-type results typically assume that the expected matrixPhas a fixed, finite rank in order to guarantee a clean separation between informative (structural) eigenvalues and the random bulk. In our model this assumption fails literally, sincePis not finite-rank. Nevertheless, both our numerics and the above arguments indicate 7 that thek-th largest (in absolute value) eigenvalueλ kofPdecays rapidly withk/lnn, so that the rank of the matrix iseffectivelyof order lnn, and henceo(n). This aligns with recent literature suggesting that a BBP-like transition can persist to ordero(n), hence also beyond strict finite rank [28, 42]. Numerics (see main text) indicate that the edge of the random spectrum contributed byHscales asC(α)√nwithC(α) independent ofn. Consequently, only those signal eigenvalues that are not exponentially suppressed can rise above the bulk, i.e., indices up tok∗∼lnn. In this sense, the signal behaves as if it hadeffective rankΘ(lnn): the spectrum ofAconsists of order lnnoutliers (delta spikes fromP) on top of the bulk determined byH. BULK SPECTRUM CHARACTERIZATION In the MSM, because edge probabilitiesp ijvary across pairs (especially spanning many orders of magnitude due to the weights heterogeneity), the matrixHdoes not fall into standard Wigner or Erd˝ os-R´ enyi classes. Classical results like the Wigner semicircle law or variants for sparse graphs do not directly apply. Nonetheless, one can attempt to derive a self-consistent equation for the Stieltjes transform. Here we show how the cavity method is able to produce a self-consistent equation for the resolvent of the Spectral Density, and how the derived formula can lead to an equation to estimate the Bulk edge. We also show a different approach based on Poisson point processes, that leads to the very same structure of the self-consistency equation. Finally, we compute a crude bound for the bulk edge and show that the scaling is the one we wrote in Eq. (25). Cavity Approach To locate the continuous part (bulk) of the spectrum of the adjacency matrixA n, we study its resolvent G(z) = (A n/√n−zI)−1, and Sn(z) =1 nTrG(z) =1 nnX i=1Gii(z), forz∈C+. By Schur’s complement (cavity approximation), one shows Gii(z) =\u0010 −z−1 nX j̸=iAijG(i) jj(z)\u0011−1 , whereG(i)is the resolvent with theith row and column removed. Defining theconditionalGreen’s function gn(x;z) :=E\u0002 Gii(z)|x i=x\u0003 , and replacing each minorG(i) jj(z) byg n(xj;z), as well asA ijby its meanE[A ij|xi=x, x j=y] = 1−e−n−1/αxy,one obtains the integral equation gn(x;z) = −z−Z∞ 1\u0000 1−e−n−1/αxy\u0001 gn(y;z)ρ α(y)dy!−1 . The above equation implicitly definesg(x;z), from which the average Stieltjes transformg H(z) =R ρα(x)g(x;z), dx can be obtained. Solving (S33) in closed form is challenging, especially becauseρ α(x) has no finite moments. However, it serves as a basis for numerical solutions or asymptotic analysis. In particular, the edges of the bulk spectrum can be estimated by finding values ofz=Efor which the denominator of (S33)",
    "dx can be obtained. Solving (S33) in closed form is challenging, especially becauseρ α(x) has no finite moments. However, it serves as a basis for numerical solutions or asymptotic analysis. In particular, the edges of the bulk spectrum can be estimated by finding values ofz=Efor which the denominator of (S33) approaches zero for somex. Intuitively, the largest bulk eigenvalueλmax bulkwould satisfy E=Z ρα(y)[1−e−ϵnxE]g(y;E)dy forxat the top of the weight distribution support. In practice, due to the diverging weight variance, one might expect λmax bulkto scale withn1/2as well (similar to the outliers).We will not delve deeper into solving (S33) here; instead, we note that a clear separation between bulk and outliers has been observed in numerical simulations (see main text). 8 Poisson Point Process Since the spectrum ofHandAin the bulk behave similarly (conditionally on the weights, one can show the closeness using Hoffman-Wielandt type inequality), we show that through a poisson point process approach, one can derive self-consistent equations for the matrixA. Letx (1)≥x(2)≥ ··· ≥x (n)be the order statistics of the i.i.d. Pareto(α) weights. Define Xn=n−1/α(x(1), x(2), . . . , x (n),0,0, . . .)∈R∞. Classical stable-limit theorems ([44]) implyX nd− →X ∞, whereX ∞= (y 1, y2, . . .) has yk= Γ−1/α k,Γ k=E 1+···+E k, andE i∼Exp(1) i.i.d. Equivalently,{y k}form a Poisson point process on (0,∞) with intensityρ α(y)dy=α y−1−αdy. Associate to each rescaled weightw j=xj/n1/αthe markh n(wj) =g n(xj;z). The finite-npoint process Nn=nX j=1δ(wj, hn(wj)) converges in law to the marked Poisson process N=∞X k=1δ(yk, g(y k;z)), whereg(y;z) = lim n→∞ gn(n1/αy;z) is thelimiting conditional resolvent. We now define the mapping Φx(Nn) :=nX j=1gn(xj;z)\u0000 1−e−n−1/αxjx\u0001 , which converges to Φx(N) =∞X k=1g(yk;z)\u0000 1−e−x y k\u0001 . The mean of Φ x(N) is E\u0002 Φx(N)\u0003 =Z∞ 0g(y;z)\u0000 1−e−xy\u0001 ρα(y)dy. Hence the deterministic limit satisfies g(x;z) =\u0010 −z−Φ x(N)\u0011−1 , or explicitly g(x;z) =−1 z+Z∞ 0g(y;z)\u0000 1−e−xy\u0001 ρα(y)dy(S33) Finally, the bulk Stieltjes transform is obtained by averaging over the fitness distribution: g(z) =Z∞ 0g(x;z)ρ α(x)dx. The bulk spectral densityρ H(λ) follows by the Sokhotski–Plemelj formula ρH(λ) =−1 πlim ε→0+ℑg(λ+iε). Equations (S33) and the above averaging fully characterize the continuous spectrum for 0< α <1. 9 Spectral norm bounds We condition on the latent variables so that the edge probabilities (p ij) are deterministic and{A ij}i<jare inde- pendent. Let vij:=p ij(1−p ij),(S34) σ:= max 1≤i≤n\u0010X j̸=ivij\u00111/2 ,(S35) σ∗:= max i̸=j√vij≤1 2.(S36) Then there exist absolute constantsC, c >0 such that E∥H∥ ≤C\u0010 σ+σ ∗p logn\u0011 .(S37) Moreover, for any 0< ε≤1 2and anyt≥0, P\u0010 ∥H∥ ≥(1 +ε) 2√ 2σ+t\u0011 ≤nexp\u0010 −t2 cεσ2∗\u0011 ,(S38) wherec ε>0 is universal. Proof.WriteH ij=√vijξijwithξ ij=\u0000 Aij−pij\u0001 /√vij. Conditionally on (p ij), theξ ijare independent, centered, and uniformly sub-Gaussian (bounded support), so the sub-Gaussian extension of the main bound applies with scale matrixb ij=√vij. This yields (S37) from theGaussianTheorem 1.1 together with its sub-Gaussian transfer [37](Cor. 3.3): E∥H∥≲σ+σ ∗p logn.(S39) For tails, note that|H ij| ≤1 andEH ij= 0. Now, [37] (Corollary 3.12) gives, forsymmetricbounded entries, a variance-sensitive inequality of the form P(∥H∥ ≥(1 +ε)2σ+t)≤nexp(−t2/˜cεσ2 ∗).(S40) Our entries are not symmetric, but [37](Remark 3.13) shows that",
    "(S37) from theGaussianTheorem 1.1 together with its sub-Gaussian transfer [37](Cor. 3.3): E∥H∥≲σ+σ ∗p logn.(S39) For tails, note that|H ij| ≤1 andEH ij= 0. Now, [37] (Corollary 3.12) gives, forsymmetricbounded entries, a variance-sensitive inequality of the form P(∥H∥ ≥(1 +ε)2σ+t)≤nexp(−t2/˜cεσ2 ∗).(S40) Our entries are not symmetric, but [37](Remark 3.13) shows that symmetrization inflates only the leading constant by a factor√ 2, which yields (S38). Asv ij≤pij, we haveσ2≤d maxwhered max:= max iP j̸=ipijis the maximal expected degree. Hence E∥H∥ ≤C\u0000p dmax+p logn\u0001 ,(S41) and ∥H∥ ≤C′\u0010p dmax+p logn\u0011 w.h.p. (S42) As a crude but universal bound, sincev ij≤1 4,σ≤√n/2, we get ∥H∥≲√n 2+O(p logn),(S43) which can be further approximated as||H||≲√n 2as in the main text. We now establish alower bound.We condition on (p ij), so entries are independent. Let vij=p ij(1−p ij),(S44) σ2= max iX j̸=ivij.(S45) Then, for any 0< δ <1, P\u0010 ∥H∥ ≥√ 1−δ σ\u0011 ≥1−exp\u0000 −c δ2σ2\u0001 ,(S46) 10 for a universal constantc >0. In particular, ifσ2≳logn, then∥H∥≳σwith high probability. Proof sketch.Choosei ⋆attainingσ2=P j̸=i⋆vi⋆j. Since∥H∥ ≥ ∥He i⋆∥2, ∥He i⋆∥2 2=X j̸=i⋆(Ai⋆j−pi⋆j)2,(S47) which is a sum of independent, bounded random variables in [0,1] with meanσ2. Hoeffding’s lower-tail inequality gives P\u0000 ∥He i⋆∥2 2<(1−δ)σ2\u0001 ≤exp(−cδ2σ2).(S48) It is predicted thatσ2≳n. Taking square roots yields the claim. EIGENVECTORS In the main text, we showed that thej-th entry of the eigenvectorv kof the expected adjacency matrixPcan be expressed as v(j) k=rn jα2ℜ \u0010α 2−iω k\u0011 Γ\u0010 1−α 2−iω k\u0011\u0012n j\u0013iωk α =−rn j\u0012α 4+ω2 k α\u0013 ℜ Γ\u0010 −α 2−iω k\u0011\u0012n j\u0013iωk α (S49) and that the leading eigenvectors of the realized adjacency matrixAfollow the same structure very closely for the smallest values ofk, but depart from it for larger values ofk. Here we provide additional numerical support for these results, forα= 0.2 (Fig. S4),α= 0.5 (Fig. S5) andα= 0.8 (Fig. S6). We also note that, when combined with Eq. (S10), the above expression allows to rewrite the eigenvector entries in terms of the corresponding eigenvalueλ kas v(j) k=(−1)k+1λk√j\u0012α 4+ω2 k α\u0013 ℜh jiωk αi =(−1)k+1λk√j\u0012α 4+ω2 k α\u0013 cos\u0012iωk αlnj\u0013 .(S50) In particular, the first entryv(1) kof each eigenvectorv k(which is the entry that localizes around the hub nodej= 1) is v(1) k= (−1)k+1λk\u0012α 4+ω2 k α\u0013 ,(S51) so that, forj= 2, n, v(j) k=v(1) kcos\u0000iωk αlnj\u0001 √j.(S52) The above expressions illustrate how each (leading) eigenvectorv khas a structure where the first entryv(1) k(located at the hub nodej= 1) has an amplitude governed by the corresponding eigenvalueλ k, and the next entriesj >1 follow a power-law decay∼j−1/2with log-periodic oscillations. 11 FIG. S4. Plot of eigenvector entriesv(j) kversusj, for the first 10 eigenvectorsk= 1, . . . ,10 (from left to right and top to bottom) and for all entriesj= 1, . . . , n. Blue dots correspond to the actual eigenvectors entries ofPobtained by solving Eq. (S8) explicitly, while red solid lines represent the corresponding predicted entries obtained from Eq. (S49). Orange dots are the entries of the eigenvectors ofA, and we can see that in the regime outside the bulk they are in quite a good accordance with those ofPand hence",
    "ofPobtained by solving Eq. (S8) explicitly, while red solid lines represent the corresponding predicted entries obtained from Eq. (S49). Orange dots are the entries of the eigenvectors ofA, and we can see that in the regime outside the bulk they are in quite a good accordance with those ofPand hence the ones we obtained analytically. Hereα= 0.2 andn= 104. 12 FIG. S5. Plot of eigenvector entriesv(j) kversusj, for the first 10 eigenvectorsk= 1, . . . ,10 (from left to right and top to bottom) and for all entriesj= 1, . . . , n. Blue dots correspond to the actual eigenvectors entries ofPobtained by solving Eq. (S8) explicitly, while red solid lines represent the corresponding predicted entries obtained from Eq. (S49). Orange dots are the entries of the eigenvectors ofA, and we can see that in the regime outside the bulk they are in quite a good accordance with those ofPand hence the ones we obtained analytically. Hereα= 0.5 andn= 104. 13 FIG. S6. Plot of eigenvector entriesv(j) kversusj, for the first 10 eigenvectorsk= 1, . . . ,10 (from left to right and top to bottom) and for all entriesj= 1, . . . , n. Blue dots correspond to the actual eigenvectors entries ofPobtained by solving Eq. (S8) explicitly, while red solid lines represent the corresponding predicted entries obtained from Eq. (S49). Orange dots are the entries of the eigenvectors ofA, and we can see that in the regime outside the bulk they are in quite a good accordance with those ofPand hence the ones we obtained analytically. Hereα= 0.8 andn= 104."
  ]
}