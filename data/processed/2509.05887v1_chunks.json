{
  "filename": "2509.05887v1.pdf",
  "total_chunks": 9,
  "text_length": 28005,
  "chunks": [
    "Near Real-Time Dust Aerosol Detection with 3D Convolutional Neural Networks on MODIS Data Caleb Gates1⋆, Patrick Moorhead1⋆, Jayden Ferguson1, Omar Darwish1⋆, Conner Stallman1⋆, Pablo Rivas1, and Paapa Quansah2 1Department of Computer Science, Baylor University, Waco, TX 76798, USA 2Dept. of Electrical & Computer Eng., Baylor University, Waco, TX 76798, USA {caleb_gates1, patrick_moorhead1, jayden_ferguson1, omar_darwish1, conner_stallman1, pablo_rivas, paapa_quansah1}@baylor.edu Abstract. Duststormsharmhealthandreducevisibility;quickdetection from satellites is needed. We present a near real-time system that flags dust at the pixel level using multi-band images from NASA’s Terra and Aqua (MODIS). A 3D convolutional network learns patterns across all 36 bands, plus split thermal bands, to separate dust from clouds and surface features. Simple normalization and local filling handle missing data. An improved version raises training speed by 21×and supports fast processing of full scenes. On 17 independent MODIS scenes, the model reaches about 0.92 accuracy with a mean squared error of 0.014. Maps show strong agreement in plume cores, with most misses along edges. These results show that joint band-and-space learning can provide timely dust alerts at global scale; using wider input windows or attention-based models may further sharpen edges. Keywords:dust storm detection·multispectral satellite imagery·3D convolutional neural networks 1 Introduction Dust storms inject fine particulate matter into the atmosphere that can alter climate patterns, reduce visibility for transportation, and exacerbate respiratory and cardiovascular illnesses [ 3,13]. Rapid and accurate identification of these events is essential for public safety, air quality management, and early warning systems [21,2,19]. TheModerateResolutionImagingSpectroradiometer(MODIS)aboardNASA’s Terra and Aqua satellites provides multispectral imagery well suited for aerosol monitoring [ 1,20]. However, real-time detection remains difficult: dust plumes often exhibit low contrast against the background, and analysis must handle high-dimensional spectral data and interference from clouds [ 7,20]. Conventional methods such as Support Vector Regression and Probabilistic Neural Networks rely on manually engineered features, incur latency from delayed aerosol products, and offer limited spectral interpretation [11,20,9,10]. ⋆Alphabetical. These authors contributed equally to this work.arXiv:2509.05887v1 [cs.CV] 7 Sep 2025 2 C. Gates et al. To address these challenges, we propose a deep learning pipeline based on three-dimensional convolutional neural networks (3DCNNs) that process all 36 MODIS bands plus high/low splits for bands 13 and 14 [ 6,4]. We further introduce 3DCNN+, an optimized extension that employs memory-mapped I/O, precomputed index sampling, large-batch training, PyTorch’s torch.compile, and mixed-precision arithmetic [ 17,8]. On NVIDIA A100 GPUs, 3DCNN+ achieves a 21×reduction in training time while maintaining high pixel-level detection accuracy [ 18,14]. This enables near real-time processing of full MODIS granules, making the system suitable for operational dust alert systems [5,11]. This paper is organized as follows. Section 2 reviews related work on satellite- based dust detection. Section 3 describes our 3D CNN architecture and optimiza- tion strategies. Section 4 details the experimental design and evaluation metrics. Section 5 presents results and analysis. Section 6 formalizes the memory-mapped dataset construction. Section 7 provides theoretical bounds on model capacity via VC dimensions and growth functions. Finally, Section 8 concludes and outlines directions for future research. Code is available here:https://github.com/Rivas-AI/dust-3dcnn.git. 2 Related Work Detection of dust storms using satellite imagery has evolved from",
    "and analysis. Section 6 formalizes the memory-mapped dataset construction. Section 7 provides theoretical bounds on model capacity via VC dimensions and growth functions. Finally, Section 8 concludes and outlines directions for future research. Code is available here:https://github.com/Rivas-AI/dust-3dcnn.git. 2 Related Work Detection of dust storms using satellite imagery has evolved from fixed spectral ratio thresholds to advanced learning methods. Early work applied band ratio thresholds and statistical models such as Probabilistic Neural Networks (PNN) and Support Vector Regression (SVR) on MODIS thermal bands B20, B29, B31, and B32, setting initial benchmarks for automated dust detection [ 9,10]. These approaches demonstrated the utility of spectral variability but were limited by manual feature design, low spatial resolution, and slow processing speeds, which hindered scalability for continuous monitoring. More recent studies have adopted data-driven classifiers to overcome these limits. Souri and Vajedian combined random forest classifiers with physical- based indices to distinguish dust plumes from other atmospheric phenomena, achieving higher sensitivity and lower false alarm rates [ 15]. In a parallel compar- ison, Shahrisvand and Akhoondzadeh showed that intelligent methods notably outperform empirical threshold techniques under varying surface and cloud condi- tions [12]. Although these methods reduce overfitting through ensemble learning, they still depend on handcrafted spectral indices and can face computational challenges when handling MODIS’s high-dimensional data. The rise of deep learning has further enhanced remote sensing analysis. Sun et al. reviewed the integration of artificial intelligence in Earth science, highlighting both the promise of automated feature learning and challenges in interpretability and computational demand [ 16]. While convolutional neural networks have excelled in related tasks, their use for joint spectral–spatial dust detection remains scarce. To address this, our work implements a 3D CNN that processes all 36 MODIS bands simultaneously and investigates transformer models to capture long-range spatial relationships in multispectral data. Dust Aerosol Detection with 3D CNNs 3 Robust preprocessing is essential for accurate detection. Atmospheric correc- tion, cloud masking, and imputation of missing values are critical steps empha- sized by both Souri and Vajedian [ 15] and Shahrisvand and Akhoondzadeh [ 12]. Our pipeline normalizes radiance values, formats labels, and fills gaps via local scanning, ensuring consistent input quality across varied conditions. Model evaluation typically relies on metrics such as overall accuracy, pre- cision, recall, and F1 score applied to held-out MODIS granules. Traditional random forest models offer fast inference but require manual feature engineering, whereas deep networks learn features automatically at the cost of higher training complexity. Our 3D CNN delivers high detection accuracy with low inference latency, meeting the operational demands of early warning systems. Overall, the trajectory from threshold-based rules through classical machine learning to deep learning frameworks reflects growing capability in dust storm detection. By uniting spectral and spatial information in a single 3D CNN and exploring transformer architectures, our approach pushes beyond prior methods toward reliable, near real-time monitoring of dust events using MODIS data. 3 Approach Our detection pipeline uses MODIS Terra and Aqua granules, each containing 36 spectral bands plus separate high- and low-radiance splits for bands 13 and 14, yielding 38 input channels. We",
    "architectures, our approach pushes beyond prior methods toward reliable, near real-time monitoring of dust events using MODIS data. 3 Approach Our detection pipeline uses MODIS Terra and Aqua granules, each containing 36 spectral bands plus separate high- and low-radiance splits for bands 13 and 14, yielding 38 input channels. We apply min–max normalization to scale each band to [0,1], ensuring consistent inputs across varied radiance ranges. About 25% of granules contained missing values. We address these with local imputation: for each NaN, we scan up to five pixels above and below in the same column, gather valid neighbors, and sample uniformly between their minimum and maximum. This preserves spatial context and retains valuable samples. Each granule is stored as a 2030×1354×38 3D array. We extract 5×5×38 patches around labeled pixels and pair them with binary dust labels. Patches are saved with memory-mapped I/O for efficient repeated access. By processing spatial and spectral data together, the model learns to distinguish dust plumes from other features. Our baseline is a 3D convolutional neural network with three convolutional blocks. Each block applies a 3×3×3 convolution, ReLU activation, and batch normalization. We include max pooling after the first two blocks and adaptive average pooling before the final layer. A sigmoid activation produces dust proba- bility outputs. We train with a weighted mean squared error loss to emphasize regions of high dust intensity. To scale training, we introduce 3DCNN+, optimized for NVIDIA A100 GPUs. We increase batch size to 32,768 using indexed patch sampling to cut data- loading overhead. We enable PyTorch’s torch.compile to fuse operations and use Automatic Mixed Precision to reduce memory use and speed up backpropagation. These enhancements shorten training time while preserving detection accuracy. 4 C. Gates et al. 4 Experiments We evaluate our approach on 117 MODIS Terra and Aqua granules, each a 2030 ×1354×38 array of radiance channels (36 spectral bands plus high/low splits for bands 13 and 14). Radiance values are scaled via min–max normalization to [0,1]. Ground truth labels are extracted from auxiliary classification files and likewise normalized. We extract overlapping patches of size 5 ×5×38 centered on each labeled pixel; these form our training and test samples. Data are accessed via memory-mapped arrays to avoid loading full granules into RAM. Our models are assessed using four metrics. Let Nbe the number of patches, yithe true label andˆy ithe predicted probability: MSE =1 NNX i=1(yi−ˆyi)2,WMSE =1PN i=1wiNX i=1wi(yi−ˆyi)2, R2= 1−PN i=1(yi−ˆyi)2 PN i=1(yi−¯y)2,Accuracy =1 NNX i=11\u0000 ˆyi≥0.5 =y i\u0001 . Here wiscales with true dust intensity so that high-dust regions incur greater penalty, and¯ydenotes the mean label. We partition the granules into 100 for training and 17 for testing, reserving five test granules as a fixed validation set. The baseline 3DCNN comprises three 3×3×3 convolutional blocks (32, 64 and 128 filters), each followed by ReLU and batch normalization. Max pooling (2 ×2×2) follows the first two blocks; adaptive average pooling precedes a fully connected layer and sigmoid output. We optimize with Adam (initial learning rate10−4, weight decay10−6), applying a ReduceLROnPlateau scheduler with patience two sub-epochs. Training proceeds for three",
    "128 filters), each followed by ReLU and batch normalization. Max pooling (2 ×2×2) follows the first two blocks; adaptive average pooling precedes a fully connected layer and sigmoid output. We optimize with Adam (initial learning rate10−4, weight decay10−6), applying a ReduceLROnPlateau scheduler with patience two sub-epochs. Training proceeds for three full passes over the data, where each pass shuffles training patches into five partitions; within each partition, three sub-epochs iterate to ensure convergence. The 3DCNN+ variant incorporates system-level optimizations for NVIDIA A100 GPUs. Patches remain memory-mapped, while valid patch indices are precomputed to eliminate mask searches. Using PyTorch’s torch.compile, we fuse operations at graph-compile time. Automatic Mixed Precision (AMP) executes convolutions in FP16, preserving FP32 where needed. These enhancements permit a batch size of 32,768, maximizing utilization of 40 GB VRAM. Across identical data splits, 3DCNN+ achieves a 21×reduction in training time relative to the baseline, without degradation in MSE,R2or classification accuracy. 5 Results and Analysis Table 1 summarizes the quantitative performance of the baseline 3DCNN and the optimized 3DCNN+ models on our test set. The baseline network yields an MSE of 0.0200, an R2score of –0.229, and an accuracy of 0.911, with a weighted MSE of 0.001417. After system and architectural optimizations, 3DCNN+ reduces the Dust Aerosol Detection with 3D CNNs 5 MSE to 0.0140, improves the R2score to –0.1282, and achieves approximately 0.92 accuracy with an MAE of 0.1098. These improvements reflect both enhanced predictive fidelity and accelerated training. Table 1: Performance comparison of baseline and optimized models. Model MSE MAER2Score Accuracy Weighted MSE 3DCNN 0.0200 – –0.2290 0.911 0.001417 3DCNN+ 0.0140 0.1098 –0.1282∼0.920 – The negative values of R2, indicate that the residual variance exceeds the total variance, despite high classification accuracy. In other words, the network effectively distinguishes dust from clear-sky pixels but lacks precision in regressing continuous dust intensity. This outcome is further supported by the mean absolute error observed in the optimized model. The convergence behavior of the baseline 3DCNN was unexpected. While the training loss decreased steadily, the validation loss exhibited oscillations and plateaus, signifying overfitting to spectral patterns in the training granules. The divergence between training and validation losses underscores the model’s reliance on memorized features rather than generalizable spectral-spatial representations. Nonetheless, both architectures demonstrate strong spatial sensitivity through their use of 5×5×38 patches. By enforcing a weighted MSE loss, LWMSE =1P iwiX iwi(yi−ˆyi)2, w i= 1 +α y i, high-intensity dust regions incur greater training penalty, leading to sharper plume core detection and reduced false positives in background areas. Visual inspection of predicted maps confirms alignment with ground truth in the central plume regions, though boundary edges remain challenging due to limited receptive field. InFig.1and2,wedemonstratethespatialgeneralityofour3DCNN+detector across contrasting dust events. Fig. 1 captures a massive dust outbreak on 27 March 2025 over central China, where a prominent mountain peak remains clear of aerosol contamination in the true-color view; the detection result faithfully isolates the surrounding dust plume while preserving the sharp topographic boundary. This confirms that the network has learned to exploit both spectral and spatial cues to distinguish terrain from airborne particles. In",
    "where a prominent mountain peak remains clear of aerosol contamination in the true-color view; the detection result faithfully isolates the surrounding dust plume while preserving the sharp topographic boundary. This confirms that the network has learned to exploit both spectral and spatial cues to distinguish terrain from airborne particles. In Fig. 2, two adjacent dust storms—one advancing inland across the Sahara and another sweeping over the adjacent Atlantic—are simultaneously identified. Despite the subtle radiometric differences between land-borne and ocean-borne aerosols, the model localizes both plumes accurately, illustrating its robustness to surface variability and its ability to generalize across distinct environmental contexts. Fig. 3 and 4 focus on two springtime dust events in Chihuahua-Texas in 2025, where the haze is nearly imperceptible to the naked eye. On 18 April 2025 (Fig. 3), 6 C. Gates et al. Fig.1: True-color image (top) and detection result (bottom) from MODIS/Terra acquired on 27 March 2025 at 04:20 UTC. China. a diffuse dust veil spans hundreds of kilometers; the detection map highlights faint streaks aligned with prevailing wind corridors, confirming sensitivity to low-contrast aerosol signatures. Similarly, the 14 March 2025 scene (Fig. 4) reveals early-season dust transport from arid soils. Here, the model delineates the plume boundaries with greater clarity than the true-color image, demonstrating that its learned spatial–spectral feature representations can reveal aerosol structures that would otherwise go unnoticed. Collectively, these examples underscore the system’s capacity for reliable, pixel-level dust detection in both overt and subtle atmospheric conditions. The 3DCNN+ variant achieves a 21×reduction in training time by combin- ing memory-mapped I/O ( np.load(...,mmap_mode=’r’) ), precomputed patch indices, PyTorch’s torch.compile , and Automatic Mixed Precision on NVIDIA A100 GPUs. This configuration supports batch sizes of 32 768 and enables near real-time inference, a critical requirement for operational environmental monitoring. Error analysis reveals that false negatives predominantly occur along the periphery of dust plumes, where spectral gradients are less pronounced. This sug- gests that expanding the receptive field via dilated convolutions or incorporating attention modules could improve boundary sensitivity. Furthermore, integrating auxiliary physical inputs, such as wind vector fields, may provide contextual information to guide the model’s predictions. Finally, increasing the diversity of training granules is expected to enhance variance explanation and elevate R2 performance in future work. Dust Aerosol Detection with 3D CNNs 7 Fig.2: True-color image (top) and detection result (bottom) from MODIS/Terra acquired on 24 August 2024 at 10:30 UTC. North West Africa. 8 C. Gates et al. Fig.3: True-color image (top) and detection result (bottom) from MODIS/Terra acquired on 18 April 2025 at 17:15 UTC. Chihuahua. 6 MMAP Justification This section formalizes the construction of the patch-center index and demon- strates the memory savings achieved by using memory-mapped I/O. Dust Aerosol Detection with 3D CNNs 9 Fig.4: True-color image (top) and detection result (bottom) from MODIS/Terra acquired on 14 March 2025 at 17:05 UTC. Texas. 6.1 Index Construction LetF={0, . . . , F− 1}index the input folders. For each f∈ F, load the label map Lf∈RHf×W f 10 C. Gates et al. from a data file. Given a patch sizeP, define h=\u0004P",
    "(bottom) from MODIS/Terra acquired on 14 March 2025 at 17:05 UTC. Texas. 6.1 Index Construction LetF={0, . . . , F− 1}index the input folders. For each f∈ F, load the label map Lf∈RHf×W f 10 C. Gates et al. from a data file. Given a patch sizeP, define h=\u0004P 2\u0005 . We then identify the set of valid label coordinates Vf={(y, x)|0≤y < H f,0≤x < W f, Lf[y, x]̸= NaN}, and the set of boundary-safe coordinates Bf={(y, x)|h≤y < H f−h, h≤x < W f−h}. The valid patch centers for folderfare Cf=Vf∩Bf, and the full index array is I=[ f∈F{(f, y, x)|(y, x)∈C f}. These operations correspond exactly to the calls to np.argwhere , boolean mask- ing, andnp.stack/np.concatenatein our dataset loader implementation. 6.2 Properties of the Index Array Theorem 1.LetIbe constructed as above. For any(f, y, x)∈ I: 1.L f[y, x]is finite (not NaN). 2.h≤y < H f−handh≤x < W f−h, ensuring extraction of a full P×P patch without out-of-bounds access. 3.Icontains every and only the triplets satisfying (1) and (2). Eachpropertyfollowsdirectlyfromthedefinitionsof Vf,Bf,andtheirintersection in the construction algorithm. 6.3 Memory Efficiency viammap We compare peak RAM requirements with and without memory mapping. Let Nbe the number of .npyfiles of sizes Si, soStotal=PN i=1Si. Let Ravailbe available RAM and Roverheadthe footprint of code, libraries, and I. A training batch of sizeBrequiresR batch =B×P sizebytes. Without memory mapping, all files must reside in RAM, giving Rpeak,no_mmap ≈S total+R overhead , which demands Stotal+R overhead ≤R avail. Dust Aerosol Detection with 3D CNNs 11 Withmmap, the operating system pages in only the accessed blocks, so Rpeak,mmap ≈R batch +R overhead , requiring Rbatch +R overhead ≤R avail. Since typically Stotal≫R availwhile Rbatch≪S total, memory-mapped I/O decouples the process’s memory footprint from the full dataset size and makes large-scale training feasible. 7 VC Dimensions and Growth Functions This section analyzes the capacity of our AR-MAE-ViT model by deriving bounds on its Vapnik–Chervonenkis (VC) dimension and relating these to sample complexity via the growth function. The VC dimension of a standard Vision Transformer with Llayers and embedding size dscales on the order of O(L d2). By introducing a masked autoencoder stage and imposing an autoregressive constraint, we effectively restrict the hypothesis space. Denote by HAR-MAE-ViT the class of functions implemented by our model. We show that VC\u0000 HAR-MAE-ViT\u0001 ≤(1−α) VC\u0000 HMAE-ViT\u0001 ,(1) where α∈(0,1)quantifies the reduction in degrees of freedom resulting from the autoregressive links between masked tokens. Standard uniform convergence theorems then imply that, for a binary classification task on nindependent samples and desired accuracyεwith confidence1−δ, n=O\u0010VC(H AR-MAE-ViT ) ε2log1 δ\u0011 . Moreover, with probability at least1 −δ, any hypothesis g∈ H AR-MAE-ViT satisfies Eout(g)≤E in(g) +s VC(H AR-MAE-ViT ) ln\u00002n VC(H AR-MAE-ViT )\u0001 + ln\u00004 δ\u0001 n, which, upon substituting the bound from Eq. (1), yields a tighter guarantee than that available for unconstrained transformers: Eout(g)≤E in(g) +s (1−α) VC(H MAE-ViT ) ln\u00002n (1−α) VC(H MAE-ViT )\u0001 + ln\u00004 δ\u0001 n. To refine these bounds for finite sample sizes, we invoke Sauer’s lemma on the growth functionΠ H(m). Ifd= VC(H AR-MAE-ViT ), then ΠHAR-MAE-ViT",
    "(1), yields a tighter guarantee than that available for unconstrained transformers: Eout(g)≤E in(g) +s (1−α) VC(H MAE-ViT ) ln\u00002n (1−α) VC(H MAE-ViT )\u0001 + ln\u00004 δ\u0001 n. To refine these bounds for finite sample sizes, we invoke Sauer’s lemma on the growth functionΠ H(m). Ifd= VC(H AR-MAE-ViT ), then ΠHAR-MAE-ViT (m)≤dX i=0\u0012m i\u0013 ≤\u0010 e m d\u0011d . 12 C. Gates et al. This implies that to ensure a generalization error at most εwith confidence1 −δ, the number of training samplesmmust satisfy m≥1 εh dln1 ε+ ln1 δi . Replacingdby the reduced dimension in Eq. (1) gives m≥1 εh (1−α) VC(H MAE-ViT ) ln1 ε+ ln1 δi . For our MODIS dust classification task, taking VC(HMAE-ViT )≈1024and α≈0.3indicates roughly a 30% reduction in required labeled samples, confirming the theoretical advantage when training data are scarce. 8 Conclusion This work has introduced a scalable deep learning pipeline for detecting dust storms from MODIS Terra and Aqua imagery at the pixel level. By employing a three-dimensional convolutional neural network, the baseline model achieved 91.1% classification accuracy, confirming that spatial and spectral features can be effectively combined to identify aerosol plumes. Building on this foundation, the optimized variant, 3DCNN+, integrates memory-mapped I/O, precomputed index sampling, large-scale batching, model graph compilation, and mixed-precision arithmetic. These system-level enhancements yield a 21×reduction in training time while maintaining accuracy, supporting near real-time inference critical for operational monitoring. Through systematic evaluation, we identified sources of error stemming from label imbalance, spatial overfitting, and limited temporal context. These insights underline the need for architectures that capture broader dependencies. Future work will explore transformer-based designs, such as Vision Transformers and Swin models, which replace fixed-kernel convolutions with global self-attention to model long-range interactions. In particular, our proposed Autoregressive Masked Autoencoder Swin Transformer (AR-MAE-Swin) applies self-supervised pretraining to constrain model capacity, reducing effective VC dimension by a factor1 −α, as shown in Section 7. This regularization improves sample efficiency by approximately 30%, making it well suited to applications where labeled data are scarce. Finally, by combining rigorous theoretical analysis with practical system optimizations, this study lays the groundwork for self-supervised, attention- driven frameworks that can generalize across diverse atmospheric conditions. The methods and results presented here offer a clear path toward robust, efficient, and adaptable models for environmental remote sensing, enabling timely detection and analysis of dust storm events. Acknowledgments.Part of this work was funded by the National Science Foundation under grant CNS-2136961. The authors thank the Rivas.AI Lab ( https://lab.rivas. ai) for the support and helpful feedback throughout this project. Dust Aerosol Detection with 3D CNNs 13 Disclosure of Interests.The authors have no competing interests to declare that are relevant to the content of this article. References 1.Asutosh,A.,Vinoj,V.,Murukesh,N.,Ramisetty,R.,Mittal,N.:Investigationofjune 2020 giant saharan dust storm using remote sensing observations and model reanaly- sis. Scientific Reports12(2022). https://doi.org/10.1038/s41598-022-10017-1 2.Bao, T., Xi, G., Hao, Y., Chang, I., Wu, J., Xue, Z., Jin, E., Zhang, W., Bao, Y.: The transport path and vertical structure of dust storms in east asia and the impacts on cities in northern china. Remote Sensing15, 3183 (2023). https: //doi.org/10.3390/rs15123183 3.Indoitu, R., Kozhoridze, G.,",
    "Reports12(2022). https://doi.org/10.1038/s41598-022-10017-1 2.Bao, T., Xi, G., Hao, Y., Chang, I., Wu, J., Xue, Z., Jin, E., Zhang, W., Bao, Y.: The transport path and vertical structure of dust storms in east asia and the impacts on cities in northern china. Remote Sensing15, 3183 (2023). https: //doi.org/10.3390/rs15123183 3.Indoitu, R., Kozhoridze, G., Batyrbaeva, M., Vitkovskaya, I., Orlovsky, N., Blum- berg, D., Orlovsky, L.: Dust emission and environmental changes in the dried bottom of the aral sea. Aeolian Research17, 101–115 (2015). https://doi.org/ 10.1016/j.aeolia.2015.02.004 4.Jain, M., Saxena, P., Sonwani, S.: Characteristics, dynamics, and impact of the thar desert dust storms on air quality over northern india (2024). https://doi. org/10.21203/rs.3.rs-3879277/v1 5.Jingning,L.,Huang,F.,Gao,S.,Liu,S.,Liu,R.,Devasthale,A.:Satellitemonitoring of the dust storm over northern china on 15 march 2021. Atmosphere13, 157 (2022).https://doi.org/10.3390/atmos13020157 6.Kleidman, R., Smirnov, A., Levy, R., Mattoo, S., Tanré, D.: Evaluation and wind speed dependence of modis aerosol retrievals over open ocean. Ieee Transactions on Geoscience and Remote Sensing50, 429–435 (2012). https://doi.org/10.1109/ tgrs.2011.2162073 7.Lei, H., Wang, J.: Observed characteristics of dust storm events over the western united states using meteorological, satellite, and air quality measurements. Atmo- spheric Chemistry and Physics14, 7847–7857 (2014). https://doi.org/10.5194/ acp-14-7847-2014 8.Li, L., Sokolik, I.: Analysis of dust aerosol retrievals using satellite data in central asia. Atmosphere9, 288 (2018).https://doi.org/10.3390/atmos9080288 9.Rivas-Perea, P., Rosiles, J.G., Chacón-Murguía, M.I., Tilton, J.J.: Automatic dust storm detection based on supervised classification of multispectral data. In: Soft Computing for Recognition Based on Biometrics (SCIRB). Lecture Notes in Computer Science, vol. 312, pp. 443–454 (2010) 10.Rivas-Perea, P., Rosiles, J.G., Cota-Ruiz, J.: Statistical and neural pattern recogni- tion methods for dust aerosol detection. International Journal of Remote Sensing 34(21), 7648–7670 (2013).https://doi.org/10.1080/01431161.2013.822660 11.Shahrisvand, M., Akhoondzadeh, M.: A comparison of empirical and inteligent methods for dust detection using modis satellite data. The International Archives of the Photogrammetry Remote Sensing and Spatial Information SciencesXL-1/W3, 371–375 (2013).https://doi.org/10.5194/isprsarchives-xl-1-w3-371-2013 12.Shahrisvand, M., Akhoondzadeh, M.: A comparison of empirical and inteligent methods for dust detection using modis satellite data. The International Archives of the Photogrammetry Remote Sensing and Spatial Information SciencesXL-1/W3, 371–375 (2013).https://doi.org/10.5194/isprsarchives-xl-1-w3-371-2013 13.Shao, Y., Dong, C.: A review on east asian dust storm climate, modelling and monitoring. Global and Planetary Change52, 1–22 (2006). https://doi.org/10. 1016/j.gloplacha.2006.02.011 14 C. Gates et al. 14.Shi, J., Yang, S., Cui, S., Luo, T., Li, X., Lu, W., Han, L.: Dust detection over east asia from multispectral and multi-temporal himawari-8/ahi thermal infrared observations. Earth and Space Science10(2023). https://doi.org/10.1029/ 2022ea002738 15.Souri, A., Vajedian, S.: Dust storm detection using random forests and physical- based approaches over the middle east. Journal of Earth System Science124, 1127–1141 (2015).https://doi.org/10.1007/s12040-015-0585-6 16.Sun, Z., Sandoval, L., Crystal-Ornelas, R., Mousavi, S.M., Wang, J., Lin, C., Cristea, N., Tong, D., Carande, W.H., Ma, X., Rao, Y., Bednar, J.A., Tan, A., Wang, J., Purushotham, S., Gill, T.E., Chastang, J., Howard, D., Holt, B., Gangodagamage, C., Zhao, P., Rivas, P., Chester, Z., Orduz, J., John, A.: A review of earth artificial intelligence. Computers & Geosciences159, 105034 (2022). https://doi.org/10. 1016/j.cageo.2022.105034 17.Taghavi, F., Owlad, E., Ackerman, S.: Enhancement and identification of dust events in the south-west region of iran using satellite observations. Journal of Earth System Science126(2017).https://doi.org/10.1007/s12040-017-0808-0 18.Tong, D., Mo, D., Wang, T., Lee, P.:",
    "J., John, A.: A review of earth artificial intelligence. Computers & Geosciences159, 105034 (2022). https://doi.org/10. 1016/j.cageo.2022.105034 17.Taghavi, F., Owlad, E., Ackerman, S.: Enhancement and identification of dust events in the south-west region of iran using satellite observations. Journal of Earth System Science126(2017).https://doi.org/10.1007/s12040-017-0808-0 18.Tong, D., Mo, D., Wang, T., Lee, P.: Long-term dust climatology in the west- ern united states reconstructed from routine aerosol ground monitoring. Atmo- spheric Chemistry and Physics12, 5189–5205 (2012). https://doi.org/10.5194/ acp-12-5189-2012 19.Tong, D.Q., Gill, T.E., Sprigg, W.A., Van Pelt, R.S., Baklanov, A.A., Barker, B.M., Bell, J.E., Castillo, J., Gassó, S., Gaston, C.J., et al.: Health and safety effects of airborne soil dust in the americas and beyond. Reviews of Geophysics61(2), e2021RG000763 (2023) 20.Wang, Y., Tang, J., Zhang, Z., Wang, W., Wang, J., Wang, Z.: Hybrid methods’ integration for remote sensing monitoring and process analysis of dust storm based on multi-source data. Atmosphere14, 3 (2022). https://doi.org/10.3390/ atmos14010003 21.Zandkarimi, A., Fatehi, P.: Dust storm detection using modis data over the middle east. The International Archives of the Photogrammetry Remote Sensing and Spatial Information SciencesXLII-4/W18, 1147–1151 (2019). https://doi.org/ 10.5194/isprs-archives-xlii-4-w18-1147-2019"
  ]
}