{
  "filename": "2509.07150v1.pdf",
  "total_chunks": 20,
  "text_length": 65556,
  "chunks": [
    "PLaID++: A Preference Aligned Language Model for Targeted Inorganic Materials Design Andy Xu Rohan Desai Larry Wang Gabriel Hope Ethan Ritz Harvey Mudd College {andxu}@hmc.edu Abstract Discovering novel materials is critical for technological advancements such as solar cells, batteries, and carbon capture. However, the development of new materials is constrained by a slow and expensive trial-and-error process. To accelerate this pipeline, we introduce PLaID++, a Large Language Model (LLM) fine-tuned for stable and property-guided crystal generation. We fine-tune Qwen-2.5 7B to generate crystal structures using a novel Wyckoff-based text representation. We show that generation can be effectively guided with a reinforcement learning technique based on Direct Preference Optimization (DPO), with sampled structures categorized by their stability, novelty, and space group. By encoding symmetry constraints directly into text and guiding model outputs towards desirable chemical space, PLaID++ generates structures that are thermodynamically stable, unique, and novel at a ∼50% greater rate than prior methods and conditionally generates structures with desired space group properties. Our experiments highlight the effectiveness of iterative DPO, achieving ∼115% and ∼50% improvements in unconditional and space group conditioned generation, respectively, compared to fine-tuning alone. Our work demonstrates the potential of adapting post-training techniques from natural language processing to materials design, paving the way for targeted and efficient discovery of novel materials. 1 Introduction The discovery of new solid-state materials is the foundation of many transformative technologies in- cluding solar cells [ 12], batteries [ 46], and carbon capture [ 35]. However, the search for new materials is constrained by the immense scale of chemical space—previous explorations have only uncovered a fraction of the total number of potential stable inorganic compounds [ 7]. Generative models offer a promising avenue for accelerating technological breakthroughs by efficiently discovering novel and stable structures in unexplored regions of chemical space. Previous work has applied variational autoencoders [ 42] and denoising models [ 45,17,25] to generate stable and novel structures. However, these works either do not explicitly encode crystallographic symmetry or use computationally inefficient and complex representations, limiting the efficacy of their models. Meanwhile, language models [ 13,36] have emerged as a promising alternative. Their pretrained knowledge makes them data-efficient, often requiring far fewer domain-specific examples than training models from scratch [ 13]. Moreover, their natural-language interface allows one model to be applied to many tasks, including unconditional and conditional generation, infilling, and crystal structure prediction [13]. Symmetry is a defining aspect of crystal structures. The set of rotations, reflections, inversions, and translations exhibited by a crystal lattice form itsspace group. A crystal’s space group and symmetries are not merely a mathematical construct but critical to many optical, electrical, and Preprint. Under review.arXiv:2509.07150v1 [cs.LG] 8 Sep 2025 Figure 1: Overview of the PLaID++ pipeline, highlighting Wyckoff fine tuning and iterative DPO. magnetic properties like piezoelectricity [ 24,44]. One way to define a crystal’s structure from its symmetries is via Wyckoff positions, whereby one can specify a few key atomic coordinates and have the remaining atomic positions filled by applying symmetry operations [14]. Other fields of machine learning have shown that general-purpose architectures that focus on",
    "[ 24,44]. One way to define a crystal’s structure from its symmetries is via Wyckoff positions, whereby one can specify a few key atomic coordinates and have the remaining atomic positions filled by applying symmetry operations [14]. Other fields of machine learning have shown that general-purpose architectures that focus on scale and data expressivity outperform models with handcrafted, domain-specific constraints [ 8,20]. We contend that the same “Bitter Lesson” holds true for materials generation [ 38]. Rather than imposing explicit crystallographic constraints, we train an LLM to learn and exploit structural parameters from the data itself. By allowing the model to discover patterns implicitly through training on Wyckoff-based text representations, we see significant improvements in generation performance. To guide our search space towards chemically useful structures, we introduce Reinforcement Learning from Interatomic Potentials (RLIP), a reinforcement learning framework for physically grounded materials generation. To do so, we adapt Direct Preference Optimization (DPO) [ 29], a computation- ally efficient reinforcement learning method. Our pipeline is as follows: first, we perform supervised finetuning on a base LLM with Wyckoff-based text encodings of crystals. Then we further fine-tune the LLM via multiple rounds of DPO on generated structures categorized by their stability, novelty, and space group. To prevent entropy collapse and increase the diversity of generated structures, we increase the sampling temperature across successive iterations of DPO. By incorporating inherent crystal symmetries and the feedback of a Machine Learning Interatomic Potential (MLIP), we significantly increase the rate of stable, unique, and novel (S.U.N.) materials. Our experiments demonstrate that our methodPLaID++ generates materials at state of the art stability rate and generates S.U.N materials at over a 20% higher ratethan prior models while retaining the flexibility of natural language prompting. We also highlight the effectiveness of reinforcement learning for materials discovery,achieving ∼115% and ∼50% improvements in unconditional and space group conditioned generation, respectively, compared to fine-tuning alone.Our contributions are as follows: 1.We develop a novel, symmetry-informed text representation for crystal structures which is compact, performant, and physically-motivated. 2.We introduce an end-to-end framework for fine-tuning LLMs for material generation using Reinforcement-Learning from Interatomic Potentials (RLIP). 3.We demonstrate that fine-tuned LLMs outperform existing state-of-the-art models in gener- ating novel and stable materials. 2 Related Work Variational autoencoders (V AEs)were among the early approaches to crystal structure generation, using learned latent spaces to produce physically plausible atomic arrangements [ 42,5]. Specifically, CDV AE introduced a continuous representation of crystal structures, however, V AEs face challenges in generating structures with strict crystallographic constraints, as their representations often lack direct symmetry considerations. 2 Diffusion modelslike DiffCSP and FlowMM iteratively denoise atomic positions to generate crystal structures, achieving higher stability and validity than earlier V AE approaches [ 17,25]. While these models excel at capturing complex chemical landscapes, they face significant inference cost due to multi-step denoising, which limits their scalability for rapidly screening a broad sample of material candidates. Language modelsare scalable and capable when leveraging extensive pre-training on vast text corpora. In particular, CrystalLLM [ 13] pioneered the use of fine-tuned LLMs for crystal generation, showcasing the effectiveness of text-based",
    "cost due to multi-step denoising, which limits their scalability for rapidly screening a broad sample of material candidates. Language modelsare scalable and capable when leveraging extensive pre-training on vast text corpora. In particular, CrystalLLM [ 13] pioneered the use of fine-tuned LLMs for crystal generation, showcasing the effectiveness of text-based representations for materials prediction. Symmetry-aware language modelshave introduced Wyckoff-position-based representations, lever- aging inherent crystallographic symmetries to more effectively constrain the generative process within physical reality. WyFormer and CrystFormer [ 21,4] utilized transformer-based architectures to predict atomic positions conditioned explicitly on predefined space groups and chemical formulas. Although these symmetry-aware methods showed improvements in structural validity, their reliance on explicit formula and space group constraints considerably limits their utility in exploratoryde novogeneration tasks. On the other hand, symmetry-preserving non-LLM methods such as WyCryst [ 47], Crystal-GFN [ 1], DiffCSP++ [ 17], and SymmCD [ 23] enforce Wyckoff or space group constraints through templates or diffusion processes. While effective, these approaches either require predefined templates or incur high computational cost, and cannot flexibly target multiple objectives. In this paper, we explore using a compact Wyckoff text encoding with preference-based post-training, enabling both unconditional and conditional generation in a single unified pipeline. 3 Background 3.1 Crystallography Crystal structures are periodic arrangements of atoms defined by repeating unit cells. Each unit cell is fully described by lattice parameters—consisting of side lengths (l1, l2, l3)and angles (θ1, θ2, θ3)—and atomic positions within the cell, characterized by their fractional coordinates (xi, yi, zi)and elemental identitiese i. Formally, a crystal structureCcan be expressed as a tuple: C= (l 1, l2, l3, θ1, θ2, θ3, e1, x1, y1, z1, . . . , e N, xN, yN, zN).(1) The properties of crystals are heavily influenced by their underlying symmetry, captured mathemat- ically by their space groups. Each space group comprises a set of symmetry operations, such as rotations, reflections, and inversions, that map the crystal structure onto itself. Atomic positions consistent with these symmetry operations are defined through Wyckoff positions [ 14], significantly reducing the degrees of freedom required to specify a structure. Consequently, employing Wyckoff po- sitions in generative modeling can greatly enhance the validity and physical plausibility of generated structures. We present additional mathematical background on Wyckoff positions in Appendix 7.5. In computational materials science, thermodynamic stability is a critical metric which can be de- scribed using the energy above hull ( Ehull), which quantifies how energetically favorable a material is compared to known competing phases [ 37]. The energy hull refers to a convex hull of formation ener- gies in composition-energy space constructed by evaluating the formation energy of each computed phase and linking the lowest-energy points to form the lower convex envelope [ 13]. Hence, the Ehull of a candidate material is defined as the distance between its computed formation energy per atom and the hull at the same composition. Materials with Ehull≤0eV/atom at a given temperature and pressure are considered thermodynami- cally stable, while those slightly above zero (typically Ehull<0.1 eV/atom) are considered metastable and potentially synthesizable [ 16]. Compounds with lower Ehullvalues have less",
    "between its computed formation energy per atom and the hull at the same composition. Materials with Ehull≤0eV/atom at a given temperature and pressure are considered thermodynami- cally stable, while those slightly above zero (typically Ehull<0.1 eV/atom) are considered metastable and potentially synthesizable [ 16]. Compounds with lower Ehullvalues have less thermodynamic driving force for decomposition, making them generally more likely to be synthesizable and thus have potential for real-world applications. Consequently, many generative models prioritize designing materials with lowEhullto maximize their physical viability. Crystallography concerns not only the validity of atomic positions and crystal stability but also the uniqueness and novelty of generated structures. In practice, two crystals may have different symmetries yet could be considered chemically equivalent if their lattices or atomic sites overlap under 3 tolerance thresholds. To address this, we rely on structure-based fingerprints such as Pymatgen’s StructureMatcher [ 26]. StructureMatcher reduces candidate crystals to canonical forms (e.g., primitive and Niggli cells) and then checks atom-by-atom equivalence within length, angle, and site tolerances. Uniqueness and novelty therefore depend on the chosen reference set and tolerance hyperparameters. These metrics underpin the S.U.N. evaluation used throughout this work, complementing stability as a necessary criterion for materials discovery. 3.2 Reinforcement learning for LLM fine-tuning. Recent advances in reinforcement learning have enabled LLMs to align generated outputs more closely with human preferences [ 2]. In general, these methods fine-tune a pre-trained LLM, πrefwith feedback from a reward model rϕ(·). The RL objective optimizes the model πθ(y|x) to maximize the expected reward of generated responses y∼π θ(y|x) , given prompt x. To preserve the diversity of response and prevent collapse to undesirable modes of the reward function, this is often regularized via an additional KL-divergence loss that prevents the model from straying too far from the initial model. This leads to the following general objective: max πθEx∼D,y∼π θ(y|x)[rϕ(x, y)]−βD KL[πθ(y|x)∥π ref(y|x)].(2) Here Drepresents the distribution of prompts and the hyperparameter βcontrols the strength of regularization. This objective can be optimized using REINFORCE or with reduced variance policy gradient such as proximal policy optimization (PPO) [ 32]. This framework requires an explicit reward function, while actor-critic methods such as PPO additionally require a value model leading to substantially increased computational overhead. In contrast, Direct Preference Optimization (DPO) [ 29] streamlines this process, using observed preference pairs of responses (yw, yl), generated from πref, where ywdenotes the preferred response. DPO optimizes an implicit reward function r∗(x, y) by maximizing the likelihood of preferences under a Bradley-Terry preference model: p(yw≻yl|x) = exp(r∗(yw|x))/(exp(r∗(yw|x)) + exp(r∗(yl|x))) . The authors show that a KL-regularized objective can be optimized without directly instantiatingr∗(x, y), leading to the following objective: LDPO=−E (x,yw,yl)\u0014 logσ\u0012 βlogπθ(yw|x) πref(yw|x)−βlogπθ(yl|x) πref(yl|x)\u0013\u0015 (3) Prior work has shown that DPO is effective in both RLHF [29] and scientific domains [40]. To effectively generate stable structures, we employ a reinforcement learning framework based on DPO. By curating a dataset of stability and novelty-ranked crystal pairs evaluated via MLIP relaxations, our model iteratively learns to favor generation of structures with lower predicted energies in unseen crystal space, thus aligning generative behavior towards",
    "To effectively generate stable structures, we employ a reinforcement learning framework based on DPO. By curating a dataset of stability and novelty-ranked crystal pairs evaluated via MLIP relaxations, our model iteratively learns to favor generation of structures with lower predicted energies in unseen crystal space, thus aligning generative behavior towards chemically stable and experimentally realizable new materials. 4 Method 4.1 Base Model Our approach begins with a pre-trained large language model (Qwen-2.5 7B) [ 43], which has demonstrated strong capabilities in text generation and reasoning. Following the methodology outlined by [ 13], we fine-tune the base version of Qwen-2.5 7B to model the crystal generation process via parameter-efficient fine-tuning [ 15]. Unlike prior works that rely on explicit space group constraints or predefined templates, our method enables more flexible and generalizable unconditional and conditional structure generation through the use of a natural language prompt. The training objective is to maximize the likelihood that the model generates the correct token sequence representing stable crystal structures. We fine-tune two versions of the base model: one where the crystal structures are represented as text-based 3D coordinates and another based on a new text-based Wyckoff representation. 4 Figure 2:Left:An example crystal highlighting the p4mm space group symmetry, where colors represent atoms of different elements. We represent the entire asymmetric unit of the crystal in our Wyckoff-based text representation by leveraging the crystal’s symmetry.Right:The template from which we generate prompts used for training. For conditional generation, we include the blue conditioning information, and for unconditional generation, we remove it from our prompt. In all prompts, the crystal string is replaced with the encoding on the left. 4.2 Wyckoff Representation Crystal structures inherently follow symmetry constraints that can be represented by space groups and Wyckoff positions. To improve the model’s ability to generate valid and stable structures, we introduce a Wyckoff representation that encodes these symmetries directly into text. Unlike previous methods such as DiffCSP++ [ 18] which rely on searching template structures for Wyckoff positions, our approach allows direct prediction of these sites within the generative process. Because Wyckoff positions specify atomic site symmetries in a given space group, they significantly increase the possibility of feasible atomic arrangements. Our encoding method represents each crystal as a sequence of tokens as shown in Figure 2. The prompt used to train PLaID++ is the same for both unconditional and conditional generation except conditional generation includes the conditioning information on space group in blue. We specify the chemical formula, space group, lattice parameters, individual chemical elements, fractional coordinates, and Wyckoff site symmetries. Note that we include the chemical formula first to ensure self-consistency during generation. 4.3 Direct Preference Optimization (DPO) Encoding symmetry improves structural validity; however, stability, uniqueness, and novelty remain critical for practical material discovery. To explicitly align our model toward generating crystals with desired properties, we employ an iterative form of Direct Preference Optimization (DPO) [29], a reinforcement learning technique that directly optimizes model outputs based on ranked preferences as highlighted by Equation 3. We jointly optimize our model on three explicit objectives: thermodynamic stability, novelty with respect",
    "model toward generating crystals with desired properties, we employ an iterative form of Direct Preference Optimization (DPO) [29], a reinforcement learning technique that directly optimizes model outputs based on ranked preferences as highlighted by Equation 3. We jointly optimize our model on three explicit objectives: thermodynamic stability, novelty with respect to a reference crystal set, and space group conditioning. StabilityTo train the model to prefer stable crystals, we use EquiformerV2 86M (eqV2) [ 3] as a reward signal. eqV2 is a Machine Learning Interatomic Potential (MLIP) that predicts relaxed formation energies for materials, serving as an efficient proxy for stability assessment. To guide the model towards generating more stable materials, we categorize a crystal’s energy above the hull into one of three buckets: stable ( ≤0eV/atomEhull), metastable ( ≤0.08eV/atomEhull), or unstable ( >0.08eV/atomEhull). We create stability preference pairs (x, y w, yl), where xis the model prompt and ywandylare accepted and rejected crystals. Concretely, we sample preference pairs to form (stable, metastable) and (stable/metastable, unstable) sets, forming a tiered dataset that encodes relative preferences over increasing degrees of thermodynamic stability. This allows us to incorporate fine-grained (stable, metastable) reward signals into our training set without overfitting to exact eqV2-predicted Ehullvalues and without relying heavily on stable generations from the base model, which are too infrequent to provide sufficient training signal as seen in Appendix 7.2. Uniqueness and NoveltyTo incorporate novelty into our reward formulation, we construct prefer- ence pairs that distinguish between (stable & novel, stable & not novel). Incorporating uniqueness into a pairwise reward is non-trivial and presents many challenges. Namely, since uniqueness is defined at the group level (i.e. whether or not crystals within a set of rollouts are considered the “same” 5 crystal as defined by Pymatgen’s StructureMatcher), pairwise reward computation of uniqueness is ambiguous. However, we can control sample diversity during rollouts via the sampling temperature. As temperature increases, uniqueness and novelty tend to increase, while stability and validity of gen- erated crystals decrease. Based on this observation, we find that increasing the sampling temperature across successive iterations of DPO can prevent overoptimization for stability, preventing the model from collapsing on narrow regions of chemical space. Space GroupTo condition our model on generating crystals with a desired space group, we add an additional constraint during preference pair construction. For each space group, we use a conditional generation prompt indicating the target space group number and compare crystals that match this group. Preference pairs are then formed by contrasting (1) stable or metastable crystals with the correct space group against other stable or metastable crystals with the incorrect space group, and (2) stable or metastable structures against unstable structures. This strategy requires stability as a base condition for generation, but also encourages the model to align for structural symmetry. Fine-TuningWe emphasize that both the S.U.N. and space group preference pairs are jointly used in the same DPO objective across the unconditional prompt and space group specific conditional prompts. This joint optimization encourages the model to learn to generate both generally stable crystals and space-group-specific structures in a unified pipeline.",
    "Fine-TuningWe emphasize that both the S.U.N. and space group preference pairs are jointly used in the same DPO objective across the unconditional prompt and space group specific conditional prompts. This joint optimization encourages the model to learn to generate both generally stable crystals and space-group-specific structures in a unified pipeline. To generate this dataset, we sample 10,000 crystal structures from our fine-tuned Qwen model for unconditional generation and sample 1,000 crystal structures across each of seven space groups. More details about our space group conditional generation is provided in Section 5.1; From here, we categorize our samples into our preference datasets based off the above metrics, resulting in a universal dataset that covers both unconditional and conditional generation. We apply DPO to fine-tune Qwen on this curated preference dataset. We adopt an iterative DPO approach in which πref=πθ−1, with generations from πθ−1used to construct the set of preference pairs for πθ. We have additional information about our DPO hyperparameters, our dataset creation process, as well as other potential DPO variants and ablations in Appendix 7.2. 5 Experiments 5.1 Setup We trained our model on the well-established MP-20 dataset [ 42], a collection of 45,231 inorganic crystalline materials from the Materials Project [ 16]. The dataset includes structures with up to 20 atoms, all of which are metastable. We follow the methodology of Gruver et al. [13] by independently fine-tuning a pre-trained Qwen-2.5 7B model using 4-bit quantization and Low-Rank Adapters (LoRA) [ 15], implemented with PyTorch [ 27] and Transformers [ 41]. Symmetry information for our Wyckoff representation is calculated by Pyxtal [ 10]. Following supervised fine-tuning, we apply DPO on the generated preference dataset to further guide generation towards stable structures. Full hyperparameters details are provided in Appendix 7.2. For unconditional generation, we sample 10,000 structures from each fine-tuned model, parsing a CIF from the generated string. We resample if a CIF cannot be parsed from the string, which guarantees all samples can be interpreted as crystals but does not guarantee validity. Similarly, for space-group conditioned generation, we sample 1,000 structures for each of seven space groups. These space groups were chosen in accordance with [ 45] as they represent each of the seven crystal systems with varying levels of symmetry. Specifically, we sample from space groups P1, C2/c, Amm2, I 4m2, P3, P6 3/mmc,andF 43m. To validate the stability and accuracy of our MLIP-based results, we performed Density Functional Theory (DFT) calculations on crystal samples generated by our flagship Qwen-based model fine-tuned with DPO and the Wyckoff encoding. Although accurate, DFT is computationally expensive, scaling typically as O(N3)with respect to the number of atoms N. Therefore, in this work, in addition to performing DFT calculations, we also leverage machine learning interatomic potentials (MLIPs) such as eqV2 [ 3] and eSEN [ 11] as efficient proxies for DFT. These MLIPs predict the relaxed atomic positions and energies with significantly reduced computational overhead. We specifically use eSEN for evaluation to ensure our generative models are guided by energetics closely aligned with DFT benchmarks, without incurring DFT’s computational expense during training. To verify",
    "[ 11] as efficient proxies for DFT. These MLIPs predict the relaxed atomic positions and energies with significantly reduced computational overhead. We specifically use eSEN for evaluation to ensure our generative models are guided by energetics closely aligned with DFT benchmarks, without incurring DFT’s computational expense during training. To verify our eSEN 6 Table 1: Results for unconditional materials generation on the MP-20 dataset. Our flagship PLaID++ variant uses a Wyckoff text representation, DPO on stability and novelty-based preference pairs, and dynamic temperature adjustment. Column-best figures are inbold. Method Params Validity (%) (↑) Stability (%) (↑) S.U.N. (%) (↑) Structural Composition CDV AE – 100.0086.70 1.6 – DiffCSP – 100.0083.25 5.0 3.3 FlowMM – 96.85 83.19 4.6 2.8 FlowLLM – 99.94 90.84 13.9 4.7 MatterGen-MP – – – 13.0 – CrystalLLM-70B – 99.60 95.40 5.28 – Jointly-trained ADiT – 99.74 92.14 15.4 5.3 PLaID++ (Non-DPO Types)3D Coord 98.93 88.94 7.20 2.81 Wyckoff 99.80 91.22 7.17 3.58 Iterative SFT 99.85 94.54 9.85 4.13 PLaID++ (DPO Types)3D Coord 96.62 89.94 13.94 1.69 Wyckoff 98.81 92.57 15.59 6.25 Stability + Novelty 99.78 95.64 16.72 6.22 PLaID++ – 99.7597.34 22.27 7.74 results, we additionally take a random 1,000 crystal subset of our generated crystals to compute stability using DFT. Detailed information regarding our DFT setup are in Appendix 7.2. 5.2 Metrics To initially evaluate the quality of our generated crystal structures, we focus on structural and compositional validity, as defined by Xie et al. [42]. These metrics provide an effective proxy for assessing the quality of generated crystals before conducting more computationally expensive stability evaluations. We explain more details about these metrics in Appendix 7.1 Our primary metric for evaluating generated crystal structures is theS.U.N Ratefrom Miller et al. [25], which measures the percentage of crystals that arestable, unique, andnovel. Stability is assessed by comparing a crystal’s energy to a convex hull of previously computed energies from Riebesell et al. [30]. Crystals on or below the hull ( ≤0eV/atomEhull) are deemedstable. We evaluateuniqueness—differentiation from other generated crystals—andnovelty, which measures diversity from the training data to calculate S.U.N. For our space group conditional generation task, we adopt theS.S.U.N Ratemetric from Zeni et al. [45], which measures the percentage of strucutures that are the correct symmetry group as deemed by Pyxtal [10] and are metastable (≤0.1eV/atomEhull), unique and novel. Due to compute constraints, we assess stability for unconditional and conditional generation primarily via the eSEN MLIP [ 11]. Note that we specificallyuse different MLIPs—eqV2 and eSEN—for preference dataset creation and crystal generation evaluation to avoid reward hacking or overfitting to a specific MLIP. 5.3 Results Unconditional GenerationWe compare our model to seven prior methods, as reported from Joshi et al. [19]: CDV AE [ 42], DiffCSP [ 17], FlowMM [ 25], FlowLLM [ 36], MatterGen-MP [ 45], CrystalLLM [ 13], and ADiT [ 19]. Our main results are presented in Table 1. On stability and S.U.N, the most important metrics, PLaID++ outperforms all prior methods. We also analyze the contribution of each training technique to our methodology. We see that our novel Wyckoff representation and iterative DPO both",
    "[ 13], and ADiT [ 19]. Our main results are presented in Table 1. On stability and S.U.N, the most important metrics, PLaID++ outperforms all prior methods. We also analyze the contribution of each training technique to our methodology. We see that our novel Wyckoff representation and iterative DPO both significantly improve S.U.N., resulting in our best PLaID++ model. For our best overall PLaID++ model, 22.27% of the relaxed structures are deemed stable, out of which 72% are novel, and 55% are unique, leading to a S.U.N. rate of 7.74%.PLaID++ achieves the highest stability rate and a∼50% higher S.U.N rate than the best previous method. On the proxy metrics, PLaID++ achieves performance on par with other methods. Our Wyckoff encoding specifically increases compositional validity for both the base and DPO fine-tuned models, 7 0 1 2 3 4 5 6 7 Iteration4567Percentage of S.U.N. Materials (%) t=0.7t=0.7t=0.9t=0.9t=1.1 t=1.1t=1.3 Jointly trained ADiT FlowLLMVariant Group Unconditional Train (Stability Only) Joint Training (Stability Only) Joint Training (Stability + Novelty) PLaID++Figure 3: Evolution of S.U.N. percentage of PLaID++ variants’ over DPO iterations. Reference lines represent S.U.N. rates from ADiT and FlowLLM’s flagship models. highlighting symmetry-based encodings as a natural and intuitive mechanism to increase the validity and stability of generated structures. Though many of these metrics have saturated, we report PLaID++’s performance for comparison and completeness. We also observe that PLaID++ is significantly more computationally efficient than comparable meth- ods. On a singular NVIDIA 80GB H100 GPU, PLaID++ samples 10,000 crystals in approximately 23 minutes, yielding 27.17 S.U.N. crystals per minute.This generation speed is 5x faster than FlowLLM, which takes 89.6 minutes to generate 10,000 materials on a NVIDIA 80GB A100 GPU, yielding 5.25 S.U.N. crystals per minute [ 36]. Such high throughput is essential in real-world discov- ery, as faster sampling dramatically shortens the design–build–test cycle, enabling rapid screening of candidates and speedups of experimental pipelines [39, 6]. Conditional GenerationTo test the ability of PLaID++ to generalize towards targeted structure synthesis, we measure the S.S.U.N. percentage for four model variants: (i) the 3D coordinate fine- tuned Qwen model (ii) the Wyckoff fine-tuned Qwen model, (iii) DPO conditioned only on space group pairs with no dynamic temperature or novelty reward,(iv) DPO trained jointly on space group, and stable and novel pairs, with dynamic temperature sampling (flagship PLaID++). As shown in Figure 4, applying DPO to space-group pairs increases S.S.U.N. by an average of 22% compared to the base Wyckoff model. Incorporating additional preference data from unconditional generation further boosts performance, resulting in a total increase of 47% over the base model—more than doubling the improvement from space-group conditioning data alone. Groups with low training data occurrences like ( Amm2 ,Im2, P6 3/mmc ) show little improvement or sometimes slight degradation after DPO. This supports the elicitation hypothesis of reinforcement learning [ 22], whereby RL amplifies existing valuable behaviors in the base model rather than teaching models new ones. With too few examples, neither the space-group nor the stability objective can generate a meaningful training signal for the model to learn from. Reinforcement Learning from Interatomic Potentials",
    "hypothesis of reinforcement learning [ 22], whereby RL amplifies existing valuable behaviors in the base model rather than teaching models new ones. With too few examples, neither the space-group nor the stability objective can generate a meaningful training signal for the model to learn from. Reinforcement Learning from Interatomic Potentials (RLIP)Across multiple iterations of Direct Preference Optimization (DPO), we observe in Figure 3 that DPO successively improves the number of S.U.N. materials generated by Qwen-7B, demonstrating that reinforcement learning is an effective and robust method to improve generation performance. On unconditional and space group conditioned generation,we improve S.U.N. by ∼115% and ∼50% respectively compared to fine tuning alone. We believe this method could be scaled further given additional compute. From our ablation on temperature sampling in Figure 3, we highlight that removing dynamic temperature updates across DPO iterations leads to a loss of diversity, where the S.U.N. rate degrades even as stability continues to increase. This suggests that increasing temperature acts as an entropy regularizer which counteracts model collapse and encourages exploration. 8 P1 C2/c Amm2 I4m2 P3 P6_3/mmc F-43m Space Group05101520253035Percent S.S.U.N. (%)3D Coordinate Base Wyckoff Base Conditional Training (Spacegroup Only) PLaID++ (Spacegroup + Stability + Novelty)Figure 4: Histogram of S.S.U.N. results across models for space group conditional generation tasks. Joint Training Improves PerformanceTable 1 and Figure 4 show that our DPO model trained together on the unconditional and space group conditioned generation tasks universally outperforms the DPO models trained individually on each respective task. This validates the efficacy of a universal foundational model that can be leveraged across multiple downstream objectives. The performance gains are particularly pronounced in conditional generation, where only a few hundred samples are available in the training set. This suggests that the additional training signal derived from unconditional generation feedback can be successfully transferred to conditional generation. Space Group Distribution AnalysisWe compare visualizations between the space group distribu- tion of the MP-20 dataset we used to perform SFT on our base models, a sample of 10,000 crystals from Qwen SFT’d on the 3D coordinate representation, and a sample of 10,000 crystals we from our PLaID++ model trained on iterative DPO finetuning with our Wyckoff representation in Figure 5. We note that the flagship model favors generating out-of-train-distribution space groups such as P212121 (19) andPnma(62), a consequence of our RLIP framework’s novelty incentive. Space groups Cm (8) and P1(1) are prominent in the base 3D coordinate representation PLaID++ model’s crystals, but not in the flagship model. Space groupCmhas a single symmetry operation (a glide plane), while space group P1only has the identity operation. In addition, space groups P63/mmc (194) and I4mmm (139) are among the five most frequently generated space groups in the flagship model, even though they are not in the top five of the training set. This supports the hypothesis that the Wyckoff representation helps PLaID++ generate systems with complex symmetry requirements, skewing the distribution towards generating crystals with higher symmetries and ensuring a more even distribution across all space groups. Density Functional Theory Performance ValidationRelaxing 1,000 structures using DFT, we find a stability rate",
    "set. This supports the hypothesis that the Wyckoff representation helps PLaID++ generate systems with complex symmetry requirements, skewing the distribution towards generating crystals with higher symmetries and ensuring a more even distribution across all space groups. Density Functional Theory Performance ValidationRelaxing 1,000 structures using DFT, we find a stability rate of approximately 19.1% and a S.U.N. rate of 13%. These results are consistent with our findings using the eSEN machine learning interatomic potential [ 11], providing strong empirical support for the quality of our generated materials. Notably, the DFT-based S.U.N. rate is higher than that obtained from the full 10,000-sample evaluation using eSEN. This discrepancy is expected due to the smaller DFT sample size, which yields a higher relative uniqueness rate. 6 Discussion In this paper, we introduce a novel Wyckoff-based text encoding for crystal structures and introduce a new reinforcement learning framework, Reinforcement Learning from Interatomic Potentials (RLIP), to guide generation towards chemically stable and useful structures. Our method achieves state-of-the- 9 Figure 5: A comparison between the three space group distributions allows us to extract valuable insights on how our PLaID variants affect model behavior. art performance across stability and S.U.N. metrics. Current random structure search methods achieve less than a 1% success rate [ 28] in identifying stable materials—PLaID++ represents a significant acceleration from traditional approaches to future methods with greater stability and real-world utility. Limitations & Future WorkWhile PLaID++ achieves state-of-the-art stability and S.U.N. rates, it has several limitations that point toward promising avenues for future work. We have fine-tuned and evaluated exclusively on the MP-20 dataset ( ∼45K structures), and scaling to larger, more diverse datasets such as Alexandria ( ∼2.6M structures) [ 31] or LeMaterial ( ∼6.7M structures) [ 34] may further broaden the model’s coverage of chemical space. Our experiments also focus on unconditional and space-group-conditioned generation, but extending generation to other objectives such as band- gap optimization or ionic conductivity targets would demonstrate wider practical utility. We also only explored Direct Preference Optimization (DPO) as our RL method; investigating alternative algorithms such as Proximal Policy Optimization (PPO) [ 32] or Group Relative Policy Optimization (GRPO) [33] might uncover different stability–diversity trade-offs. Impact StatementOur approach has the potential to dramatically speed up the design of novel materials for renewable energy, electronics, and carbon-capture applications—paving the way for more efficient, sustainable technologies that benefit society. At the same time, deploying generative models carries risks, including the synthesis of dangerous compounds and uneven access to these tools. References [1]Mila AI4Science, Alex Hernandez-Garcia, Alexandre Duval, Alexandra V olokhova, Yoshua Bengio, Divya Sharma, Pierre Luc Carrier, Yasmine Benabed, Michał Koziarski, and Victor Schmidt. Crystal-gfn: sampling crystals with desirable properties and constraints, 2023. URL https://arxiv.org/abs/2310.04925. [2]Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna Chen, Nova DasSarma, Dawn Drain, Stanislav Fort, Deep Ganguli, Tom Henighan, et al. Training a helpful and harmless assistant with reinforcement learning from human feedback.arXiv preprint arXiv:2204.05862, 2022. [3]Luis Barroso-Luque, Muhammed Shuaibi, Xiang Fu, Brandon M Wood, Misko Dzamba, Meng Gao, Ammar Rizvi, C Lawrence Zitnick, and Zachary W Ulissi. Open materials 2024 (omat24) inorganic materials",
    "Fort, Deep Ganguli, Tom Henighan, et al. Training a helpful and harmless assistant with reinforcement learning from human feedback.arXiv preprint arXiv:2204.05862, 2022. [3]Luis Barroso-Luque, Muhammed Shuaibi, Xiang Fu, Brandon M Wood, Misko Dzamba, Meng Gao, Ammar Rizvi, C Lawrence Zitnick, and Zachary W Ulissi. Open materials 2024 (omat24) inorganic materials dataset and models.arXiv preprint arXiv:2410.12771, 2024. [4]Zhendong Cao, Xiaoshan Luo, Jian Lv, and Lei Wang. Space group informed transformer for crystalline materials generation.arXiv preprint arXiv:2403.15734, 2024. 10 [5]Callum J Court, Batuhan Yildirim, Apoorv Jain, and Jacqueline M Cole. 3-d inorganic crystal structure generation and property prediction via representation learning.Journal of Chemical Information and Modeling, 60(10):4518–4535, 2020. [6]Stefano Curtarolo, Gus LW Hart, Marco Buongiorno Nardelli, Natalio Mingo, Stefano Sanvito, and Ohad Levy. The high-throughput highway to computational materials design.Nature materials, 12(3):191–201, 2013. [7]Daniel W Davies, Keith T Butler, Adam J Jackson, Andrew Morris, Jarvist M Frost, Jonathan M Skelton, and Aron Walsh. Computational screening of all stoichiometric inorganic materials. Chem, 1(4):617–627, 2016. [8]Alexey Dosovitskiy. An image is worth 16x16 words: Transformers for image recognition at scale.arXiv preprint arXiv:2010.11929, 2020. [9]Robert A Evarestov and Vyacheslav P Smirnov.Site symmetry in crystals: theory and applica- tions. Springer Berlin Heidelberg, 1997. [10] Scott Fredericks, Kevin Parrish, Dean Sayre, and Qiang Zhu. Pyxtal: A python library for crystal structure generation and symmetry analysis.Computer Physics Communications, 261: 107810, 2021. ISSN 0010-4655. doi: https://doi.org/10.1016/j.cpc.2020.107810. URL http: //www.sciencedirect.com/science/article/pii/S0010465520304057. [11] Xiang Fu, Brandon M Wood, Luis Barroso-Luque, Daniel S Levine, Meng Gao, Misko Dzamba, and C Lawrence Zitnick. Learning smooth and expressive interatomic potentials for physical property prediction.arXiv preprint arXiv:2502.12147, 2025. [12] Martin A Green, Anita Ho-Baillie, and Henry J Snaith. The emergence of perovskite solar cells. Nature photonics, 8(7):506–514, 2014. [13] Nate Gruver, Anuroop Sriram, Andrea Madotto, Andrew Gordon Wilson, C. Lawrence Zitnick, and Zachary Ward Ulissi. Fine-tuned language models generate stable inorganic materials as text. InThe Twelfth International Conference on Learning Representations, 2024. URL https://openreview.net/forum?id=vN9fpfqoP1. [14] Theo Hahn, Uri Shmueli, and JC Wilson Arthur.International tables for crystallography, volume 1. Reidel Dordrecht, 1983. [15] Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. Lora: Low-rank adaptation of large language models, 2021. [16] Anubhav Jain, Shyue Ping Ong, Geoffroy Hautier, Wei Chen, William Davidson Richards, Stephen Dacek, Shreyas Cholia, Dan Gunter, David Skinner, Gerbrand Ceder, and Kristin A. Persson. Commentary: The materials project: A materials genome approach to accelerating materials innovation.APL Materials, 1(1), 7 2013. doi: 10.1063/1.4812323. [17] Rui Jiao, Wenbing Huang, Peijia Lin, Jiaqi Han, Pin Chen, Yutong Lu, and Yang Liu. Crystal structure prediction by joint equivariant diffusion.Advances in Neural Information Processing Systems, 36:17464–17497, 2023. [18] Rui Jiao, Wenbing Huang, Yu Liu, Deli Zhao, and Yang Liu. Space group constrained crystal generation.arXiv preprint arXiv:2402.03992, 2024. [19] Chaitanya K. Joshi, Xiang Fu, Yi-Lun Liao, Vahe Gharakhanyan, Benjamin Kurt Miller, Anuroop Sriram, and Zachary W. Ulissi. All-atom diffusion transformers: Unified generative modelling of molecules and materials, 2025. URLhttps://arxiv.org/abs/2503.03965. [20] Jared Kaplan, Sam McCandlish, Tom Henighan, Tom B Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei. Scaling laws",
    "Yi-Lun Liao, Vahe Gharakhanyan, Benjamin Kurt Miller, Anuroop Sriram, and Zachary W. Ulissi. All-atom diffusion transformers: Unified generative modelling of molecules and materials, 2025. URLhttps://arxiv.org/abs/2503.03965. [20] Jared Kaplan, Sam McCandlish, Tom Henighan, Tom B Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei. Scaling laws for neural language models.arXiv preprint arXiv:2001.08361, 2020. [21] Nikita Kazeev, Ruiming Zhu, Ignat Romanov, Andrey E Ustyuzhanin, Shuya Yamazaki, Wei Nong, and Kedar Hippalgaonkar. Wyckofftransformer: Generation of symmetric crystals. InAI for Accelerated Materials Design-NeurIPS 2024, 2024. 11 [22] Nathan Lambert. Elicitation, the simplest way to understand post-training. https://www.interconnects.ai/p/elicitation-theory-of-post-training, November 2023. [23] Daniel Levy, Siba Smarak Panigrahi, Sékou-Oumar Kaba, Qiang Zhu, Mikhail Galkin, Santiago Miret, and Siamak Ravanbakhsh. Symmcd: Symmetry-preserving crystal generation with diffusion models. InAI for Accelerated Materials Design-NeurIPS 2024, 2024. [24] Cécile Malgrange, Christian Ricolleau, and Michel Schlenker.Symmetry and physical properties of crystals. Springer, 2014. [25] Benjamin Kurt Miller, Ricky TQ Chen, Anuroop Sriram, and Brandon M Wood. Flowmm: Generating materials with riemannian flow matching.arXiv preprint arXiv:2406.04713, 2024. [26] Shyue Ping Ong, William Davidson Richards, Anubhav Jain, Geoffroy Hautier, Michael Kocher, Shreyas Cholia, Dan Gunter, Vincent L Chevrier, Kristin A Persson, and Gerbrand Ceder. Python materials genomics (pymatgen): A robust, open-source python library for materials analysis.Computational Materials Science, 68:314–319, 2013. [27] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Köpf, Edward Yang, Zach DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, and Soumith Chintala. Pytorch: An imperative style, high-performance deep learning library, 2019. URL http://arxiv.org/abs/1912.01703 . cite arxiv:1912.01703Comment: 12 pages, 3 figures, NeurIPS 2019. [28] Chris J Pickard and RJ Needs. Ab initio random structure searching.Journal of Physics: Condensed Matter, 23(5):053201, 2011. [29] Rafael Rafailov, Archit Sharma, Eric Mitchell, Christopher D Manning, Stefano Ermon, and Chelsea Finn. Direct preference optimization: Your language model is secretly a reward model. Advances in Neural Information Processing Systems, 36, 2023. [30] Janosh Riebesell, Rhys EA Goodall, Anubhav Jain, Philipp Benner, Kristin A Persson, and Alpha A Lee. Matbench discovery–an evaluation framework for machine learning crystal stability prediction.arXiv preprint arXiv:2308.14920, 2023. [31] Jonathan Schmidt, Tiago F.T. Cerqueira, Aldo H. Romero, Antoine Loew, Fabian Jäger, Hai-Chen Wang, Silvana Botti, and Miguel A.L. Marques. Improving machine-learning models in materials science through large datasets.Materials Today Physics, 48:101560, 2024. ISSN 2542-5293. doi: https://doi.org/10.1016/j.mtphys.2024.101560. URL https: //www.sciencedirect.com/science/article/pii/S2542529324002360. [32] John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov. Proximal policy optimization algorithms.arXiv preprint arXiv:1707.06347, 2017. [33] Zhihong Shao, Peiyi Wang, Qihao Zhu, Runxin Xu, Junxiao Song, Xiao Bi, Haowei Zhang, Mingchuan Zhang, YK Li, Y Wu, et al. Deepseekmath: Pushing the limits of mathematical reasoning in open language models.arXiv preprint arXiv:2402.03300, 2024. [34] Martin Siron, Inel Djafar, Lucile Ritchie, Etienne Du-Fayet, Amandine Rossello, Ali Ramlaoui, Leandro von Werra, Thomas Wolf, and Alexandre Duval. Lemat-bulk dataset, 2024. URL https://huggingface.co/datasets/LeMaterial/LeMat-Bulk. [35] Anuroop Sriram, Sihoon Choi, Xiaohan Yu, Logan M Brabson, Abhishek Das, Zachary Ulissi, Matt Uyttendaele, Andrew J Medford, and David S Sholl. The open dac 2023 dataset and challenges for sorbent",
    "Du-Fayet, Amandine Rossello, Ali Ramlaoui, Leandro von Werra, Thomas Wolf, and Alexandre Duval. Lemat-bulk dataset, 2024. URL https://huggingface.co/datasets/LeMaterial/LeMat-Bulk. [35] Anuroop Sriram, Sihoon Choi, Xiaohan Yu, Logan M Brabson, Abhishek Das, Zachary Ulissi, Matt Uyttendaele, Andrew J Medford, and David S Sholl. The open dac 2023 dataset and challenges for sorbent discovery in direct air capture.ACS Central Science, 10(5):923–941, 2024. doi: 10.1021/acscentsci.3c01629. URL https://doi.org/10.1021/acscentsci. 3c01629. [36] Anuroop Sriram, Benjamin Kurt Miller, Ricky T. Q. Chen, and Brandon M Wood. FlowLLM: Flow matching for material generation with large language models as base distributions. In The Thirty-eighth Annual Conference on Neural Information Processing Systems, 2024. URL https://openreview.net/forum?id=0bFXbEMz8e. 12 [37] Wenhao Sun, Stephen Dacek, Shyue Ong, Geoffroy Hautier, Anubhav Jain, William Richards, Anthony Gamst, Kristin Persson, and Gerbrand Ceder. The thermodynamic scale of inorganic crystalline metastability.Science Advances, 2:e1600225–e1600225, 11 2016. doi: 10.1126/ sciadv.1600225. [38] Richard Sutton. The bitter lesson.Incomplete Ideas (blog), 13(1):38, 2019. [39] Nathan J Szymanski, Bernardus Rendy, Yuxing Fei, Rishi E Kumar, Tanjin He, David Milsted, Matthew J McDermott, Max Gallant, Ekin Dogus Cubuk, Amil Merchant, et al. An autonomous laboratory for the accelerated synthesis of novel materials.Nature, 624(7990):86–91, 2023. [40] Talal Widatalla, Rafael Rafailov, and Brian Hie. Aligning protein generative models with experimental fitness via direct preference optimization.bioRxiv, pages 2024–05, 2024. [41] Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Remi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, and Alexander Rush. Transformers: State-of-the-art natural language processing. In Qun Liu and David Schlangen, editors,Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, pages 38–45, Online, October 2020. Association for Computational Linguistics. doi: 10.18653/ v1/2020.emnlp-demos.6. URLhttps://aclanthology.org/2020.emnlp-demos.6/. [42] Tian Xie, Xiang Fu, Octavian-Eugen Ganea, Regina Barzilay, and Tommi Jaakkola. Crys- tal diffusion variational autoencoder for periodic material generation.arXiv preprint arXiv:2110.06197, 2021. [43] An Yang, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chengyuan Li, Dayiheng Liu, Fei Huang, Haoran Wei, et al. Qwen2. 5 technical report.arXiv preprint arXiv:2412.15115, 2024. [44] Jiashi Yang et al.An introduction to the theory of piezoelectricity, volume 9. Springer, 2005. [45] Claudio Zeni, Robert Pinsler, Daniel Zügner, Andrew Fowler, Matthew Horton, Xiang Fu, Zilong Wang, Aliaksandra Shysheya, Jonathan Crabbé, Shoko Ueda, et al. A generative model for inorganic materials design.Nature, pages 1–3, 2025. [46] Qing Zhao, Sanjuna Stalin, Chen-Zi Zhao, and Lynden A Archer. Designing solid-state electrolytes for safe, energy-dense batteries.Nature Reviews Materials, 5(3):229–252, 2020. [47] Ruiming Zhu, Wei Nong, Shuya Yamazaki, and Kedar Hippalgaonkar. Wycryst: Wyckoff inorganic crystal generator framework, 2024. URLhttps://arxiv.org/abs/2311.17916. 13 7 Appendix 7.1 Proxy Metric Details Validityprovides a computationally efficient check on whether a generated crystal is physically plausible. We assess this through two criteria:structural validity, which ensures that no two atoms are closer than 0.5 Å, andpositional validity, which verifies charge neutrality. Stability Rateassesses how many generated materials are thermodynamically stable. Stability is determined by the energy above the hull ( Ehull) metric, which measures the energy difference between a material and",
    "two criteria:structural validity, which ensures that no two atoms are closer than 0.5 Å, andpositional validity, which verifies charge neutrality. Stability Rateassesses how many generated materials are thermodynamically stable. Stability is determined by the energy above the hull ( Ehull) metric, which measures the energy difference between a material and the convex hull of competing phases with the same composition. A material is considered stable if Ehull≤0 eV/atom, while those with Ehull<0. eV/atom are classified as metastable. We compute Ehullby relaxing generated structures using eSEN using the Materials Project dataset (February 2023) as a reference. Total energies were corrected using the MP2020 compatability scheme, which maintains consistency across various functionals (DFT/DFT+U). S.U.N. Rateextends the stability metric to assess both novelty and uniqueness. A structure is novel if it is not structurally similar to any training set material, determined using Pymatgen’s StructureMatcher [ 26]. Uniqueness ensures that duplicate generations are not counted separately by grouping structurally similar outputs into equivalence classes. The S.U.N. rate is defined as the fraction of generated structures that are Stable, Unique, and Novel: Stability Rate=Nstable Ngen×100%(4) SUN Rate=NSUN Ngen×100%(5) Together, these metrics provide a more rigorous assessment of generative model performance by quantifying both the stability and originality of discovered materials. 7.2 Additional Experiment Details Wyckoff Crystal Representation.We represent each crystal structure in PLaID++ as a structured text sequence that encodes key physical and symmetry-related attributes. The representation begins with the chemical formula, expressed as a concatenation of each element and its corresponding multiplicity. This is followed by the space group number, calculated using Pyxtal [ 10] with a symmetry tolerance of 0.01. Next, we include the lattice parameters: side lengths and angles, each rounded to two decimal places. Finally, for each atom in the structure, we list the element type, fractional coordinates (rounded to three decimal places), Wyckoff site label, and site multiplicity also from Pyxtal [ 10]. This format provides a comprehensive and consistent description of a crystal’s composition, geometry, and symmetry. On the training dataset MP-20, the average number of tokens per crystal is 185.5 using PLaID’s Wyckoff representation versus 214.7 using the standard representation from Gruver et al. [13]. This 14% reduction translates into shorter sequences, better sample efficiency, and faster training. Our representation also scales more efficiently with increasing numbers of atoms, as additional atoms occupying the same Wyckoff site only require an update to the multiplicity rather than the inclusion of separate lines for each atom. We provide additional examples of generated structures in Appendix 7.6. Beyond efficiency, the representation is physically motivated: because atoms are tied to Wyckoff sites, changing one coordinate or element type can propagate to multiple atoms through symmetry operations. This increases information density and acts as a natural regularizer, leading to more diverse yet valid generations. In contrast, coordinate-based encodings lack such inductive bias and more often collapse under iterative post-training, as demonstrated in our DPO ablations below. Supervised Finetuning.We perform supervised finetuning (SFT) on Qwen to adapt the model for crystal structure generation. For our fine-tuning, the model performs infilling one-third of the time. The remaining",
    "contrast, coordinate-based encodings lack such inductive bias and more often collapse under iterative post-training, as demonstrated in our DPO ablations below. Supervised Finetuning.We perform supervised finetuning (SFT) on Qwen to adapt the model for crystal structure generation. For our fine-tuning, the model performs infilling one-third of the time. The remaining two-thirds of the time, we generate structuresde novo, where we either generate crystals unconditionally, or randomly append between one and five additional properties in our prompt. The properties we include are the chemical formula, energy above the hull, formation energy per atom, band gap and space group although space group generation was the focus of this work. 14 To fine-tune different Qwen-2.5 7B models on both text-based and Wyckoff-based crystal repre- sentation, we followed the steps outlined by Gruver et al. [13] to reproduce their results. We use an AdamW optimizer with batch size of 16 samples, a learning rate of 10−5, fp-4 mixed precision alongside LoRA adapters (with a LoRA rank of 8, LoRA alpha of 32, and LoRA dropout of 0.05) to fine-tune over the MP-20 dataset for 10 epochs. Iterative SFT Ablation.To directly compare rejection-sampled supervised finetuning (SFT) against Direct Preference Optimization (DPO), we trained a baseline that repeatedly fine-tuned only on metastable structures, matching our DPO iteration count, learning rate, and sample size. Results are summarized below. We find that although iterative SFT improves upon vanilla SFT, it underperforms DPO by a large margin, underscoring the benefit of fine-grained preference learning for stability and novelty. DPO.After supervised finetuning, we apply Direct Preference Optimization (DPO) to align the model’s probability distribution to favor selected structures. We use the DPO Trainer from TRL [ 41] using the Adam optimizer with a batch size of 16samples, a learning rate of 10−6, fp-4/bfloat-16 precision, and aβof0.1on one epoch of our dataset. To fine-tune our model using Direct Preference Optimization (DPO), we curate a dataset of preference pairs drawn from two sources: (1) unconditional generation outputs and (2) space group–conditioned generation outputs. These datasets are merged and used jointly in the DPO training objective. For the 10,000 samples generated from our unconditional generation task, we classify each structure using energy above the hull as predicted by eqV2. We use the following stability thresholds: stable (Ehull≤0), metastable ( 0< Ehull≤0.08 ), and unstable ( Ehull>0.08 ). We form preference pairs using the following procedure. For each stable crystal, we sample one metastable and two unstable crystals to create three pairs: one (stable,metastable) and two (stable,unstable) . For each metastable crystal, we sample two unstable crystals to create(metastable,unstable)pairs. This tiered pairing strategy provides a more fine-grained reward signal than binary stable/unstable classification and avoids overfitting to exact energy values while increasing the diversity of preference samples. We also construct a preference dataset from crystals generated using prompts that specify a desired space group number as described in Figure 2. For each of the seven selected space groups, we sample 1,000 structures and compute both the eqV2-predicted energy and the actual space group using Pyxtal with a symmetry tolerance of 0.01 [ 10]. Crystals with Ehull≤0.08",
    "using prompts that specify a desired space group number as described in Figure 2. For each of the seven selected space groups, we sample 1,000 structures and compute both the eqV2-predicted energy and the actual space group using Pyxtal with a symmetry tolerance of 0.01 [ 10]. Crystals with Ehull≤0.08 are considered acceptable. Within this set, we further divide crystals into those that match the target space group and those that do not. We construct preference pairs by sampling (matching SG,non-matching SG) pairs among stable/metastable crystals and sampling (stable/metastableunstable) pairs in a 1:2 accept reject ratio to enforce both symmetry and stability constraints. By combining these unconditional and conditional preference pairs into a single dataset, we enable the model to jointly learn to generate stable crystals and adhere to symmetry constraints within a unified DPO training pipeline. This creates between 10,000 to 20,000 DPO pairs depending on the iteration number and metastability and symmetry rates. Interestingly, the model incurs significantly worse performance when we compile our dataset using a 1:1 and 1:10 ratio. We hypothesize that smaller ratios perform worse as our training dataset becomes noticeably smaller, and larger ratios perform worse as the model overfits to each positive sample and consequently generates less diverse structures and lower S.U.N. rates. DPO Ablation.We analyze the S.U.N. performance for different DPO variants in Figure 6. The PLaID++ (Non-Tiered Stability DPO) variant applies DPO using stability-based preference pairs, where accepted crystals are stable or metastable and rejected crystals are unstable. The PLaID++ (Non-Tiered Stability π0) variant keeps the reference model fixed as the supervised fine-tuned Qwen Wyckoff base model instead of updating the reference to the previous iteration’s model ( πref=πθ−1) as in the flagship PLaID++ method. The PLaID++ (Tiered Stability) variant is the model which uses tiering on (stable, metastable), and (metastable, unstable) pairs. The results demonstrate the efficacy of both using a tiered DPO stability objective and using the previous iteration model as the reference model for KL divergence calculation. 15 0 1 2 3 4 Iteration3.54.04.55.05.56.0Percentage of S.U.N. Materials (%) Jointly trained ADiT FlowLLMVariant Group PLaID++ (Non-Tiered Stability DPO) PLaID++ (Non-Tiered Stability _0) PLaID++ (Tiered Stability)Figure 6: DPO Ablation, highlighting percentage of S.U.N. Materials across iterations of PLaID++ variants with different DPO pairs eSEN-30M-OAM and eqV2 MLIPs.We employ eqV2 to curate our preference dataset (assessing crystal structures above and below the 0.08 eV/atomEhullthreshold) and eSEN-30M-OAM (eSEN) for our stability evaluations by computing relaxed formation energies. For eqV2 and eSEN, we used their reported settings with 500 relaxation steps and a max force of 0.02 [11, 3]. Density Functional Theory Setup.We used the Vienna Ab initio Simulation Package (V ASP) version 6.3.2 software. All unit cells were relaxed using the default V ASP parameters used for calculations in the Materials Project database as described in Pymatgen v2025.5.1 [ 26]. These are collinear spin-polarized calculations which include a plane wave energy cutoff of 520 eV , a maximum force tolerance of0.5×10−5eV/Å, aΓcentered k-point mesh of 64 k-points per Å3. Experiments – Server Details.We conducted training on a high performance computing (HPC) cluster equipped with",
    "described in Pymatgen v2025.5.1 [ 26]. These are collinear spin-polarized calculations which include a plane wave energy cutoff of 520 eV , a maximum force tolerance of0.5×10−5eV/Å, aΓcentered k-point mesh of 64 k-points per Å3. Experiments – Server Details.We conducted training on a high performance computing (HPC) cluster equipped with NVIDIA H100 GPUs. We used a single NVIDIA H100 GPU for Qwen-2.5 7B SFT and DPO as well as inference. We used an AMD Epyc 7443P for S.U.N. rate evaluations and DFT calculations. 7.3 Validation of MLIPs as a Surrogate for DFT Energy Above Hull To justify using eSEN and eqV2 MLIP energies for evaluations in place of expensive DFT calculations, we compared eSEN/eqV2-predicted and DFT-computed energies above the convex hull ( Ehull) on a sample of 1000 generated structures. All structures were sampled from PLaID++, then filtered to those whose DFT energies are between [−0.2,0.2] eV/atom. This “near-hull” window was chosen because (i) our stability metric depends on correctly classifying structures around the zero-energy threshold, (ii) crystals with |Ehull|>0.2 eV/atom either fail catastrophically in DFT or are unambiguously unstable/stable, making the precise MLIP Ehull’s accuracy less relevant for our evaluation metrics like S.U.N, and (iii) correctly classifying crystals as stable, metastable, or unstable is essential for creating accurate preference pairs used during the iterative DPO process. eSEN. Figure 7 on the left shows a strong linear correlation ( R2= 0.84 ) between eSEN and DFT energies in the critical near-hull region. Based of this high coefficient of determination, eSEN serves as a reasonable proxy for DFT in our evaluation pipeline: it reproduces stability classifications (stable vs. unstable) and catastrophic failure cases outside [−0.2,0.2] eV/atom while enabling a large reduction in computational cost. Experimentally, eSEN relaxes 10,000 crystals in approximately 5 hours, whereas DFT requires 12 hours for 1,000 crystals—yielding a ∼24× speedup with only a minimal accuracy trade-off. 16 0.2 0.1 0.0 0.1 0.2 E Above Hull, DFT (eV/atom)0.2 0.1 0.00.10.2E Above Hull, eSEN (eV/atom)R2=0.84 Sampled Structures Fit line y=x Reference Line Metastability x=0.1 0.2 0.1 0.0 0.1 0.2 E Above Hull, DFT (eV/atom)0.2 0.1 0.00.10.2E Above Hull, eqV2 (eV/atom)R2=0.68 Sampled Structures Fit line y=x Reference Line Metastability x=0.1Figure 7: Scatter of MLIP vs. DFT energies above hull for 1000 sampled structures each with a least-squares fit line.Left:eSEN predictions (R2= 0.84).Right:eqV2 predictions (R2= 0.68). We calculate eSEN’s accuracy as a proxy for DFT in evaluation of the stability and metastability of crystals. When classifying the stability of structures at 0.0 eV eSEN achieves a precision of 0.696, a recall of 0.688 and F1= 0.692 (accuracy = 0.90), highlighting its accuracy in stability classification. Allowing for a small metastability margin (cutoff = 0.1 eV) boosts precision to 0.933 and recall to 0.992, giving F1= 0.962 (accuracy 0.95). Although imperfect, eSEN’s relatively high F1 and accuracy scores demonstrate that it can be useful to approximate metrics like stability rate and S.U.N. without needing the prohibitive cost of DFT on a full 10,000 samples. eqV2. Figure 7 demonstrates a strong linear correlation ( R2= 0.68 ) between eqV2 and DFT energies near the stability",
    "F1 and accuracy scores demonstrate that it can be useful to approximate metrics like stability rate and S.U.N. without needing the prohibitive cost of DFT on a full 10,000 samples. eqV2. Figure 7 demonstrates a strong linear correlation ( R2= 0.68 ) between eqV2 and DFT energies near the stability threshold. Although noisier than eSEN, its high coefficient of determination demonstrates that eqV2 is a reliable surrogate for DFT in the critical near-hull region: replacing DFT with eqV2 in reward evaluation allows the pipeline to accurately create preference pairs for the iterative DPO process at a significantly lower computational cost compared to DFT. Experimentally, eqV2 performed at similar speeds to eSEN, yielding a∼25× speedup over DFT. We further justify eqV2’s ability to act as an accurate and efficient reward model proxy for the crystal stability and metastability classification tasks. At the stability cutoff (0.0 eV/atom), eqV2 attains a precision of 0.591, a recall of 0.818, and an F1score of 0.686 (accuracy = 0.87), reflecting strong sensitivity but moderate specificity around the exact hull threshold. Increasing the cutoff to metastability (0.08 eV) boosts precision to 0.915 and recall to 0.992, yielding an F1score of 0.952 (accuracy = 0.94). This justifies our tiered DPO reward formulation, whereby we provide the model with useful but noisy stability information and more accurate but less useful metastability information. 7.4 PLaID++ Overview Algorithm 1 provides an overview of the full PLaID++ pipeline for the unconditional case (without space-group conditioning). Note thats w≻sldenotes preference (stable≻metastable≻unstable). 7.5 Wyckoff Theory: Mathematical Background A Wyckoff position defines a set of equivalent atomic sites in a given space group [ 9]. These positions are characterized by symmetry constraints, which reduce the degrees of freedom in atomic placement. For a crystal structure belonging to a space groupG, the Wyckoff positions can be defined as: W={gx|g∈G}(6) wherexis a fractional atomic coordinate, andgis an element of the space group. 17 Algorithm 1:PLAID++ Pipeline Input:Crystal corpusD={ˆy i}D i=1▷In Wyckoff format Initial policyπ θref▷QWEN-2.5 7B Stability predictorf MLIP ▷eqV2 MLIP Batch sizeB, DPO Regularizationβ, Promptx Output:PLAID++ policyπ θi Supervised fine-tuning θ0←θref ▷Initialize from reference formini-batchB={ˆy b}B b=1∼ Ddo LSFT=−PB b=1logπ 0(ˆyb|x) θ0←OptimizerStep(L SFT;θ0) RLIP fine-tuning (Stability-only) fori= 1, . . . , Rdo θi←θi−1 ▷Initialize from previous round {yj}K j=1∼πθi−1(y|x)▷Generate candidates sj←f MLIP(yj)▷≈e above hull Create preference pairsP={(y w, yl)j}S j=1wheres w≻slaccording to stability/metastability thresholds formini-batchB={(y w, yl)b}B b=1∼ Pdo LDPO=−1 BPB b=1h σ\u0010 βlogπθi(yw|x) πθi−1(yw|x)−βlogπθi(yl|x) πθi−1(yl|x)\u0011i θi←OptimizerStep(L DPO;θi) returnπ θi▷Optimized policy Each Wyckoff site follows symmetry constraints that ensure atoms occupy positions dictated by the underlying crystallographic symmetry: x′=Rx+t(7) where Ris a symmetry operation (such as a rotation, reflection, or inversion) that can be represented as a matrix, andtis a translation vector. In this notation, x′is considered to be part of the same crystallographic orbit as x, where xis referred to as the generating point. As any one arbitrary point in the crystallographic orbit can be used to generate all other points in the orbit, the choice ofxis not unique. All symmetry operations (R, t) which map a point in the crystallographic orbit to itself form a",
    "where xis referred to as the generating point. As any one arbitrary point in the crystallographic orbit can be used to generate all other points in the orbit, the choice ofxis not unique. All symmetry operations (R, t) which map a point in the crystallographic orbit to itself form a finite subgroup of G, which can be identified as one of the 32 crystallographic point groups. Each Wyckoff site in each space group is associated with one such point group, and is often labeled according to the multiplicity of W(the number of points in the orbit generated by the space group in a single unit cell) and a letter encoding the point group (i.e. ‘4a’). 7.6 Miscellaneous Examples of Generated Crystals We present additional qualitative examples of crystal structures generated by our model. The prompts and generated Wyckoff representations from PLaID for both unconditional generation and two examples of space group conditioned generation are shown in Table 2. Seperately, we visualize four crystals using the ASE and PyMatGen toolkits. Figure 8 show several samples from different space groups. 18 Prompt Model Output Below is a description of a bulk material. Generate a description of the lengths and angles of the lattice vectors and then the element type and coordinates for each atom within the lattice:Ho4Al4Ni4 Spacegroup: Pnma abc: 6.91 4.32 7.44 angles: 90.00 90.00 90.00 Sites (12) Ho 0.005 0.250 0.195 4c Al 0.190 0.250 0.590 4c Ni 0.789 0.250 0.591 4c Below is a description of a bulk material. The spacegroup number is 15. Generate a description of the lengths and angles of the lattice vectors and then the element type and coordinates for each atom within the lattice:Mn8O12F4 Spacegroup: C2/c abc: 9.55 4.98 6.95 angles: 90.00 96.49 90.00 Sites (24) Mn 0.826 0.495 0.074 8f O 0.832 0.906 0.599 8f O 0.000 0.489 0.250 4e F 0.000 0.000 0.000 4a Below is a description of a bulk material. The spacegroup number is 216. Generate a description of the lengths and angles of the lattice vectors and then the element type and coordinates for each atom within the lattice:Ti4Ni4Sn4 Spacegroup: F-43m abc: 5.89 5.89 5.89 angles: 90.00 90.00 90.00 Sites (12) Ti 0.500 0.500 0.500 4b Ni 0.750 0.750 0.750 4d Sn 0.000 0.000 0.000 4a Table 2: Example PLaID++ generations in response to unconditional and space group–conditioned prompts using the Wyckoff-based representation. 19 Figure 8: Examples of crystals generated by our Qwen-2.5-7B model fine-tuned with Wyckoff representation and Direct Preference Optimization (DPO). The crystals’ corresponding chemical formulas are from top left to bottom right respectively, Ce2Si4Ru4,Li4Gd4Au8,Cs4Ce4Sb4Te12, and Li 4Fe4O4F4, respectively. 20"
  ]
}