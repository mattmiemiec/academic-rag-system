{
  "filename": "2509.21653v1.pdf",
  "total_chunks": 32,
  "text_length": 101459,
  "chunks": [
    "A REGRET MINIMIZATION APPROACH TO FIXED-POINT ITERATIONS JOON KWON Abstract.We propose a conversion scheme that turns regret minimizing algorithms into fixed point iterations, with convergence guarantees following from regret bounds. The resulting iterations can be seen as a grand extension of the classical Krasnoselskii–Mann iterations, as the latter are recovered by converting the Online Gradient Descent algorithm. This approach yields new simple iterations for finding fixed points of non-self operators. We also focus on converting algorithms from the AdaGrad family of regret minimizers, and thus obtain fixed point iterations with adaptive guarantees of a new kind. Numerical experiments on various problems demonstrate faster convergence of AdaGrad-based fixed point iterations over Krasnoselskii–Mann iterations. Contents 1. Introduction 1 2. Properties of operators 7 3. Fixed points via Online Linear Optimization 9 4. Simple iterations for non-self mappings 12 5. Adaptivity to positive scalings 15 6. Adaptivity to positive definite scalings 19 7. Numerical experiments 24 8. Conclusion and perspectives 29 Acknowledgments 32 References 33 Appendix A. Mirror Descent type regret bounds 39 Appendix B. A Follow-the-Regularized-Leader regret bound 45 Appendix C. Extension to quasi-nonexpansiveness 46 1.Introduction In optimization and numerical analysis, iterative methods play a central role for solving complex and large-scale problems. Instead of aiming for an exact so- lution, they output a sequence of points that hopefully converges to a solution. They offer important computational advantages: cheap iteration cost, low memory requirements, and great scalability. They have been successfully used for solving linear systems [Jacobi, 1845, Seidel, 1874], ODEs and PDEe [Runge, 1895, Kutta, 1901, Richardson, 1911, Douglas and Rachford, 1956, Young, 1954], optimization problems [Cauchy, 1847, Kuhn and Tucker, 1951], and in particular, have been an Date: September 29, 2025. 1arXiv:2509.21653v1 [math.OC] 25 Sep 2025 2 indispensable tool for the current AI revolution by offering excellent scalability for neural network optimization [Robbins and Monro, 1951, McMahan and Streeter, 2010, Duchi et al., 2011, Tieleman and Hinton, 2012, Kingma and Ba, 2015]. Fixed-point iterations.Fixed points are a very general framework where for a given operatorF, a solution is defined as a pointx ∗such thatF(x ∗) =x ∗. In this context, iterative methods calledfixed-point iterations. The most simple and favorable case is when the operatorF:X → Xis acontractionin some metric space(X, ν), meaning it isL-Lipschitz continuous for some coefficient0⩽L <1. Then, the Banach–Picard theorem [Banach, 1922] assures that there exists a unique fixed pointx ∗∈ Xand that from any initial pointx 1∈ X, iterating operatorF, meaning definingx t+1=F(x t)for allt⩾1, ensures thatν(x t, x∗)⩽Lt−1ν(x1, x∗) for allt⩾1, which corresponds to a geometric convergence to the fixed point. Applications include the proof of the Picard–Lindelöf theorem [Lindelöf, 1894], computation of stationary distribution of Markov chains [Kemeny and Snell, 1960] and value iteration in dynamic programming [Bellman, 1957]. An important relaxation is the case of where the operator is only1-Lipschitz continuous, which is also callednonexpansive. This situation is not as straightfor- ward because a fixed point may not exist (e.g., for a translation), and even if a fixed points exists, iterating the operator may not converge to the fixed point (e.g., for a rotation, if",
    "where the operator is only1-Lipschitz continuous, which is also callednonexpansive. This situation is not as straightfor- ward because a fixed point may not exist (e.g., for a translation), and even if a fixed points exists, iterating the operator may not converge to the fixed point (e.g., for a rotation, if the initial point is not already the center of the rotation). But remarkably, on a convex set in an Euclidean space1, as soon as a fixed point exists, the Krasnoselskii–Mann (KM) iteration [Mann, 1953, Krasnosel’skii, 1955] xt+1=xt+F(x t) 2, t⩾1, which averages the previous point with its image by the operator, guarantees con- vergence to a fixed point, as well as an upper bound on thefixed-point residualthat vanishes as1/√ T, whereTis the number of iterations. Proposition 1.1(Krasnoselskii–Mann iterations [Vaisman, 2005, Cominetti et al., 2014]).Letd⩾1be an integer,X ⊂Rda convex set,F:X → Xa1-Lipschitz continuous function for∥·∥2,x1∈ X, and fort⩾1, xt+1=xt+F(x t) 2. We assume thatFadmits a fixed pointx ∗∈ X. Then,(x t)t⩾1converges to a fixed point ofFand for allT⩾1, ∥F(x T)−x T∥2⩽2∥x 1−x∗∥2√ T. 1Proposition 1.1 was first presented in the Hilbert setting by Vaisman [2005] and formally pub- lished in Cominetti et al. [2014]. Prior to that, Krasnosel’skii [1955], Schaefer [1957], Edelstein [1966], Ishikawa [1976], Edelstein and O’Brien [1978] established strong convergence in various kinds of normed spaces; weak convergence in uniformly convex with Fréchet differentiable norms was studied in Reich [1979]. In more general spaces, having a vanishing fixed-point residual is a weaker property, calledasymptotic regularity, that has been established under various assump- tions by Goebel and Kirk [1983], Groetsch [1972], and in general normed spaces by Baillon and Bruck [1996] and Cominetti et al. [2014]. Note that in turn, asymptotic regularity imply weak convergence as soon as the normed space is a Banach space satisfying the so-called Opial’s prop- erty [Opial, 1967]. 3 Note that it is not possible to deduce an upper bound on the distance of the iterates to their limit from the above upper bound on the fixed-point residual ∥F(x T)−x T∥2. The latter is a weaker measure, of how far a point is frombe- inga fixed point. As first noted by Combettes [2004], many important optimization algorithms are instances of KM iterations: Gradient Descent [Cauchy, 1847], the Proximal Point method[Martinet,1970], theForward-Backwardsplitting[LionsandMercier,1979], the Douglas–Rachford splitting [Douglas and Rachford, 1956], the Chambolle–Pock algorithm [Chambolle and Pock, 2011], etc., which can all be seen through the lens of the very generalmonotone operator splittingframework, which applies KM iterations to a wide range of problems [Bauschke and Combettes, 2017, Ryu and Boyd, 2016, Ryu and Yin, 2022, Combettes, 2024]. Remarkably, it has been recently proved thatHalpern iterationswith carefully chosen viscosity parameters [Lieder, 2021] as well as KM iterations with Nesterov’s momentum [Boţ and Nguyen, 2023] guarantee vanishing fixed-point residual at rate 1/Tfor nonexpansive operators. The wish foradaptivefixed-point iterations.Letd⩾1be an integer,Ithe identity map onRdandX ⊂Rda convex set. An interesting remark is that for F:X → XandL̸= 0, operatorsFandF L:=I+1 L(F−I)have the same fixed points. For simplicity, we restrict the discussion to coefficientsL >0. OperatorF L is then obtained fromFby a kind of positive",
    "nonexpansive operators. The wish foradaptivefixed-point iterations.Letd⩾1be an integer,Ithe identity map onRdandX ⊂Rda convex set. An interesting remark is that for F:X → XandL̸= 0, operatorsFandF L:=I+1 L(F−I)have the same fixed points. For simplicity, we restrict the discussion to coefficientsL >0. OperatorF L is then obtained fromFby a kind of positive scaling that preserves the fixed points. In the case whereFis not nonexpansive, there may exist a valueL >0such that FLis nonexpansive, and using the latter for performing KM iterations would then be beneficial. Even in the case whereFisnonexpansive, performing KM iterations withF Linstead ofFmay provide stronger guarantees and faster convergence in practice. Specifically, ifF Lis nonexpansive, applying Proposition 1.1 gives ∥F(x T)−x T∥2=L∥F L(xT)−x T∥2⩽2L∥x 1−x∗∥2√ T, T⩾1. for all fixed pointx ∗ofF. Focusing on the above bound, because it scales with L, the best such guarantee would be obtained by the smallest value ofLsuch thatF Lis nonexpansive. This is closely related to the problem of finding the right step-size (aka learning rate, which here corresponds to the inverse ofL) in first-order optimization—the following intuition is well-known to all practitioners, in particular in machine/deep learning: if the step-size is too small, convergence happens but may be extremely slow, and if the step-size is too large, convergence does not happen. The above discussion can be extended to e.g., positive definite matricesA∈ Sd ++(R)which can act aspreconditioners: operatorsFandF A:=I+A−1(F−I) have the same fixed points. OperatorF Ais obtained fromFby a kind of change of coordinates that preserves the fixed points. Consider the following toy example. Letα >1,ε∈(0,1)andF:R2→R2be the linear operator defined as F(x) =Mx, x∈R2,whereM=\u0012 −α0 0 1−ε\u0013 . OperatorFhas the origin as its unique fixed point because it is linear and does not have1as eigenvalue. And because−αis the largest eigenvalue (in magnitude),F isα-Lipschitz continuous for∥·∥2, withαbeing the optimal coefficient. Because 4 α >1, operatorFis not nonexpansive, and the guarantee for KM iterates from Proposition 1.1 does not apply. In fact, starting from an initial point with nonzero first component, both the power iterationsx t+1=F(x t) (t⩾1)and the standard KM iterationsx t+1= (x t+F(x t))/2can be seen todiverge. In this example however, it is easy to deduce that the operator F2/(1+α) =I+2 1 +α(F−I), which corresponds to applying scalingL= (α+ 1)/2toF,isnonexpansive. The corresponding KM iterations: xt+1=xt+F2/(1+α) (xt) 2, t⩾1, enjoy the following convergence guarantee given by Proposition 1.1: (1)∥F(x T)−x T∥2=α+ 1 2 F2/(1+α) (xT)−x T 2⩽(α+ 1)∥x 1∥2√ T, T⩾1. Furthermore, a better convergence guarantee can be obtained by considering the following positive definite matrix: A=\u0012(1 +α)/2 0 0ε/2\u0013 . The associated operatorF A(x) =I+A−1(F−I)is also nonexpansive (because it is in fact equal to−I) and the corresponding KM iterationsx(A) t+1= (x(A) t+ FA(x(A) t))/2(t⩾1) satisfy the following convergence guarantee given again by Proposition 1.1: A−1(F(x(A) T)−x(A) T) 2⩽2∥x 1∥2√ T, T⩾1. The above is a stronger guarantee than (1) because the we can deduce a bound for the second component of the residual that is improved by a factor(α+ 1)/2. As a matter of fact, the very simple form of operatorF Amakes the iterations(x(A) t)t⩾1 reach the fixed point in only one iteration from",
    "a stronger guarantee than (1) because the we can deduce a bound for the second component of the residual that is improved by a factor(α+ 1)/2. As a matter of fact, the very simple form of operatorF Amakes the iterations(x(A) t)t⩾1 reach the fixed point in only one iteration from any initial point. In general however, even when operatorFis given in an explicit form, it may be very difficult to guess a positive scalingL >0(resp. a positive definite change of coordinatesA) such thatI+1 L(F−I)(resp.I+A−1(F−I)) is nonexpansive and to benefit from the corresponding convergence guarantee. Even if initial operator Fis already nonexpansive, there may be a scaling (resp. positive definite change of coordinates) that could provide a better convergence guarantee, and that we might want to benefit from. We therefore wish to defineadaptiveiterations that enjoy convergence guarantees that are similar to those given by the best positive scaling (resp. the best positive definite change of coordinates),without prior knowledgeof the latter. In the context of solving linear systems and optimization, a problem is said to beill-conditionedwhen basic methods converge slowly because it happens to be described in an unfavorable system of coordinates [Nemirovski and Yudin, 1983, Polyak, 1987]. This issue is of central importance in practice. Using available information on the problem structure and geometry for finding, before performing the iterations, a change of coordinates that hopefully accelerates convergence, is calledpreconditioning[Young, 1954, Varga, 1962, Meijerink and Van der Vorst, 5 1977]. The approach we propose is to seek for a generic fixed-point iterations that adapton-the-flyto the best possible change of coordinates (among certain classes). This approach is calledonline preconditioningorvariable-metric, and has been proposed for e.g., Forward-Backward splitting [Combettes and V˜ u, 2014, 2013]. , and has been very sucessful for first-order optimization through quasi-Newton methods [Broyden, 1970, Goldfarb, 1970, Fletcher, 1970, Shanno, 1970, Davidon, 1991, Fletcher, 1987]. Adversarial regret minimization.This work introduces a new approach for defining and analyzing fixed-point iterations, based on adversarial regret minimiza- tion. The latter is a kind of sequential decision problems where we aim at defining decision rules that provide worst case guarantees (i.e., that hold for any sequence of decisions made by the environment, seen as an adversary). Theregretis a quantity that compares the actual gain obtained by the decision maker with the gain of the best constant decision in hindsight (meaning the best gain thatcouldhave been obtained with a constant decision over time withprior knowledgeof the decisions of the environment). Adversarial regret minimization was first introduced in the fifties by Han- nan [1957], but underwent a spectacular development over the last thirty years [Cesa-Bianchi and Lugosi, 2006, Bubeck, 2011, Shalev-Shwartz, 2011, Hazan, 2016, Orabona, 2025], with applications to numerous related problems [Freund and Schapire, 1999, Hart and Mas-Colell, 2000, Cesa-Bianchi et al., 2004, Zinkevich et al., 2007, Perchet, 2014]. In particular, deep links with first-order methods in convex and nonconvex optimization were noticed and developed [Levy, 2017, Cutkosky, 2019, Cutkosky et al., 2023, Defazio et al., 2024, Jiang et al., 2025]. At the intersection with first-order optimization, a remarkable breakthrough was the introduction of the AdaGrad family",
    "Perchet, 2014]. In particular, deep links with first-order methods in convex and nonconvex optimization were noticed and developed [Levy, 2017, Cutkosky, 2019, Cutkosky et al., 2023, Defazio et al., 2024, Jiang et al., 2025]. At the intersection with first-order optimization, a remarkable breakthrough was the introduction of the AdaGrad family of algorithms [McMahan and Streeter, 2010, Duchi et al., 2011], which at their core are regret minimizers with theoretical guar- antees that have a strongadaptivecharacter, but then were found to also have excellent performance in practice for first-order optimization, and in particular, for the optimization of neural networks. As a matter of fact, AdaGrad variants such as RMSprop [Tieleman and Hinton, 2012] and Adam [Kingma and Ba, 2015] (and many others) are the state-of-the-art optimizers for deep learning. Contributions.Thebasecontributionofthisworkisaconversionschemeofregret minimization algorithms into fixed-point iterations, with convergence guarantees derived from the regret bounds. A notable special case is the KM iterations which can be seen as the conversion of Online Gradient Descent (one of the most basic regret minimization algorithms) into fixed-point iterations, with the corresponding regret bound recovering the optimal convergence guarantee for KM. Regret-based fixed-point iterations can therefore be seen as a grand extension of KM. A first byproduct is the definition of simple fixed-point iterations for non-self operators (meaning the operator is not defined at all of its image points) and we derive corresponding guarantees. We then apply this conversion scheme to AdaGrad-type algorithms which pro- duce fixed-point iterations that enjoy adaptive convergence guarantees of a new kind. Iterations based on AdaGrad-Norm (the most simple version of AdaGrad, that involves a single data-dependent step-size) are adaptive to the most favorable 6 scalar scaling, meaning the lowest coefficientL >0such thatI+1 L(F−I)is nonex- pansive. Going further, we introduce the notion ofA-nonexpansiveness (whereAis a positive definite matrix), which corresponds to nonexpansiveness after applying a change of coordinates (i.e., preconditioning) using matrixA, and establish that iterations based on AdaGrad-Diagonal are adaptive to the most favorable change of coordinates by a positive diagonal matrix. Similarly, iterations based on AdaGrad- Full are shown to be adaptive to the most favorable change of coordinates among all positive definite matrices. These can be seen as generic variable metric methods that offer some on-the-fly remedy to ill-conditioning. Relatedwork.TheAdaGradfamilyofhasbeenextensivelystudiedinthecontext of convex and nonconvex (possibility stochastic) first-order optimization [Cutkosky and Busa-Fekete, 2018, Ward et al., 2020, Défossez et al., 2022, Traoré and Pauwels, 2021,Xieetal.,2020,Fawetal.,2022,Liuetal.,2023,AttiaandKoren,2023,Wang et al., 2023]. Notably, AdaGrad-Norm was show to be adaptive to the smoothness leveloftheobjectivefunction(meaningtheLipschitzconstantofthegradient)inthe convex case [Levy et al., 2018]. The adaptivity to positive scalings that we obtain for fixed points is analogous. In a similar vein, AdaGrad-Diagonal has been proved in Liu et al. [2024], Jiang et al. [2024] to be adaptive to the anisotropic smoothness (aka coordinate-wise smoothness) of the objective function. The adaptivity to the most favorable change of coordinates with diagonal matrices that we establish has a similar spirit. Summary.Section 2 recalls basic properties and characterizations around nonex- pansiveness, and introduces an extension that we callA-nonexpansiveness. Section 3 first recalls the regret minimization framework called online linear optimization, presents in Lemma 3.2 the",
    "the most favorable change of coordinates with diagonal matrices that we establish has a similar spirit. Summary.Section 2 recalls basic properties and characterizations around nonex- pansiveness, and introduces an extension that we callA-nonexpansiveness. Section 3 first recalls the regret minimization framework called online linear optimization, presents in Lemma 3.2 the core result that connects fixed points and regret and show how Krasnoselskii–Mann iterations can be reinterpreted through Online Gradient Descent. Section 4 considers fixed point problems with non-self operators and pro- poses iterations based on the Projected Online Gradient Descent and Follow-the- Regularized-Leader regret minimizing algorithms, and derive corresponding guar- antees. Section 5 first recalls the general regret bound for AdaGrad-Norm iterations and derives for fixed points a convergence guarantee that adapts to the most favor- able positive scaling. Section 6 applies AdaGrad-Diagonal (resp. AdaGrad-Full) to fixed points and derives guarantees that adapts to the most favorable change of coordinates among positive diagonal matrices (resp. among all positive definite matrices). Section 7 presents numerical experiments that demonstrate that iterations based on AdaGrad (and several variants used as heuristics) compare favorably in practice to Krasnoselskii–Mann iterations. Notation.Throughout the paper,d⩾1is an integer,X ⊂Rdis a nonempty closed convex set.Idenotes the identity map whose domain is to be deduced from the context (usuallyXorRd). The canonical inner product and Euclidean norm inRdare denoted as ⟨x, x′⟩=dX i=1xix′ iand∥x∥2=p ⟨x, x⟩, x, x′∈Rd. 7 Iddenotes the identity matrix of sized. For a vectoru∈Rd,diagudenotes the diagonal matrix of sizedwith diagonal coefficients given byu. IfAis a symmetric positive semidefinite matrix, its square root is denotedA1/2. The set of symmetric positivedefinitematrixofsizedisdenotedSd ++(R). ForA∈ Sd ++(R),theassociated dot product and Mahalanobis norm are denoted: ⟨x, x′⟩A=⟨x, Ax′⟩and∥x∥A=q ⟨x, x⟩A, x, x′∈Rd. For a given norm∥·∥inRd, the (possibly infinite) diameter of a setA ⊂Rdis defined as diam ∥·∥(A) = sup x,x′∈A∥x′−x∥. The diameter with respect to∥·∥2and∥·∥∞are denoteddiam 2anddiam ∞respec- tively. The Euclidean projection (resp. the projection with respect to Mahalanobis norm∥·∥Afor a given matrixA∈ Sd ++(R)) onto a closed convex setX ⊂Rdis denotedΠ X(resp.Π X,A). The unit simplex inRddenoted as ∆d=( x∈Rd +,dX i=1xi= 1) . 2.Properties of operators This section recalls several basic definitions and introducesA-nonexpansiveness. A key remark is that operatorsFandF L:=I+1 L(F−I)(resp.F A:=I+A−1(F− I)) have the same fixed points for anyL >0(resp. for any matrixA∈ Sd ++(R)). NotethatF LisaspecialcaseofF A(withA=LI d). OperatorF Lcanbeinterpreted as a scaled version ofF, and operatorF Ais obtained fromFvia a kind of change of coordinates. Even ifFis not nonexpansive,F Amay very well be nonexpansive (for e.g., some Mahalanobis norm) and KM iterations withF Awould then converge to a fixed point ofF. Even ifFisnonexpansive,F Amay yield a better convergence for some matrixA. It will turn out that a natural notion isF Abeing nonexpansive with respect to∥·∥A, and that will be the definition ofA-nonexpansiveness. Besides, the fixed points of an operatorFare the zeros of associated operatorG=I−F 2, and the characterization throughGof (A-)nonexpansiveness ofFwill be particularly useful. Definition 2.1.LetF, G:X →Rdandx ∗∈ X. (i)x∗∈ Xis afixed pointof operatorFifF(x ∗) =x ∗. (ii)x ∗∈ Xis azeroof operatorGifG(x ∗) = 0. We now recall nonexpansiveness and introduce two successive extensions that involves",
    "an operatorFare the zeros of associated operatorG=I−F 2, and the characterization throughGof (A-)nonexpansiveness ofFwill be particularly useful. Definition 2.1.LetF, G:X →Rdandx ∗∈ X. (i)x∗∈ Xis afixed pointof operatorFifF(x ∗) =x ∗. (ii)x ∗∈ Xis azeroof operatorGifG(x ∗) = 0. We now recall nonexpansiveness and introduce two successive extensions that involves a positive scalar and a positive definite matrix respectively. Definition 2.2(Nonexpansiveness).LetF:X →Rdand∥·∥a norm inRd. (i) OperatorFisnonexpansivewith respect to∥·∥if for allx, x′∈ X, ∥F(x′)−F(x)∥⩽∥x′−x∥. IfFisnonexpansivewithrespectto∥·∥2,Fissimplysaidtobenonexpansive. (ii) LetL >0. OperatorFisL-nonexpansiveifI+1 L(F−I)is nonexpansive for ∥·∥2. 8 (iii) LetA∈ Sd ++(R). OperatorFisA-nonexpansiveifI+A−1(F−I)is nonex- pansive for∥·∥A. In the case whereL∈(0,1),L-nonexpansiveness corresponds to beingL- averaged, which is a notion that was first formalized in Baillon et al. [1978]. It is called so because the operator then is a convex combination of the identity and a nonexpansive operator. We here consider any valueL >0. Obviously, the notion ofA-nonexpansiveness encompasses the other two, which are recovered byA=I dandA=LI drespectively. Note thatA-nonexpansiveness ofFisnotequivalent to nonexpansiveness ofFwith respect to∥·∥A. As noted in Section 1, an operatorFmay fail to be nonexpansive and yet beA-nonexpansive for some matrixA∈ Sd ++(R). We now recall the notion of co-coercivity, and allow for arbitrary norms. It is well-known that the nonexpansiveness ofF(with respect to∥·∥2) is charac- terized by the co-coercivity ofG=I−F 2(with respect to∥·∥2). RegardingA- nonexpansiveness, its characterization will naturally involve co-coercivity with re- spect to∥·∥A. Definition 2.3(Co-coercivity for arbitrary norms).LetG:X →Rd,∥·∥a norm inRd, andL >0. OperatorGisL-co-coercivewith respect to∥·∥if for all x, x′∈ X, ⟨G(x′)−G(x), x′−x⟩⩾1 L∥G(x′)−G(x)∥2 ∗, where∥·∥∗denotes the dual norm of∥·∥. In the literature,L-co-coercivity is sometimes defined with factorLin the above right-hand side instead of1/L—see e.g., [Bauschke and Combettes, 2017]. The above convention has the advantage of the following linear property: ifGisL-co- coercive andη >0, thenηGisηL-co-coercive. Let us keep in mind that the same solutions can be expressed through various operators of interest: forF:X →RdandA∈ Sd ++(R), a pointx ∗∈ Xis a fixed point ofFif, and only if, it is a fixed point ofI+A−1(F−I), which is also equivalent to being a zero ofG:=I−F 2. We now extend the well-known characterization of nonexpansiveness (see e.g., [Bauschke and Combettes, 2017, Proposition 4.2]) toA-nonexpansiveness. Proposition 2.4.LetF:X →Rd,G=I−F 2, andA∈ Sd ++(R). Then,Fis A-nonexpansive if, and only if,Gis1-co-coercive for∥·∥A, in other words, (2)∀x, x′∈ X,⟨G(x′)−G(x), x′−x⟩⩾∥G(x′)−G(x)∥2 A−1. Proof.Note thatI+A−1(F−I) =I−2A−1G. This operator being nonexpansive for∥·∥Awrites (I−2A−1G)(x′)−(I−2A−1G)(x) 2 A⩽∥x′−x∥2 A, x, x′∈ X. Letx, x′∈ Xbe given. Developing the above left-hand side, we obtain (I−2A−1G)(x′)−(I−2A−1G)(x) 2 A= 4 A−1(G(x′)−G(x)) 2 A −4 A−1(G(x′)−G(x)), A(x′−x) +∥x′−x∥2 A = 4∥G(x′)−G(x)∥2 A−1−4⟨G(x′)−G(x), x′−x⟩+∥x′−x∥2 A. Plugging the above into the first inequality and rearranging gives the result.□ 9 Through the lens of the above characterization, the notionA-nonexpansiveness may feel more natural: for operatorF, going from nonexpansiveness toA- nonexpansiveness corresponds to norm∥·∥2being simply replaced by∥·∥Ain the co-coercivity of associated operatorG=I−F 2. 3.Fixed points via Online Linear Optimization This section first recalls the classical adversarial regret minimization framework called Online Linear Optimization as well as the regret bound of Online Gradient Descent (OGD), which is one of the most simple algorithms. We then turn to the connectionbetweenfixedpointsandregret: Lemma3.2providesanupperboundon fixed-point residuals that can be interpreted as a",
    "Linear Optimization This section first recalls the classical adversarial regret minimization framework called Online Linear Optimization as well as the regret bound of Online Gradient Descent (OGD), which is one of the most simple algorithms. We then turn to the connectionbetweenfixedpointsandregret: Lemma3.2providesanupperboundon fixed-point residuals that can be interpreted as a regret. This connection naturally suggest a scheme for converting regret minimization algorithms into fixed-point iterations, because bounds on the regret would then become bounds of the fixed- point residuals. As an illustration, Corollary 3.5 applies this conversion scheme to Online Gradient Descent and recovers the fundamental KM iterations and its analysis in the Euclidean case. 3.1.Online linear optimization.Online Linear Optimization [Zinkevich, 2003, Kalai and Vempala, 2005] can be described as a sequential decision problem where theDecision Makerchooses itsactionsin the closed convex setX ⊂Rd: at step t⩾1, •the Decision Marker choosesactionx t∈ X, •Nature chooses and revealspayoff vectoru t∈Rd, •the Decision Maker obtainspayoff⟨u t, xt⟩. LetT⩾1be an integer. The Decision Maker wishes to maximize its cumulative payoffPT t=1ut, but no worst-case type guarantee can be achieved on this quantity, in an absolute sense. We instead aim at establishing upper bounds on theregret (with respect to some comparison pointx∈ X): (3)TX t=1⟨ut, x⟩ −TX t=1⟨ut, xt⟩=TX t=1⟨ut, x−x t⟩, which compares the cumulative payoff actually obtained by the Decision Maker to thecumulativepayoffthathewouldhaveobtainedbychoosingactionxateachstep. We recall the elementary regret bound guaranteed by OGD in the unconstrained caseX=Rd. Proposition3.1(UnconstrainedOnlineGradientDescent).Let(u t)t⩾1a sequence inRd,η >0,x 1∈Rdand (4)x t+1=xt+ηu t, t⩾1. Then for all integerT⩾1andx∈Rd, TX t=1⟨ut, x−x t⟩=∥x−x 1∥2 2 2η+η 2TX t=1∥ut∥2 2. Proof.Fort⩾1, writing ∥xt+1−x∥2 2=∥x t+ηu t−x∥2 2=∥x t−x∥2 2+ 2⟨ηu t, xt−x⟩+η2∥ut∥2 2, thendividingby2η, summingovert= 1, . . . , Tandrearranginggivestheresult.□ 10 If the vectors(u t)t⩾1are assumed to be bounded, choosingη= 1/√ Tabove yields a regret bound that grows as√ T. In other words, theaverageregret has an upper bound that vanishes as1/√ T, which is a foundational result in adversarial regret minimization: with such an algorithm, for largeTand on average, the Deci- sion Maker is guaranteed to perform as well as the constant algorithm that chooses actionxat each step, this being true for allx∈ X. Beyond sequential decision problemsper se, regret minimization has deep con- nections with first-order optimization. OGD is of course an extension of Gradient Descent. But many other optimization algorithms can be analyzed using regret bounds e.g., the Nesterov Accelerated Gradient method [Nesterov, 1983] and Mir- ror Descent [Nemirovski and Yudin, 1983, Beck and Teboulle, 2003]. We now turn to the connection between regret and fixed points. 3.2.Key lemma.The following lemma is the key connection between fixed points and regret forA-nonexpansive operators. It provides an upper bound on afixed-point residual, which is a measure of how far a point is from being a fixed point—in particular, the residual is zero at a point if, and only if, it is a fixed point. We then remark that this upper bound can be interpreted as a (one-step) regret. Lemma 3.2.LetA∈ Sd ++(R),F:X →RdanA-nonexpansive operator and x∗∈ Xa fixed point ofF. Then for allx∈ X, ∥F(x)−x∥2 A−1⩽2⟨F(x)−x, x ∗−x⟩. Proof.LetG=I−F 2, which according to Proposition",
    "point if, and only if, it is a fixed point. We then remark that this upper bound can be interpreted as a (one-step) regret. Lemma 3.2.LetA∈ Sd ++(R),F:X →RdanA-nonexpansive operator and x∗∈ Xa fixed point ofF. Then for allx∈ X, ∥F(x)−x∥2 A−1⩽2⟨F(x)−x, x ∗−x⟩. Proof.LetG=I−F 2, which according to Proposition 2.4 is1-co-coercive for∥·∥A. By definition ofx ∗,G(x ∗) = 0. Letx∈ X. Using co-coercivity, ∥G(x)∥2 A−1=∥G(x)−G(x ∗)∥2 A−1⩽⟨G(x)−G(x ∗), x−x ∗⟩ =⟨G(x), x−x ∗⟩= x−F(x) 2, x−x ∗ . Besides,∥G(x)∥2 Arewrites as ∥G(x)∥2 A−1= x−F(x) 2 2 A−1=1 4∥F(x)−x∥2 A−1. The result follows from simplifying.□ We deduce the following immediate corollary by considering the weighted sum of the inequality from the above lemma, for each of the three cases: nonexpansiveness, L-nonexpansiveness andA-nonexpansiveness. Corollary 3.3.LetF:X →Rd,x∗∈ Xa fixed point ofF,T⩾1an integer, x1, . . . , x T∈ X, andγ 1, . . . , γ T>0. (i) IfFis nonexpansive, then TX t=1γt∥F(x t)−x t∥2 2⩽2TX t=1⟨γt(F(x t)−x t), x∗−xt⟩. (ii) LetL >0. IfFisL-nonexpansive, then TX t=1γt∥F(x t)−x t∥2 2⩽2LTX t=1⟨γt(F(x t)−x t), x∗−xt⟩. 11 (iii) LetA∈ Sd ++(R). IfFisA-nonexpansive, then TX t=1γt∥F(x t)−x t∥2 A−1⩽2TX t=1⟨γt(F(x t)−x t), x∗−xt⟩. By considering payoff vectorsu t=γt(F(x t)−x t)fort⩾1andη= 1, the above upper bounds have the form of a cumulative regret as in (3) and thus suggest the following approach. If points(x t)t⩾1are chosen so that some upper bound on the regret is guaranteed, the same bound holds for the (weighted) sum of the fixed-point residuals. Interestingly, in cases (ii) and (iii), the expression of the cumulative regretPT t=1⟨γt(F(x t)−x t), x∗−xt⟩does not depend onLorA, and therefore, the regret minimizing algorithm that chooses the points(x t)t⩾1need not have prior knowledgeofLorA. This feature will be of importance in Sections 5 and 6 when obtaining guarantees that that adapts toL-/A-nonexpansivenesswithout prior knowledgeofLorA. The nonexpansiveness assumptions in Lemma 3.2 and Corollary 3.5 above can easily be relaxed intoquasi-nonexpansiveness. For a given fixed pointx ∗∈ Xof FandA∈ Sd ++(R), we can define theA-quasi-nonexpansiveness operatorFwith respect tox ∗as operatorF A:=I+A−1(F−I)not increasing the distance tox ∗ (measured with∥·∥A), in other words ∀x∈ X,∥F A(x)−x ∗∥A⩽∥x−x ∗∥A. Then, extending Proposition 2.4, this property can seen to be equivalent tostar- co-coercivityofG(see [Gorbunov et al., 2022]): ∀x∈ X,∥G(x)∥2 A−1⩽⟨G(x), x−x ∗⟩, whereG= (I−F)/2, and the conclusions of Lemma 3.2 and Corollary 3.5 then remain true. The details are worked out in Appendix C. RegardingL-(quasi-)nonexpansiveness, we can further relax theglobalcharacter of the assumption, by considering in the lemma below alocalcoefficientL Tthat only depends on pointsx ∗, x1, . . . , x Tand their images by operatorF. Lemma 3.4.LetF:X →Rdbe an operator,x ∗∈ X,T⩾1an integer and x1, . . . , x T∈ Xsuch that LT:= infn L >0,∀1⩽t⩽T,∥F(x t)−x t∥2 2⩽2L⟨F(x t)−x t, x∗−xt⟩o is finite. Then, (i) Then, TX t=1∥F(x t)−x t∥2 2⩽2L TTX t=1⟨F(x t)−x t, x∗−xt⟩. (ii) LetL >0. IfFisL-nonexpansive and ifx ∗is a fixed point ofF, then LT⩽L. Proof.(i) follows from the definition ofL Tand (ii) folows from Lemma 3.2.□ Ifx∗∈ Xis a fixed point ofFand operatorFdoes satisfyL-nonexpansiveness for someglobalcoefficientL >0, then the abovelocalcoefficient satisfiesL T⩽L by Proposition 2.4 and",
    "TTX t=1⟨F(x t)−x t, x∗−xt⟩. (ii) LetL >0. IfFisL-nonexpansive and ifx ∗is a fixed point ofF, then LT⩽L. Proof.(i) follows from the definition ofL Tand (ii) folows from Lemma 3.2.□ Ifx∗∈ Xis a fixed point ofFand operatorFdoes satisfyL-nonexpansiveness for someglobalcoefficientL >0, then the abovelocalcoefficient satisfiesL T⩽L by Proposition 2.4 and we recover case (ii) in Corollary 3.3. But in cases where global coefficientLis infinite, or where local coefficientL Tis much lower, the above lemma will allow in Section 5 to obtain guarantees that scale withL T. 12 3.3.Krasnoselskii–Mann iterations as a special case.As a basic illustration of our conversion scheme, we combine Lemma 3.2 with the Online Gradient De- scent algorithm (4) to recover the classical KM iterations and its analysis in the Euclidean/Hilbert setting [Vaisman, 2005, Cominetti et al., 2014]. Corollary 3.5(Krasnoselskii–Mann iterations).LetF:X → Xbe a nonexpansive operator,x ∗∈ Xa fixed point ofF,(γ t)t⩾1a sequence in(0,1),x 1∈ Xand for t⩾1, xt+1=γtF(xt) + (1−γ t)xt. Then for allT⩾1, ∥F(x T)−x T∥2⩽∥x1−x∗∥2qPT t=1(1−γ t)γt. Proof.The iteration rewrites xt+1=xt+γt(F(x t)−x t), t⩾1, which corresponds to Online Gradient Descent (4) with payoff vectorsu t= γt(F(x t)−x t)(fort⩾1). Combining the regret bound from Proposition 3.1 with bound (i) in Corollary 3.3 gives TX t=1γt∥F(x t)−x t∥2 2⩽∥x 1−x∗∥2 2+TX t=1γ2 t∥F(x t)−x t∥2 2, which simplifies into TX t=1(1−γ t)γt∥F(x t)−x t∥2 2⩽∥x 1−x∗∥2 2. Let us now prove that(∥F(x t)−x t∥2)t⩾1is nonincreasing, the result will follow. Fort⩾1, using the nonexpansiveness ofF, ∥F(x t+1)−x t+1∥2=∥F(x t+1)−F(x t) +F(x t)−x t+1∥2 ⩽∥F(x t+1)−F(x t)∥2+∥F(x t)−x t+1∥2 ⩽∥x t+1−xt∥2+ (1−γ t)∥F(x t)−x t∥2 =γt∥F(x t)−x t∥2+ (1−γ t)∥F(x t)−x t∥2 =∥F(x t)−x t∥2. □ 4.Simple iterations for non-self mappings A requirement of the basic KM iteration is that operatorF:X → Xis aself mapping, meaning its images all belong to its convex domainX, so that the next iterate can be chosen as a weighted average of the current iterate and its image, which then remains in the domain. In this paper, we remove this assumption and consider operatorsF:X →Rdthat admit a fixed pointx ∗∈ X. Then, KM iterations are not defined in general. One idea is to consider operatorΠ X◦Fwhich is a self-mapping, is nonexpansive as soon asFis (because the projection is also nonexpansive), and each fixed point ofFis also a fixed point ofΠ X◦F. However, the converse is not true, there may 13 be fixed points ofΠ X◦Fthat are not fixed point ofF, and this is a drawback of this approach. Alternatively, Colao and Marino [2015] proposed to choose the averaging weights of the KM iteration at each step in such a way that the next iteratedoesbelong to thedomainX—inadditiontononexpansivenessofoperatorF, geometricconditions on the domainX(strict convexity) and the operatorF(inward condition) are required. We propose simple alternative algorithms based onProjectedOGD [Zinkevich, 2003] and Follow-the Regularized-Leader (FTRL, aka Dual Averaging) [Shalev- Shwartz and Singer, 2007, Abernethy et al., 2008, Nesterov, 2009, Xiao, 2010]. The resulting iterates are two different extensions of KM that recover a1/√ T convergence rate on the fixed-point residual, with no assumption other than nonex- pansiveness of operatorFand existence of a fixed point. The proof of the following regret",
    "and Singer, 2007, Abernethy et al., 2008, Nesterov, 2009, Xiao, 2010]. The resulting iterates are two different extensions of KM that recover a1/√ T convergence rate on the fixed-point residual, with no assumption other than nonex- pansiveness of operatorFand existence of a fixed point. The proof of the following regret bounds are given in Appendix A and B for completeness. Proposition 4.1(Regret bound for Projected Online Gradient Descent).Let (ut)t⩾1be a sequence inRd,x1∈Rdand (5)x t+1= ΠX(xt+ut), t⩾1. Then for all integerT⩾1andx∈Rd, TX t=1⟨ut, x−x t⟩⩽∥x−x 1∥2 2 2+1 2TX t=1∥ut∥2 2. Proposition 4.2(Regret bound for Follow-the-Regularized-Leader).Let(u t)t⩾1 be a sequence inRd,(ηt)t⩾2a positive and nonincreasing sequence,x 1∈ X, and xt+1= ΠX x1+ηt+1tX s=1ut! , t⩾1. Then for all integerT⩾1andx∈Rd, TX t=1⟨ut, x−x t⟩⩽∥x−x 1∥2 2 2ηT+TX t=1ηt∥ut∥2 2 2. The above regret minimizers are now turned into fixed-point iterations using the scheme described in Section 3.2. Theorem 4.3(Projected Krasnoselskii–Mann iterations).LetF:X →Rdbe a nonexpansive operator,x ∗∈ Xa fixed point ofF,(γ t)t⩾1a sequence in(0,1), x1∈ Xand fort⩾1, xt+1= ΠX(γtF(xt) + (1−γ t)xt). Then for allT⩾1, min 1⩽t⩽T∥F(x t)−x t∥2⩽∥x1−x∗∥2qPT t=1(1−γ t)γt. 14 Proof.Fort⩾1, considering payoff vectoru t=γt(F(x t)−x t), the points(x t)t⩾1 are the corresponding Projected Online Gradient Descent iterates, and we can write TX t=1γt∥F(x t)−x t∥2 2⩽2TX t=1⟨γt(F(x t)−x t), x∗−xt⟩ ⩽∥x 1−x∗∥2 2+TX t=1γ2 t∥F(x t)−x t∥2 2, where the first inequality holds by Corollary 3.3 and the second inequality is by the regret bound from Proposition 4.1. Rearranging gives TX t=1γt(1−γ t)∥F(x t)−x t∥2 2⩽∥x 1−x∗∥2 2. Dividing byPT t=1γt(1−γ t)and yields min 1⩽t⩽T∥F(x t)−x t∥2 2⩽PT t=1γt(1−γ t)∥F(x t)−x t∥2 2PT t=1γt(1−γ t)⩽∥x1−x∗∥2 2PT t=1(1−γ t)γt, hence the result.□ Like for basic KM iterations in Corollary 3.5, because the upper bound is the same, the best guarantee is obtained by choosingγ t= 1/2for allt⩾1. However, the bound holds on the lowest fixed-point residual so far, and not the last fixed- pointresidualasinCorollary3.5. Inthecontextofsmoothconvexoptimization, the corresponding algorithm is Projection Gradient Descent, which is known to offer a last-iterate guarantee on the optimality gapf(x T)−f(x ∗). Whether an analogous last-iterate guarantee is possible for fixed-point iterations is an interesting question. The following guarantee for FTRL iterates also holds for the lowest fixed-point residual so far. Theorem 4.4(Follow-the-Regularized-Leader for fixed points).LetF:X →Rd be a nonexpansive operator,x ∗∈ Xa fixed point ofF,(η t)t⩾1a nonincreasing sequence in(0,1),x 1∈ X, and xt+1= ΠX x1+ηt+1tX s=1(F(x t)−x t)! , t⩾1. Then for all integerT⩾1, min 1⩽t⩽T∥F(x t)−x t∥2⩽∥x1−x∗∥2q ηTPT t=1(1−η t). Proof.Applying regret bound from Proposition 4.2 together with Corollary 3.3 gives TX t=1∥F(x t)−x t∥2 2⩽∥x1−x∗∥2 2 ηT+TX t=1ηt∥F(x t)−x t∥2 2. Reorganizing gives TX t=1(1−η t)∥F(x t)−x t∥2 2⩽∥x1−x∗∥2 2 ηT, and the result follows.□ 15 Somewhat similarly to Projected KM iterations in Theorem 4.3, the best bound is obtained by choosingη t= 1/2for allt⩾1. Like the above iterations, the methods introduced in Sections 5 and 6 below also involve a projection onto the domainXand can therefore be used with non-self mappings. 5.Adaptivity to positive scalings In this section, we apply the conversion scheme presented in Section 3 to the AdaGrad-Normregretminimizerandobtainfixed-pointiterationsthatareadaptive to unknownL-nonexpansiveness, in other words to",
    "above iterations, the methods introduced in Sections 5 and 6 below also involve a projection onto the domainXand can therefore be used with non-self mappings. 5.Adaptivity to positive scalings In this section, we apply the conversion scheme presented in Section 3 to the AdaGrad-Normregretminimizerandobtainfixed-pointiterationsthatareadaptive to unknownL-nonexpansiveness, in other words to the most favorable positive scaling. More precisely, forL >0, operatorFbeingL-nonexpansive means by definition that associated operatorF L:=I+1 L(F−I)is nonexpansive. If such a coefficient Lwere known, and if operatorFadmits a fixed pointx ∗∈ X, KM iterates with operatorF Lcould be used (with e.g., constant weightsγ t= 1/2,t⩾1) and would offer the following guarantee: ∥F(x T)−x T∥2=L∥F L(xT)−x T∥2⩽2L∥x 1−x∗∥2√ T, T⩾1. Theadaptiveguarantee obtained in Theorem 5.2 below gives a bound with the same dependency inLandTwithout prior knowledge ofL. The AdaGrad family was initially introduced as regret minimization algorithms with step-sizes that depend on data observed in previous steps in a specific way [McMahan and Streeter, 2010, Duchi et al., 2011]. Perhaps the most pop- ular variant is called AdaGrad-Diagonal, and has per-coordinates step-sizes. This variant has been very successful for first-order optimization, especially in neural network optimization. Nowadays, the state-of-the-art optimizers for deep learning are variants of AdaGrad-Diagonal with stronger performance but lesser theoretical understanding, e.g., Tieleman and Hinton [2012], Kingma and Ba [2015]. Another variant within the family is AdaGrad-Full, which involves scalings using full matri- ces (instead of being restricted to diagonal matrices in the case of per-coordinate step-sizes), but has been less popular in practice, because each iteration then re- quires the computation ofA−1/2 tmultiplied by a vector, whereA tis a fulld×d matrix, which does not scale to high dimensions. We first focus on the most simple variant, sometimes called AdaGrad-Norm, which has a single step-size that depends on the data from previous steps. In the context of first-order convex optimization, an important theoretical guarantee explaining the good practical performance was obtained by Levy et al. [2018]. It established that the algorithm was adaptive to the unknown Lipschitz constant of the gradient of the objective function (also called the smoothness constant), in other words, it obtained a convergence guarantee that was similar to Gradient Descent tuned with prior knowledge of the smoothness constant. The adaptivity to unknownL-nonexpansiveness that we obtain for fixed points in Theorem 5.2 is analogous to that result, but is not a direct extension, as will be discussed. AdaGrad-Diagonal and AdaGrad-Full will also be converted for fixed points in Section 6 and will enjoy guarantees with stronger adaptivity. 16 The following statement first recalls the definition and the general regret bound for AdaGrad-Norm first studied in Levy [2017]. The proof is recalled in Appendix A for completeness. Proposition 5.1(Regret bound for AdaGrad-Norm).Let(u t)t⩾1be a sequence in Rd,η >0,x 1∈ Xand fort⩾1, xt+1= ΠX xt+ηqPt s=1∥us∥2 2ut . Then for allx∈ XandT⩾1, TX t=1⟨ut, x−x t⟩⩽ D2 2,T 2η+η!vuutTX t=1∥ut∥2 2. whereD 2,T= max 1⩽t⩽T ∥xt−x∥2. In particular, forD⩾(diam 2X), choosing η=D/√ 2yields TX t=1⟨ut, x−x t⟩⩽Dvuut2TX t=1∥ut∥2 2. For a given operatorF:X →R, the conversion scheme from Section 3.2 suggest using the above iteration with payoff vectorsu",
    "Then for allx∈ XandT⩾1, TX t=1⟨ut, x−x t⟩⩽ D2 2,T 2η+η!vuutTX t=1∥ut∥2 2. whereD 2,T= max 1⩽t⩽T ∥xt−x∥2. In particular, forD⩾(diam 2X), choosing η=D/√ 2yields TX t=1⟨ut, x−x t⟩⩽Dvuut2TX t=1∥ut∥2 2. For a given operatorF:X →R, the conversion scheme from Section 3.2 suggest using the above iteration with payoff vectorsu t=F(x t)−x t(fort⩾1), in other words xt+1= ΠX xt+ηqPt s=1∥F(x s)−x s∥2 2(F(x t)−x t) . As stated in Theorem 5.2 below, the domainXshould be known to contain a fixed pointx ∗and operatorFshould be defined at each point ofX.Fmay initially be defined on a larger set, but constraining the iterates onXmay improve convergence since we obtain below a convergence bound that scales linearly with the diameter of the setX. Fort⩾1, denoteη t=η/qPt s=1∥F(x s)−x s∥2 2. We can see that above itera- tions are special cases of KM iterationsifFtakes values inXandifη t<1for all t⩾1, which is equivalent to simply havingη <∥F(x 1)−x 1∥, because then xt+ηt(F(x t)−x t) = (1−η t)xt+ηtF(xt), is a convex combination of points ifXfor allt⩾1, and the projection stepΠ Xhas no effect. Theorem 5.2(Guarantee for AdaGrad-Norm for fixed points).LetF:X →Rd, x∗∈ Xa fixed point ofF,η >0,x 1∈ X, and fort⩾1, xt+1= ΠX xt+ηqPt s=1∥F(x s)−x s∥2 2(F(x t)−x t) . LetT⩾1be an integer and assume that LT:= infn L >0,∀1⩽t⩽T,∥F(x t)−x t∥2 2⩽2L⟨F(x t)−x t, x∗−xt⟩o is finite. 17 (i) Then, min 1⩽t⩽T∥F(x t)−x t∥2⩽LT√ T ∥x1−x∗∥2 2 η+ 3η+ 2 log\u0012ηLT ∥F(x 1)−x 1∥2\u0013! . (ii) Moreover, letD⩾(diam 2X). Then choosingη=D/√ 2yields min 1⩽t⩽T∥F(x t)−x t∥2⩽2√ 2DL T√ T. (iii) LetL >0. IfFisL-nonexpansive, then the above holds withL T⩽L. Proof.In the caseL T= 0, the definition ofL Timplies thatF(x t) =x tfor all 1⩽t⩽Tand the result trivially holds. We now assume thatL T>0. UsingLemma3.4andapplyingtheregretboundforAdaGrad-NormfromPropo- sition 5.1 with payoff vectorsu t=F(x t)−x t(fort⩾1) yields TX t=1∥F(x t)−x t∥2 2⩽2L T⟨F(x t)−x t, x∗−xt⟩ ⩽2L T max 1⩽t⩽T ∥xt−x∗∥2 2 2η+η!vuutTX t=1∥F(x t)−x t∥2 2. IfqPT t=1∥F(x t)−x t∥2 2= 0, the result holds. Otherwise, dividing the above by vuutTTX t=1∥F(x t)−x t∥2 2 gives min 1⩽t⩽T∥F(x t)−x t∥2⩽vuut1 TTX t=1∥F(x t)−x t∥2 2 ⩽LT√ T max 1⩽t⩽T ∥xt−x∗∥2 2 η+ 2η! .(6) In the case wheremax 1⩽t⩽T ∥xt−x∗∥2⩽D, the above bound together with the choiceη=D/√ 2yields upper bound (ii). Let us now prove guarantee (i). Lett⩾1. We denote ηt=ηqPt s=1∥F(x s)−x x∥2 2 so that xt+1= ΠX(xt+ηt(F(x t)−x t)). 18 Becausex ∗∈ X, we use the nonexpansiveness of projection operatorΠ Xto write ∥xt+1−x∗∥2 2=∥Π X(xt+ut)−Π X(x∗)∥2 2 ⩽∥x t+ut−x∗∥2 2 =∥x t−x∗∥2 2−2η t⟨F(x t)−x t, x∗−xt⟩+η2 t∥F(x t)−x t∥2 2 ⩽∥x t−x∗∥2 2−ηt LT∥F(x t)−x t∥2 2+η2 t∥F(x t)−x t∥2 2 =∥x t−x∗∥2 2+\u0012 η2 t−ηt LT\u0013 ∥F(x t)−x t∥2 2, where the second equality simply follows from the definition ofL T. Summing, we obtain ∥xt−x∗∥2 2⩽∥x 1−x∗∥2 2+t−1X s=1\u0012 η2 s−ηs LT\u0013 ∥F(x s)−x s∥2 2. Letτbe the largest integer in{1, . . . , T−1}such thatη τ⩾1/L T, orτ= 0if such an integer does not exist. Then because(η t)t⩾1is nonincreasing by definition, for all1⩽t⩽τ, it holds thatη t⩾1/L T. Then, ∥xt−x∗∥2 2⩽∥x 1−x∗∥2 2+τX s=1\u0012",
    "1−x∗∥2 2+t−1X s=1\u0012 η2 s−ηs LT\u0013 ∥F(x s)−x s∥2 2. Letτbe the largest integer in{1, . . . , T−1}such thatη τ⩾1/L T, orτ= 0if such an integer does not exist. Then because(η t)t⩾1is nonincreasing by definition, for all1⩽t⩽τ, it holds thatη t⩾1/L T. Then, ∥xt−x∗∥2 2⩽∥x 1−x∗∥2 2+τX s=1\u0012 η2 s−ηs LT\u0013 ∥F(x s)−x s∥2 2 ⩽∥x 1−x∗∥2 2+τX s=1η2 s∥F(x s)−x s∥2 2 =∥x 1−x∗∥2 2+η2 1 +τX s=2η−2 s−η−2 s−1 η−2s! ⩽∥x 1−x∗∥2 2+η2 1 +τX s=2Zη−2 s η−2 s−1dv v! =∥x 1−x∗∥2 2+η2\u0012 1 + log\u0012η−2 τ η−2 1\u0013\u0013 ⩽∥x 1−x∗∥2 2+η2\u0012 1 + 2 log\u0012ηLT ∥F(x 1)−x 1∥\u0013\u0013 . Plugging the above into (6) gives guarantee (i). Case (iii) whereFisL-nonexpansive follows from Lemma 3.4.□ The above guarantee gives an upper bound on the minimum of the fixed-point residuals of the past iterates measured with the Euclidean norm. The value of this minimum and the point achieving it is easy to track, as one only needs to store the value of the minimum and the corresponding point: then, at each step, the fixed- point residual at the new iterate is computed, compared with the stored minimum, and substituted if lower. In the case whereFisL-nonexpansive as in (iii) (or more generally, if(L T)T⩾1 is bounded), the upper bound vanishes at speed1/√ T(similarly to KM iterations) and has the same dependency inLas the bound that would be guaranteed by KM iterates defined with operatorF L:=I+1 L(F−I). But running KM iterations with operatorF Lrequires prior knowledge ofL. The guarantee for AdaGrad-Norm 19 iterates have the important advantage of beingadaptivein the sens that they do not require prior knowledge ofL. The upper bound also have a dependency in the distance to a solution: ∥x1−x∗∥2. Without any prior knowledge on this quantity, the upper bounds grow as the square of this distance. If an upper boundD 0on this distance is known, choosing parameterη=D 0makes the bound depend linearly inD 0. In the case where the domainXis bounded, its diameter can play the role ofD 0, as presented in (ii) above. An interesting question is whether it is possible to define iterations that achieve linear dependency in∥x 1−x∗∥with no prior knowledge on this quantity, and is left for future research. This adaptive guarantee is somewhat analogous to the adaptivity of AdaGrad- Norm in smooth convex optimization established by Levy et al. [2018]. In the latter setting however, the guarantee is an upper bound on the suboptimality gap which is defined in terms of the objection function. This quantity cannot be expressed nor bounded from above by the corresponding fixed-point residual. Therefore, the above guarantee for fixed points is not a direct extension of the result for smooth convex optimization. 6.Adaptivity to positive definite scalings We now apply the conversion scheme to the AdaGrad-Diagonal and AdaGrad- FullvariantsandobtainiterationsthatareadaptivetounknownA-nonexpansiveness (whereAis restricted to positive diagonal matrices in the former case). If an operatorF:X → X, that admits some fixed pointx ∗∈ X, isA- nonexpansiveforsomeknownmatrixA∈ Sd ++(R),thenoperatorF A:=I+A−1(F− I)is nonexpansive with respect to∥·∥Aby definition, and could be used in KM iterations that would guarantee (replacing⟨·,·⟩by⟨·,·⟩Ain Corollary 3.5): ∥F(x T)−x",
    "AdaGrad- FullvariantsandobtainiterationsthatareadaptivetounknownA-nonexpansiveness (whereAis restricted to positive diagonal matrices in the former case). If an operatorF:X → X, that admits some fixed pointx ∗∈ X, isA- nonexpansiveforsomeknownmatrixA∈ Sd ++(R),thenoperatorF A:=I+A−1(F− I)is nonexpansive with respect to∥·∥Aby definition, and could be used in KM iterations that would guarantee (replacing⟨·,·⟩by⟨·,·⟩Ain Corollary 3.5): ∥F(x T)−x T∥A−1=∥F A(xT)−x T∥A⩽2∥x 1−x∗∥A√ T, T⩾1. The adaptive guarantees that we obtain below will provide similar bounds without prior knowledge ofA. For a vectoru∈Rd,diagudenotes the diagonal matrix of sizedwith diagonal coefficients given byu. For a matrixA∈ Sd ++(R),A−1/2denotes the inverse of the square-root ofAand the projection ontoXwith respect to Mahalanobis norm ∥·∥Ais denotedΠ X,A. Proposition 6.1(Regret bound for AdaGrad-Diagonal).Let(u t)t⩾1be a sequence inRd,η, ε >0,x 1∈ Xand fort⩾1, xt+1= ΠX,A t(xt+A−1 tut), where At=η−1diag vuutε2+tX s=1u2 s,i  1⩽i⩽d. Letx∈ XandT⩾1. 20 (i) Then, TX t=1⟨ut, x−x t⟩⩽ε 2η∥x1−x∥2 2+ D2 ∞,T 2η+η! inf A∈Sd ++(R) Adiagonalvuut(TrA)TX t=1∥ut∥2 A−1, whereD ∞,T= max 1⩽t⩽T ∥xt−x∥∞. (ii) LetD⩾diam ∞(X). Then choosingη=D/√ 2yields TX t=1⟨ut, x−x t⟩⩽D εd√ 2+ inf A∈Sd ++(R) Adiagonalvuut2(TrA)TX t=1∥ut∥2 A−1 . Proposition 6.2(Regret bound for AdaGrad-Full).Let(u t)t⩾1be a sequence in Rd,η, ε >0,x 1∈ Xand fort⩾1, xt+1= ΠX,A t(xt+ηA−1 tut), where At=η−1 ε2Id+tX s=1usu⊤ s!1/2 . Letx∈ XandT⩾1. (i) Then, TX t=1⟨ut, x−x t⟩⩽ε 2η∥x1−x∥2 2+ max 1⩽t⩽T ∥xt−x∥2 2 2η+η! ×inf A∈Sd ++(R)vuut(TrA)TX t=1∥ut∥2 A−1. (ii) Moreover, letD⩾diam 2(X). Then choosingη=D/√ 2yields, TX t=1⟨ut, x−x t⟩⩽D εd√ 2+ inf A∈Sd ++(R)vuut(TrA)TX t=1∥ut∥2 A−1 . In the unconstrained caseX=Rd, both AdaGrad-Diagonal and AdaGrad-Full can be simply written xt+1=xt+A−1 tut, t⩾1. In both iterations, the only role ofε >0is to makeA tinvertible, and is taken very small in practice, e.g.,10−10. Theorem 6.3(Guarantee for AdaGrad-Diagonal for fixed points).LetF:X → Rd,x∗∈ Xa fixed point ofF,η, ε >0,x 1∈ X, and fort⩾1, xt+1= ΠX,A t(xt+A−1 t(F(x t)−x t)), where At=η−1diag vuutε2+tX s=1(F(x s)i−xs,i)2  1⩽i⩽d. LetT⩾1be an integer. 21 (i) IfA∈ Sd ++is a diagonal matrix such that for all1⩽t⩽T, ∥F(x t)−x t∥2 A−1⩽2⟨F(x t)−x t, x∗−xt⟩, then min 1⩽t⩽T∥F(x t)−x t∥A−1⩽r TrA T D2 ∞,T η+ 2η! +εdp T(TrA), whereD ∞,T= max 1⩽t⩽T ∥xt−x∗∥∞and consequently min 1⩽t⩽T∥F(x t)−x t∥2⩽r (TrA)λ max(A) T D2 ∞,T η+ 2η! +εd√ T. (ii) Moreover, letD⩾diam ∞(X). Then choosingη=D/√ 2yields, min 1⩽t⩽T∥F(x t)−x t∥A−1⩽2√ 2Dr TrA T+εdp T(TrA) and min 1⩽t⩽T∥F(x t)−x t∥2⩽2√ 2Dr (TrA)λ max(A) T+εd√ T. (iii) In particular, if operatorFisA-nonexpansive, the above guarantees(i) and(ii)hold. Proof.Summing inequality ∥F(x t)−x t∥2 A−1⩽2⟨F(x t)−x t, x∗−xt⟩, t⩾1, and applying the regret bound for AdaGrad-Diagonal from Proposition 6.1 gives TX t=1∥F(x t)−x t∥2 A−1 ⩽2 ε 2η∥x1−x∗∥2 2+ D2 ∞,T 2η+η!vuut(TrA)TX t=1∥F(x t)−x t∥2 A−1 , whereD ∞,T = max 1⩽t⩽T ∥xt−x∗∥∞. The above shows that quantityX=qPT t=1∥F(x t)−x t∥2 A−1satisfies inequalityX2⩽α+βX, where α=ε η∥x1−x∗∥2 2andβ= D2 ∞,T η+ 2η! √ TrA. We deduce that X⩽β+p β2+ 4α 2⩽1 2\u0012 β+βr 1 +4α β2\u0013 ⩽1 2\u0012 β+β\u0012 1 +2α β2\u0013\u0013 =β+α β=β+ε(TrA)−1/2∥x1−x∗∥2 2 max 1⩽t⩽T ∥xt−x∗∥2 ∞+ 2η2 ⩽β+ε(TrA)−1/2∥x1−x∗∥2 2 ∥x1−x∗∥2 ∞⩽β+εd√ TrA. 22 Then, dividing by√ T, we obtain min 1⩽t⩽T∥F(x t)−x t∥A−1⩽vuut1 TTX t=1∥F(x t)−x t∥2 A−1 ⩽r TrA T D2 ∞,T η+ 2η! +εdp T(TrA), whichgivesthefirstinequalityfrom(i).",
    "2\u0012 β+βr 1 +4α β2\u0013 ⩽1 2\u0012 β+β\u0012 1 +2α β2\u0013\u0013 =β+α β=β+ε(TrA)−1/2∥x1−x∗∥2 2 max 1⩽t⩽T ∥xt−x∗∥2 ∞+ 2η2 ⩽β+ε(TrA)−1/2∥x1−x∗∥2 2 ∥x1−x∗∥2 ∞⩽β+εd√ TrA. 22 Then, dividing by√ T, we obtain min 1⩽t⩽T∥F(x t)−x t∥A−1⩽vuut1 TTX t=1∥F(x t)−x t∥2 A−1 ⩽r TrA T D2 ∞,T η+ 2η! +εdp T(TrA), whichgivesthefirstinequalityfrom(i). Theotherinequalityonmin 1⩽t⩽T ∥F(x t)−x t∥2 is simply obtained by using inequalities ∥·∥2⩽p λmax(A)∥·∥A−1andλ max(A)⩽TrA. Then, (ii) follow immediately. Case (iii) simply corresponds to the sufficient condi- tion given by Lemma 3.2.□ Theorem 6.4(Guarantee for AdaGrad-Full for fixed points).LetF:X →Rd, x∗∈ Xa fixed point ofF,η, ε >0,x 1∈ X, and fort⩾1, xt+1= ΠX,A t(xt+A−1 t(F(x t)−x t)), where At=η−1 ε2+tX s=1(F(x s)−x s)(F(x s)−x s)⊤!1/2 . LetT⩾1be an integer. (i) If for all1⩽t⩽T, ∥F(x t)−x t∥2 A−1⩽2⟨F(x t)−x t, x∗−xt⟩, then min 1⩽t⩽T∥F(x t)−x t∥A−1⩽r TrA T D2 2,T η+ 2η! +εp T(TrA), whereD 2,T= max 1⩽t⩽T ∥xt−x∗∥2and consequently, min 1⩽t⩽T∥F(x t)−x t∥2⩽r λmax(A)(TrA) T D2 2,T η+ 2η! +ε√ T, (ii) Moreover, letD⩾diam 2(X). Then, choosingη=D/√ 2yields, min 1⩽t⩽T∥F(x t)−x t∥A−1⩽2Dr 2 TrA T+εp T(TrA), and therefore min 1⩽t⩽T∥F(x t)−x t∥2⩽2Dr 2λmax(A)(TrA) T+ε√ T. (iii) In particular, ifA∈ Sd ++is such that operatorFisA-nonexpansive, the above guarantees(i)and(ii)hold. Proof.The proof involves the regret bound for AdaGrad-Full from Proposition 6.2 and is similar to Theorem 6.4.□ 23 The assumption relating operatorFand matrixAin (i) in Theorems 6.3 and 6.4 is, as stated in (iii), a relaxation ofA-nonexpansiveness focusing on solutionx ∗, and which is local along the trajectory of iteratesx 1, . . . , x T. The existence of a matrix Asatisfying this condition is a relaxation of coefficientL Tfrom Theorem 5.2 being finite. The main guarantee in Theorems 6.3 and 6.4 is an upper bound on min 1⩽t⩽T∥F(x t)−x t∥A−1, meaning the lowest fixed-point residual so far, measured with norm∥·∥A−1, where Asatisfies the assumption from (i). This quantity is not tractable as matrixAmay be unknown. In particular, one does not know which point amongx 1, . . . , x Tactu- ally enjoys the upper bound on its fixed-point residual. Fortunately, a guarantee on min1⩽t⩽T ∥F(x t)−x t∥2is immediately deduced at the cost of a factorp λmax(A) in the bound. Although this a weaker guarantee, the quantity is at least tractable. Regarding AdaGrad-Diagonal, the adaptivity to the most favorable diagonal change of coordinates achieved in Theorem 6.3 is analogous to the results obtained for AdaGrad-Diagonal in the context of smooth convex optimization [Liu et al., 2024, Jiang et al., 2024], where the corresponding property is calledanisotropic smoothnessorcoordinate-wise smoothness. In the case of an unbounded domainX, unlike the guarantee for AdaGrad-Norm from Theorem 5.2, the above statements do not always guarantee a1/√ Tspeed of convergence over fixed-point residuals, because the distance to solutions (D ∞,T andD 2,Tin Theorems 6.3 and 6.4, respectively) appear in the upper bound and are not known to be bounded in general. In the context of smooth convex optimization however, AdaGrad-Diagonal has been proved to ensure the convergence of the it- erates [Traoré and Pauwels, 2021], and therefore their boundedness. Whether such a guarantee can be adapted to fixed points is",
    "upper bound and are not known to be bounded in general. In the context of smooth convex optimization however, AdaGrad-Diagonal has been proved to ensure the convergence of the it- erates [Traoré and Pauwels, 2021], and therefore their boundedness. Whether such a guarantee can be adapted to fixed points is an open question. In the case where the domainisbounded, or if the iterates are known to be bounded for some reason, we recover a1/√ Tconvergence rate. We now restrict the discussion to that case and focus on the dependency of the upper bounds in the diameter of the domain and in the matrixA. For this discussion, we neglect the term inε, as it is chosen very small in practice. Regarding the dependency inAand in the diameter of the domainX, the upper bound for AdaGrad-Diagonal scales as√ TrA(diam ∞X), whereas as discussed in the introduction, the KM iterations run with operatorF A:=I+A−1(F−I) would guarantee a dependency indiam AX, which denotes the diameter measured with∥·∥A. Although the latter quantity is lower in general, the upper bound for AdaGrad-Diagonal is in√ TrA(diam ∞X), without prior knowledge ofA, which is remarkable. The upper bound achieved by AdaGrad-Full is seemingly weaker, as it scales as√ TrA(diam 2X), but it is adaptive to all positive definite matricesA instead of just diagonal ones. Furthermore, let us compare the above guarantees for AdaGrad-Diagonal and AdaGrad-Full with the guarantee achieved by AdaGrad-Norm in Theorem 5.2. Di- rect comparison is difficult, because for the latter algorithms, the assumption is finer and the main guarantee is a bound on the fixed-point residuals measured with ∥·∥A−1and not∥·∥2as for AdaGrad-Norm. Of course, bounds on Euclidean fixed- point residuals can be deduced but are weaker than the main guarantee. We can nevertheless try the following comparison. Let us first assume that diagonal matrix 24 A∈ Sd ++(R)satisfies assumption from (i) in Theorem 6.3. Then, theL Tcoefficient from Theorem 5.2 can be bounded as follows: LT:= sup 1⩽t⩽T∥F(x t)−x t∥2 2 2⟨F(x t)−x t, x∗−xt⟩ ⩽sup 1⩽t⩽Tλmax(A)∥F(x t)−x t∥2 A−1 2⟨F(x t)−x t, x∗−xt⟩ ⩽λmax(A). Then, AdaGrad-Norm guarantees onmin 1⩽t⩽T ∥F(x t)−x t∥2 2an upper bound that scalesasdiam 2(X)λ max(A),whereasAdaGrad-Diagonalguaranteesanupperbound on the same quantitythat scalesdiam ∞(A)√ TrA. Comparing these two depen- dencies, the deduced bound for AdaGrad-Diagonal is stronger in cases where the ratio(diam ∞X)/(diam 2X)(which can be as low as1/√ d, depending on the shape of the domain) is significantly lower thatp λmax(A)/(TrA), which can be as high as1. But note that this comparison is biased towards AdaGrad-Norm, as the main guarantee for AdaGrad-Diagonal is on a different quantity. Direct comparison is even more difficult with AdaGrad-Full because, compared to AdaGrad-Diagonal and AdaGrad-Norm it does not offer a better bound on Eu- clidean residualsmin 1⩽t⩽T ∥F(x t)−x t∥2 2, but its advantage only comes from the fact that its main guarantee is a bound onmin 1⩽t⩽T ∥F(x t)−x t∥2 A−1, which may be a much higher quantity, becauseAmay be any positive definite matrix satisfying assumption from (i). UnlikeAdaGrad-Diagonal, webelievethattheinterestofAdaGrad-Fullismostly theoretical, because computingA−1/2 t(F(x t)−x t)requires an eigendecomposition andscalesasO(d3). Imayhoweverbeinterestingtoconsideravariantthatrestricts to a class of block-diagonal matrices that",
    "fact that its main guarantee is a bound onmin 1⩽t⩽T ∥F(x t)−x t∥2 A−1, which may be a much higher quantity, becauseAmay be any positive definite matrix satisfying assumption from (i). UnlikeAdaGrad-Diagonal, webelievethattheinterestofAdaGrad-Fullismostly theoretical, because computingA−1/2 t(F(x t)−x t)requires an eigendecomposition andscalesasO(d3). Imayhoweverbeinterestingtoconsideravariantthatrestricts to a class of block-diagonal matrices that remains scalable. 7.Numerical experiments We examine the practical advantage of using AdaGrad-based iterations (as well as a few variants) for solving fixed point problems. We consider three problems that are commonly solved by methods that can be interpreted as fixed-point iterations: finding the stationary distribution of a Markov chain, image denoising using total- variation regularization and solving two-player zero-sum games. These experiments are only presented as illustrations, and contain comparison with a given baseline method only. They do not aim at competing with state-of-the-art methods for each problem, which would be out of the scope of the present work. 7.1.AdaGrad variants as heuristics.In addition to AdaGrad-Norm and AdaGrad-Diagonal algorithms, we consider adaptations of RMSprop [Tieleman and Hinton, 2012] and Adam Kingma and Ba [2015] algorithms, which are AdaGrad variants that are extremely efficient in the context of deep learning. Their theo- retical understanding is not as solid as for AdaGrad, and we only consider them as heuristics. RMSprop replaces the plain sum in the square-root of the scaling by an exponential moving average. Adam also replaces the step direction vector F(xt)−x tby an exponential moving average. 25 (RMSprop-Norm) xt+1= ΠX xt+ηqPt s=1βt−s∥F(x s)−x s∥2 2(F(x t)−x t) , t⩾1. (Adam-Norm) xt+1= ΠX xt+ηqPt s=1βt−s∥F(x s)−x s∥2 2tX s=1αt−s(F(x s)−x s) , t⩾1. At=η−1diag vuutε2+tX s=1βt−s(F(x s)i−xs,i)2  1⩽i⩽d, xt+1= ΠX,A t\u0000 xt+A−1 t(F(x t)−x t)\u0001 , t⩾1.(RMSprop-Diagonal) At=η−1diag vuutε2+tX s=1βt−s(F(x s)i−xs,i)2  1⩽i⩽d, xt+1= ΠX,A t xt+A−1 t tX s=1αt−s(F(x s)−x s)!! , t⩾1.(Adam-Diagonal) In the experiments below, we useβ=.999andα=.9which are common defaults in deep learning. Values forηare obtained from tuning. We do not implement AdaGrad-Full iterations, as their precise computation does not scale well for large problems. 7.2.Markov chain stationary distribution computation.We construct a Markov Chain that is difficult to explore by splitting the states into two almost- disconnectedclusters. Letn⩾1and{1, . . . ,2n}bethesetsofstates. Let{1, . . . , n} and{n+ 1, . . . ,2n}bethetwoclusters. States1, n, n+1and2narecalledboundary statesand the others are calledinterior states. Letp∈(0,1)be the probability of jumping from one cluster to the other, uniformly. Conditionally on not jumping to the other cluster, an interior state (resp. boundary state) has probability1/3(resp. 1/2) to stay put and1/3to move to each neighbor (resp.1/2to move to its unique neighbor). These probabilities are encoded in the transition matrixP∈R2n×2n. We aim at iteratively computing the stationary distributionπ ∗that belongs to X= ∆ 2d(the unit simplex inR2d) that is defined by the fixed point property π∗P=π ∗. The basicpower iterationcorresponds toπ t+1=π tP(fort⩾1) [Kemeny and Snell, 1960]. We considern= 10000andp= 10−8. Convergence is observed through theℓ 1residual and is plotted in Figure 1. AdaGrad-Norm,RMSprop-Norm,AdaGrad-DiagonalandRMSprop-Diagonalachieve similar convergence as the power iteration. Adam-Norm and Adam-Diagonal how- ever, after an initial slower convergence, quickly reach lower values that the other methods, demonstrating a potential benefit for this problem.",
    "Snell, 1960]. We considern= 10000andp= 10−8. Convergence is observed through theℓ 1residual and is plotted in Figure 1. AdaGrad-Norm,RMSprop-Norm,AdaGrad-DiagonalandRMSprop-Diagonalachieve similar convergence as the power iteration. Adam-Norm and Adam-Diagonal how- ever, after an initial slower convergence, quickly reach lower values that the other methods, demonstrating a potential benefit for this problem. 26 0 100 200 300 400 500 Iteration10−810−710−610−510−4ℓ1residualPower iteration AdaGrad-Norm RMSprop-Norm Adam-Norm AdaGrad-Diagonal RMSprop-Diagonal Adam-Diagonal Figure 1.ComputationofthestationarydistributionofaMarkov chain. 7.3.Total variation image denoising with the Chambolle–Pock operator. Letm, n⩾1. We consider the classical ROF image denoising model [Rudin et al., 1992]: min u∈Rm×n\u001a1 2∥u−f∥2 2+λ∥∇u∥1\u001b , wheref∈Rm×ndenotesanoisygrayscaleimageofsizem×n,u∈Rm×ntheoutput (denoised) image,∇uthe spatial gradient, andλ >0a regularization parameter. The celebrated Chambolle–Pock (CP) algorithm [Chambolle and Pock, 2011] solves the dual problem and can be written as KM iterations associated with the following operator, defined for(u, p)∈Rm×n×R2(m×n)as Fτ,σ,λ(u, p) =\u0000 2u′−u,2·Π ∥·∥∞⩽λ(p+σ∇¯u)−p\u0001 , where u′=u+τdivp+τf 1 +τand¯u=u′+θ(u′−u), and wheredivdenotes the backward divergence operator andΠ ∥·∥∞⩽λthe component-wise projection onto theℓ∞ball of radiusλ. AdaGrad-based iterations onX=Rm×n×R2(m×n)and variants are implemented with the above operator. The image we use is the standard boat test image2of size512×512. Additive Gaussian noise with standard deviation0.1is applied. We use extrapolation pa- rameterθ= 1and regularization parameterλ= 0.1. The convergence is observed through the total-variation residual and is plotted in Figure 2. We try three differ- ent values for the step-sizesτandσ, to which the CP algorithm is very sensitive. Forτ=σ= 10−2, the convergence of the CP algorithm is relatively slow. The AdaGrad-Norm and AdaGrad-Diagonal algorithms also converge slowly. The AdaGrad-Norm algorithm seems to converge slightly faster than CP and the AdaGrad-Diagonal converges faster than CP during the initial iterations only. The RMSprop-Norm algorithm reaches lower values faster than the others algorithm, but is unstable, and the overall convergence speed seems comparable to the other 2https://sipi.usc.edu/database/preview/misc/boat.512.png 27 converging algorithms. Remaining algorithms Adam-Norm, RMSprop-Diagonal and Adam-Diagonal do not converge. Forτ=σ= 0.2, the CP algorithm, AdaGrad-Norm and AdaGrad-Diagonal converge quickly with similar speeds, with AdaGrad-Norm being slightly faster. The remaining algorithms do not converge. Forτ=σ= 1, the CP algorithm does not converge. Interestingly, AdaGrad- Norm and AdaGrad-Diagonal both still converge quickly. Adam-Norm reaches a solution up to numerical precision very quickly, but has a very unstable behavior. Remaining algorithms do not converge. Overall, the AdaGrad-Norm algorithm demonstrates good robustness and better performance than the CP algorithm, and even achieves fast convergence forτ= σ= 1, whereas then, the CP algorithm does not converge. The AdaGrad-Norm and RMSprop-Norm iterations are both used withη= 100 and achieve faster convergence than the Chambolle–Pock algorithm. AdaGrad-Diagonal withη= 3·10−2converge slightly fast up to 2 whereas RMSprop-Diagonal, Adam-Norm and Adam-Diagonal do not converge. 7.4.Solving games with the Mirror-Prox operator.Letm, n⩾1. We con- sider a two-player zero-sum game, encoded in a matrixA∈Rm×n. The von Neu- mann minimax theorem [von Neumann, 1928] ensures the existence of a solution (a∗, b∗)∈∆ m×∆ n, characterized by ⟨a∗, Ab∗⟩= max a∈∆ mmin b∈∆ n⟨a, Ab⟩ −min b∈∆ nmax a∈∆ m⟨a, Ab⟩. Then, a point(a, b)∈∆ m×∆ nis a solution if, and only if, its duality gap, defined as δ(a, b) := max a′∈∆m⟨a′, Ab⟩ −min b′∈∆n⟨a, b′⟩, is zero. This quantity is",
    "b∗)∈∆ m×∆ n, characterized by ⟨a∗, Ab∗⟩= max a∈∆ mmin b∈∆ n⟨a, Ab⟩ −min b∈∆ nmax a∈∆ m⟨a, Ab⟩. Then, a point(a, b)∈∆ m×∆ nis a solution if, and only if, its duality gap, defined as δ(a, b) := max a′∈∆m⟨a′, Ab⟩ −min b′∈∆n⟨a, b′⟩, is zero. This quantity is commonly used as a measure of convergence. Aclassicalapproachforsolvingsuchagameistocastitasavariationalinequality problem, because the above can be equivalently written as max (a,b)∈∆ m×∆n⟨G(a∗, b∗),(a, b)−(a ∗, b∗)⟩⩾0, where operatorGis defined as G(a, b) = (Ab,−A⊤a),(a, b)∈∆ m×∆ n. Key properties of this operator are Lipschitz continuity, and monotonicity, in the sense that ⟨G(a′, b′)−G(a, b,),(a′, b′)−(a, b)⟩,(a, b),(a′, b′)∈∆ m×∆ n. An important family of algorithms for solving variational inequalities with mono- tone and Lipschitz continuous operators is Mirror-Prox (MP) [Nemirovski, 2004], which involves the choice of a regularizer, aka distance-generating function which defines the underlying geometry followed by the algorithm. For simplicity, we only consider the Euclidean instance of MP, which can be rewritten as KM iterations associated with the following operator Fγ:= 2·Π ∆m×∆n◦(I−γ(G◦Π ∆m×∆n◦(I−γG)))−I, whereγ >0is a step-size. We perform experiments by sampling a game matrixAof size600×400and rank30, and using operatorF γonX= ∆ m×∆ n. The convergence is observed 28 0 2500 5000 7500 10000 12500 15000 17500 20000 Iteration10−310−1101103105TV residualChambolle-Pock AdaGrad-Norm RMSprop-Norm Adam-Norm Adagrad-Diagonal RMSprop-Diagonal Adam-Diagonal (a)τ=σ= 10−2, the Chambolle–Pock algorithm converges slowly. 0 2500 5000 7500 10000 12500 15000 17500 20000 Iteration10−1010−710−410−1102105TV residualChambolle-Pock AdaGrad-Norm RMSprop-Norm Adam-Norm Adagrad-Diagonal RMSprop-Diagonal Adam-Diagonal (b)τ=σ= 0.2, the Chambolle–Pock algorithm converges quickly. 0 2500 5000 7500 10000 12500 15000 17500 20000 Iteration10−1110−910−710−510−310−1101103105TV residualChambolle-Pock AdaGrad-Norm RMSprop-Norm Adam-Norm Adagrad-Diagonal RMSprop-Diagonal Adam-Diagonal (c)τ=σ= 1, the Chambolle–Pock algorithm does not converge. Figure 2.Total-variation image denoising. 29 through the duality gap and is plotted in Figure 3. MP is highly sensitive to the choice of the step-sizeγ, for which we try three different values. Forγ= 3·10−4, the MP algorithm converges slowly. Except for initial iterations, AdaGrad-Norm seems to converge slightly faster than MP. AdaGrad-Diagonal con- verges slightly slower than MP. The remaining algorithms do not converge. Forγ= 10−3, the MP algorithm converges quickly, and AdaGrad-Norm achieves a very similar convergence. AdaGrad-Diagonal converges faster than MP. The remaining algorithms do not converge. Forγ= 10−2, the MP algorithm does not converge. Except for RMSprop- Diagonal, all other algorithms quickly reach a solution up to numerical precision. Surprisingly, the fastest algorithm to reach a solution is RMSprop-Norm, which shows instability, as it diverges afterwards. AdaGrad-Norm and AdaGrad-Diagonal converge quickly (faster than MP withγ= 10−3). Overall, AdaGrad-Norm and AdaGrad-Diagonal seem to converge similarly to MP in cases where the latter converge, and still achieve (faster) convergence in the case where MP does not converge, demonstrating excellent robustness. RMSprop- Norm indicate the possibility of a very fast convergence in the case of a large step-sizeγ, but with instability. 8.Conclusion and perspectives We introduced a novel approach for defining and analyzing fixed point iterations based on regret minimization. This approach recovers the important Krasnoselskii– Mann iterations as a special case. The great variety of existing regret minimization algorithms with various sophisticated regret bounds suggest that this approach",
    "with instability. 8.Conclusion and perspectives We introduced a novel approach for defining and analyzing fixed point iterations based on regret minimization. This approach recovers the important Krasnoselskii– Mann iterations as a special case. The great variety of existing regret minimization algorithms with various sophisticated regret bounds suggest that this approach could give rise to many novel fixed-point iterations with interesting convergence properties, as well as shedding new light on existing ones. We also hope that this will lead to faster algorithms in practice in various fields of application. In this paper, we have obtained simple iterations for non-self mappings and then focused on iterations based on the AdaGrad family of regret minimizers. The conversion of AdaGrad-Norm into fixed-point iterations offered convergence guar- antees that areadaptiveto unknownL-nonexpansiveness (meaning to the most favorable positive scaling). AdaGrad-Diagonal and AdaGrad-Full achieved even stronger adaptivity toA-nonexpansiveness (meaning to the most favorable posi- tive definite change of coordinates). To the best of our knowledge, these adaptive guarantees are the first of their kind. Numerical experiments on three different problems demonstrated that AdaGrad- based iterations achieve faster convergence in practice than baseline methods. The ideas and results presented this work suggest a wide array of research directions—let us mention a few. Adaptivity to the distance to the solution.Parameterη >0in the AdaGrad- type iterations has to be chosen either as function of a known upper bound on the distance to the solution, or as function of the diameter of the domain (if finite), in order for the convergence bound to scale only linearly in the upper bound on the distance. Without such a known upper bound, the dependence becomes quadratic. In the context of convex optimization, parameter-free variants of AdaGrad that adaptively achieve the best dependence in the distance to the solution have been proposed [Orabona and Pál, 2018, Defazio and Mishchenko, 2023, Ivgi et al., 2023, 30 0 200 400 600 800 1000 Iteration10−310−210−1100101Duality gapMirror-Prox AdaGrad-Norm RMSprop-Norm Adam-Norm AdaGrad-Diagonal RMSprop-Diagonal Adam-Diagonal (a)γ= 3·10−4, the Mirror-Prox algorithm converges slowly. 0 200 400 600 800 1000 Iteration10−1510−1310−1110−910−710−510−310−1101Duality gapMirror-Prox AdaGrad-Norm RMSprop-Norm Adam-Norm AdaGrad-Diagonal RMSprop-Diagonal Adam-Diagonal (b)γ= 10−3, the Mirror-Prox algorithm converges quickly. 0 200 400 600 800 1000 Iteration10−1410−1110−810−510−2101Duality gapMirror-Prox AdaGrad-Norm RMSprop-Norm Adam-Norm AdaGrad-Diagonal RMSprop-Diagonal Adam-Diagonal (c)γ= 10−2, the Mirror-Prox algorithm does not converge. Figure 3.Solving a two-player zero-sum game. 31 Khaledetal.,2023]—obtaininganalogousiterationsforfixedpointsisaninteresting problem. More AdaGrad variants.Our numerical experiments include fixed-point iter- ations converted from AdaGrad variants RMSprop and Adam: these algorithms are very successful in deep learning optimization, but with lesser theoretical under- standing. From a practical perspective, we could further explore the performance of the many other AdaGrad variants [Reddi et al., 2018, Loshchilov and Hutter, 2019, Liu et al., 2020, Zhuang et al., 2020] even if they often lack solid theoretical guarantees. Some other AdaGrad variants both provide solid theoretical guarantees as well as excellent practical performance [Kavis et al., 2019, Antonakopoulos et al., 2022], and adapting them for fixed points looks very tempting and promising. Beyond finite dimension.The present work is restricted to finite dimension, but the theory of fixed-point iterations is much developed in Hilbert spaces [Bauschke and",
    "guarantees as well as excellent practical performance [Kavis et al., 2019, Antonakopoulos et al., 2022], and adapting them for fixed points looks very tempting and promising. Beyond finite dimension.The present work is restricted to finite dimension, but the theory of fixed-point iterations is much developed in Hilbert spaces [Bauschke and Combettes, 2017] and Banach spaces [Berinde, 2007]. An important question is whether a regret-based approach is possible and relevant in infinite dimension. At least, the extension to Hilbert spaces of the AdaGrad-Norm-based iterations should be straightforward. Adaptivity to contractive properties.An important aspect of fixed-point iter- ationsisthatcontractivepropertiesleadtogeometricconvergenceasintheBanach– Picard theorem. An interesting question is whether geometric convergence can be analyzed through regret minimization, and whether it can be achieved in situation when an unknown positive (definite) scaling is necessary to obtain a contractive operator. For instance, operator F(x) =Mx, x∈R2,whereM=\u0012 −α0 0 1−ε\u0013 , α >2,0< ε <2, from Section 1 is not a contraction (not even nonexpansive), but scaled operator FL:=I+1 L(F−I)is a(1+α−ε)/(1+α+ε)-contraction forL= (1+α+ε)/2. The question is whether there exists iterations that guarantee geometric convergence in such cases without prior knowledge ofL. Adaptive guarantees with1/Tconvergence.An important recent break- through regarding fixed-point iterations with nonexpansive operators is the1/T convergence obtained for carefullytuned Halperniterations [Halpern, 1967, Lieder, 2021]. A similar rate was also achieved using a Nesterov-type momentum applied to KM [Boţ and Nguyen, 2023]. A natural question is whether such fast rates can be recovered using the regret minimization approach and whether adaptivity to unknown positive (definite) scaling can be achieved in addition. Bundle methods: fixed points iterations with memory.In first-order con- vex optimization, a class of methods [Lemarechal, 1975, Kiwiel, 1983, 1990] use (a subset of) previously computed gradients to create a model of the objective function. For instance, as soon as a gradient of the objective function∇f(x t) is computed at some pointx t, then a minimizerx ∗belong to the half-space Xt:=\b x∈Rd,⟨x−x t,∇f(x t)⟩⩽0 because it holds by convexity that 0⩾f(x ∗)−f(x t)⩾⟨∇f(x t), x∗−xt⟩. 32 Then by keeping each previously computed gradient in memory, an algorithm can speed up convergence by performing at each step a projection onto the intersection of previous sets(X s)1⩽s⩽t. A similar remark holds with nonexpansive operatorsFwith fixed pointx ∗. As soon asF(x t)is computed at some pointx t, solutionx ∗necessarily belongs to half-space Xt:=( x∈Rd,⟨x, F(x t)−x t⟩⩽⟨x t, F(x t)−x t⟩ −∥xt−F(x t)∥2 2 4) , because by co-coercivity ofG=I−F 2(see Proposition 2.4), 0⩽ xt−F(x t) 2 2 2⩽ xt−F(x t) 2, xt−x∗ . Just like projected fixed points iterates on a constant domain are naturally ana- lyzedwithProjectedOnlineGradientDescentinTheorem4.3, projectedfixed-point iterations on smaller and smaller domain could be defined and analyzed through regret minimization. Stochastic approximations.An interesting extension is the setting where the operatorFis accessed through noisy observations [Bravo and Cominetti, 2024], which is closely related to the topic ofstochastic approximations[Robbins and Monro, 1951, Kiefer and Wolfowitz, 1952]. At timet⩾1, given a pointx t∈ X, if onlyF(x t) +ξ tis available, whereξ tis ax t-measurable random vector, then with notation and assumptions from Corollary 3.3, TX t=1γt∥F(x t)−x t∥2 2⩽2TX t=1⟨γt(F(x t)−x t), x∗−xt⟩",
    "closely related to the topic ofstochastic approximations[Robbins and Monro, 1951, Kiefer and Wolfowitz, 1952]. At timet⩾1, given a pointx t∈ X, if onlyF(x t) +ξ tis available, whereξ tis ax t-measurable random vector, then with notation and assumptions from Corollary 3.3, TX t=1γt∥F(x t)−x t∥2 2⩽2TX t=1⟨γt(F(x t)−x t), x∗−xt⟩ = 2TX t=1E[⟨γ t(F(x t)−x t+ξt), x∗−xt⟩ |x t], which gives, taking the expectation, E\"TX t=1γt∥F(x t)−x t∥2 2# ⩽E\" 2TX t=1⟨γt(F(x t)−x t+ξt), x∗−xt⟩# , where in the last expectation we recognize aregretwith respect to payoff vectors ut=F(x t)−x t+ξt. Then, an upper bound on a corresponding regret bound would also be an upper bound on the above left-hand side. Extending the approach of the present paper in that direction, and in particular, defining adaptive methods for stochastic approximations, is left for future work. Acknowledgments The author is indebted to Roberto Cominetti for introducing him to the topic of fixed point iterations, and Krasnoselskii–Mann iterations in particular, during the author’s stay at Universidad de Chile, Santiago, in November 2016, funded by ECOS-Sud project No.C15E03. This work was supported by the French Agence Nationale de la Recherche (ANR) under referenceANR-21-CE40-0020(CONVER- GENCE project), and by a public grant as part of theInvestissement d’avenir project, referenceANR-11-LABX-0056-LMH, LabEx LMH. This work also benefited 33 from insightful discussions with Patrick L. Combettes, Sylvain Sorin, Kfir Levy and Makiel Riveline. References J. Abernethy, E. Hazan, and A. Rakhlin. Competing in the dark: An efficient algorithm for bandit linear optimization. In21st Annual Conference on Learning Theory, 2008. K. Antonakopoulos, D. Q. Vu, V. Cevher, K. Levy, and P. Mertikopoulos. Under- Grad: A universal black-box optimization method with almost dimension-free convergence rate guarantees. InInternational Conference on Machine Learning, pages 772–795. PMLR, 2022. A. Attia and T. Koren. SGD with AdaGrad stepsizes: Full adaptivity with high probability to unknown parameters, unbounded gradients and affine variance. In International Conference on Machine Learning, pages 1147–1171, 2023. P. Auer, N. Cesa-Bianchi, and C. Gentile. Adaptive and self-confident on-line learning algorithms.Journal of Computer and System Sciences, 64(1):48–75, 2002. J. B. Baillon, R. E. Bruck, and S. Reich. On the asymptotic behavior of nonexpan- sive mappings and semigroups in Banach spaces.Houston Journal of Mathemat- ics, 4:1–9, 1978. J.-P. Baillon and R. E. Bruck. The rate of asymptotic regularity isO(1/√n). Lecture Notes in Pure and Applied Mathematics, 178:51–81, 1996. S. Banach. Sur les opérations dans les ensembles abstraits et leur application aux équations intégrales.Fundamenta Mathematicae, 3(1):133–181, 1922. H. H. Bauschke and P. L. Combettes.Convex analysis and monotone operator theory in Hilbert spaces. Springer Science & Business Media, 2nd edition, 2017. A. Beck and M. Teboulle. Mirror descent and nonlinear projected subgradient methods for convex optimization.Operations Research Letters, 31(3):167–175, 2003. R. Bellman.Dynamic Programming. Princeton University Press, 1957. V. Berinde.Iterative approximation of fixed points. Springer, 2007. R.I.BoţandD.-K.Nguyen. FastKrasnosel’ski˘ ı-Mannalgorithmwithaconvergence rate of the fixed point iteration ofo\u00001 k\u0001 .SIAM Journal on Numerical Analysis, 61(6):2813–2843, 2023. M. Bravo and R. Cominetti. Stochastic fixed-point iterations for nonexpansive maps: Convergence and error bounds.SIAM Journal on Control and Optimiza- tion, 62(1):191–219, 2024. C. G. Broyden. The convergence of a class of double-rank minimization",
    "ı-Mannalgorithmwithaconvergence rate of the fixed point iteration ofo\u00001 k\u0001 .SIAM Journal on Numerical Analysis, 61(6):2813–2843, 2023. M. Bravo and R. Cominetti. Stochastic fixed-point iterations for nonexpansive maps: Convergence and error bounds.SIAM Journal on Control and Optimiza- tion, 62(1):191–219, 2024. C. G. Broyden. The convergence of a class of double-rank minimization algorithms. IMA Journal of Applied Mathematics, 6(1):76–90, 1970. S. Bubeck.Introduction to Online Optimization: Lecture Notes. Princeton Univer- sity, 2011. E. Carlen. Trace inequalities and quantum entropy: An introductory course. In Entropy and the Quantum, volume 529 ofContemporary Mathematics, pages 73– 140. American Mathematical Society, 2010. A.-L. Cauchy. Méthode générale pour la résolution des systemes d’équations simul- tanées.Comptes rendus de l’Académie des sciences, 25(1847):536–538, 1847. N. Cesa-Bianchi and G. Lugosi.Prediction, Learning, and Games. Cambridge University Press, 2006. 34 N. Cesa-Bianchi, A. Conconi, and C. Gentile. On the generalization ability of on-line learning algorithms.IEEE Transactions on Information Theory, 50(9): 2050–2057, 2004. A. Chambolle and T. Pock. A first-order primal-dual algorithm for convex problems with applications to imaging.Journal of Mathematical Imaging and Vision, 40 (1):120–145, 2011. V. Colao and G. Marino. Krasnoselskii-Mann method for non-self mappings.Fixed Point Theory and Applications, 2015:1–7, 2015. P. L. Combettes. Solving monotone inclusions via compositions of nonexpansive averaged operators.Optimization, 53(5-6):475–504, 2004. P. L. Combettes. The geometry of monotone operator splitting methods.Acta Numerica, 33:487–632, 2024. P. L. Combettes and B. C. V˜ u. Variable metric quasi-Fejér monotonicity.Nonlinear Analysis: Theory, Methods & Applications, 78:17–31, 2013. P. L. Combettes and B. C. V˜ u. Variable metric forward–backward splitting with applications to monotone inclusions in duality.Optimization, 63(9):1289–1318, 2014. R. Cominetti, J. A. Soto, and J. Vaisman. On the rate of convergence of Krasnosel’skii–Mann iterations and their connection with sums of Bernoullis. Israel Journal of Mathematics, 199(2):757–772, 2014. A. Cutkosky. Anytime online-to-batch, optimism and acceleration. InInternational Conference on Machine Learning, pages 1446–1454. PMLR, 2019. A. Cutkosky and R. Busa-Fekete. Distributed stochastic optimization via adaptive SGD. InProceedings of the 32nd International Conference on Neural Information Processing Systems, pages 1914–1923, 2018. A. Cutkosky, H. Mehta, and F. Orabona. Optimal stochastic non-smooth non- convex optimization through online-to-non-convex conversion. InInternational Conference on Machine Learning, pages 6643–6670. PMLR, 2023. W. C. Davidon. Variable metric method for minimization.SIAM Journal on Optimization, 1(1):1–17, 1991. A. Defazio and K. Mishchenko. Learning-Rate-Free Learning by D-adaptation. In International Conference on Machine Learning, pages 7449–7479, 2023. A. Defazio, X. A. Yang, H. Mehta, K. Mishchenko, A. Khaled, and A. Cutkosky. The road less scheduled. InThe Thirty-eighth Annual Conference on Neural Information Processing Systems, 2024. A. Défossez, L. Bottou, F. Bach, and N. Usunier. A simple convergence proof of Adam and Adagrad.Transactions on Machine Learning Research, 2022. W. Dotson, Jr. Fixed points of quasi-nonexpansive mappings.Journal of the Australian Mathematical Society, 13(2):167–170, 1972. J. Douglas and H. H. Rachford. On the numerical solution of heat conduction problems in two and three space variables.Transactions of the American Math- ematical Society, 82:421–439, 1956. J. Duchi, E. Hazan, and Y. Singer. Adaptive subgradient methods for online learn- ing and stochastic optimization.Journal of Machine Learning Research, 12(Jul): 2121–2159, 2011. M. Edelstein. A remark on a theorem of M. A. Krasnoselski.American Mathemat- ical",
    "two and three space variables.Transactions of the American Math- ematical Society, 82:421–439, 1956. J. Duchi, E. Hazan, and Y. Singer. Adaptive subgradient methods for online learn- ing and stochastic optimization.Journal of Machine Learning Research, 12(Jul): 2121–2159, 2011. M. Edelstein. A remark on a theorem of M. A. Krasnoselski.American Mathemat- ical Monthly, 73:509–510, 1966. 35 M. Edelstein and R. C. O’Brien. Nonexpansive mappings, asymptotic regularity and successive approximations.Journal of the London Mathematical Society, 2 (3):547–554, 1978. M. Faw, I. Tziotis, C. Caramanis, A. Mokhtari, S. Shakkottai, and R. Ward. The power of adaptivity in SGD: Self-tuning step sizes with unbounded gradients and affine variance. InConference on Learning Theory, pages 313–355. PMLR, 2022. R. Fletcher. A new approach to variable metric algorithms.The Computer Journal, 13(3):317–322, 1970. R. Fletcher.Practical methods of optimization. John Wiley & Sons, 2nd ed. edition, 1987. Y. Freund and R. E. Schapire. Adaptive game playing using multiplicative weights. Games and Economic Behavior, 29(1):79–103, 1999. K. Goebel and W. A. Kirk. Iteration processes for nonexpansive mappings.Con- temporary Mathematics, 21:115–123, 1983. D. Goldfarb. A family of variable-metric methods derived by variational means. Mathematics of Computation, 24(109):23–26, 1970. E. Gorbunov, N. Loizou, and G. Gidel. Extragradient method:o(1/k)last-iterate convergence for monotone variational inequalities and connections with cocoer- civity. InInternational Conference on Artificial Intelligence and Statistics, pages 366–402. PMLR, 2022. C. W. Groetsch. A note on segmenting Mann iterates.Journal of Mathematical Analysis and Applications, 40(2):369–372, 1972. B. Halpern. Fixed points of nonexpanding maps.Bulletin of the American Mathe- matical Society, 73(6):957–961, 1967. J. Hannan. Approximation to Bayes risk in repeated play. InContributions to the Theory of Games, Vol. III, number 39 in Annals of Mathematics Studies, pages 97–139. Princeton University Press, 1957. S. Hart and A. Mas-Colell. A simple adaptive procedure leading to correlated equilibrium.Econometrica, 68:1127–1150, 2000. E. Hazan. Introduction to online convex optimization.Foundations and Trends in Optimization, 2(3-4):157–325, 2016. S. Ishikawa. Fixed points and iteration of a nonexpansive mapping in a Banach space.Proceedings of the American Mathematical Society, 59(1):65–71, 1976. M. Ivgi, O. Hinder, and Y. Carmon. DoG is SGD’s best friend: A parameter-free dynamic step size schedule. InInternational Conference on Machine Learning, pages 14465–14499, 2023. C. G. J. Jacobi. Ueber eine neue Auflösungsart der bei der Methode der kleinsten Quadrate vorkommenden lineären Gleichungen.Astronomische Nachrichten, 22 (20):297–306, 1845. R. Jiang, D. Maladkar, and A. Mokhtari. Convergence analysis of adaptive gra- dient methods under refined smoothness and noise assumptions.arXiv preprint arXiv:2406.04592, 2024. R. Jiang, A. Mokhtari, and F. Patitucci. Improved complexity for smooth non- convex optimization: A two-level online learning approach with quasi-Newton methods. InProceedings of the 57th Annual ACM Symposium on Theory of Computing, pages 2225–2236, 2025. A. Kalai and S. Vempala. Efficient algorithms for online decision problems.Journal of Computer and System Sciences, 71(3):291–307, 2005. 36 A. Kavis, K. Y. Levy, F. Bach, and V. Cevher. UnixGrad: A universal, adaptive algorithm with optimal guarantees for constrained optimization.Advances in Neural Information Processing Systems, 32, 2019. J. G. Kemeny and J. L. Snell.Finite Markov Chains. Van Nostrand, 1960. A. Khaled, K. Mishchenko, and C. Jin. DoWG unleashed: An efficient univer- sal parameter-free gradient descent method.Advances in Neural Information",
    "UnixGrad: A universal, adaptive algorithm with optimal guarantees for constrained optimization.Advances in Neural Information Processing Systems, 32, 2019. J. G. Kemeny and J. L. Snell.Finite Markov Chains. Van Nostrand, 1960. A. Khaled, K. Mishchenko, and C. Jin. DoWG unleashed: An efficient univer- sal parameter-free gradient descent method.Advances in Neural Information Processing Systems, 36:6748–6769, 2023. J. Kiefer and J. Wolfowitz. Stochastic estimation of the maximum of a regression function.The Annals of Mathematical Statistics, pages 462–466, 1952. D. P. Kingma and J. Ba. Adam: A method for stochastic optimization. InInter- national Conference on Learning Representations (ICLR), 2015. K. C. Kiwiel. An aggregate subgradient method for nonsmooth convex minimiza- tion.Mathematical Programming, 27:320–341, 1983. K. C. Kiwiel. Proximity control in bundle methods for convex nondifferentiable minimization.Mathematical Programming, 46(1-3):105–122, 1990. M. A. Krasnosel’skii. Two remarks on the method of successive approximations. Uspekhi Matematicheskikh Nauk, 10(1):123–127, 1955. H. W. Kuhn and A. W. Tucker. Nonlinear programming. InProceedings of the sec- ond Berkeley Symposium on Mathematical Statistics and Probability, California, pages 481–492, 1951. W. Kutta. Beitrag zur näherungsweisen Integration totaler Differentialgleichungen. Zeitschrift für Mathematik und Physik, 46:435–453, 1901. C. Lemarechal.An extension of Davidon methods to non differentiable problems, volume 3 ofMathematical Programming Study, pages 95–109. Springer Berlin Heidelberg, 1975. K. Y. Levy. Online to offline conversions, universality and adaptive minibatch sizes. InAdvances in Neural Information Processing Systems, pages 1613–1622, 2017. K. Y. Levy, A. Yurtsever, and V. Cevher. Online adaptive methods, universality and acceleration. InAdvances in Neural Information Processing Systems, pages 6500–6509, 2018. F. Lieder. On the convergence rate of the Halpern-iteration.Optimization Letters, 15(2):405–418, 2021. E. Lindelöf. Sur l’application des méthodes d’approximations successives à l’étude des intégrales réelles des équations différentielles ordinaires.Journal de mathé- matiques pures et appliquées, 10:117–128, 1894. P.-L. Lions and B. Mercier. Splitting algorithms for the sum of two nonlinear operators.SIAM Journal on Numerical Analysis, 16(6):964–979, 1979. L. Liu, H. Jiang, P. He, W. Chen, X. Liu, J. Gao, and J. Han. On the variance of the adaptive learning rate and beyond. InInternational Conference on Learning Representations, 2020. Y. Liu, R. Pan, and T. Zhang. AdaGrad under anisotropic smoothness.arXiv preprint arXiv:2406.15244, 2024. Z. Liu, T. D. Nguyen, A. Ene, and H. Nguyen. On the convergence of AdaGrad (Norm) onRd: Beyond convexity, non-asymptotic rate and acceleration. InThe Eleventh International Conference on Learning Representations, 2023. I. Loshchilov and F. Hutter. Decoupled weight decay regularization. InInterna- tional Conference on Learning Representations, 2019. 37 W. Mann. Mean value methods in iteration.Proceedings of the American Mathe- matical Society, 4(3):506–510, 1953. B. Martinet. Régularisation d’inéquations variationnelles par approximations suc- cessives.Revue française d’informatique et de recherche opérationnelle. Série rouge, 4(R3):154–158, 1970. H. B. McMahan and M. Streeter. Adaptive bound optimization for online convex optimization. In23rd Conference on Learning Theory, pages 244–256, 2010. J. A. Meijerink and H. A. Van der Vorst. An iterative solution method for linear systems of which the coefficient matrix is a symmetric M-matrix.Mathematics of Computation, 31(137):148–162, 1977. A. Nemirovski. Prox-method with rate of convergenceO(1/t)for variational in- equalities with Lipschitz continuous monotone operators and smooth convex- concave saddle point problems.SIAM Journal on Optimization, 15(1):229–251, 2004. A. Nemirovski and D. B.",
    "solution method for linear systems of which the coefficient matrix is a symmetric M-matrix.Mathematics of Computation, 31(137):148–162, 1977. A. Nemirovski. Prox-method with rate of convergenceO(1/t)for variational in- equalities with Lipschitz continuous monotone operators and smooth convex- concave saddle point problems.SIAM Journal on Optimization, 15(1):229–251, 2004. A. Nemirovski and D. B. Yudin.Problem Complexity and Method Efficiency in Optimization. Wiley Interscience, 1983. Y. Nesterov. Primal-dual subgradient methods for convex problems.Mathematical Programming, 120(1):221–259, 2009. Y. E. Nesterov. A method of solving a convex programming problem with conver- gence rate0(1/k2).Soviet Mathematics. Doklady, 27:372–376, 1983. Z. Opial. Weak convergence of the sequence of successive approximations for non- expansive mappings.Bull. Am. Math. Soc., 73:591–597, 1967. F. Orabona. A modern introduction to online learning.arXiv:1912.13213, 2025. F. Orabona and D. Pál. Scale-free online learning.Theoretical Computer Science, 716:50–69, 2018. V. Perchet. Approachability, regret and calibration: Implications and equivalences. Journal of Dynamics and Games, 1(2):181–254, 2014. B. T. Polyak. Introduction to optimization.Optimization Software, 1987. S. J. Reddi, S. Kale, and S. Kumar. On the convergence of Adam and beyond. In International Conference on Learning Representations, 2018. S. Reich. Weak convergence theorems for nonexpansive mappings in Banach spaces. J. Math. Anal. Appl, 67(2):274–276, 1979. L. F. Richardson. The approximate arithmetical solution by finite differences of physical problems involving differential equations, with an application to the stresses in a masonry dam.Philosophical Transactions of the Royal Society of London Series A, 210:307–357, 1911. H. Robbins and S. Monro. A stochastic approximation method.The Annals of Mathematical Statistics, pages 400–407, 1951. L. I. Rudin, S. Osher, and E. Fatemi. Nonlinear total variation based noise removal algorithms.Physica D, 60(1-4):259–268, 1992. C. Runge. Über die numerische Auflösung von Differentialgleichungen.Mathema- tische Annalen, 46(2):167–178, 1895. E. K. Ryu and S. Boyd. A primer on monotone operator methods.Applied and Computational Mathematics, 15(1):3–43, 2016. E. K. Ryu and W. Yin.Large-scale convex optimization: algorithms & analyses via monotone operators. Cambridge University Press, 2022. H. Schaefer. Über die Methode sukzessiver Approximationen.Jahresbericht der Deutschen Mathematiker-Vereinigung, 59:131–140, 1957. 38 L. Seidel. Über ein Verfahren, die Gleichungen, auf welche die Methode der klein- sten Quadrate führt, sowie lineare Gleichungen überhaupt, durch sucessive An- näherung aufzulösen.Abhandlungen der Königlich Bayerischen Akademie der Wissenschaften, 11(3):83–108, 1874. S. Shalev-Shwartz.Online learning: Theory, Algorithms, and Applications. PhD thesis, The Hebrew University of Jerusalem, 2007. S. Shalev-Shwartz. Online learning and online convex optimization.Foundations and Trends in Machine Learning, 4(2):107–194, 2011. S. Shalev-Shwartz and Y. Singer. A primal-dual perspective of online learning algorithms.Machine Learning, 69:115–142, 2007. D. F. Shanno. Conditioning of quasi-Newton methods for function minimization. Mathematics of Computation, 24(111):647–656, 1970. T. Tieleman and G. Hinton. Lecture 6.5-RMSprop: Divide the gradient by a run- ning average of its recent magnitude, 2012. C.TraoréandE.Pauwels. SequentialconvergenceofAdaGradalgorithmforsmooth convex optimization.Operations Research Letters, 49(4):452–458, 2021. J. Vaisman. Convergencia fuerte del método de medias sucesivas para operadores lineales no-expansivos. Memoria de ingenierıa civil matemática, Universidad de Chile, 2005. R. S. Varga.Matrix iterative analysis. Prentice-Hall, Inc., 1962. J. von Neumann. Zur theorie der Gesellschaftsspiele.Mathematische annalen, 100 (1):295–320, 1928. B. Wang, H. Zhang, Z.-M. Ma, and W. Chen. Convergence of AdaGrad for non- convex objectives: Simple proofs and relaxed assumptions. InThe Thirty Sixth Annual Conference",
    "matemática, Universidad de Chile, 2005. R. S. Varga.Matrix iterative analysis. Prentice-Hall, Inc., 1962. J. von Neumann. Zur theorie der Gesellschaftsspiele.Mathematische annalen, 100 (1):295–320, 1928. B. Wang, H. Zhang, Z.-M. Ma, and W. Chen. Convergence of AdaGrad for non- convex objectives: Simple proofs and relaxed assumptions. InThe Thirty Sixth Annual Conference on Learning Theory, pages 161–190. PMLR, 2023. R. Ward, X. Wu, and L. Bottou. AdaGrad stepsizes: Sharp convergence over nonconvex landscapes.The Journal of Machine Learning Research, 21(1):9047– 9076, 2020. L. Xiao. Dual averaging methods for regularized stochastic learning and online optimization.Journal of Machine Learning Research, 11(Oct):2543–2596, 2010. Y. Xie, X. Wu, and R. Ward. Linear convergence of adaptive stochastic gradient descent. InInternational Conference on Artificial Intelligence and Statistics, pages 1475–1485. PMLR, 2020. D. Young. Iterative methods for solving partial difference equations of elliptic type. Transactions of the American Mathematical Society, 76:92–111, 1954. ISSN 0002- 9947. J. Zhuang, T. Tang, Y. Ding, S. C. Tatikonda, N. Dvornek, X. Papademetris, and J. Duncan. AdaBelief optimizer: Adapting stepsizes by the belief in observed gradients. InAdvances in Neural Information Processing Systems, volume 33, pages 18795–18806, 2020. M. Zinkevich. Online convex programming and generalized infinitesimal gradient ascent. InProceedings of the Twentieth International Conference on Machine Learning, 2003. M. Zinkevich, M. Johanson, M. Bowling, and C. Piccione. Regret minimization in games with incomplete information. InAdvances in Neural Information Process- ing Systems, volume 20, pages 1729–1736, 2007. 39 AppendixA.Mirror Descent type regret bounds We first state a generic regret bound for Online Mirror Descent associated with nondecreasing squared Mahalanobis norms that contain as special cases Projected Online Gradient Descent, AdaGrad-Norm, AdaGrad-Diagonal and AdaGrad-Full. Specific bounds for each of these special cases are then deduced. Proposition A.1(Regret bound for Online Mirror Descent with nondecreasing squared Mahalanobis norms).Let(u t)t⩾1be a sequence inRd,(A t)t⩾0a sequence inSd ++(R)such thatA t+1−A tis positive semidefinite for allt⩾1. Letx 1∈ X and xt+1= ΠX,A t(xt+A−1 tut), t⩾1. Letx∈ XandT⩾1. (i) Then, TX t=1⟨ut, x−x t⟩⩽∥x−x 1∥2 A0 2+1 2TX t=1\u0010 ∥x−x t∥2 At−At−1+∥u t∥2 A−1 t\u0011 . (ii) LetA∈ Sd ++(R)and(η t)t⩾1be a positive and nonincreasing sequence. If At=η−1 tIdfor allt⩾1, then xt+1= ΠX(xt+ηtut), t⩾1, and TX t=1⟨ut, x−x t⟩⩽max 1⩽t⩽T∥x−x 1∥2 2 2ηT+TX t=1ηt∥ut∥2 2 2. Proof.Lett⩾1. Becausex∈ XandtheprojectionoperatorΠ X,A tisnonexpansive for∥·∥At, using the definitionx t+1yields ∥xt+1−x∥2 At⩽ xt+A−1 tut−x 2 At=∥x t−x∥2 At−2⟨u t, xt−x⟩+∥u t∥2 A−1 t. It follows that ⟨ut, x−x t⟩⩽∥x−x t∥2 At 2−∥x−x t+1∥2 At+1 2+∥x−x t+1∥2 At+1−At 2+∥ut∥2 A−1 t 2. Then summing yields inequality (i). We now turn to (ii). InjectingA t=η−1 tId into the general case, we obtain TX t=1⟨ut, x−x t⟩⩽∥x−x 1∥2 2 2η1+TX t=2\u00121 ηt−1 ηt−1\u0013∥x−x t∥2 2 2+TX t=1ηt∥ut∥2 2 2. Because the sequence(η t)t⩾1is positive and nonincreasing,1/η t−1/η t−1⩾0and we can bound each squared distance∥x−x t∥2 2by their maximum and write TX t=1⟨ut, x−x t⟩⩽max 1⩽t⩽T∥x−x t∥2 2 2ηT+TX t=1ηt∥ut∥2 2 2. □ 40 A.1.Projected Online Gradient Descent: proof of Proposition 4.1.Pro- jected Online Gradient Descent corresponds to Online Mirror Descent onXwith constant matrixA t=Id(for allt⩾1). Then, the iteration reduces to xt+1= arg min x∈X1 2∥x−(x t+ut)∥2 2= ΠX(xt+ut), t⩾1, whichisexactlyProjectionOnlineGradientDescent. TheregretboundfromPropo- sition",
    "x−x t⟩⩽max 1⩽t⩽T∥x−x t∥2 2 2ηT+TX t=1ηt∥ut∥2 2 2. □ 40 A.1.Projected Online Gradient Descent: proof of Proposition 4.1.Pro- jected Online Gradient Descent corresponds to Online Mirror Descent onXwith constant matrixA t=Id(for allt⩾1). Then, the iteration reduces to xt+1= arg min x∈X1 2∥x−(x t+ut)∥2 2= ΠX(xt+ut), t⩾1, whichisexactlyProjectionOnlineGradientDescent. TheregretboundfromPropo- sition A.1 boils down to TX t=1⟨ut, x−x t⟩⩽∥x−x 1∥2 2 2+TX t=1∥ut∥2 2 2, hence the result. A.2.AdaGrad-Norm: proof of Proposition 5.1.The proof is adapted from Levy [2017]. Ifu t= 0for allt⩾1, the result holds. Otherwise, let τ= min{t⩾1, u t̸= 0}. Let(η t)t⩾1be a positive and nonincreasing sequence defined as ηt=  η ∥uτ∥2ift⩽τ ηqPt s=1∥us∥2 2ift⩾τ. Then,(x t)t⩾1is a sequence of Projected OGD iterates onXwith positive and nonincreasing step-sizes(η t)t⩾1as in Proposition A.1 (ii), because for1⩽t⩽τ−1, ut= 0and thus, xt+1= ΠX(xt) = Π X(xt+ηtut), and fort⩾τ, xt+1= ΠX xt+ηqPt s=1∥us∥2 2ut = ΠX(xt+ηtut). IfT < τ, the result holds because both quantities are zero. IfT⩾τ, the regret bound for Projected OGD with nonincreasing step-sizes from Proposition A.1 (ii) gives TX t=1⟨ut, x−x t⟩⩽max 1⩽t⩽T∥x−x t∥2 2 2ηT+TX t=1ηt∥ut∥2 2 2 =max 1⩽t⩽T∥xt−x∥2 2 2ηvuutTX t=1∥ut∥2 2+η 2TX t=1∥ut∥2 2qPt s=1∥us∥2 2 ⩽ max 1⩽t⩽T ∥xt−x∥2 2 2η+η!vuutTX t=1∥ut∥2 2. using Lemma A.2 below. Hence the result. 41 Lemma A.2(Lemma 3.5 in Auer et al. [2002]).Let(a t)t⩾1be a nonnegative sequence. Then for allT⩾1, TX t=1atqPt s=1as⩽2vuutTX t=1at. with convention0/0 = 0. A.3.AdaGrad-Diagonal: proof of Proposition 6.1.The proof is adapted from Duchi et al. [2011]. LetA 0=η−1εId. Then,(x t)t⩾1is the sequence of Online Mirror Descent iterates onXassociated with positive diagonal matrices(A t)t⩾1. Then, Proposition A.1 gives (7)TX t=1⟨ut, x−x t⟩⩽ε∥x−x 1∥2 2 2η+1 2TX t=1∥ut∥2 A−1 t+1 2TX t=1∥x−x t∥2 At−At−1. Because matrices(A t)t⩾0are diagonal and nonincreasing, the above last sum is bounded as 1 2TX t=2∥x−x t∥2 At−At−1=1 2TX t=1dX i=1(xi−xt,i)2(At,ii−At−1,ii ) ⩽max 1⩽t⩽T∥x−x t∥2 ∞ 2dX i=1TX t=1(At,ii−At−1,ii ) =max 1⩽t⩽T∥x−x t∥2 ∞ 2dX i=1(AT,ii−A 0,ii) =max 1⩽t⩽T∥x−x t∥2 ∞ 2ηdX i=1 vuutε2+TX t=1u2 t,i−ε  ⩽max 1⩽t⩽T∥x−x t∥2 ∞ 2ηdX i=1vuutTX t=1u2 t,i.(8) Regarding the second term from the right-hand side of (7), 1 2TX t=1∥ut∥2 A−1 t=η 2TX t=1dX i=1u2 t,iq ε2+Pt s=1u2 s,i ⩽η 2TX t=1dX i=1u2 t,iqPt s=1u2 s,i ⩽ηdX i=1vuutTX t=1u2 t,i ⩽ηinf A∈Sd ++(R) Adiagonalvuut(TrA)TX t=1∥ut∥2 A−1,(9) 42 where we used Lemma A.2 (resp. Lemma A.3 below) for the penultimate inequality (resp. the last inequality). Then combining (7), (8) and (9) gives the result. Lemma A.3.Letb= (b 1, . . . , b d)∈Rd +. Then, dX i=1bi= inf A∈Sd ++(R) Adiagonalvuut(TrA)dX i=1∥b∥2 A−1. Proof.Leta 1, . . . , a d>0. Then using Jensen’s inequality forz7→z2, dX i=1 aiPd j=1aj!\u0012bi ai\u0013!2 ⩽dX i=1aiPd j=1ajb2 i a2 i=dX i=1b2 i/aiPd j=1aj. Taking the square root gives dX i=1bj⩽vuuut dX j=1aj dX i=1b2 i ai=vuut(TrA)dX i=1∥b∥2 A−1, whereA= diag(a 1, . . . , a d)is a positive diagonal matrix. This proves dX i=1bi⩽inf A∈Sd ++(R) Adiagonalvuut(TrA)dX i=1∥b∥2 A−1. Letε >0and consider ai=bi+ε,1⩽i⩽d, which are always positive. Then, vuut(TrA)dX i=1b2 i ai=vuuut dX j=1bj+dε dX i=1bi 1 +ε which converges toPd i=1biasε→0+. This proves dX",
    "i=1∥b∥2 A−1, whereA= diag(a 1, . . . , a d)is a positive diagonal matrix. This proves dX i=1bi⩽inf A∈Sd ++(R) Adiagonalvuut(TrA)dX i=1∥b∥2 A−1. Letε >0and consider ai=bi+ε,1⩽i⩽d, which are always positive. Then, vuut(TrA)dX i=1b2 i ai=vuuut dX j=1bj+dε dX i=1bi 1 +ε which converges toPd i=1biasε→0+. This proves dX i=1bi⩾inf A∈Sd ++(R) Adiagonalvuut(TrA)dX i=1∥b∥2 A−1. Hence the result.□ A.4.AdaGrad-Full: proof of Proposition 6.2.The proof is adapted from Duchi et al. [2011]. Similarly to the proof of the regret bound for AdaGrad- Diagonal, applying Proposition A.1 withA 0=η−1εIdyields (10)TX t=1⟨ut, x−x t⟩⩽ε∥x−x 1∥2 2 2η+1 2TX t=1∥x−x t∥2 At−At−1+1 2TX t=1∥ut∥2 A−1 t. 43 The above second term can be bounded from above as 1 2TX t=1∥x−x t∥2 At−At−1=1 2TX t=1⟨x−x t,(At−At−1)(x−x t)⟩ ⩽1 2TX t=1∥x−x t∥2 2·λmax(At−At−1) ⩽1 2TX t=1∥x−x t∥2 2·Tr(A t−At−1) ⩽1 2max 1⩽t⩽T∥x−x t∥2 2·Tr(A T−A 0) =max 1⩽t⩽T∥x−x t∥2 2 2η·Tr  TX t=1utu⊤ t!1/2 . Using Lemma A.4 below, the last term from (10) is bounded as 1 2TX t=1∥ut∥2 A−1 t=1 2TX t=1Tr(A−1 tutu⊤ t) =η2 2TX t=1Tr(A−1 t(A2 t−A2 t−1)) ⩽η2TX t=1Tr(A t−At−1) =η2(Tr(A T)−Tr(A 0)) =ηTr  ε2Id+TX t=1utu⊤ t!1/2 −εI d . Using the spectral decomposition of positive semidefinite matrixPT t=1utu⊤ t= Pdiag(λ 1, . . . , λ d)P⊤, wherePis an orthogonal matrix, the above last quantity is equal to ηTr\u0010\u0000 ε2Id+ diag(λ 1, . . . , λ d)\u00011/2−εI d\u0011 =ηTr\u0012 diag\u0010p ε2+λi−ε\u0011 1⩽i⩽d\u0013 ⩽ηTr\u0010 diag\u0010p λ1, . . . ,p λd\u0011\u0011 =ηTr  TX t=1utu⊤ t!1/2 . Besides, applying Lemma A.5 below withM=PT t=1utu⊤ tensures that Tr  TX t=1utu⊤ t!1/2 = inf A∈Sd ++(R)vuut(TrA)TX t=1∥ut∥2 A−1. 44 because then for allA∈ Sd ++(R), quantityTr(A−1M)that appears in the lemma rewrites as Tr(A−1M) = Tr A−1TX t=1utu⊤ t! =TX t=1Tr\u0000 A−1utu⊤ t\u0001 =TX t=1Tr(u⊤ tA−1ut) =TX t=1u⊤ tA−1ut =TX t=1∥ut∥2 A−1. Injecting the above inequalities into (10) gives the result. Lemma A.4.LetA, B∈ Sd ++(R). Then, Tr(A1/2)⩽Tr(B1/2) +1 2Tr(B−1/2(A−B)). Proof.The inequality is a special case of Klein’s trace inequality [Carlen, 2010, Theorem 2.11] applied with concave real-valued functionx7→x1/2.□ Lemma A.5.LetMbe a real symmetric positive semidefinite matrix of sized. Then, Tr\u0010 M1/2\u0011 = inf A∈Sd ++(R)p (TrA) Tr(A−1M). Proof.LetA∈ Sd ++. Applying the Cauchy–Schwarz inequality for the Frobenius inner product, Tr(M1/2) = Tr(A1/2(A−1/2M1/2))⩽p Tr(A) Tr(A−1M), which proves Tr\u0010 M1/2\u0011 ⩽inf A∈Sd ++(R)p (TrA) Tr(A−1M). Conversely, letε >0,rbe the rank ofM,λ 1(M), . . . , λ d(M)be the eigenvalues ofMwith multiplicity in nonincreasing order, andPbe an orthogonal matrix such that P⊤MP= λ1(M) 0 ... 0λ d(M) . Then consider positive definite matrix A=Pdiag(p λ1(M), . . . ,p λr(M), ε, . . . , ε)P⊤, which imply that A−1M=Pdiag(p λ1(M), . . . ,p λr(M),0, . . . ,0)P⊤. Hence,p (TrA)(Tr(A−1M)) =q (TrM1/2+ (d−r)ε)(TrM1/2), which converges toTrM1/2asε→0+and this proves Tr\u0010 M1/2\u0011 ⩾inf A∈Sd ++(R)p (TrA) Tr(A−1M). Hence the result.□ 45 AppendixB.A Follow-the-Regularized-Leader regret bound Leth:Rd→R∪ {+∞}be defined as h(x) =1 2∥x−x 1∥2 2+IX(x), x∈Rd, whereI Xdenotes the convex indicator ofX, that has value0onXand+∞ elsewhere. We consider itsLegendre–Fenchel transform: h∗(y) = sup x∈Rd{⟨y, x⟩ −h(x)}, y∈Rd. An immediate consequence of this definition",
    "⩾inf A∈Sd ++(R)p (TrA) Tr(A−1M). Hence the result.□ 45 AppendixB.A Follow-the-Regularized-Leader regret bound Leth:Rd→R∪ {+∞}be defined as h(x) =1 2∥x−x 1∥2 2+IX(x), x∈Rd, whereI Xdenotes the convex indicator ofX, that has value0onXand+∞ elsewhere. We consider itsLegendre–Fenchel transform: h∗(y) = sup x∈Rd{⟨y, x⟩ −h(x)}, y∈Rd. An immediate consequence of this definition isFenchel’s inequality: for allx, y∈ Rd, ⟨y, x⟩⩽h(x) +h∗(y). Proposition B.1(Lemma 1 in Nesterov [2009] and Lemma 15 in Shalev-Shwartz [2007]).h∗has finite values onRd, is differentiable, and ∇h∗(y) = arg max x∈Rd{⟨y, x⟩ −h(x)}, y∈Rd. Moreover, theBregman divergenceofh∗, defined fory, y′∈Rdas Dh∗(y′, y) =h∗(y′)−h∗(y)− ⟨∇h∗(y), y′−y⟩, satisfies Dh∗(y′, y)⩽1 2∥y′−y∥2 2, y, y′∈Rd. B.1.Proof of Proposition 4.2.Lett⩾1and denoteU t=Pt s=1us. Then, it holds thatx t+1=∇h∗(ηt+1Ut); indeed, using the expression of∇h∗from Proposi- tion B.1, ∇h∗(ηt+1Ut) = arg max x∈X\u001a ⟨ηt+1Ut, x⟩ −1 2∥x−x 1∥2 2\u001b = arg max x∈X\u001a ⟨ηt+1Ut, x⟩ −1 2∥x∥2 2+⟨x, x 1⟩+1 2∥x∥2 2\u001b = arg max x∈X\u001a ⟨x1+ηt+1Ut, x⟩ −1 2∥x∥2 2\u001b = arg min x∈X\u001a1 2∥x1+ηt+1Ut∥2 2− ⟨x 1+ηt+1Ut, x⟩+1 2∥x∥2 2\u001b = ΠX(x1+ηt+1Ut) =x t+1. Then forT⩾1andx∈ X, using Fenchel’s inequality and conventionη 1=η2, ⟨Ut, x⟩=⟨ηT+1UT, x⟩ ηT+1⩽h∗(ηT+1UT) ηT+1+h(x) ηT+1 =h∗(0) η1+TX t=1\u0012h∗(ηt+1Ut) ηt+1−h∗(ηtUt−1) ηt\u0013 +h(x) ηT+1 =TX t=1\u0012h∗(ηt+1Ut) ηt+1−h∗(ηtUt−1) ηt\u0013 +h(x) ηT+1, 46 where the last equality stands because h∗(0) = max x∈Rd{⟨0, x⟩ −h(x)}= min x∈Rdh(x) = 0. We now boundh∗(ηt+1Ut)/ηt+1from above as follows h∗(ηt+1Ut) ηt+1= max x∈Rd\u001a⟨ηt+1Ut, x⟩ −h(x) ηt+1\u001b = max x∈Rd\u001a⟨ηtUt, x⟩ −h(x) ηt−h(x)\u00121 ηt+1−1 ηt\u0013\u001b ⩽max x∈Rd\u001a⟨ηtUt, x⟩ −h(x) ηt\u001b =h∗(ηtUt) ηt, wheretheinequalityfollowsfromsequence(η t)t⩾1beingpositiveandnonincreasing. It follows that ⟨UT, x⟩⩽TX t=1h∗(ηtUt)−h∗(ηtUt−1) ηt+h(x) ηT+1. We can make the Bregman divergence appear in the above first sum by substracting ⟨ηtUt−ηtUt−1,∇h∗(ηtUt−1)⟩ ηt=⟨u t, xt⟩. Therefore, TX t=1⟨ut, x−x t⟩=⟨U T, x⟩ −TX t=1⟨ut, xt⟩=TX t=1Dh∗(ηtUt, ηtUt−1) ηt+h(x) ηT+1 ⩽TX t=1ηt∥ut∥2 2 2+∥x−x 1∥2 2 2ηT+1, wheretheinequalityfollowsfromtheboundontheBregmandivergencefromPropo- sition B.1. The result follows from noting that for a givenT⩾1, the above analysis can be carried withη T+1=ηT. AppendixC.Extension to quasi-nonexpansiveness We here formally state the extensions of the results from Sections 2 and 3 to quasi-nonexpansiveness. The basic notion of quasi-nonexpansiveness first appears in [Dotson, 1972]. We extend it as follows. Definition C.1(Quasi-nonexpansiveness).LetF:X →Rd,x∗∈ Xa fixed point ofFand∥·∥a norm inRd. (i) OperatorFisquasi-nonexpansivewith respect tox ∗and∥·∥if for allx∈ X, ∥F(x)−F(x ∗)∥⩽∥x−x ∗∥. (ii) LetL >0. OperatorFisL-quasi-nonexpansivewith respect tox ∗ifI+ 1 L(F−I)is quasi-nonexpansive with respect tox ∗and∥·∥2. (iii) LetA∈ Sd ++(R). OperatorFisA-quasi-nonexpansivewith respect tox ∗if I+A−1(F−I)is quasi-nonexpansive with respect tox ∗and∥·∥A. 47 We extend to arbitrary norms the notion of star-co-coercivity introduced by [Gorbunov et al., 2022]. Definition C.2(Star-co-coercivity).LetG:X →Rd,x∗∈ Xa zero ofG,∥·∥a norm inRd, andL >0. OperatorGisL-star-co-coercivewith respect tox ∗and ∥·∥if for allx∈ X, ⟨G(x), x−x ∗⟩⩾1 L∥G(x)∥2 ∗, where∥·∥∗denotes the dual norm of∥·∥. The following characterization is an extension of Gorbunov et al. [2022, Lemmas C.5 and C.6]. Proposition C.3.LetF:X →Rd,x∗∈ Xa fixed point ofF,G=I−F 2, and A∈ Sd ++(R). Then,FisA-quasi-nonexpansive with respect tox ∗if, and only if, Gis1-star-co-coercive with respect tox ∗and∥·∥A, in other words, (11)∀x∈ X,⟨G(x), x−x ∗⟩⩾∥G(x)∥2 A−1. Proof.Note thatI+A−1(F−I) =I−2A−1G. This operator being quasi- nonexpansive with respect tox ∗and∥·∥Awrites (I−2A−1G)(x)−(I−2A−1G)(x∗) 2 A⩽∥x−x ∗∥2 A, x∈ X. BecauseG(x ∗) = 0by definition ofx",
    "and A∈ Sd ++(R). Then,FisA-quasi-nonexpansive with respect tox ∗if, and only if, Gis1-star-co-coercive with respect tox ∗and∥·∥A, in other words, (11)∀x∈ X,⟨G(x), x−x ∗⟩⩾∥G(x)∥2 A−1. Proof.Note thatI+A−1(F−I) =I−2A−1G. This operator being quasi- nonexpansive with respect tox ∗and∥·∥Awrites (I−2A−1G)(x)−(I−2A−1G)(x∗) 2 A⩽∥x−x ∗∥2 A, x∈ X. BecauseG(x ∗) = 0by definition ofx ∗, the above rewrites as (12) (I−2A−1G)(x)−x ∗ 2 A⩽∥x−x ∗∥2 A, x∈ X. Letx∈ Xbe given. Developing the above left-hand side, we obtain (I−2A−1G)(x)−x ∗ 2 A= 4 A−1G(x) 2 A −4 A−1G(x∗), A(x−x ∗) +∥x−x ∗∥2 A = 4∥G(x)∥2 A−1−4⟨G(x), x−x ∗⟩+∥x−x ∗∥2 A. Pluggingtheaboveidentityintoinequality(12)andrearranginggivestheresult.□ Lemma C.4.LetA∈ Sd ++(R),F:X →Rd,x∗∈ Xa fixed point ofF. IfFis A-quasi-nonexpansive with respect tox ∗, then for allx∈ X, ∥F(x)−x∥2 A−1⩽2⟨F(x)−x, x ∗−x⟩. Proof.Uses Proposition C.3 and is similar to Proposition 2.4.□"
  ]
}